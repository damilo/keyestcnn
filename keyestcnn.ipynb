{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio key estimation of digital music with CNNs\n",
    "Udacity Machine Learning Nanodegree - Capstone project\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "The project is structured as stated in section 'Project Design' of the Capstone project proposal.\n",
    "\n",
    "_\n",
    "<pre>\n",
    "<a href='#Data-Preprocessing'>Data Preprocessing</a>\n",
    "  <a href='#Million-Song-Dataset'>Million Song Dataset</a> - selection of appropriate songs, separate jupyter notebook\n",
    "  <a href='#Signal-Processing-and-Feature-Extraction'>Signal Processing and Feature Extraction</a> - separate jupyter notebook\n",
    "\n",
    "<a href='#Model-Preparation'>Model Preparation</a>\n",
    "  <a href='#Load-and-prepare-data'>Load and prepare data</a> - read spectrogram images, conversion to tensors\n",
    "  <a href='#Split-data-into-train-and-test-set'>Splitting data into training/testing sets</a>\n",
    "  <a href='#Model-architecture'>CNN model architecture</a>\n",
    "  <a href='#Model-parameter'>CNN model parameter</a>\n",
    "\n",
    "<a href='#Model-Training-and-Evaluation'>Model Training and Evaluation</a>\n",
    "  <a href='#Model-training'>Model training</a>\n",
    "  <a href='#Model-evaluation-and-comparison'>Model evaluation and comparison</a>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current version of the project is working, but\n",
    "\n",
    "the project is still ongoing...\n",
    "\n",
    "discussion and remarks of what to do can be found in section\n",
    "\n",
    "<a href='#reasons-/-todo'>reasons / todo</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Million Song Dataset\n",
    "- utilized to select appropriate song samples\n",
    "- holds information about key and mode per song (targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juypter Notebook <a href='./00.hlp/msd/msd.ipynb'>msd</a>\n",
    "\n",
    "outputs: csv file *songs_conf=75_tracks_filt.csv*, which holds all songs with key confidence and mode confidence > 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>key_confidence</th>\n",
       "      <th>mode</th>\n",
       "      <th>mode_confidence</th>\n",
       "      <th>track_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852</td>\n",
       "      <td>TRMMMGL128F92FD6AB</td>\n",
       "      <td>SOHSSPG12A8C144BE0</td>\n",
       "      <td>Clifford T. Ward</td>\n",
       "      <td>Mad About You</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  key_confidence  mode  mode_confidence            track_id  \\\n",
       "0    7           0.896     1            0.852  TRMMMGL128F92FD6AB   \n",
       "\n",
       "              song_id       artist_name     song_title  \n",
       "0  SOHSSPG12A8C144BE0  Clifford T. Ward  Mad About You  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] number of records: 47913\n"
     ]
    }
   ],
   "source": [
    "# LIST SELECTED SONGS\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "selsongsfile = os.path.join ('00.hlp', 'msd', 'songs_conf=75_tracks_filt.csv')\n",
    "selsongs = pd.read_csv (selsongsfile, header=0, index_col=0)\n",
    "display (selsongs.head (1))\n",
    "print ('[i] number of records:', len (selsongs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD AUDIO DATASET\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "PARAM_RND_STATE = 42\n",
    "\n",
    "container_path = os.path.join ('src_audio')\n",
    "load_content = False\n",
    "description = ['key C, mode minor', 'key C, mode major',\n",
    "               'key C#, mode minor', 'key C#, mode major',\n",
    "               'key D, mode minor', 'key D, mode major',\n",
    "               'key D#, mode minor', 'key D#, mode major',\n",
    "               'key E, mode minor', 'key E, mode major',\n",
    "               'key F, mode minor', 'key F, mode major',\n",
    "               'key F#, mode minor', 'key F#, mode major',\n",
    "               'key G, mode minor', 'key G, mode major',\n",
    "               'key G#, mode minor', 'key G#, mode major',\n",
    "               'key A, mode minor', 'key A, mode major',\n",
    "               'key A#, mode minor', 'key A#, mode major',\n",
    "               'key B, mode minor', 'key B, mode major']\n",
    "\n",
    "src_audio_data = datasets.load_files (container_path=container_path,\n",
    "                                      description=description,\n",
    "                                      load_content=load_content,\n",
    "                                      random_state=PARAM_RND_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>key_confidence</th>\n",
       "      <th>mode</th>\n",
       "      <th>mode_confidence</th>\n",
       "      <th>track_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10070</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.849</td>\n",
       "      <td>TRRTCMY128F9326B32</td>\n",
       "      <td>SOYGPIR12AB018646A</td>\n",
       "      <td>The Levon Helm Band</td>\n",
       "      <td>A Fool In Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22522</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.927</td>\n",
       "      <td>TRNFTSL128F4259524</td>\n",
       "      <td>SOAAUTE12A8C13491F</td>\n",
       "      <td>Vanilla Sky</td>\n",
       "      <td>Gotta Believe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25187</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>TRPJEER128F426E291</td>\n",
       "      <td>SOLUZSQ12A8C13C968</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>Anywhere You Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46978</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.810</td>\n",
       "      <td>TRYNAXP128F93205A9</td>\n",
       "      <td>SOGZYYE12AB0183215</td>\n",
       "      <td>CJ Stone</td>\n",
       "      <td>Shining Star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45681</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.913</td>\n",
       "      <td>TRKVLFA12903CD12C4</td>\n",
       "      <td>SOQZPLI12AB0186D42</td>\n",
       "      <td>temposhark</td>\n",
       "      <td>Bye Bye Baby</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       key  key_confidence  mode  mode_confidence            track_id  \\\n",
       "10070    0             1.0     0            0.849  TRRTCMY128F9326B32   \n",
       "22522    1             1.0     1            0.927  TRNFTSL128F4259524   \n",
       "25187    4             1.0     1            1.000  TRPJEER128F426E291   \n",
       "46978    3             1.0     0            0.810  TRYNAXP128F93205A9   \n",
       "45681    6             1.0     0            0.913  TRKVLFA12903CD12C4   \n",
       "\n",
       "                  song_id          artist_name       song_title  \n",
       "10070  SOYGPIR12AB018646A  The Levon Helm Band   A Fool In Love  \n",
       "22522  SOAAUTE12A8C13491F          Vanilla Sky    Gotta Believe  \n",
       "25187  SOLUZSQ12A8C13C968              Embrace  Anywhere You Go  \n",
       "46978  SOGZYYE12AB0183215             CJ Stone     Shining Star  \n",
       "45681  SOQZPLI12AB0186D42           temposhark     Bye Bye Baby  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] min of: key_confidence = 0.809 , mode_confidence = 0.777\n",
      "[i] number of records: 240\n"
     ]
    }
   ],
   "source": [
    "# FYI: LIST SOME OF THE USED SONGS\n",
    "filenames = list (os.path.basename (filepath) for filepath in src_audio_data['filenames'])\n",
    "usedsongs_track_id = list (os.path.splitext (fn)[0] for fn in filenames)\n",
    "usedsongs = selsongs.query ('track_id in @usedsongs_track_id')\n",
    "\n",
    "display (usedsongs.sample(5))\n",
    "print ('[i] min of: key_confidence =', usedsongs['key_confidence'].min (), ',', \\\n",
    "       'mode_confidence =', usedsongs['mode_confidence'].min ())\n",
    "print ('[i] number of records:', len (usedsongs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Processing and Feature Extraction\n",
    "- create spectrograms of audio files with discrete Fourier transform (DFT)\n",
    "- save spectrograms as images for further use in CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juypter Notebook <a href='./00.hlp/fft/fft.ipynb'>fft</a>\n",
    "\n",
    "ouptuts: spectrograms (png images) of audio files with same folder structure as *src_audio* in new container path named *src_spectro*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of a spectrogram image**\n",
    "\n",
    "<img src ='./src_spectro/7-0/TREDRTV12903D03829.png' align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['target', 'target_names', 'DESCR', 'filenames'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD SPECTROGRAM FILENAMES\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "PARAM_RND_STATE = 42\n",
    "\n",
    "container_path = os.path.join ('src_spectro')\n",
    "load_content = False\n",
    "description = ['key C, mode minor', 'key C, mode major',\n",
    "               'key C#, mode minor', 'key C#, mode major',\n",
    "               'key D, mode minor', 'key D, mode major',\n",
    "               'key D#, mode minor', 'key D#, mode major',\n",
    "               'key E, mode minor', 'key E, mode major',\n",
    "               'key F, mode minor', 'key F, mode major',\n",
    "               'key F#, mode minor', 'key F#, mode major',\n",
    "               'key G, mode minor', 'key G, mode major',\n",
    "               'key G#, mode minor', 'key G#, mode major',\n",
    "               'key A, mode minor', 'key A, mode major',\n",
    "               'key A#, mode minor', 'key A#, mode major',\n",
    "               'key B, mode minor', 'key B, mode major']\n",
    "\n",
    "src_spectro_data = datasets.load_files (container_path=container_path,\n",
    "                                        description=description,\n",
    "                                        load_content=load_content,\n",
    "                                        random_state=PARAM_RND_STATE)\n",
    "src_spectro_data.keys ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] example of loaded spectrogram file data:\n",
      "    spectrogram image name: src_spectro/1-0/TRLZZOJ128F1494C12.png\n",
      "    spectrogram image key-mode pair: 1-0 = key C#, mode minor = target class 2\n"
     ]
    }
   ],
   "source": [
    "print ('[i] example of loaded spectrogram file data:')\n",
    "print ('    spectrogram image name:', src_spectro_data['filenames'][0])\n",
    "print ('    spectrogram image key-mode pair:',\\\n",
    "       src_spectro_data['target_names'][src_spectro_data['target'][0]],\\\n",
    "       '=', src_spectro_data['DESCR'][src_spectro_data['target'][0]],\\\n",
    "       '= target class', src_spectro_data['target'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in images, convert to tensors**\n",
    "\n",
    "Keras Conv2D layers expect a **4D tensor with shape (batch, rows, cols, channels)** (if param data_format='channels_last') (src: <a href='https://keras.io/layers/convolutional/#conv2d'>Keras Conv2D</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] image size: (323, 115)\n",
      "[i] pixel format: RGB\n"
     ]
    }
   ],
   "source": [
    "# open a random image and take a look at the attributes\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open (src_spectro_data['filenames'][0])\n",
    "print ('[i] image size:', im.size)\n",
    "print ('[i] pixel format:', im.mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images are of size (323, 115) and have 3 channels\n",
    "\n",
    "for CNN: no need to change target size\n",
    "\n",
    "below functions read images and convert those to tensors - code taken from Udacity MLND dog-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor (img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img (img_path, color_mode='grayscale')#, target_size=(88, 88))\n",
    "    # convert PIL.Image.Image type to 3D tensor\n",
    "    x = image.img_to_array (img)\n",
    "    # convert 3D tensor to 4D tensor\n",
    "    return np.expand_dims (x, axis=0)\n",
    "\n",
    "def paths_to_tensor (img_paths):\n",
    "    list_of_tensors = [path_to_tensor (img_path) for img_path in tqdm (img_paths)]\n",
    "    return np.vstack (list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 1274.07it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "spectro_tensors = paths_to_tensor (src_spectro_data['filenames'])#.astype ('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] shape of spectrogram tensors: (240, 115, 323, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('[i] shape of spectrogram tensors:', spectro_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] number of output classes: 24\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "targets = np_utils.to_categorical (np.array (src_spectro_data['target']), 24)\n",
    "print ('[i] number of output classes:', targets.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Training dataset consists of 216 samples\n",
      "[i] Testing dataset consists of 24 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split (spectro_tensors, targets, test_size=0.10, shuffle=True, random_state=PARAM_RND_STATE)\n",
    "\n",
    "print ('[i] Training dataset consists of {} samples'.format (X_train.shape[0]))\n",
    "print ('[i] Testing dataset consists of {} samples'.format (X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 115, 323, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 115, 323, 16)      32        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 115, 323, 32)      2080      \n",
      "_________________________________________________________________\n",
      "maxp_2 (MaxPooling2D)        (None, 57, 161, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 57, 161, 64)       8256      \n",
      "_________________________________________________________________\n",
      "maxp_3 (MaxPooling2D)        (None, 28, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "avg_flatten (GlobalAveragePo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 24)                1560      \n",
      "=================================================================\n",
      "Total params: 11,928\n",
      "Trainable params: 11,928\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "from keras import backend as K\n",
    "\n",
    "# clear everything known of past instances (\"useful to avoid clutter from old models / layers\")\n",
    "K.clear_session ()\n",
    "\n",
    "# input layer\n",
    "inputs = layers.Input (shape=spectro_tensors.shape[1:], name='input')\n",
    "\n",
    "# hidden layers\n",
    "net = layers.Conv2D (filters=16, kernel_size=(1,1), strides=(1,1),\n",
    "                     padding='same', # don't lose information due to conv window runs out of image / strides = 1 = OK\n",
    "                     activation='relu',\n",
    "                     name='conv2d_1') (inputs)\n",
    "#net = layers.MaxPooling2D (pool_size=(2,2), strides=None, name='maxp_1') (net)\n",
    "\n",
    "net = layers.Conv2D (filters=32, kernel_size=(2,2), strides=(1,1),\n",
    "              padding='same',\n",
    "              activation='relu',\n",
    "              name='conv2d_2') (net)\n",
    "net = layers.MaxPooling2D (pool_size=(2,2), strides=None, name='maxp_2') (net)\n",
    "\n",
    "net = layers.Conv2D (filters=64, kernel_size=(2,2), strides=(1,1),\n",
    "              padding='same',\n",
    "              activation='relu',\n",
    "              name='conv2d_3') (net)\n",
    "net = layers.MaxPooling2D (pool_size=(2,2), strides=None, name='maxp_3') (net)\n",
    "\n",
    "#net = layers.Conv2D (filters=64, kernel_size=(2,2), strides=(1,1),\n",
    "#              padding='same',\n",
    "#              activation='relu',\n",
    "#              name='conv2d_4') (net)\n",
    "#net = layers.MaxPooling2D (pool_size=(2,2), strides=None, name='maxp_4') (net)\n",
    "\n",
    "# 'flatten layer'\n",
    "net = layers.GlobalAveragePooling2D (name='avg_flatten') (net)\n",
    "\n",
    "# output layer\n",
    "outputs = layers.Dense (units=targets.shape[1], activation='softmax', name='output') (net)\n",
    "\n",
    "\n",
    "model = models.Model (inputs=inputs, outputs=outputs)\n",
    "model.summary ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameter\n",
    "(metric, loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: Arseny Kravchenko http://arseny.info/2017/f-beta-score-for-keras.html\n",
    "from keras import backend as K\n",
    "\n",
    "PARAM_BETA = 1\n",
    "def fbeta (y_true, y_pred):\n",
    "\n",
    "    # just in case of hipster activation at the final layer\n",
    "    y_pred = K.clip (y_pred, 0, 1)\n",
    "\n",
    "    tp = K.sum (K.round (y_true * y_pred)) + K.epsilon ()\n",
    "    fp = K.sum (K.round (K.clip (y_pred - y_true, 0, 1)))\n",
    "    fn = K.sum (K.round (K.clip (y_true - y_pred, 0, 1)))\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    beta_squared = PARAM_BETA ** 2\n",
    "    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers, losses\n",
    "\n",
    "PARAM_LR = 0.0001\n",
    "opt_sgd = optimizers.SGD (lr=PARAM_LR, momentum=0.8)\n",
    "opt_adamax = optimizers.Adamax (lr=PARAM_LR, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "\n",
    "\n",
    "model.compile (optimizer=opt_sgd, loss=losses.mean_squared_error, metrics=[fbeta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 194 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "194/194 [==============================] - 17s 87ms/step - loss: 0.0517 - fbeta: 0.0318 - val_loss: 0.0495 - val_fbeta: 0.0568\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04949, saving model to model/model.w.best.h5\n",
      "Epoch 2/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0511 - fbeta: 0.0313 - val_loss: 0.0489 - val_fbeta: 0.0649\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04949 to 0.04892, saving model to model/model.w.best.h5\n",
      "Epoch 3/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0506 - fbeta: 0.0210 - val_loss: 0.0484 - val_fbeta: 0.0699\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04892 to 0.04838, saving model to model/model.w.best.h5\n",
      "Epoch 4/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0501 - fbeta: 0.0125 - val_loss: 0.0479 - val_fbeta: 0.0699\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04838 to 0.04790, saving model to model/model.w.best.h5\n",
      "Epoch 5/100\n",
      "194/194 [==============================] - 17s 85ms/step - loss: 0.0497 - fbeta: 0.0140 - val_loss: 0.0474 - val_fbeta: 2.3160e-08\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04790 to 0.04744, saving model to model/model.w.best.h5\n",
      "Epoch 6/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0493 - fbeta: 0.0148 - val_loss: 0.0470 - val_fbeta: 2.3160e-08\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04744 to 0.04702, saving model to model/model.w.best.h5\n",
      "Epoch 7/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0489 - fbeta: 0.0153 - val_loss: 0.0466 - val_fbeta: 2.3849e-08\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.04702 to 0.04664, saving model to model/model.w.best.h5\n",
      "Epoch 8/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0485 - fbeta: 0.0159 - val_loss: 0.0463 - val_fbeta: 2.3849e-08\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04664 to 0.04628, saving model to model/model.w.best.h5\n",
      "Epoch 9/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0482 - fbeta: 0.0074 - val_loss: 0.0460 - val_fbeta: 2.5620e-08\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04628 to 0.04596, saving model to model/model.w.best.h5\n",
      "Epoch 10/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0479 - fbeta: 0.0069 - val_loss: 0.0457 - val_fbeta: 2.6446e-08\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.04596 to 0.04566, saving model to model/model.w.best.h5\n",
      "Epoch 11/100\n",
      "194/194 [==============================] - 16s 85ms/step - loss: 0.0476 - fbeta: 0.0086 - val_loss: 0.0454 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.04566 to 0.04539, saving model to model/model.w.best.h5\n",
      "Epoch 12/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0474 - fbeta: 1.8956e-08 - val_loss: 0.0451 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.04539 to 0.04513, saving model to model/model.w.best.h5\n",
      "Epoch 13/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0471 - fbeta: 1.9475e-08 - val_loss: 0.0449 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.04513 to 0.04491, saving model to model/model.w.best.h5\n",
      "Epoch 14/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0469 - fbeta: 1.9791e-08 - val_loss: 0.0447 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.04491 to 0.04470, saving model to model/model.w.best.h5\n",
      "Epoch 15/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0467 - fbeta: 2.0056e-08 - val_loss: 0.0445 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.04470 to 0.04450, saving model to model/model.w.best.h5\n",
      "Epoch 16/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0465 - fbeta: 2.0244e-08 - val_loss: 0.0443 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.04450 to 0.04432, saving model to model/model.w.best.h5\n",
      "Epoch 17/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0464 - fbeta: 2.0431e-08 - val_loss: 0.0442 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.04432 to 0.04416, saving model to model/model.w.best.h5\n",
      "Epoch 18/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0462 - fbeta: 2.0431e-08 - val_loss: 0.0440 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.04416 to 0.04400, saving model to model/model.w.best.h5\n",
      "Epoch 19/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0461 - fbeta: 2.0619e-08 - val_loss: 0.0439 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.04400 to 0.04387, saving model to model/model.w.best.h5\n",
      "Epoch 20/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0459 - fbeta: 2.0619e-08 - val_loss: 0.0437 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.04387 to 0.04373, saving model to model/model.w.best.h5\n",
      "Epoch 21/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0458 - fbeta: 2.0619e-08 - val_loss: 0.0436 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.04373 to 0.04361, saving model to model/model.w.best.h5\n",
      "Epoch 22/100\n",
      "194/194 [==============================] - 16s 83ms/step - loss: 0.0457 - fbeta: 2.0619e-08 - val_loss: 0.0435 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.04361 to 0.04350, saving model to model/model.w.best.h5\n",
      "Epoch 23/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0456 - fbeta: 2.0619e-08 - val_loss: 0.0434 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.04350 to 0.04340, saving model to model/model.w.best.h5\n",
      "Epoch 24/100\n",
      "194/194 [==============================] - 16s 83ms/step - loss: 0.0455 - fbeta: 2.0619e-08 - val_loss: 0.0433 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.04340 to 0.04330, saving model to model/model.w.best.h5\n",
      "Epoch 25/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0454 - fbeta: 2.0619e-08 - val_loss: 0.0432 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.04330 to 0.04321, saving model to model/model.w.best.h5\n",
      "Epoch 26/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0453 - fbeta: 2.0619e-08 - val_loss: 0.0431 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.04321 to 0.04312, saving model to model/model.w.best.h5\n",
      "Epoch 27/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0452 - fbeta: 2.0619e-08 - val_loss: 0.0430 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.04312 to 0.04304, saving model to model/model.w.best.h5\n",
      "Epoch 28/100\n",
      "194/194 [==============================] - 16s 85ms/step - loss: 0.0452 - fbeta: 2.0619e-08 - val_loss: 0.0430 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.04304 to 0.04297, saving model to model/model.w.best.h5\n",
      "Epoch 29/100\n",
      "194/194 [==============================] - 17s 87ms/step - loss: 0.0451 - fbeta: 2.0619e-08 - val_loss: 0.0429 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.04297 to 0.04290, saving model to model/model.w.best.h5\n",
      "Epoch 30/100\n",
      "194/194 [==============================] - 17s 85ms/step - loss: 0.0450 - fbeta: 2.0619e-08 - val_loss: 0.0428 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.04290 to 0.04283, saving model to model/model.w.best.h5\n",
      "Epoch 31/100\n",
      "194/194 [==============================] - 16s 85ms/step - loss: 0.0449 - fbeta: 2.0619e-08 - val_loss: 0.0428 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.04283 to 0.04277, saving model to model/model.w.best.h5\n",
      "Epoch 32/100\n",
      "194/194 [==============================] - 16s 84ms/step - loss: 0.0449 - fbeta: 2.0619e-08 - val_loss: 0.0427 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.04277 to 0.04271, saving model to model/model.w.best.h5\n",
      "Epoch 33/100\n",
      "194/194 [==============================] - 16s 83ms/step - loss: 0.0448 - fbeta: 2.0619e-08 - val_loss: 0.0426 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.04271 to 0.04265, saving model to model/model.w.best.h5\n",
      "Epoch 34/100\n",
      "194/194 [==============================] - 16s 81ms/step - loss: 0.0448 - fbeta: 2.0619e-08 - val_loss: 0.0426 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.04265 to 0.04259, saving model to model/model.w.best.h5\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 16s 80ms/step - loss: 0.0447 - fbeta: 2.0619e-08 - val_loss: 0.0425 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.04259 to 0.04254, saving model to model/model.w.best.h5\n",
      "Epoch 36/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0447 - fbeta: 2.0619e-08 - val_loss: 0.0425 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.04254 to 0.04249, saving model to model/model.w.best.h5\n",
      "Epoch 37/100\n",
      "194/194 [==============================] - 15s 79ms/step - loss: 0.0446 - fbeta: 2.0619e-08 - val_loss: 0.0424 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.04249 to 0.04244, saving model to model/model.w.best.h5\n",
      "Epoch 38/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0446 - fbeta: 2.0619e-08 - val_loss: 0.0424 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.04244 to 0.04240, saving model to model/model.w.best.h5\n",
      "Epoch 39/100\n",
      "194/194 [==============================] - 15s 79ms/step - loss: 0.0445 - fbeta: 2.0619e-08 - val_loss: 0.0424 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.04240 to 0.04236, saving model to model/model.w.best.h5\n",
      "Epoch 40/100\n",
      "194/194 [==============================] - 15s 79ms/step - loss: 0.0445 - fbeta: 2.0619e-08 - val_loss: 0.0423 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.04236 to 0.04231, saving model to model/model.w.best.h5\n",
      "Epoch 41/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0444 - fbeta: 2.0619e-08 - val_loss: 0.0423 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.04231 to 0.04228, saving model to model/model.w.best.h5\n",
      "Epoch 42/100\n",
      "194/194 [==============================] - 15s 79ms/step - loss: 0.0444 - fbeta: 2.0619e-08 - val_loss: 0.0422 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.04228 to 0.04224, saving model to model/model.w.best.h5\n",
      "Epoch 43/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0443 - fbeta: 2.0619e-08 - val_loss: 0.0422 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.04224 to 0.04220, saving model to model/model.w.best.h5\n",
      "Epoch 44/100\n",
      "194/194 [==============================] - 15s 79ms/step - loss: 0.0443 - fbeta: 2.0619e-08 - val_loss: 0.0422 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.04220 to 0.04216, saving model to model/model.w.best.h5\n",
      "Epoch 45/100\n",
      "194/194 [==============================] - 15s 79ms/step - loss: 0.0443 - fbeta: 2.0619e-08 - val_loss: 0.0421 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.04216 to 0.04213, saving model to model/model.w.best.h5\n",
      "Epoch 46/100\n",
      "194/194 [==============================] - 15s 79ms/step - loss: 0.0442 - fbeta: 2.0619e-08 - val_loss: 0.0421 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.04213 to 0.04210, saving model to model/model.w.best.h5\n",
      "Epoch 47/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0442 - fbeta: 2.0619e-08 - val_loss: 0.0421 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.04210 to 0.04207, saving model to model/model.w.best.h5\n",
      "Epoch 48/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0442 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.04207 to 0.04204, saving model to model/model.w.best.h5\n",
      "Epoch 49/100\n",
      "194/194 [==============================] - 16s 80ms/step - loss: 0.0441 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.04204 to 0.04201, saving model to model/model.w.best.h5\n",
      "Epoch 50/100\n",
      "194/194 [==============================] - 15s 79ms/step - loss: 0.0441 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.04201 to 0.04198, saving model to model/model.w.best.h5\n",
      "Epoch 51/100\n",
      "194/194 [==============================] - 15s 79ms/step - loss: 0.0441 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.04198 to 0.04195, saving model to model/model.w.best.h5\n",
      "Epoch 52/100\n",
      "194/194 [==============================] - 16s 80ms/step - loss: 0.0440 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.04195 to 0.04192, saving model to model/model.w.best.h5\n",
      "Epoch 53/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0440 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.04192 to 0.04190, saving model to model/model.w.best.h5\n",
      "Epoch 54/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0440 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.04190 to 0.04188, saving model to model/model.w.best.h5\n",
      "Epoch 55/100\n",
      "194/194 [==============================] - 16s 80ms/step - loss: 0.0439 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.04188 to 0.04185, saving model to model/model.w.best.h5\n",
      "Epoch 56/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0439 - fbeta: 2.0619e-08 - val_loss: 0.0418 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.04185 to 0.04183, saving model to model/model.w.best.h5\n",
      "Epoch 57/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0439 - fbeta: 2.0619e-08 - val_loss: 0.0418 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.04183 to 0.04180, saving model to model/model.w.best.h5\n",
      "Epoch 58/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0439 - fbeta: 2.0619e-08 - val_loss: 0.0418 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.04180 to 0.04178, saving model to model/model.w.best.h5\n",
      "Epoch 59/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0438 - fbeta: 2.0619e-08 - val_loss: 0.0418 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.04178 to 0.04176, saving model to model/model.w.best.h5\n",
      "Epoch 60/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0438 - fbeta: 2.0619e-08 - val_loss: 0.0417 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.04176 to 0.04174, saving model to model/model.w.best.h5\n",
      "Epoch 61/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0438 - fbeta: 2.0619e-08 - val_loss: 0.0417 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.04174 to 0.04172, saving model to model/model.w.best.h5\n",
      "Epoch 62/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0438 - fbeta: 2.0619e-08 - val_loss: 0.0417 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.04172 to 0.04170, saving model to model/model.w.best.h5\n",
      "Epoch 63/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0437 - fbeta: 2.0619e-08 - val_loss: 0.0417 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.04170 to 0.04168, saving model to model/model.w.best.h5\n",
      "Epoch 64/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0437 - fbeta: 2.0619e-08 - val_loss: 0.0417 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.04168 to 0.04166, saving model to model/model.w.best.h5\n",
      "Epoch 65/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0437 - fbeta: 2.0619e-08 - val_loss: 0.0416 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.04166 to 0.04164, saving model to model/model.w.best.h5\n",
      "Epoch 66/100\n",
      "194/194 [==============================] - 15s 79ms/step - loss: 0.0437 - fbeta: 2.0619e-08 - val_loss: 0.0416 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.04164 to 0.04162, saving model to model/model.w.best.h5\n",
      "Epoch 67/100\n",
      "194/194 [==============================] - 16s 81ms/step - loss: 0.0437 - fbeta: 2.0619e-08 - val_loss: 0.0416 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.04162 to 0.04160, saving model to model/model.w.best.h5\n",
      "Epoch 68/100\n",
      "194/194 [==============================] - 16s 80ms/step - loss: 0.0436 - fbeta: 2.0619e-08 - val_loss: 0.0416 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.04160 to 0.04159, saving model to model/model.w.best.h5\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0436 - fbeta: 2.0619e-08 - val_loss: 0.0416 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.04159 to 0.04157, saving model to model/model.w.best.h5\n",
      "Epoch 70/100\n",
      "194/194 [==============================] - 16s 80ms/step - loss: 0.0436 - fbeta: 2.0619e-08 - val_loss: 0.0416 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.04157 to 0.04155, saving model to model/model.w.best.h5\n",
      "Epoch 71/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0436 - fbeta: 2.0619e-08 - val_loss: 0.0415 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.04155 to 0.04154, saving model to model/model.w.best.h5\n",
      "Epoch 72/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0436 - fbeta: 2.0619e-08 - val_loss: 0.0415 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.04154 to 0.04152, saving model to model/model.w.best.h5\n",
      "Epoch 73/100\n",
      "194/194 [==============================] - 16s 80ms/step - loss: 0.0435 - fbeta: 2.0619e-08 - val_loss: 0.0415 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.04152 to 0.04150, saving model to model/model.w.best.h5\n",
      "Epoch 74/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0435 - fbeta: 2.0619e-08 - val_loss: 0.0415 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.04150 to 0.04149, saving model to model/model.w.best.h5\n",
      "Epoch 75/100\n",
      "194/194 [==============================] - 15s 79ms/step - loss: 0.0435 - fbeta: 2.0619e-08 - val_loss: 0.0415 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.04149 to 0.04147, saving model to model/model.w.best.h5\n",
      "Epoch 76/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0435 - fbeta: 2.0619e-08 - val_loss: 0.0415 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.04147 to 0.04146, saving model to model/model.w.best.h5\n",
      "Epoch 77/100\n",
      "194/194 [==============================] - 15s 79ms/step - loss: 0.0435 - fbeta: 2.0619e-08 - val_loss: 0.0414 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.04146 to 0.04144, saving model to model/model.w.best.h5\n",
      "Epoch 78/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0435 - fbeta: 2.0619e-08 - val_loss: 0.0414 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.04144 to 0.04143, saving model to model/model.w.best.h5\n",
      "Epoch 79/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0434 - fbeta: 2.0619e-08 - val_loss: 0.0414 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.04143 to 0.04141, saving model to model/model.w.best.h5\n",
      "Epoch 80/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0434 - fbeta: 2.0619e-08 - val_loss: 0.0414 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.04141 to 0.04140, saving model to model/model.w.best.h5\n",
      "Epoch 81/100\n",
      "194/194 [==============================] - 16s 80ms/step - loss: 0.0434 - fbeta: 2.0619e-08 - val_loss: 0.0414 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.04140 to 0.04139, saving model to model/model.w.best.h5\n",
      "Epoch 82/100\n",
      "194/194 [==============================] - 16s 80ms/step - loss: 0.0434 - fbeta: 2.0619e-08 - val_loss: 0.0414 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.04139 to 0.04137, saving model to model/model.w.best.h5\n",
      "Epoch 83/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0434 - fbeta: 2.0619e-08 - val_loss: 0.0414 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.04137 to 0.04136, saving model to model/model.w.best.h5\n",
      "Epoch 84/100\n",
      "194/194 [==============================] - 15s 79ms/step - loss: 0.0434 - fbeta: 2.0619e-08 - val_loss: 0.0413 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.04136 to 0.04135, saving model to model/model.w.best.h5\n",
      "Epoch 85/100\n",
      "194/194 [==============================] - 15s 79ms/step - loss: 0.0433 - fbeta: 2.0619e-08 - val_loss: 0.0413 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.04135 to 0.04133, saving model to model/model.w.best.h5\n",
      "Epoch 86/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0433 - fbeta: 2.0619e-08 - val_loss: 0.0413 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.04133 to 0.04132, saving model to model/model.w.best.h5\n",
      "Epoch 87/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0433 - fbeta: 2.0619e-08 - val_loss: 0.0413 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.04132 to 0.04131, saving model to model/model.w.best.h5\n",
      "Epoch 88/100\n",
      "194/194 [==============================] - 16s 80ms/step - loss: 0.0433 - fbeta: 2.0619e-08 - val_loss: 0.0413 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.04131 to 0.04129, saving model to model/model.w.best.h5\n",
      "Epoch 89/100\n",
      "194/194 [==============================] - 16s 80ms/step - loss: 0.0433 - fbeta: 2.0619e-08 - val_loss: 0.0413 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.04129 to 0.04128, saving model to model/model.w.best.h5\n",
      "Epoch 90/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0433 - fbeta: 2.0619e-08 - val_loss: 0.0413 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04128 to 0.04127, saving model to model/model.w.best.h5\n",
      "Epoch 91/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0433 - fbeta: 2.0619e-08 - val_loss: 0.0413 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.04127 to 0.04126, saving model to model/model.w.best.h5\n",
      "Epoch 92/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0432 - fbeta: 2.0619e-08 - val_loss: 0.0412 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.04126 to 0.04125, saving model to model/model.w.best.h5\n",
      "Epoch 93/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0432 - fbeta: 2.0619e-08 - val_loss: 0.0412 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.04125 to 0.04124, saving model to model/model.w.best.h5\n",
      "Epoch 94/100\n",
      "194/194 [==============================] - 16s 80ms/step - loss: 0.0432 - fbeta: 2.0619e-08 - val_loss: 0.0412 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.04124 to 0.04123, saving model to model/model.w.best.h5\n",
      "Epoch 95/100\n",
      "194/194 [==============================] - 16s 81ms/step - loss: 0.0432 - fbeta: 2.0619e-08 - val_loss: 0.0412 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.04123 to 0.04121, saving model to model/model.w.best.h5\n",
      "Epoch 96/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0432 - fbeta: 2.0619e-08 - val_loss: 0.0412 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04121 to 0.04120, saving model to model/model.w.best.h5\n",
      "Epoch 97/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0432 - fbeta: 2.0619e-08 - val_loss: 0.0412 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.04120 to 0.04119, saving model to model/model.w.best.h5\n",
      "Epoch 98/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0432 - fbeta: 2.0619e-08 - val_loss: 0.0412 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.04119 to 0.04118, saving model to model/model.w.best.h5\n",
      "Epoch 99/100\n",
      "194/194 [==============================] - 16s 80ms/step - loss: 0.0432 - fbeta: 2.0619e-08 - val_loss: 0.0412 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.04118 to 0.04117, saving model to model/model.w.best.h5\n",
      "Epoch 100/100\n",
      "194/194 [==============================] - 15s 80ms/step - loss: 0.0431 - fbeta: 2.0619e-08 - val_loss: 0.0412 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.04117 to 0.04116, saving model to model/model.w.best.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras import callbacks\n",
    "\n",
    "PARAM_MAX_EPOCHS = 100 # PARAM: number of model-fit runs\n",
    "PARAM_N_BATCH = 10 # PARAM: number of input samples for one feedfwd-backprop step\n",
    "\n",
    "checkpointer = callbacks.ModelCheckpoint (\n",
    "    filepath=os.path.join ('model','model.w.best.h5'),\n",
    "    verbose=1,\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model.fit (X_train, y_train,\n",
    "                     epochs=PARAM_MAX_EPOCHS, batch_size=PARAM_N_BATCH, validation_split=0.1, shuffle=True,\n",
    "                     callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_fbeta', 'loss', 'val_loss', 'fbeta'])\n"
     ]
    }
   ],
   "source": [
    "print (history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, axs = plt.subplots (1, 2)\n",
    "\n",
    "# summarize history for accuracy\n",
    "axs[0].plot (history.history['fbeta'])\n",
    "if 'val_fbeta' in history.history:\n",
    "    axs[0].plot (history.history['val_fbeta'])\n",
    "axs[0].set (xlabel='epoch', ylabel='score (higher better)', title='F-{} score'.format (PARAM_BETA))\n",
    "axs[0].legend (['train', 'validation'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "axs[1].plot (history.history['loss'])\n",
    "if 'val_loss' in history.history:\n",
    "    axs[1].plot (history.history['val_loss'])\n",
    "axs[1].set (xlabel='epoch', ylabel='loss (lower better)', title='loss (mse)')\n",
    "axs[1].legend (['train', 'validation'], loc='upper left')\n",
    "\n",
    "fig.set_size_inches ((15., 6.), forward=True)\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**discussion**\n",
    "\n",
    "Above graphs show the F-beta score per epoch with beta = 1 on the left and the *loss per epoch*, calulated by the mean squared error (mse) on the right.\n",
    "\n",
    "*loss per epoch*:\n",
    "- gradient steps start with a loss of 0.052, end by 0.042 and show a smooth concave curve. The curve couldn't be better except a faster drop in the first 10 epochs.\n",
    "- the worse: mse after 1st epoch = 0.052 - the CNN learns very slow and in tiny steps (1st/2nd epoch: 0.052-0.049 = 0.003)\n",
    "\n",
    "*F-beta score per epoch*\n",
    "- evaluation metric immediately drops to zero after some epochs - the CNN doesn't learn anything yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reasons / todo\n",
    "\n",
    "*input data*\n",
    "\n",
    "(1) The used dataset only has 240 samples for training, validation and test. This is by far nothing for the CNN.\n",
    "\n",
    "Todo: retrieve more samples for the dataset\n",
    "\n",
    "(2) A quick look at random spectrograms show kind of chaotic information - as a human being it is hard to tell if there's any structure behind each key-mode pair. This may apply to the CNN too.\n",
    "\n",
    "Todo: find additional filter techniques / methods to clearly bring out structures for the CNN\n",
    "\n",
    "(3) Songs can change in key over their whole length.\n",
    "\n",
    "Todo: take appropriate sample of a song - ommit bridges, refrains, silent passages, noisy songs\n",
    "\n",
    "_\n",
    "\n",
    "*model training*\n",
    "\n",
    "The model was trained for 100 epochs, each in batches of 10 samples per feedfwd-backprop step. To make sure that the architecture is well suited, more epochs shall be run.\n",
    "\n",
    "Todo: increase epochs, change batch size\n",
    "\n",
    "_\n",
    "\n",
    "*model architecture*\n",
    "\n",
    "Todo: To better understand the insight of the CNN, visualize the filter of the convolutions. May there be enlightenment what kind of architecture works best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compare learning algorithm to benchmarks\n",
    "\n",
    "[i] below statements can be run without executing the whole notebook\n",
    "\n",
    "Therefor, go to and execute <a href='#load-learning-algorithm'>load learning algorithm</a>\n",
    "\n",
    "**TODO** **TODO** **TODO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 16ms/step\n",
      "[0.042050689458847046, 8.333333134658005e-09]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate (X_test, y_test, verbose=1)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> saving model... done\n"
     ]
    }
   ],
   "source": [
    "# serialization of model architecture\n",
    "import os\n",
    "\n",
    "save_name = os.path.join ('model', 'model.arch.yaml')\n",
    "\n",
    "print ('>>> saving model...', end=' ', flush=True)\n",
    "yaml_string = model.to_yaml ()\n",
    "with open (save_name, 'w') as yaml_file:\n",
    "    yaml_file.write (yaml_string)\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> loading and compiling model... done\n",
      ">>> loading best weights into model... done\n"
     ]
    }
   ],
   "source": [
    "# load model architecture\n",
    "from keras import models\n",
    "\n",
    "print ('>>> loading and compiling model...', end=' ', flush=True)\n",
    "with open (save_name, 'r') as yaml_file:\n",
    "    yaml_string = yaml_file.read ()\n",
    "model = models.model_from_yaml (yaml_string)\n",
    "model.compile (optimizer=opt_sgd, loss=losses.mean_squared_error, metrics=[fbeta])\n",
    "print ('done')\n",
    "\n",
    "# load best weights\n",
    "print ('>>> loading best weights into model...', end=' ', flush=True)\n",
    "model.load_weights (os.path.join ('model','model.w.best.h5'))\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_spectro/4-0/TROEPPK128F92F33EC.png\n",
      "y_true 4-0\n",
      "y_pred 6-1\n"
     ]
    }
   ],
   "source": [
    "idx = 20\n",
    "test_file = src_spectro_data['filenames'][idx]\n",
    "\n",
    "test_spectro = path_to_tensor (test_file)\n",
    "test_pred = model.predict (test_spectro)\n",
    "\n",
    "print (test_file)\n",
    "print ('y_true', src_spectro_data['target_names'][src_spectro_data['target'][idx]])\n",
    "print ('y_pred', src_spectro_data['target_names'][test_pred.argmax ()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obsolete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**drawbacks** (known, unresolvable issues)\n",
    "\n",
    "(WRONG) *music keys vs CNN key classes*\n",
    "\n",
    "See <a href='https://www.researchgate.net/publication/228963946_Audio_onset_detection_using_machine_learning_techniques_the_effect_and_applicability_of_key_and_tempo_information'>Chuan, Ching-Hua & Chew, Elaine. (2018). Audio onset detection using machine learning techniques: the effect and applicability of key and tempo information.</a>, p. 18\n",
    "\n",
    "The spectrograms show a pitch range given by the <a href='https://en.wikipedia.org/wiki/Scientific_pitch_notation#Table_of_note_frequencies'>Scientific Pitch Notation</a>. By that the range of notes goes from $C_{-1}$ = $0_{MIDI}$ up to $G_9$ = $127_{MIDI}$.\n",
    "\n",
    "Each note can be the tonic of a music key - for example the key 'C major' exists 11 times (ocatve -1 to 9). Thus the information of 128 keys is now squeezed into 24 key classes.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
