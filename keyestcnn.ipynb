{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio key estimation of digital music with CNNs\n",
    "Udacity Machine Learning Nanodegree - Capstone project\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "The project is structured as stated in section 'Project Design' of the Capstone project proposal.\n",
    "\n",
    "_\n",
    "<pre>\n",
    "<a href='#Data-Preprocessing'>Data Preprocessing</a>\n",
    "  <a href='#Million-Song-Dataset'>Million Song Dataset</a> - selection of appropriate songs, separate jupyter notebook\n",
    "  <a href='#Signal-Processing-and-Feature-Extraction'>Signal Processing and Feature Extraction</a> - separate jupyter notebook\n",
    "\n",
    "<a href='#Model-Preparation'>Model Preparation</a>\n",
    "  <a href='#Load-and-preprocess-data'>Load and preprocess data</a> - read spectrogram images, conversion to tensors\n",
    "  <a href='#Split-data-into-train-and-test-set'>Splitting data into training/testing sets</a>\n",
    "  <a href='#Model-architecture'>CNN model architecture</a>\n",
    "  <a href='#Model-parameter'>CNN model parameter</a>\n",
    "\n",
    "<a href='#Model-Training-and-Evaluation'>Model Training and Evaluation</a>\n",
    "  <a href='#Model-training'>Model training</a>\n",
    "  <a href='#Model-evaluation-and-comparison'>Model evaluation and comparison</a>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current version of the project is working, but\n",
    "\n",
    "the project is still ongoing...\n",
    "\n",
    "discussion and remarks of what to do can be found in section\n",
    "\n",
    "<a href='#reasons-/-todo'>reasons / todo</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Million Song Dataset\n",
    "- utilized to select appropriate song samples\n",
    "- holds information about key and mode per song (targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juypter Notebook <a href='./00.hlp/msd/msd.ipynb'>msd</a>\n",
    "\n",
    "outputs: csv file *songs_conf=75_tracks_filt.csv*, which holds all songs with key confidence and mode confidence > 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>key_confidence</th>\n",
       "      <th>mode</th>\n",
       "      <th>mode_confidence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>track_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852</td>\n",
       "      <td>114.493</td>\n",
       "      <td>TRMMMGL128F92FD6AB</td>\n",
       "      <td>SOHSSPG12A8C144BE0</td>\n",
       "      <td>Clifford T. Ward</td>\n",
       "      <td>Mad About You</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  key_confidence  mode  mode_confidence    tempo            track_id  \\\n",
       "0    7           0.896     1            0.852  114.493  TRMMMGL128F92FD6AB   \n",
       "\n",
       "              song_id       artist_name     song_title  \n",
       "0  SOHSSPG12A8C144BE0  Clifford T. Ward  Mad About You  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] number of records: 47913\n"
     ]
    }
   ],
   "source": [
    "# LIST SELECTED SONGS\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "selsongsfile = os.path.join ('00.hlp', 'msd', 'songs_conf=75_tracks_filt.csv')\n",
    "selsongs = pd.read_csv (selsongsfile, header=0, index_col=0)\n",
    "display (selsongs.head (1))\n",
    "print ('[i] number of records:', len (selsongs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD AUDIO DATASET\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "PARAM_RND_STATE = 42\n",
    "\n",
    "container_path = os.path.join ('src_audio')\n",
    "load_content = False\n",
    "description = ['key C, mode minor', 'key C, mode major',\n",
    "               'key C#, mode minor', 'key C#, mode major',\n",
    "               'key D, mode minor', 'key D, mode major',\n",
    "               'key D#, mode minor', 'key D#, mode major',\n",
    "               'key E, mode minor', 'key E, mode major',\n",
    "               'key F, mode minor', 'key F, mode major',\n",
    "               'key F#, mode minor', 'key F#, mode major',\n",
    "               'key G, mode minor', 'key G, mode major',\n",
    "               'key G#, mode minor', 'key G#, mode major',\n",
    "               'key A, mode minor', 'key A, mode major',\n",
    "               'key A#, mode minor', 'key A#, mode major',\n",
    "               'key B, mode minor', 'key B, mode major']\n",
    "\n",
    "src_audio_data = datasets.load_files (container_path=container_path,\n",
    "                                      description=description,\n",
    "                                      load_content=load_content,\n",
    "                                      random_state=PARAM_RND_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>key_confidence</th>\n",
       "      <th>mode</th>\n",
       "      <th>mode_confidence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>track_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9446</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902</td>\n",
       "      <td>168.906</td>\n",
       "      <td>TRRRPKJ128F146AFD4</td>\n",
       "      <td>SOXGRHH12A58A7D67E</td>\n",
       "      <td>Hot Chocolate</td>\n",
       "      <td>You'll Always Be A Friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32233</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.884</td>\n",
       "      <td>149.973</td>\n",
       "      <td>TRENOSF128F14552A5</td>\n",
       "      <td>SOIYDYW12A6D4F6F20</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>When I'm Gone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27745</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>127.951</td>\n",
       "      <td>TRUGCKB128F425AC16</td>\n",
       "      <td>SODHLDK12A8C136CFD</td>\n",
       "      <td>Jeff And Sheri Easter</td>\n",
       "      <td>Forever And A Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7510</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>113.208</td>\n",
       "      <td>TRCHSTZ12903CAAAB9</td>\n",
       "      <td>SOLPFMY12A58A7B830</td>\n",
       "      <td>Brian Hyland</td>\n",
       "      <td>Just Knowing You Is  A Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10070</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.849</td>\n",
       "      <td>112.893</td>\n",
       "      <td>TRRTCMY128F9326B32</td>\n",
       "      <td>SOYGPIR12AB018646A</td>\n",
       "      <td>The Levon Helm Band</td>\n",
       "      <td>A Fool In Love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       key  key_confidence  mode  mode_confidence    tempo  \\\n",
       "9446     3             1.0     1            0.902  168.906   \n",
       "32233   10             1.0     0            0.884  149.973   \n",
       "27745    8             1.0     1            1.000  127.951   \n",
       "7510     8             1.0     1            1.000  113.208   \n",
       "10070    0             1.0     0            0.849  112.893   \n",
       "\n",
       "                 track_id             song_id            artist_name  \\\n",
       "9446   TRRRPKJ128F146AFD4  SOXGRHH12A58A7D67E          Hot Chocolate   \n",
       "32233  TRENOSF128F14552A5  SOIYDYW12A6D4F6F20                 Eminem   \n",
       "27745  TRUGCKB128F425AC16  SODHLDK12A8C136CFD  Jeff And Sheri Easter   \n",
       "7510   TRCHSTZ12903CAAAB9  SOLPFMY12A58A7B830           Brian Hyland   \n",
       "10070  TRRTCMY128F9326B32  SOYGPIR12AB018646A    The Levon Helm Band   \n",
       "\n",
       "                            song_title  \n",
       "9446         You'll Always Be A Friend  \n",
       "32233                    When I'm Gone  \n",
       "27745                Forever And A Day  \n",
       "7510   Just Knowing You Is  A Pleasure  \n",
       "10070                   A Fool In Love  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] number of records: 240\n",
      "[i] min of: key_confidence = 0.809 , mode_confidence = 0.777\n",
      "[i] tempo: min = 0.0 , max = 248.32299999999998\n"
     ]
    }
   ],
   "source": [
    "# FYI: LIST SOME OF THE USED SONGS\n",
    "filenames = list (os.path.basename (filepath) for filepath in src_audio_data['filenames'])\n",
    "usedsongs_track_id = list (os.path.splitext (fn)[0] for fn in filenames)\n",
    "usedsongs = selsongs.query ('track_id in @usedsongs_track_id')\n",
    "\n",
    "display (usedsongs.sample(5))\n",
    "print ('[i] number of records:', len (usedsongs))\n",
    "print ('[i] min of: key_confidence =', usedsongs['key_confidence'].min (), ',', \\\n",
    "       'mode_confidence =', usedsongs['mode_confidence'].min ())\n",
    "print ('[i] tempo: min =', usedsongs['tempo'].min (), ',', \\\n",
    "       'max =', usedsongs['tempo'].max ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- save list of used songs\n",
    "usedsongs.to_csv ('usedsongs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- save list of unused songs\n",
    "unusedsongs = selsongs.drop ((usedsongs.index.values))\n",
    "unusedsongs.to_csv ('unusedsongs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Processing and Feature Extraction\n",
    "- create spectrograms of audio files with discrete Fourier transform (DFT)\n",
    "- save spectrograms as images for further use in CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juypter Notebook <a href='./00.hlp/fft/fft.ipynb'>fft</a>\n",
    "\n",
    "ouptuts: spectrograms (png images) of audio files with same folder structure as *src_audio* in new container path named *src_spectro*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of a spectrogram image**\n",
    "\n",
    "<img src ='./src_spectro/7-0/TREDRTV12903D03829.png' align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "Since there aren't enough samples to proper train the classifier, image augmentation is used.\n",
    "\n",
    "Below jupyter notebook does the work.\n",
    "\n",
    "Juypter Notebook <a href='./00.hlp/trnsp/trnsp.ipynb'>transposing songs</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['DESCR', 'filenames', 'target', 'target_names'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD SPECTROGRAM FILENAMES\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "PARAM_RND_STATE = 42\n",
    "\n",
    "container_path = os.path.join ('src_spectro')\n",
    "load_content = False\n",
    "description = ['key C, mode minor', 'key C, mode major',\n",
    "               'key C#, mode minor', 'key C#, mode major',\n",
    "               'key D, mode minor', 'key D, mode major',\n",
    "               'key D#, mode minor', 'key D#, mode major',\n",
    "               'key E, mode minor', 'key E, mode major',\n",
    "               'key F, mode minor', 'key F, mode major',\n",
    "               'key F#, mode minor', 'key F#, mode major',\n",
    "               'key G, mode minor', 'key G, mode major',\n",
    "               'key G#, mode minor', 'key G#, mode major',\n",
    "               'key A, mode minor', 'key A, mode major',\n",
    "               'key A#, mode minor', 'key A#, mode major',\n",
    "               'key B, mode minor', 'key B, mode major']\n",
    "\n",
    "src_spectro_data = datasets.load_files (container_path=container_path,\n",
    "                                        description=description,\n",
    "                                        load_content=load_content,\n",
    "                                        random_state=PARAM_RND_STATE)\n",
    "src_spectro_data.keys ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] example of loaded spectrogram file data:\n",
      "    spectrogram image name: src_spectro/9-0/TRINRNG128F93539C0_1-oct.png\n",
      "    spectrogram image key-mode pair: 9-0 = key B, mode minor = target class 22\n"
     ]
    }
   ],
   "source": [
    "print ('[i] example of loaded spectrogram file data:')\n",
    "print ('    spectrogram image name:', src_spectro_data['filenames'][0])\n",
    "print ('    spectrogram image key-mode pair:',\\\n",
    "       src_spectro_data['target_names'][src_spectro_data['target'][0]],\\\n",
    "       '=', src_spectro_data['DESCR'][src_spectro_data['target'][0]],\\\n",
    "       '= target class', src_spectro_data['target'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in images, convert to tensors**\n",
    "\n",
    "Keras Conv2D layers expect a **4D tensor with shape (batch, rows, cols, channels)** (if param data_format='channels_last') (src: <a href='https://keras.io/layers/convolutional/#conv2d'>Keras Conv2D</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] image size: (150, 128)\n",
      "[i] pixel format: RGB\n"
     ]
    }
   ],
   "source": [
    "# open a random image and take a look at the attributes\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open (src_spectro_data['filenames'][0])\n",
    "print ('[i] image size:', im.size)\n",
    "print ('[i] pixel format:', im.mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changing target size of image**\n",
    "\n",
    "CNNs work best if input size is divisible by 2 many times - image size needs to be changed. (<a href='http://cs231n.github.io/convolutional-networks/#layersizepat'>cs231n - Layer Sizing Patterns</a>)\n",
    "\n",
    "Current image size is 150 x 128: possible options\n",
    "- (-) cut down the image to 128 x 128: information loss in song length\n",
    "- (-) resize to 150 x 150: not divisible by 2 many times (exactly 1 time)\n",
    "- (+) resize to 160 x 160: divisible by 2 many times (exactly 5 times, this is enough)\n",
    "\n",
    "Resizing is done by appending zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "PARAM_TARGET_SIZE = 160\n",
    "def resize_image (img_arr):\n",
    "    #print ('>>> resizing image to [{}, {}]...'.format (PARAM_IMG_SIZE, PARAM_IMG_SIZE), end=' ', flush=True)\n",
    "    \n",
    "    m = img_arr.shape[0] #128\n",
    "    n = img_arr.shape[1] #150\n",
    "    \n",
    "    # how many additional cols to add?\n",
    "    cols_to_add = PARAM_TARGET_SIZE - n\n",
    "    \n",
    "    img_resized = np.empty ((1, PARAM_TARGET_SIZE))\n",
    "    for i in range (m):\n",
    "        new_line = np.append (img_arr[i], np.zeros (cols_to_add))\n",
    "        img_resized = np.vstack ((img_resized, new_line))\n",
    "    \n",
    "    img_resized = img_resized[1:]\n",
    "    # now img_resized = (128, 160)\n",
    "    \n",
    "    # how many additional rows to add?\n",
    "    rows_to_add = PARAM_TARGET_SIZE - m\n",
    "    img_resized = np.vstack ((img_resized, np.zeros ((rows_to_add, PARAM_TARGET_SIZE))))\n",
    "    # now img_resize = (160, 160)\n",
    "    \n",
    "    #print ('done')\n",
    "    \n",
    "    return img_resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature scaling by feature standardization**\n",
    "\n",
    "$x^{'}= \\frac{x-\\bar{x}}{\\sigma}$\n",
    "\n",
    "tensorflow function used to do this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below functions read the images and convert those to tensors - original code taken from Udacity MLND dog-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor (img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img (img_path, color_mode='grayscale')\n",
    "    \n",
    "    # convert PIL.Image.Image type to 3D tensor\n",
    "    x = image.img_to_array (img)\n",
    "    x = resize_image (x)\n",
    "    x = x[:,:,np.newaxis]\n",
    "    \n",
    "    # feature standardization to zero mean and stdev of one\n",
    "    x = K.eval (tf.image.per_image_standardization (x))\n",
    "    \n",
    "    # convert 3D tensor to 4D tensor\n",
    "    return np.expand_dims (x, axis=0)\n",
    "\n",
    "def paths_to_tensor (img_paths):\n",
    "    list_of_tensors = [path_to_tensor (img_path) for img_path in tqdm (img_paths)]\n",
    "    return np.vstack (list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 866/866 [00:02<00:00, 391.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "spectro_tensors = paths_to_tensor (src_spectro_data['filenames'])#.astype ('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] shape of spectrogram tensors: (866, 160, 160, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('[i] shape of spectrogram tensors:', spectro_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] number of output classes: 24\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "targets = np_utils.to_categorical (np.array (src_spectro_data['target']), 24)\n",
    "print ('[i] number of output classes:', targets.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Training dataset consists of 692 samples\n",
      "[i] Testing dataset consists of 174 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split (spectro_tensors, targets, test_size=0.20, shuffle=True, random_state=PARAM_RND_STATE)\n",
    "\n",
    "print ('[i] Training dataset consists of {} samples'.format (X_train.shape[0]))\n",
    "print ('[i] Testing dataset consists of {} samples'.format (X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture\n",
    "\n",
    "(<a href='http://cs231n.github.io/convolutional-networks/#layersizepat'>cs231n - Layer Sizing Patterns</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 160, 160, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 160, 160, 32)      160       \n",
      "_________________________________________________________________\n",
      "maxp_1 (MaxPooling2D)        (None, 80, 80, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 80, 80, 64)        8256      \n",
      "_________________________________________________________________\n",
      "maxp_2 (MaxPooling2D)        (None, 40, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 40, 40, 128)       32896     \n",
      "_________________________________________________________________\n",
      "maxp_3 (MaxPooling2D)        (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "avg_flatten (GlobalAveragePo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 24)                3096      \n",
      "=================================================================\n",
      "Total params: 44,408\n",
      "Trainable params: 44,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "from keras import backend as K\n",
    "\n",
    "# clear everything known of past instances (\"useful to avoid clutter from old models / layers\")\n",
    "K.clear_session ()\n",
    "\n",
    "# input layer\n",
    "inputs = layers.Input (shape=spectro_tensors.shape[1:], name='input')\n",
    "\n",
    "# hidden layers\n",
    "net = layers.Conv2D (filters=32, kernel_size=(2,2), strides=(1,1),\n",
    "                     padding='same', # don't lose information due to conv window runs out of image / strides = 1 = OK\n",
    "                     activation='relu',\n",
    "                     name='conv2d_1') (inputs)\n",
    "net = layers.MaxPooling2D (pool_size=(2,2), strides=None, name='maxp_1') (net)\n",
    "\n",
    "net = layers.Conv2D (filters=64, kernel_size=(2,2), strides=(1,1),\n",
    "              padding='same',\n",
    "              activation='relu',\n",
    "              name='conv2d_2') (net)\n",
    "net = layers.MaxPooling2D (pool_size=(2,2), strides=None, name='maxp_2') (net)\n",
    "\n",
    "net = layers.Conv2D (filters=128, kernel_size=(2,2), strides=(1,1),\n",
    "              padding='same',\n",
    "              activation='relu',\n",
    "              name='conv2d_3') (net)\n",
    "net = layers.MaxPooling2D (pool_size=(2,2), strides=None, name='maxp_3') (net)\n",
    "\n",
    "#net = layers.Conv2D (filters=256, kernel_size=(2,2), strides=(1,1),\n",
    "#              padding='same',\n",
    "#              activation='relu',\n",
    "#              name='conv2d_4') (net)\n",
    "#net = layers.MaxPooling2D (pool_size=(2,2), strides=None, name='maxp_4') (net)\n",
    "\n",
    "# 'flatten layer'\n",
    "net = layers.GlobalAveragePooling2D (name='avg_flatten') (net)\n",
    "\n",
    "# output layer\n",
    "outputs = layers.Dense (units=targets.shape[1], activation='softmax', name='output') (net)\n",
    "\n",
    "\n",
    "model = models.Model (inputs=inputs, outputs=outputs)\n",
    "model.summary ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameter\n",
    "(metric, loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: Arseny Kravchenko http://arseny.info/2017/f-beta-score-for-keras.html\n",
    "from keras import backend as K\n",
    "\n",
    "PARAM_BETA = 1\n",
    "def fbeta (y_true, y_pred):\n",
    "\n",
    "    # just in case of hipster activation at the final layer\n",
    "    y_pred = K.clip (y_pred, 0, 1)\n",
    "\n",
    "    tp = K.sum (K.round (y_true * y_pred)) + K.epsilon ()\n",
    "    fp = K.sum (K.round (K.clip (y_pred - y_true, 0, 1)))\n",
    "    fn = K.sum (K.round (K.clip (y_true - y_pred, 0, 1)))\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    beta_squared = PARAM_BETA ** 2\n",
    "    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers, losses\n",
    "\n",
    "PARAM_LR = 0.001\n",
    "opt_sgd = optimizers.SGD (lr=PARAM_LR, momentum=0.8)\n",
    "opt_adamax = optimizers.Adamax (lr=PARAM_LR, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "\n",
    "loss = losses.categorical_crossentropy\n",
    "#loss = losses.mean_squared_error\n",
    "\n",
    "model.compile (optimizer=opt_sgd, loss=loss, metrics=[fbeta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 622 samples, validate on 70 samples\n",
      "Epoch 1/5000\n",
      "622/622 [==============================] - 26s 42ms/step - loss: 3.6549 - fbeta: 0.0032 - val_loss: 3.2850 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.28498, saving model to model/model.w.best.h5\n",
      "Epoch 2/5000\n",
      "622/622 [==============================] - 25s 41ms/step - loss: 3.2209 - fbeta: 1.0289e-08 - val_loss: 3.1163 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.28498 to 3.11634, saving model to model/model.w.best.h5\n",
      "Epoch 3/5000\n",
      "622/622 [==============================] - 25s 41ms/step - loss: 3.1918 - fbeta: 1.0289e-08 - val_loss: 3.1638 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.11634\n",
      "Epoch 4/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1334 - fbeta: 1.0289e-08 - val_loss: 3.2035 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.11634\n",
      "Epoch 5/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1114 - fbeta: 1.0289e-08 - val_loss: 3.0966 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.11634 to 3.09663, saving model to model/model.w.best.h5\n",
      "Epoch 6/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0931 - fbeta: 1.0289e-08 - val_loss: 3.1283 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.09663\n",
      "Epoch 7/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0624 - fbeta: 1.0289e-08 - val_loss: 3.1381 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.09663\n",
      "Epoch 8/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0459 - fbeta: 1.0289e-08 - val_loss: 3.0183 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.09663 to 3.01827, saving model to model/model.w.best.h5\n",
      "Epoch 9/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0413 - fbeta: 1.0289e-08 - val_loss: 3.0683 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.01827\n",
      "Epoch 10/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0086 - fbeta: 1.0289e-08 - val_loss: 3.0470 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.01827\n",
      "Epoch 11/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0051 - fbeta: 1.0260e-08 - val_loss: 2.9569 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.01827 to 2.95690, saving model to model/model.w.best.h5\n",
      "Epoch 12/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9496 - fbeta: 1.0289e-08 - val_loss: 3.0567 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.95690\n",
      "Epoch 13/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9274 - fbeta: 1.0289e-08 - val_loss: 2.9681 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.95690\n",
      "Epoch 14/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8807 - fbeta: 1.0289e-08 - val_loss: 2.9122 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.95690 to 2.91218, saving model to model/model.w.best.h5\n",
      "Epoch 15/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8631 - fbeta: 1.0289e-08 - val_loss: 2.9335 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.91218\n",
      "Epoch 16/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8021 - fbeta: 1.0289e-08 - val_loss: 2.8615 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.91218 to 2.86155, saving model to model/model.w.best.h5\n",
      "Epoch 17/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7719 - fbeta: 1.0289e-08 - val_loss: 2.9720 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.86155\n",
      "Epoch 18/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7403 - fbeta: 0.0031 - val_loss: 2.7881 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.86155 to 2.78806, saving model to model/model.w.best.h5\n",
      "Epoch 19/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7518 - fbeta: 1.0289e-08 - val_loss: 2.8417 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.78806\n",
      "Epoch 20/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6448 - fbeta: 1.0289e-08 - val_loss: 2.6747 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.78806 to 2.67474, saving model to model/model.w.best.h5\n",
      "Epoch 21/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6326 - fbeta: 0.0031 - val_loss: 2.8720 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.67474\n",
      "Epoch 22/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6107 - fbeta: 0.0115 - val_loss: 3.0120 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.67474\n",
      "Epoch 23/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6092 - fbeta: 0.0117 - val_loss: 2.7199 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.67474\n",
      "Epoch 24/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5627 - fbeta: 0.0031 - val_loss: 2.6345 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.67474 to 2.63455, saving model to model/model.w.best.h5\n",
      "Epoch 25/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4395 - fbeta: 0.0092 - val_loss: 2.7118 - val_fbeta: 0.0260\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.63455\n",
      "Epoch 26/5000\n",
      "622/622 [==============================] - 25s 41ms/step - loss: 2.4764 - fbeta: 0.0278 - val_loss: 2.6656 - val_fbeta: 0.0519\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.63455\n",
      "Epoch 27/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4751 - fbeta: 0.0149 - val_loss: 2.5609 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.63455 to 2.56095, saving model to model/model.w.best.h5\n",
      "Epoch 28/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3927 - fbeta: 0.0153 - val_loss: 2.7772 - val_fbeta: 0.0272\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.56095\n",
      "Epoch 29/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4216 - fbeta: 0.0295 - val_loss: 2.8382 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.56095\n",
      "Epoch 30/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4071 - fbeta: 0.0326 - val_loss: 2.5358 - val_fbeta: 0.1255\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.56095 to 2.53579, saving model to model/model.w.best.h5\n",
      "Epoch 31/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3844 - fbeta: 0.0347 - val_loss: 2.6070 - val_fbeta: 1.1169e-08\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.53579\n",
      "Epoch 32/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3235 - fbeta: 0.0334 - val_loss: 2.7060 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.53579\n",
      "Epoch 33/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3830 - fbeta: 0.0302 - val_loss: 2.6686 - val_fbeta: 0.0260\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.53579\n",
      "Epoch 34/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2999 - fbeta: 0.0409 - val_loss: 2.4526 - val_fbeta: 0.1039\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.53579 to 2.45257, saving model to model/model.w.best.h5\n",
      "Epoch 35/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2922 - fbeta: 0.0561 - val_loss: 2.5121 - val_fbeta: 0.0238\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.45257\n",
      "Epoch 36/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2484 - fbeta: 0.0463 - val_loss: 2.5390 - val_fbeta: 1.0773e-08\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.45257\n",
      "Epoch 37/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2025 - fbeta: 0.0596 - val_loss: 2.6558 - val_fbeta: 0.1331\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.45257\n",
      "Epoch 38/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2349 - fbeta: 0.0670 - val_loss: 2.6602 - val_fbeta: 0.1896\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.45257\n",
      "Epoch 39/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2042 - fbeta: 0.0665 - val_loss: 2.7372 - val_fbeta: 0.2667\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.45257\n",
      "Epoch 40/5000\n",
      "622/622 [==============================] - 25s 41ms/step - loss: 2.2269 - fbeta: 0.0595 - val_loss: 2.5277 - val_fbeta: 1.1429e-08\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.45257\n",
      "Epoch 41/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1535 - fbeta: 0.0722 - val_loss: 2.5979 - val_fbeta: 0.0519\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.45257\n",
      "Epoch 42/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1685 - fbeta: 0.0784 - val_loss: 2.3413 - val_fbeta: 0.0272\n",
      "\n",
      "Epoch 00042: val_loss improved from 2.45257 to 2.34134, saving model to model/model.w.best.h5\n",
      "Epoch 43/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1073 - fbeta: 0.1066 - val_loss: 2.6653 - val_fbeta: 0.0238\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.34134\n",
      "Epoch 44/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1321 - fbeta: 0.0858 - val_loss: 2.4134 - val_fbeta: 0.1957\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.34134\n",
      "Epoch 45/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0300 - fbeta: 0.1104 - val_loss: 2.7216 - val_fbeta: 0.0467\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.34134\n",
      "Epoch 46/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1351 - fbeta: 0.1249 - val_loss: 2.5988 - val_fbeta: 0.0260\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.34134\n",
      "Epoch 47/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0906 - fbeta: 0.1250 - val_loss: 2.3663 - val_fbeta: 0.1496\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.34134\n",
      "Epoch 48/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0107 - fbeta: 0.1285 - val_loss: 2.4215 - val_fbeta: 0.0497\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.34134\n",
      "Epoch 49/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0394 - fbeta: 0.1312 - val_loss: 2.3552 - val_fbeta: 0.0686\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.34134\n",
      "Epoch 50/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9949 - fbeta: 0.1606 - val_loss: 2.4209 - val_fbeta: 0.1381\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.34134\n",
      "Epoch 51/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0096 - fbeta: 0.1802 - val_loss: 2.8471 - val_fbeta: 0.0880\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.34134\n",
      "Epoch 52/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9867 - fbeta: 0.1930 - val_loss: 2.4878 - val_fbeta: 0.1426\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.34134\n",
      "Epoch 53/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0357 - fbeta: 0.1426 - val_loss: 2.2771 - val_fbeta: 0.2442\n",
      "\n",
      "Epoch 00053: val_loss improved from 2.34134 to 2.27706, saving model to model/model.w.best.h5\n",
      "Epoch 54/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9828 - fbeta: 0.1413 - val_loss: 2.6500 - val_fbeta: 0.0816\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 2.27706\n",
      "Epoch 55/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9744 - fbeta: 0.1625 - val_loss: 2.5224 - val_fbeta: 0.0770\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2.27706\n",
      "Epoch 56/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9041 - fbeta: 0.1905 - val_loss: 2.3944 - val_fbeta: 0.0248\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2.27706\n",
      "Epoch 57/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8370 - fbeta: 0.2269 - val_loss: 2.5676 - val_fbeta: 0.1477\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2.27706\n",
      "Epoch 58/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9375 - fbeta: 0.2125 - val_loss: 2.5507 - val_fbeta: 0.0897\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2.27706\n",
      "Epoch 59/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8741 - fbeta: 0.2403 - val_loss: 2.3501 - val_fbeta: 0.0944\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2.27706\n",
      "Epoch 60/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9009 - fbeta: 0.2170 - val_loss: 2.2199 - val_fbeta: 0.1462\n",
      "\n",
      "Epoch 00060: val_loss improved from 2.27706 to 2.21992, saving model to model/model.w.best.h5\n",
      "Epoch 61/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8475 - fbeta: 0.2224 - val_loss: 2.4221 - val_fbeta: 0.1028\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.21992\n",
      "Epoch 62/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8910 - fbeta: 0.2576 - val_loss: 2.7331 - val_fbeta: 0.2061\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2.21992\n",
      "Epoch 63/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8232 - fbeta: 0.2407 - val_loss: 2.5306 - val_fbeta: 0.1520\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2.21992\n",
      "Epoch 64/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8212 - fbeta: 0.2315 - val_loss: 2.4332 - val_fbeta: 0.1274\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.21992\n",
      "Epoch 65/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8164 - fbeta: 0.2575 - val_loss: 2.5507 - val_fbeta: 0.1514\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2.21992\n",
      "Epoch 66/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8636 - fbeta: 0.2248 - val_loss: 2.9060 - val_fbeta: 0.1140\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2.21992\n",
      "Epoch 67/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9101 - fbeta: 0.2565 - val_loss: 2.2014 - val_fbeta: 0.1674\n",
      "\n",
      "Epoch 00067: val_loss improved from 2.21992 to 2.20138, saving model to model/model.w.best.h5\n",
      "Epoch 68/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7477 - fbeta: 0.2558 - val_loss: 2.1301 - val_fbeta: 0.2575\n",
      "\n",
      "Epoch 00068: val_loss improved from 2.20138 to 2.13014, saving model to model/model.w.best.h5\n",
      "Epoch 69/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6761 - fbeta: 0.2786 - val_loss: 2.3147 - val_fbeta: 0.1246\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2.13014\n",
      "Epoch 70/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8021 - fbeta: 0.2678 - val_loss: 2.1945 - val_fbeta: 0.1670\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2.13014\n",
      "Epoch 71/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6598 - fbeta: 0.3092 - val_loss: 2.5529 - val_fbeta: 0.1331\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2.13014\n",
      "Epoch 72/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7156 - fbeta: 0.3273 - val_loss: 2.4344 - val_fbeta: 0.1834\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2.13014\n",
      "Epoch 73/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6290 - fbeta: 0.3369 - val_loss: 2.1598 - val_fbeta: 0.2272\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2.13014\n",
      "Epoch 74/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6089 - fbeta: 0.3690 - val_loss: 2.1977 - val_fbeta: 0.2318\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 2.13014\n",
      "Epoch 75/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6402 - fbeta: 0.3870 - val_loss: 2.1438 - val_fbeta: 0.1693\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2.13014\n",
      "Epoch 76/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5877 - fbeta: 0.3824 - val_loss: 2.1721 - val_fbeta: 0.2294\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2.13014\n",
      "Epoch 77/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6314 - fbeta: 0.4010 - val_loss: 2.1459 - val_fbeta: 0.1460\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2.13014\n",
      "Epoch 78/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5526 - fbeta: 0.3827 - val_loss: 1.9209 - val_fbeta: 0.3460\n",
      "\n",
      "Epoch 00078: val_loss improved from 2.13014 to 1.92086, saving model to model/model.w.best.h5\n",
      "Epoch 79/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4908 - fbeta: 0.4065 - val_loss: 2.3593 - val_fbeta: 0.2633\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.92086\n",
      "Epoch 80/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5203 - fbeta: 0.4182 - val_loss: 2.5458 - val_fbeta: 0.2852\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.92086\n",
      "Epoch 81/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5123 - fbeta: 0.4405 - val_loss: 1.9693 - val_fbeta: 0.3187\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.92086\n",
      "Epoch 82/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5546 - fbeta: 0.4288 - val_loss: 2.0487 - val_fbeta: 0.3910\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.92086\n",
      "Epoch 83/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5100 - fbeta: 0.4200 - val_loss: 2.4617 - val_fbeta: 0.1274\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.92086\n",
      "Epoch 84/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3708 - fbeta: 0.4714 - val_loss: 2.1486 - val_fbeta: 0.3191\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.92086\n",
      "Epoch 85/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3903 - fbeta: 0.4464 - val_loss: 2.1020 - val_fbeta: 0.3428\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.92086\n",
      "Epoch 86/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2882 - fbeta: 0.5113 - val_loss: 2.8425 - val_fbeta: 0.1471\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.92086\n",
      "Epoch 87/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6452 - fbeta: 0.4359 - val_loss: 2.1096 - val_fbeta: 0.2652\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.92086\n",
      "Epoch 88/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3447 - fbeta: 0.4941 - val_loss: 2.0865 - val_fbeta: 0.1957\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.92086\n",
      "Epoch 89/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2948 - fbeta: 0.5081 - val_loss: 2.9785 - val_fbeta: 0.1311\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.92086\n",
      "Epoch 90/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4137 - fbeta: 0.4896 - val_loss: 2.1429 - val_fbeta: 0.2492\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.92086\n",
      "Epoch 91/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4130 - fbeta: 0.4840 - val_loss: 2.0752 - val_fbeta: 0.2631\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.92086\n",
      "Epoch 92/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2966 - fbeta: 0.5150 - val_loss: 2.3033 - val_fbeta: 0.3701\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.92086\n",
      "Epoch 93/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2039 - fbeta: 0.5442 - val_loss: 2.3267 - val_fbeta: 0.2379\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.92086\n",
      "Epoch 94/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2113 - fbeta: 0.5470 - val_loss: 2.2533 - val_fbeta: 0.2976\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.92086\n",
      "Epoch 95/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2532 - fbeta: 0.5537 - val_loss: 2.0766 - val_fbeta: 0.3199\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.92086\n",
      "Epoch 96/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3209 - fbeta: 0.5251 - val_loss: 1.8527 - val_fbeta: 0.3842\n",
      "\n",
      "Epoch 00096: val_loss improved from 1.92086 to 1.85272, saving model to model/model.w.best.h5\n",
      "Epoch 97/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2349 - fbeta: 0.5422 - val_loss: 1.9049 - val_fbeta: 0.4010\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.85272\n",
      "Epoch 98/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1172 - fbeta: 0.5901 - val_loss: 2.1106 - val_fbeta: 0.2943\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.85272\n",
      "Epoch 99/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1990 - fbeta: 0.5899 - val_loss: 2.2352 - val_fbeta: 0.2778\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.85272\n",
      "Epoch 100/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3239 - fbeta: 0.5646 - val_loss: 2.4736 - val_fbeta: 0.2328\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.85272\n",
      "Epoch 101/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2738 - fbeta: 0.5875 - val_loss: 2.3946 - val_fbeta: 0.2690\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1.85272\n",
      "Epoch 102/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1769 - fbeta: 0.5869 - val_loss: 1.9878 - val_fbeta: 0.3658\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.85272\n",
      "Epoch 103/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0520 - fbeta: 0.6348 - val_loss: 2.6712 - val_fbeta: 0.2894\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.85272\n",
      "Epoch 104/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3264 - fbeta: 0.5747 - val_loss: 1.7759 - val_fbeta: 0.4320\n",
      "\n",
      "Epoch 00104: val_loss improved from 1.85272 to 1.77585, saving model to model/model.w.best.h5\n",
      "Epoch 105/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0623 - fbeta: 0.6655 - val_loss: 2.3852 - val_fbeta: 0.3094\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.77585\n",
      "Epoch 106/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0723 - fbeta: 0.6293 - val_loss: 1.8100 - val_fbeta: 0.3955\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.77585\n",
      "Epoch 107/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0509 - fbeta: 0.6441 - val_loss: 2.5692 - val_fbeta: 0.2469\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.77585\n",
      "Epoch 108/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0766 - fbeta: 0.6314 - val_loss: 1.7304 - val_fbeta: 0.3824\n",
      "\n",
      "Epoch 00108: val_loss improved from 1.77585 to 1.73042, saving model to model/model.w.best.h5\n",
      "Epoch 109/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.9959 - fbeta: 0.6588 - val_loss: 2.8093 - val_fbeta: 0.2392\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.73042\n",
      "Epoch 110/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1916 - fbeta: 0.6189 - val_loss: 1.7256 - val_fbeta: 0.4425\n",
      "\n",
      "Epoch 00110: val_loss improved from 1.73042 to 1.72562, saving model to model/model.w.best.h5\n",
      "Epoch 111/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1551 - fbeta: 0.6207 - val_loss: 1.7626 - val_fbeta: 0.2866\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1.72562\n",
      "Epoch 112/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0133 - fbeta: 0.6592 - val_loss: 1.5406 - val_fbeta: 0.4377\n",
      "\n",
      "Epoch 00112: val_loss improved from 1.72562 to 1.54055, saving model to model/model.w.best.h5\n",
      "Epoch 113/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.8508 - fbeta: 0.7192 - val_loss: 1.9456 - val_fbeta: 0.3804\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.54055\n",
      "Epoch 114/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0035 - fbeta: 0.6870 - val_loss: 1.6428 - val_fbeta: 0.4305\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.54055\n",
      "Epoch 115/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.8250 - fbeta: 0.7110 - val_loss: 2.0523 - val_fbeta: 0.2947\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.54055\n",
      "Epoch 116/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.8839 - fbeta: 0.7065 - val_loss: 1.9557 - val_fbeta: 0.3883\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1.54055\n",
      "Epoch 117/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0386 - fbeta: 0.6835 - val_loss: 1.6051 - val_fbeta: 0.4221\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.54055\n",
      "Epoch 118/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.8252 - fbeta: 0.7298 - val_loss: 1.6924 - val_fbeta: 0.5286\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.54055\n",
      "Epoch 119/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.8195 - fbeta: 0.7233 - val_loss: 2.1459 - val_fbeta: 0.3442\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.54055\n",
      "Epoch 120/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.7771 - fbeta: 0.7709 - val_loss: 1.5580 - val_fbeta: 0.5146\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.54055\n",
      "Epoch 121/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 0.8857 - fbeta: 0.7366 - val_loss: 2.4962 - val_fbeta: 0.2060\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.54055\n",
      "Epoch 122/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0910 - fbeta: 0.6960 - val_loss: 2.4967 - val_fbeta: 0.2163\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1.54055\n",
      "Epoch 123/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0135 - fbeta: 0.6800 - val_loss: 2.0403 - val_fbeta: 0.4020\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1.54055\n",
      "Epoch 124/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.7902 - fbeta: 0.7331 - val_loss: 1.5222 - val_fbeta: 0.5813\n",
      "\n",
      "Epoch 00124: val_loss improved from 1.54055 to 1.52224, saving model to model/model.w.best.h5\n",
      "Epoch 125/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.6873 - fbeta: 0.7996 - val_loss: 3.5962 - val_fbeta: 0.1740\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1.52224\n",
      "Epoch 126/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1307 - fbeta: 0.6574 - val_loss: 1.9246 - val_fbeta: 0.3866\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.52224\n",
      "Epoch 127/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.6881 - fbeta: 0.8001 - val_loss: 2.1486 - val_fbeta: 0.3443\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1.52224\n",
      "Epoch 128/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.8225 - fbeta: 0.7485 - val_loss: 1.9477 - val_fbeta: 0.3636\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1.52224\n",
      "Epoch 129/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.7588 - fbeta: 0.7772 - val_loss: 1.5433 - val_fbeta: 0.4800\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1.52224\n",
      "Epoch 130/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.7475 - fbeta: 0.7546 - val_loss: 2.5985 - val_fbeta: 0.2525\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1.52224\n",
      "Epoch 131/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.7128 - fbeta: 0.7815 - val_loss: 1.4079 - val_fbeta: 0.6351\n",
      "\n",
      "Epoch 00131: val_loss improved from 1.52224 to 1.40787, saving model to model/model.w.best.h5\n",
      "Epoch 132/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.6418 - fbeta: 0.8195 - val_loss: 1.3337 - val_fbeta: 0.5330\n",
      "\n",
      "Epoch 00132: val_loss improved from 1.40787 to 1.33370, saving model to model/model.w.best.h5\n",
      "Epoch 133/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.5975 - fbeta: 0.8195 - val_loss: 2.2478 - val_fbeta: 0.3514\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1.33370\n",
      "Epoch 134/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.6855 - fbeta: 0.7845 - val_loss: 1.1939 - val_fbeta: 0.5860\n",
      "\n",
      "Epoch 00134: val_loss improved from 1.33370 to 1.19386, saving model to model/model.w.best.h5\n",
      "Epoch 135/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.5208 - fbeta: 0.8393 - val_loss: 1.7566 - val_fbeta: 0.4666\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1.19386\n",
      "Epoch 136/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.7170 - fbeta: 0.7831 - val_loss: 1.6902 - val_fbeta: 0.4565\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1.19386\n",
      "Epoch 137/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.8891 - fbeta: 0.7455 - val_loss: 1.5321 - val_fbeta: 0.5870\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1.19386\n",
      "Epoch 138/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.4795 - fbeta: 0.8690 - val_loss: 2.4088 - val_fbeta: 0.3330\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1.19386\n",
      "Epoch 139/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.8000 - fbeta: 0.7664 - val_loss: 1.4595 - val_fbeta: 0.6233\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1.19386\n",
      "Epoch 140/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.5295 - fbeta: 0.8523 - val_loss: 0.9107 - val_fbeta: 0.7391\n",
      "\n",
      "Epoch 00140: val_loss improved from 1.19386 to 0.91072, saving model to model/model.w.best.h5\n",
      "Epoch 141/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.4212 - fbeta: 0.8949 - val_loss: 1.1113 - val_fbeta: 0.6548\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.91072\n",
      "Epoch 142/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.3373 - fbeta: 0.9221 - val_loss: 1.2895 - val_fbeta: 0.6296\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.91072\n",
      "Epoch 143/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.3988 - fbeta: 0.9079 - val_loss: 1.9516 - val_fbeta: 0.4858\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.91072\n",
      "Epoch 144/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.7558 - fbeta: 0.7852 - val_loss: 1.3123 - val_fbeta: 0.5755\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.91072\n",
      "Epoch 145/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.4726 - fbeta: 0.8610 - val_loss: 0.9512 - val_fbeta: 0.7315\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.91072\n",
      "Epoch 146/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.3534 - fbeta: 0.9087 - val_loss: 1.3262 - val_fbeta: 0.5526\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.91072\n",
      "Epoch 147/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.4363 - fbeta: 0.8788 - val_loss: 1.1369 - val_fbeta: 0.6649\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.91072\n",
      "Epoch 148/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.5912 - fbeta: 0.8425 - val_loss: 1.3406 - val_fbeta: 0.5829\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.91072\n",
      "Epoch 149/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.3842 - fbeta: 0.9021 - val_loss: 1.1068 - val_fbeta: 0.6951\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.91072\n",
      "Epoch 150/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.3670 - fbeta: 0.8930 - val_loss: 1.2104 - val_fbeta: 0.6548\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.91072\n",
      "Epoch 151/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.3352 - fbeta: 0.9170 - val_loss: 1.4407 - val_fbeta: 0.5774\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.91072\n",
      "Epoch 152/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.4432 - fbeta: 0.8859 - val_loss: 1.1506 - val_fbeta: 0.7004\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.91072\n",
      "Epoch 153/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.2862 - fbeta: 0.9342 - val_loss: 1.3053 - val_fbeta: 0.6165\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.91072\n",
      "Epoch 154/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.3155 - fbeta: 0.9187 - val_loss: 0.9668 - val_fbeta: 0.7325\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.91072\n",
      "Epoch 155/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.4033 - fbeta: 0.8912 - val_loss: 1.9052 - val_fbeta: 0.5045\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.91072\n",
      "Epoch 156/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4481 - fbeta: 0.7930 - val_loss: 1.3201 - val_fbeta: 0.6179\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.91072\n",
      "Epoch 157/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.4594 - fbeta: 0.8578 - val_loss: 1.0099 - val_fbeta: 0.7172\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.91072\n",
      "Epoch 158/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.2279 - fbeta: 0.9523 - val_loss: 0.8404 - val_fbeta: 0.8120\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.91072 to 0.84036, saving model to model/model.w.best.h5\n",
      "Epoch 159/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.2120 - fbeta: 0.9608 - val_loss: 0.7844 - val_fbeta: 0.8192\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.84036 to 0.78443, saving model to model/model.w.best.h5\n",
      "Epoch 160/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.1768 - fbeta: 0.9670 - val_loss: 0.7571 - val_fbeta: 0.7879\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.78443 to 0.75707, saving model to model/model.w.best.h5\n",
      "Epoch 161/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.1994 - fbeta: 0.9607 - val_loss: 1.4909 - val_fbeta: 0.5380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00161: val_loss did not improve from 0.75707\n",
      "Epoch 162/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5307 - fbeta: 0.7732 - val_loss: 2.3099 - val_fbeta: 0.3986\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.75707\n",
      "Epoch 163/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.6154 - fbeta: 0.8802 - val_loss: 1.4432 - val_fbeta: 0.5623\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.75707\n",
      "Epoch 164/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.3119 - fbeta: 0.9281 - val_loss: 1.1156 - val_fbeta: 0.7022\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.75707\n",
      "Epoch 165/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.2585 - fbeta: 0.9503 - val_loss: 0.9131 - val_fbeta: 0.7488\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.75707\n",
      "Epoch 166/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.1757 - fbeta: 0.9732 - val_loss: 0.6747 - val_fbeta: 0.8345\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.75707 to 0.67474, saving model to model/model.w.best.h5\n",
      "Epoch 167/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.1422 - fbeta: 0.9851 - val_loss: 0.9057 - val_fbeta: 0.6877\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.67474\n",
      "Epoch 168/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.4232 - fbeta: 0.8821 - val_loss: 1.0959 - val_fbeta: 0.7087\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.67474\n",
      "Epoch 169/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.3103 - fbeta: 0.9120 - val_loss: 0.7792 - val_fbeta: 0.7553\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.67474\n",
      "Epoch 170/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.1833 - fbeta: 0.9635 - val_loss: 0.7988 - val_fbeta: 0.7538\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.67474\n",
      "Epoch 171/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.2000 - fbeta: 0.9551 - val_loss: 1.5310 - val_fbeta: 0.5615\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.67474\n",
      "Epoch 172/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.6538 - fbeta: 0.8707 - val_loss: 1.5119 - val_fbeta: 0.5189\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.67474\n",
      "Epoch 173/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.3236 - fbeta: 0.9291 - val_loss: 1.2027 - val_fbeta: 0.6472\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.67474\n",
      "Epoch 174/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.2185 - fbeta: 0.9515 - val_loss: 0.5964 - val_fbeta: 0.8379\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.67474 to 0.59640, saving model to model/model.w.best.h5\n",
      "Epoch 175/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.1594 - fbeta: 0.9675 - val_loss: 0.6423 - val_fbeta: 0.8239\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.59640\n",
      "Epoch 176/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.1133 - fbeta: 0.9852 - val_loss: 0.5824 - val_fbeta: 0.8141\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.59640 to 0.58245, saving model to model/model.w.best.h5\n",
      "Epoch 177/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.1250 - fbeta: 0.9795 - val_loss: 0.5727 - val_fbeta: 0.8717\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.58245 to 0.57267, saving model to model/model.w.best.h5\n",
      "Epoch 178/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.1727 - fbeta: 0.9590 - val_loss: 2.0004 - val_fbeta: 0.4031\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.57267\n",
      "Epoch 179/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.9880 - fbeta: 0.8371 - val_loss: 1.9422 - val_fbeta: 0.6704\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.57267\n",
      "Epoch 180/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.6632 - fbeta: 0.9491 - val_loss: 1.7667 - val_fbeta: 0.8016\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.57267\n",
      "Epoch 181/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.6589 - fbeta: 0.9403 - val_loss: 1.6121 - val_fbeta: 0.8550\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.57267\n",
      "Epoch 182/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.5954 - fbeta: 0.9677 - val_loss: 1.9893 - val_fbeta: 0.6721\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.57267\n",
      "Epoch 183/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.7833 - fbeta: 0.9099 - val_loss: 1.9286 - val_fbeta: 0.6581\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.57267\n",
      "Epoch 184/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.6360 - fbeta: 0.9533 - val_loss: 1.6846 - val_fbeta: 0.8391\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.57267\n",
      "Epoch 185/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.6962 - fbeta: 0.9232 - val_loss: 1.9485 - val_fbeta: 0.7718\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.57267\n",
      "Epoch 186/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.6276 - fbeta: 0.9616 - val_loss: 1.8723 - val_fbeta: 0.7450\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.57267\n",
      "Epoch 187/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.7862 - fbeta: 0.9000 - val_loss: 2.6498 - val_fbeta: 0.6260\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.57267\n",
      "Epoch 188/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.6898 - fbeta: 0.9420 - val_loss: 1.4428 - val_fbeta: 0.8833\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.57267\n",
      "Epoch 189/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.2334 - fbeta: 0.9502 - val_loss: 1.2527 - val_fbeta: 0.6254\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.57267\n",
      "Epoch 190/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.2128 - fbeta: 0.9506 - val_loss: 1.0404 - val_fbeta: 0.5978\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.57267\n",
      "Epoch 191/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.4295 - fbeta: 0.8882 - val_loss: 0.8685 - val_fbeta: 0.7678\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.57267\n",
      "Epoch 192/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.1432 - fbeta: 0.9694 - val_loss: 0.5605 - val_fbeta: 0.8981\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.57267 to 0.56045, saving model to model/model.w.best.h5\n",
      "Epoch 193/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0589 - fbeta: 0.9951 - val_loss: 0.4497 - val_fbeta: 0.9190\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.56045 to 0.44966, saving model to model/model.w.best.h5\n",
      "Epoch 194/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0647 - fbeta: 0.9958 - val_loss: 0.5597 - val_fbeta: 0.8957\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.44966\n",
      "Epoch 195/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0560 - fbeta: 0.9967 - val_loss: 0.4810 - val_fbeta: 0.9038\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.44966\n",
      "Epoch 196/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0524 - fbeta: 0.9967 - val_loss: 0.4070 - val_fbeta: 0.9412\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.44966 to 0.40701, saving model to model/model.w.best.h5\n",
      "Epoch 197/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0462 - fbeta: 0.9984 - val_loss: 0.5201 - val_fbeta: 0.8892\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.40701\n",
      "Epoch 198/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0403 - fbeta: 0.9992 - val_loss: 0.4846 - val_fbeta: 0.9026\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.40701\n",
      "Epoch 199/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0352 - fbeta: 0.9992 - val_loss: 0.5133 - val_fbeta: 0.9024\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.40701\n",
      "Epoch 200/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0537 - fbeta: 0.9951 - val_loss: 0.4893 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.40701\n",
      "Epoch 201/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0351 - fbeta: 1.0000 - val_loss: 0.5261 - val_fbeta: 0.8846\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.40701\n",
      "Epoch 202/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0354 - fbeta: 1.0000 - val_loss: 0.4071 - val_fbeta: 0.9319\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.40701\n",
      "Epoch 203/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0287 - fbeta: 1.0000 - val_loss: 0.4486 - val_fbeta: 0.9024\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.40701\n",
      "Epoch 204/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0286 - fbeta: 1.0000 - val_loss: 0.4840 - val_fbeta: 0.8825\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.40701\n",
      "Epoch 205/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0271 - fbeta: 1.0000 - val_loss: 0.3950 - val_fbeta: 0.9331\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.40701 to 0.39496, saving model to model/model.w.best.h5\n",
      "Epoch 206/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0280 - fbeta: 1.0000 - val_loss: 0.4546 - val_fbeta: 0.9412\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.39496\n",
      "Epoch 207/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0248 - fbeta: 1.0000 - val_loss: 0.4921 - val_fbeta: 0.8957\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.39496\n",
      "Epoch 208/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0243 - fbeta: 1.0000 - val_loss: 0.5253 - val_fbeta: 0.9100\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.39496\n",
      "Epoch 209/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0232 - fbeta: 1.0000 - val_loss: 0.4131 - val_fbeta: 0.9034\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.39496\n",
      "Epoch 210/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0257 - fbeta: 1.0000 - val_loss: 0.4997 - val_fbeta: 0.9045\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.39496\n",
      "Epoch 211/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0230 - fbeta: 1.0000 - val_loss: 0.4779 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.39496\n",
      "Epoch 212/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0231 - fbeta: 1.0000 - val_loss: 0.4578 - val_fbeta: 0.9265\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.39496\n",
      "Epoch 213/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0212 - fbeta: 1.0000 - val_loss: 0.4626 - val_fbeta: 0.8895\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.39496\n",
      "Epoch 214/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0208 - fbeta: 1.0000 - val_loss: 0.4899 - val_fbeta: 0.9258\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.39496\n",
      "Epoch 215/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0220 - fbeta: 1.0000 - val_loss: 0.4980 - val_fbeta: 0.9043\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.39496\n",
      "Epoch 216/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0192 - fbeta: 1.0000 - val_loss: 0.4483 - val_fbeta: 0.9121\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.39496\n",
      "Epoch 217/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0200 - fbeta: 1.0000 - val_loss: 0.4933 - val_fbeta: 0.9188\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.39496\n",
      "Epoch 218/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0186 - fbeta: 1.0000 - val_loss: 0.4312 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.39496\n",
      "Epoch 219/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0178 - fbeta: 1.0000 - val_loss: 0.4629 - val_fbeta: 0.9265\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.39496\n",
      "Epoch 220/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0166 - fbeta: 1.0000 - val_loss: 0.4851 - val_fbeta: 0.9130\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.39496\n",
      "Epoch 221/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0196 - fbeta: 1.0000 - val_loss: 0.4226 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.39496\n",
      "Epoch 222/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0199 - fbeta: 1.0000 - val_loss: 0.4800 - val_fbeta: 0.9198\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.39496\n",
      "Epoch 223/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0162 - fbeta: 1.0000 - val_loss: 0.4780 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.39496\n",
      "Epoch 224/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0170 - fbeta: 1.0000 - val_loss: 0.4621 - val_fbeta: 0.9212\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.39496\n",
      "Epoch 225/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0162 - fbeta: 1.0000 - val_loss: 0.4325 - val_fbeta: 0.9192\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.39496\n",
      "Epoch 226/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0181 - fbeta: 1.0000 - val_loss: 0.4565 - val_fbeta: 0.9259\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.39496\n",
      "Epoch 227/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0156 - fbeta: 1.0000 - val_loss: 0.4789 - val_fbeta: 0.9265\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.39496\n",
      "Epoch 228/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0159 - fbeta: 1.0000 - val_loss: 0.4683 - val_fbeta: 0.9412\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.39496\n",
      "Epoch 229/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0151 - fbeta: 1.0000 - val_loss: 0.4810 - val_fbeta: 0.9198\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.39496\n",
      "Epoch 230/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0140 - fbeta: 1.0000 - val_loss: 0.4530 - val_fbeta: 0.9344\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.39496\n",
      "Epoch 231/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0139 - fbeta: 1.0000 - val_loss: 0.4510 - val_fbeta: 0.9127\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.39496\n",
      "Epoch 232/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0132 - fbeta: 1.0000 - val_loss: 0.4728 - val_fbeta: 0.9280\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.39496\n",
      "Epoch 233/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0133 - fbeta: 1.0000 - val_loss: 0.4330 - val_fbeta: 0.9408\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.39496\n",
      "Epoch 234/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0134 - fbeta: 1.0000 - val_loss: 0.4556 - val_fbeta: 0.9259\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.39496\n",
      "Epoch 235/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0143 - fbeta: 1.0000 - val_loss: 0.4479 - val_fbeta: 0.9412\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.39496\n",
      "Epoch 236/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0132 - fbeta: 1.0000 - val_loss: 0.4398 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.39496\n",
      "Epoch 237/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0126 - fbeta: 1.0000 - val_loss: 0.4399 - val_fbeta: 0.9280\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.39496\n",
      "Epoch 238/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0120 - fbeta: 1.0000 - val_loss: 0.5057 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.39496\n",
      "Epoch 239/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0123 - fbeta: 1.0000 - val_loss: 0.4771 - val_fbeta: 0.9265\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.39496\n",
      "Epoch 240/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0117 - fbeta: 1.0000 - val_loss: 0.5052 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.39496\n",
      "Epoch 241/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0244 - fbeta: 0.9967 - val_loss: 0.4696 - val_fbeta: 0.9412\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.39496\n",
      "Epoch 242/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0125 - fbeta: 1.0000 - val_loss: 0.4835 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.39496\n",
      "Epoch 243/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0116 - fbeta: 1.0000 - val_loss: 0.4611 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.39496\n",
      "Epoch 244/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0113 - fbeta: 1.0000 - val_loss: 0.4620 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.39496\n",
      "Epoch 245/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0109 - fbeta: 1.0000 - val_loss: 0.4608 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.39496\n",
      "Epoch 246/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0108 - fbeta: 1.0000 - val_loss: 0.4859 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.39496\n",
      "Epoch 247/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0104 - fbeta: 1.0000 - val_loss: 0.4843 - val_fbeta: 0.9066\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.39496\n",
      "Epoch 248/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0111 - fbeta: 1.0000 - val_loss: 0.4594 - val_fbeta: 0.9344\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.39496\n",
      "Epoch 249/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0101 - fbeta: 1.0000 - val_loss: 0.4900 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.39496\n",
      "Epoch 250/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0101 - fbeta: 1.0000 - val_loss: 0.4471 - val_fbeta: 0.9282\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.39496\n",
      "Epoch 251/5000\n",
      "622/622 [==============================] - 25s 41ms/step - loss: 0.0102 - fbeta: 1.0000 - val_loss: 0.4515 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.39496\n",
      "Epoch 252/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0106 - fbeta: 1.0000 - val_loss: 0.4653 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.39496\n",
      "Epoch 253/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0104 - fbeta: 1.0000 - val_loss: 0.4686 - val_fbeta: 0.9130\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.39496\n",
      "Epoch 254/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0099 - fbeta: 1.0000 - val_loss: 0.4433 - val_fbeta: 0.9412\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.39496\n",
      "Epoch 255/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0112 - fbeta: 1.0000 - val_loss: 0.4657 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.39496\n",
      "Epoch 256/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0096 - fbeta: 1.0000 - val_loss: 0.4839 - val_fbeta: 0.9128\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.39496\n",
      "Epoch 257/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0098 - fbeta: 1.0000 - val_loss: 0.4837 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.39496\n",
      "Epoch 258/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0090 - fbeta: 1.0000 - val_loss: 0.4781 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.39496\n",
      "Epoch 259/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0090 - fbeta: 1.0000 - val_loss: 0.5048 - val_fbeta: 0.9280\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.39496\n",
      "Epoch 260/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0095 - fbeta: 1.0000 - val_loss: 0.4593 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.39496\n",
      "Epoch 261/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0090 - fbeta: 1.0000 - val_loss: 0.4581 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.39496\n",
      "Epoch 262/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0085 - fbeta: 1.0000 - val_loss: 0.5155 - val_fbeta: 0.9280\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.39496\n",
      "Epoch 263/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0090 - fbeta: 1.0000 - val_loss: 0.4716 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.39496\n",
      "Epoch 264/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0083 - fbeta: 1.0000 - val_loss: 0.4822 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.39496\n",
      "Epoch 265/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0083 - fbeta: 1.0000 - val_loss: 0.4569 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.39496\n",
      "Epoch 266/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0083 - fbeta: 1.0000 - val_loss: 0.5035 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.39496\n",
      "Epoch 267/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0089 - fbeta: 1.0000 - val_loss: 0.4509 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.39496\n",
      "Epoch 268/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0082 - fbeta: 1.0000 - val_loss: 0.4746 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.39496\n",
      "Epoch 269/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0089 - fbeta: 1.0000 - val_loss: 0.4841 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.39496\n",
      "Epoch 270/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0079 - fbeta: 1.0000 - val_loss: 0.4850 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.39496\n",
      "Epoch 271/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0078 - fbeta: 1.0000 - val_loss: 0.4578 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.39496\n",
      "Epoch 272/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0077 - fbeta: 1.0000 - val_loss: 0.4486 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.39496\n",
      "Epoch 273/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0077 - fbeta: 1.0000 - val_loss: 0.4887 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.39496\n",
      "Epoch 274/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0081 - fbeta: 1.0000 - val_loss: 0.4895 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.39496\n",
      "Epoch 275/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0074 - fbeta: 1.0000 - val_loss: 0.4865 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.39496\n",
      "Epoch 276/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0074 - fbeta: 1.0000 - val_loss: 0.4879 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.39496\n",
      "Epoch 277/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0075 - fbeta: 1.0000 - val_loss: 0.4878 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.39496\n",
      "Epoch 278/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0072 - fbeta: 1.0000 - val_loss: 0.5139 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.39496\n",
      "Epoch 279/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0078 - fbeta: 1.0000 - val_loss: 0.4743 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.39496\n",
      "Epoch 280/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0070 - fbeta: 1.0000 - val_loss: 0.4754 - val_fbeta: 0.9273\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.39496\n",
      "Epoch 281/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0074 - fbeta: 1.0000 - val_loss: 0.5027 - val_fbeta: 0.9280\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.39496\n",
      "Epoch 282/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0071 - fbeta: 1.0000 - val_loss: 0.4916 - val_fbeta: 0.9280\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.39496\n",
      "Epoch 283/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0068 - fbeta: 1.0000 - val_loss: 0.4853 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.39496\n",
      "Epoch 284/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0067 - fbeta: 1.0000 - val_loss: 0.4938 - val_fbeta: 0.9273\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.39496\n",
      "Epoch 285/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0067 - fbeta: 1.0000 - val_loss: 0.4915 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.39496\n",
      "Epoch 286/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0074 - fbeta: 1.0000 - val_loss: 0.4976 - val_fbeta: 0.9192\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.39496\n",
      "Epoch 287/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0064 - fbeta: 1.0000 - val_loss: 0.5024 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.39496\n",
      "Epoch 288/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0066 - fbeta: 1.0000 - val_loss: 0.5042 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.39496\n",
      "Epoch 289/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0064 - fbeta: 1.0000 - val_loss: 0.4984 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.39496\n",
      "Epoch 290/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0064 - fbeta: 1.0000 - val_loss: 0.4664 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.39496\n",
      "Epoch 291/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0064 - fbeta: 1.0000 - val_loss: 0.4801 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.39496\n",
      "Epoch 292/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0063 - fbeta: 1.0000 - val_loss: 0.4998 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.39496\n",
      "Epoch 293/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0060 - fbeta: 1.0000 - val_loss: 0.4567 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.39496\n",
      "Epoch 294/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0067 - fbeta: 1.0000 - val_loss: 0.4660 - val_fbeta: 0.9273\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.39496\n",
      "Epoch 295/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0062 - fbeta: 1.0000 - val_loss: 0.4858 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.39496\n",
      "Epoch 296/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0061 - fbeta: 1.0000 - val_loss: 0.4779 - val_fbeta: 0.9273\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.39496\n",
      "Epoch 297/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0060 - fbeta: 1.0000 - val_loss: 0.4909 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.39496\n",
      "Epoch 298/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0060 - fbeta: 1.0000 - val_loss: 0.5047 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.39496\n",
      "Epoch 299/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0063 - fbeta: 1.0000 - val_loss: 0.4967 - val_fbeta: 0.9344\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.39496\n",
      "Epoch 300/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0060 - fbeta: 1.0000 - val_loss: 0.4956 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.39496\n",
      "Epoch 301/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0058 - fbeta: 1.0000 - val_loss: 0.4848 - val_fbeta: 0.9344\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.39496\n",
      "Epoch 302/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0058 - fbeta: 1.0000 - val_loss: 0.4912 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.39496\n",
      "Epoch 303/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0058 - fbeta: 1.0000 - val_loss: 0.4885 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.39496\n",
      "Epoch 304/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0056 - fbeta: 1.0000 - val_loss: 0.4876 - val_fbeta: 0.9280\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.39496\n",
      "Epoch 305/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0056 - fbeta: 1.0000 - val_loss: 0.4832 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.39496\n",
      "Epoch 306/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0055 - fbeta: 1.0000 - val_loss: 0.4880 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.39496\n",
      "Epoch 307/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0055 - fbeta: 1.0000 - val_loss: 0.4812 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.39496\n",
      "Epoch 308/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0054 - fbeta: 1.0000 - val_loss: 0.5174 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.39496\n",
      "Epoch 309/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0054 - fbeta: 1.0000 - val_loss: 0.5011 - val_fbeta: 0.9280\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.39496\n",
      "Epoch 310/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0055 - fbeta: 1.0000 - val_loss: 0.4879 - val_fbeta: 0.9273\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.39496\n",
      "Epoch 311/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0055 - fbeta: 1.0000 - val_loss: 0.5016 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.39496\n",
      "Epoch 312/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0052 - fbeta: 1.0000 - val_loss: 0.4900 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.39496\n",
      "Epoch 313/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0053 - fbeta: 1.0000 - val_loss: 0.5005 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.39496\n",
      "Epoch 314/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0053 - fbeta: 1.0000 - val_loss: 0.5303 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.39496\n",
      "Epoch 315/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0053 - fbeta: 1.0000 - val_loss: 0.5000 - val_fbeta: 0.9143\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.39496\n",
      "Epoch 316/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0054 - fbeta: 1.0000 - val_loss: 0.4806 - val_fbeta: 0.9211\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.39496\n",
      "Epoch 317/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0053 - fbeta: 1.0000 - val_loss: 0.4954 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.39496\n",
      "Epoch 318/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0054 - fbeta: 1.0000 - val_loss: 0.5112 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.39496\n",
      "Epoch 319/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0051 - fbeta: 1.0000 - val_loss: 0.5102 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.39496\n",
      "Epoch 320/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0050 - fbeta: 1.0000 - val_loss: 0.5172 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.39496\n",
      "Epoch 321/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0051 - fbeta: 1.0000 - val_loss: 0.4971 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.39496\n",
      "Epoch 322/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0049 - fbeta: 1.0000 - val_loss: 0.5232 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.39496\n",
      "Epoch 323/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0049 - fbeta: 1.0000 - val_loss: 0.5013 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.39496\n",
      "Epoch 324/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0049 - fbeta: 1.0000 - val_loss: 0.4989 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.39496\n",
      "Epoch 325/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0111 - fbeta: 0.9992 - val_loss: 0.4848 - val_fbeta: 0.8899\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.39496\n",
      "Epoch 326/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0064 - fbeta: 1.0000 - val_loss: 0.5098 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.39496\n",
      "Epoch 327/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0047 - fbeta: 1.0000 - val_loss: 0.5187 - val_fbeta: 0.9212\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.39496\n",
      "Epoch 328/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0051 - fbeta: 1.0000 - val_loss: 0.4942 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.39496\n",
      "Epoch 329/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0053 - fbeta: 1.0000 - val_loss: 0.4983 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.39496\n",
      "Epoch 330/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0046 - fbeta: 1.0000 - val_loss: 0.4938 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.39496\n",
      "Epoch 331/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0046 - fbeta: 1.0000 - val_loss: 0.5054 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.39496\n",
      "Epoch 332/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0045 - fbeta: 1.0000 - val_loss: 0.5167 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.39496\n",
      "Epoch 333/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0045 - fbeta: 1.0000 - val_loss: 0.5072 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.39496\n",
      "Epoch 334/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0045 - fbeta: 1.0000 - val_loss: 0.5103 - val_fbeta: 0.9273\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.39496\n",
      "Epoch 335/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0044 - fbeta: 1.0000 - val_loss: 0.5038 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.39496\n",
      "Epoch 336/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0044 - fbeta: 1.0000 - val_loss: 0.5098 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.39496\n",
      "Epoch 337/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0043 - fbeta: 1.0000 - val_loss: 0.5236 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.39496\n",
      "Epoch 338/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0044 - fbeta: 1.0000 - val_loss: 0.5094 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.39496\n",
      "Epoch 339/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0043 - fbeta: 1.0000 - val_loss: 0.4945 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.39496\n",
      "Epoch 340/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0043 - fbeta: 1.0000 - val_loss: 0.5022 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.39496\n",
      "Epoch 341/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0042 - fbeta: 1.0000 - val_loss: 0.5124 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.39496\n",
      "Epoch 342/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0042 - fbeta: 1.0000 - val_loss: 0.5105 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.39496\n",
      "Epoch 343/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0042 - fbeta: 1.0000 - val_loss: 0.5162 - val_fbeta: 0.9211\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.39496\n",
      "Epoch 344/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0042 - fbeta: 1.0000 - val_loss: 0.5095 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.39496\n",
      "Epoch 345/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0042 - fbeta: 1.0000 - val_loss: 0.5190 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.39496\n",
      "Epoch 346/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0041 - fbeta: 1.0000 - val_loss: 0.5124 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.39496\n",
      "Epoch 347/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0041 - fbeta: 1.0000 - val_loss: 0.4988 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.39496\n",
      "Epoch 348/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0041 - fbeta: 1.0000 - val_loss: 0.5069 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.39496\n",
      "Epoch 349/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0041 - fbeta: 1.0000 - val_loss: 0.5092 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.39496\n",
      "Epoch 350/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0040 - fbeta: 1.0000 - val_loss: 0.4858 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.39496\n",
      "Epoch 351/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0040 - fbeta: 1.0000 - val_loss: 0.5093 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.39496\n",
      "Epoch 352/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0060 - fbeta: 1.0000 - val_loss: 0.5388 - val_fbeta: 0.9265\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.39496\n",
      "Epoch 353/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0041 - fbeta: 1.0000 - val_loss: 0.4951 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.39496\n",
      "Epoch 354/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0040 - fbeta: 1.0000 - val_loss: 0.5257 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.39496\n",
      "Epoch 355/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0040 - fbeta: 1.0000 - val_loss: 0.5029 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.39496\n",
      "Epoch 356/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0039 - fbeta: 1.0000 - val_loss: 0.5153 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.39496\n",
      "Epoch 357/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0038 - fbeta: 1.0000 - val_loss: 0.5069 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.39496\n",
      "Epoch 358/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0038 - fbeta: 1.0000 - val_loss: 0.5227 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.39496\n",
      "Epoch 359/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0038 - fbeta: 1.0000 - val_loss: 0.5115 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.39496\n",
      "Epoch 360/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0041 - fbeta: 1.0000 - val_loss: 0.5103 - val_fbeta: 0.9211\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.39496\n",
      "Epoch 361/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0038 - fbeta: 1.0000 - val_loss: 0.5311 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.39496\n",
      "Epoch 362/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0037 - fbeta: 1.0000 - val_loss: 0.5083 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.39496\n",
      "Epoch 363/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0037 - fbeta: 1.0000 - val_loss: 0.5184 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.39496\n",
      "Epoch 364/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0038 - fbeta: 1.0000 - val_loss: 0.5241 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.39496\n",
      "Epoch 365/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0037 - fbeta: 1.0000 - val_loss: 0.5067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.39496\n",
      "Epoch 366/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0036 - fbeta: 1.0000 - val_loss: 0.5308 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.39496\n",
      "Epoch 367/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0036 - fbeta: 1.0000 - val_loss: 0.5184 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.39496\n",
      "Epoch 368/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0037 - fbeta: 1.0000 - val_loss: 0.5334 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.39496\n",
      "Epoch 369/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0036 - fbeta: 1.0000 - val_loss: 0.5265 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.39496\n",
      "Epoch 370/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0036 - fbeta: 1.0000 - val_loss: 0.5057 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.39496\n",
      "Epoch 371/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0035 - fbeta: 1.0000 - val_loss: 0.5278 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.39496\n",
      "Epoch 372/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0035 - fbeta: 1.0000 - val_loss: 0.5157 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.39496\n",
      "Epoch 373/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0035 - fbeta: 1.0000 - val_loss: 0.5142 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.39496\n",
      "Epoch 374/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0035 - fbeta: 1.0000 - val_loss: 0.5112 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.39496\n",
      "Epoch 375/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0035 - fbeta: 1.0000 - val_loss: 0.5047 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.39496\n",
      "Epoch 376/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0034 - fbeta: 1.0000 - val_loss: 0.5247 - val_fbeta: 0.9273\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.39496\n",
      "Epoch 377/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0036 - fbeta: 1.0000 - val_loss: 0.4983 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.39496\n",
      "Epoch 378/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0035 - fbeta: 1.0000 - val_loss: 0.5366 - val_fbeta: 0.9342\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.39496\n",
      "Epoch 379/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0034 - fbeta: 1.0000 - val_loss: 0.5243 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.39496\n",
      "Epoch 380/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0033 - fbeta: 1.0000 - val_loss: 0.4977 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.39496\n",
      "Epoch 381/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0037 - fbeta: 1.0000 - val_loss: 0.5269 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.39496\n",
      "Epoch 382/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0033 - fbeta: 1.0000 - val_loss: 0.5136 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.39496\n",
      "Epoch 383/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0033 - fbeta: 1.0000 - val_loss: 0.5341 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.39496\n",
      "Epoch 384/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0033 - fbeta: 1.0000 - val_loss: 0.5027 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.39496\n",
      "Epoch 385/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0033 - fbeta: 1.0000 - val_loss: 0.5111 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.39496\n",
      "Epoch 386/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0033 - fbeta: 1.0000 - val_loss: 0.5060 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.39496\n",
      "Epoch 387/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0033 - fbeta: 1.0000 - val_loss: 0.5305 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.39496\n",
      "Epoch 388/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0033 - fbeta: 1.0000 - val_loss: 0.5226 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.39496\n",
      "Epoch 389/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0032 - fbeta: 1.0000 - val_loss: 0.5215 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.39496\n",
      "Epoch 390/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0032 - fbeta: 1.0000 - val_loss: 0.5127 - val_fbeta: 0.9275\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.39496\n",
      "Epoch 391/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0032 - fbeta: 1.0000 - val_loss: 0.5177 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.39496\n",
      "Epoch 392/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0032 - fbeta: 1.0000 - val_loss: 0.5328 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.39496\n",
      "Epoch 393/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0032 - fbeta: 1.0000 - val_loss: 0.5148 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.39496\n",
      "Epoch 394/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0032 - fbeta: 1.0000 - val_loss: 0.5355 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.39496\n",
      "Epoch 395/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0032 - fbeta: 1.0000 - val_loss: 0.5230 - val_fbeta: 0.9211\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.39496\n",
      "Epoch 396/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0031 - fbeta: 1.0000 - val_loss: 0.5327 - val_fbeta: 0.9273\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.39496\n",
      "Epoch 397/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0031 - fbeta: 1.0000 - val_loss: 0.5213 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.39496\n",
      "Epoch 398/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0032 - fbeta: 1.0000 - val_loss: 0.5272 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.39496\n",
      "Epoch 399/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0031 - fbeta: 1.0000 - val_loss: 0.5280 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.39496\n",
      "Epoch 400/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0030 - fbeta: 1.0000 - val_loss: 0.5180 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.39496\n",
      "Epoch 401/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0031 - fbeta: 1.0000 - val_loss: 0.5359 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.39496\n",
      "Epoch 402/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0030 - fbeta: 1.0000 - val_loss: 0.5141 - val_fbeta: 0.9273\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.39496\n",
      "Epoch 403/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0030 - fbeta: 1.0000 - val_loss: 0.5337 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.39496\n",
      "Epoch 404/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0030 - fbeta: 1.0000 - val_loss: 0.5248 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.39496\n",
      "Epoch 405/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0030 - fbeta: 1.0000 - val_loss: 0.5376 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.39496\n",
      "Epoch 406/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0030 - fbeta: 1.0000 - val_loss: 0.5260 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.39496\n",
      "Epoch 407/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0029 - fbeta: 1.0000 - val_loss: 0.5366 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.39496\n",
      "Epoch 408/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0029 - fbeta: 1.0000 - val_loss: 0.5402 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.39496\n",
      "Epoch 409/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0029 - fbeta: 1.0000 - val_loss: 0.5332 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.39496\n",
      "Epoch 410/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0030 - fbeta: 1.0000 - val_loss: 0.5133 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.39496\n",
      "Epoch 411/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0036 - fbeta: 1.0000 - val_loss: 0.5406 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.39496\n",
      "Epoch 412/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0029 - fbeta: 1.0000 - val_loss: 0.5274 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.39496\n",
      "Epoch 413/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0029 - fbeta: 1.0000 - val_loss: 0.5253 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.39496\n",
      "Epoch 414/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0028 - fbeta: 1.0000 - val_loss: 0.5521 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.39496\n",
      "Epoch 415/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0029 - fbeta: 1.0000 - val_loss: 0.5364 - val_fbeta: 0.9273\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.39496\n",
      "Epoch 416/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0028 - fbeta: 1.0000 - val_loss: 0.5331 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.39496\n",
      "Epoch 417/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0028 - fbeta: 1.0000 - val_loss: 0.5270 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.39496\n",
      "Epoch 418/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0029 - fbeta: 1.0000 - val_loss: 0.5458 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.39496\n",
      "Epoch 419/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0028 - fbeta: 1.0000 - val_loss: 0.5263 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.39496\n",
      "Epoch 420/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0028 - fbeta: 1.0000 - val_loss: 0.5316 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.39496\n",
      "Epoch 421/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0027 - fbeta: 1.0000 - val_loss: 0.5337 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.39496\n",
      "Epoch 422/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0027 - fbeta: 1.0000 - val_loss: 0.5215 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.39496\n",
      "Epoch 423/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0028 - fbeta: 1.0000 - val_loss: 0.5418 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.39496\n",
      "Epoch 424/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0028 - fbeta: 1.0000 - val_loss: 0.5222 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.39496\n",
      "Epoch 425/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0028 - fbeta: 1.0000 - val_loss: 0.5300 - val_fbeta: 0.9273\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.39496\n",
      "Epoch 426/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0027 - fbeta: 1.0000 - val_loss: 0.5296 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.39496\n",
      "Epoch 427/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0028 - fbeta: 1.0000 - val_loss: 0.5382 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.39496\n",
      "Epoch 428/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0032 - fbeta: 1.0000 - val_loss: 0.5321 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.39496\n",
      "Epoch 429/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0027 - fbeta: 1.0000 - val_loss: 0.5378 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.39496\n",
      "Epoch 430/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0027 - fbeta: 1.0000 - val_loss: 0.5309 - val_fbeta: 0.9211\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.39496\n",
      "Epoch 431/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0026 - fbeta: 1.0000 - val_loss: 0.5281 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.39496\n",
      "Epoch 432/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0026 - fbeta: 1.0000 - val_loss: 0.5273 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.39496\n",
      "Epoch 433/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0026 - fbeta: 1.0000 - val_loss: 0.5198 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.39496\n",
      "Epoch 434/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0026 - fbeta: 1.0000 - val_loss: 0.5438 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.39496\n",
      "Epoch 435/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0026 - fbeta: 1.0000 - val_loss: 0.5421 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.39496\n",
      "Epoch 436/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0025 - fbeta: 1.0000 - val_loss: 0.5365 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.39496\n",
      "Epoch 437/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0027 - fbeta: 1.0000 - val_loss: 0.5526 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.39496\n",
      "Epoch 438/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0026 - fbeta: 1.0000 - val_loss: 0.5221 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.39496\n",
      "Epoch 439/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0026 - fbeta: 1.0000 - val_loss: 0.5289 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.39496\n",
      "Epoch 440/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0025 - fbeta: 1.0000 - val_loss: 0.5342 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.39496\n",
      "Epoch 441/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0025 - fbeta: 1.0000 - val_loss: 0.5365 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.39496\n",
      "Epoch 442/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0025 - fbeta: 1.0000 - val_loss: 0.5419 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.39496\n",
      "Epoch 443/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0025 - fbeta: 1.0000 - val_loss: 0.5323 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.39496\n",
      "Epoch 444/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0025 - fbeta: 1.0000 - val_loss: 0.5387 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.39496\n",
      "Epoch 445/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0026 - fbeta: 1.0000 - val_loss: 0.5310 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.39496\n",
      "Epoch 446/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0025 - fbeta: 1.0000 - val_loss: 0.5268 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.39496\n",
      "Epoch 447/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0025 - fbeta: 1.0000 - val_loss: 0.5463 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.39496\n",
      "Epoch 448/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0024 - fbeta: 1.0000 - val_loss: 0.5225 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.39496\n",
      "Epoch 449/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0026 - fbeta: 1.0000 - val_loss: 0.5408 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.39496\n",
      "Epoch 450/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0024 - fbeta: 1.0000 - val_loss: 0.5393 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.39496\n",
      "Epoch 451/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0025 - fbeta: 1.0000 - val_loss: 0.5396 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.39496\n",
      "Epoch 452/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0025 - fbeta: 1.0000 - val_loss: 0.5407 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.39496\n",
      "Epoch 453/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0025 - fbeta: 1.0000 - val_loss: 0.5243 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.39496\n",
      "Epoch 454/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0024 - fbeta: 1.0000 - val_loss: 0.5412 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.39496\n",
      "Epoch 455/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0024 - fbeta: 1.0000 - val_loss: 0.5453 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.39496\n",
      "Epoch 456/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0024 - fbeta: 1.0000 - val_loss: 0.5365 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.39496\n",
      "Epoch 457/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0024 - fbeta: 1.0000 - val_loss: 0.5488 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.39496\n",
      "Epoch 458/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0023 - fbeta: 1.0000 - val_loss: 0.5389 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.39496\n",
      "Epoch 459/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0024 - fbeta: 1.0000 - val_loss: 0.5517 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.39496\n",
      "Epoch 460/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0023 - fbeta: 1.0000 - val_loss: 0.5409 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.39496\n",
      "Epoch 461/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0023 - fbeta: 1.0000 - val_loss: 0.5410 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.39496\n",
      "Epoch 462/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0023 - fbeta: 1.0000 - val_loss: 0.5320 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.39496\n",
      "Epoch 463/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0023 - fbeta: 1.0000 - val_loss: 0.5611 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.39496\n",
      "Epoch 464/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0024 - fbeta: 1.0000 - val_loss: 0.5326 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.39496\n",
      "Epoch 465/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0023 - fbeta: 1.0000 - val_loss: 0.5423 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.39496\n",
      "Epoch 466/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0025 - fbeta: 1.0000 - val_loss: 0.5323 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.39496\n",
      "Epoch 467/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0023 - fbeta: 1.0000 - val_loss: 0.5529 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.39496\n",
      "Epoch 468/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0023 - fbeta: 1.0000 - val_loss: 0.5279 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.39496\n",
      "Epoch 469/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0023 - fbeta: 1.0000 - val_loss: 0.5519 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.39496\n",
      "Epoch 470/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0023 - fbeta: 1.0000 - val_loss: 0.5503 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.39496\n",
      "Epoch 471/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0022 - fbeta: 1.0000 - val_loss: 0.5284 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.39496\n",
      "Epoch 472/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0023 - fbeta: 1.0000 - val_loss: 0.5536 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.39496\n",
      "Epoch 473/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0023 - fbeta: 1.0000 - val_loss: 0.5393 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.39496\n",
      "Epoch 474/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0022 - fbeta: 1.0000 - val_loss: 0.5399 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.39496\n",
      "Epoch 475/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0022 - fbeta: 1.0000 - val_loss: 0.5443 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.39496\n",
      "Epoch 476/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0022 - fbeta: 1.0000 - val_loss: 0.5413 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.39496\n",
      "Epoch 477/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0022 - fbeta: 1.0000 - val_loss: 0.5406 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.39496\n",
      "Epoch 478/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0022 - fbeta: 1.0000 - val_loss: 0.5457 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.39496\n",
      "Epoch 479/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0023 - fbeta: 1.0000 - val_loss: 0.5590 - val_fbeta: 0.9143\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.39496\n",
      "Epoch 480/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0024 - fbeta: 1.0000 - val_loss: 0.5559 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.39496\n",
      "Epoch 481/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0022 - fbeta: 1.0000 - val_loss: 0.5424 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.39496\n",
      "Epoch 482/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0022 - fbeta: 1.0000 - val_loss: 0.5451 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.39496\n",
      "Epoch 483/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0021 - fbeta: 1.0000 - val_loss: 0.5502 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.39496\n",
      "Epoch 484/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0022 - fbeta: 1.0000 - val_loss: 0.5317 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.39496\n",
      "Epoch 485/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0022 - fbeta: 1.0000 - val_loss: 0.5509 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.39496\n",
      "Epoch 486/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0021 - fbeta: 1.0000 - val_loss: 0.5323 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.39496\n",
      "Epoch 487/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0021 - fbeta: 1.0000 - val_loss: 0.5479 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.39496\n",
      "Epoch 488/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0021 - fbeta: 1.0000 - val_loss: 0.5345 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.39496\n",
      "Epoch 489/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0021 - fbeta: 1.0000 - val_loss: 0.5480 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.39496\n",
      "Epoch 490/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0021 - fbeta: 1.0000 - val_loss: 0.5554 - val_fbeta: 0.9273\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.39496\n",
      "Epoch 491/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0021 - fbeta: 1.0000 - val_loss: 0.5388 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.39496\n",
      "Epoch 492/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0023 - fbeta: 1.0000 - val_loss: 0.5409 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.39496\n",
      "Epoch 493/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0021 - fbeta: 1.0000 - val_loss: 0.5675 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.39496\n",
      "Epoch 494/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0021 - fbeta: 1.0000 - val_loss: 0.5397 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.39496\n",
      "Epoch 495/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0021 - fbeta: 1.0000 - val_loss: 0.5481 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.39496\n",
      "Epoch 496/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0020 - fbeta: 1.0000 - val_loss: 0.5439 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.39496\n",
      "Epoch 497/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0020 - fbeta: 1.0000 - val_loss: 0.5424 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.39496\n",
      "Epoch 498/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0020 - fbeta: 1.0000 - val_loss: 0.5403 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.39496\n",
      "Epoch 499/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0020 - fbeta: 1.0000 - val_loss: 0.5487 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.39496\n",
      "Epoch 500/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0020 - fbeta: 1.0000 - val_loss: 0.5458 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.39496\n",
      "Epoch 501/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0021 - fbeta: 1.0000 - val_loss: 0.5522 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.39496\n",
      "Epoch 502/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0020 - fbeta: 1.0000 - val_loss: 0.5461 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.39496\n",
      "Epoch 503/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0020 - fbeta: 1.0000 - val_loss: 0.5487 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.39496\n",
      "Epoch 504/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0020 - fbeta: 1.0000 - val_loss: 0.5551 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.39496\n",
      "Epoch 505/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0020 - fbeta: 1.0000 - val_loss: 0.5578 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.39496\n",
      "Epoch 506/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0021 - fbeta: 1.0000 - val_loss: 0.5463 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.39496\n",
      "Epoch 507/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0020 - fbeta: 1.0000 - val_loss: 0.5555 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.39496\n",
      "Epoch 508/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5468 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.39496\n",
      "Epoch 509/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0020 - fbeta: 1.0000 - val_loss: 0.5562 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.39496\n",
      "Epoch 510/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5549 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.39496\n",
      "Epoch 511/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5486 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.39496\n",
      "Epoch 512/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5472 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.39496\n",
      "Epoch 513/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5377 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.39496\n",
      "Epoch 514/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5492 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.39496\n",
      "Epoch 515/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5533 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.39496\n",
      "Epoch 516/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5557 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.39496\n",
      "Epoch 517/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5464 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.39496\n",
      "Epoch 518/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5538 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.39496\n",
      "Epoch 519/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5594 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.39496\n",
      "Epoch 520/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5523 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.39496\n",
      "Epoch 521/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5516 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.39496\n",
      "Epoch 522/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5556 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.39496\n",
      "Epoch 523/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5454 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.39496\n",
      "Epoch 524/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5498 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.39496\n",
      "Epoch 525/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5441 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.39496\n",
      "Epoch 526/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5547 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.39496\n",
      "Epoch 527/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0018 - fbeta: 1.0000 - val_loss: 0.5469 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.39496\n",
      "Epoch 528/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5472 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.39496\n",
      "Epoch 529/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5483 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.39496\n",
      "Epoch 530/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0018 - fbeta: 1.0000 - val_loss: 0.5513 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.39496\n",
      "Epoch 531/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0018 - fbeta: 1.0000 - val_loss: 0.5431 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.39496\n",
      "Epoch 532/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0018 - fbeta: 1.0000 - val_loss: 0.5533 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.39496\n",
      "Epoch 533/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0018 - fbeta: 1.0000 - val_loss: 0.5491 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.39496\n",
      "Epoch 534/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0019 - fbeta: 1.0000 - val_loss: 0.5447 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.39496\n",
      "Epoch 535/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0018 - fbeta: 1.0000 - val_loss: 0.5663 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.39496\n",
      "Epoch 536/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0018 - fbeta: 1.0000 - val_loss: 0.5539 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.39496\n",
      "Epoch 537/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0018 - fbeta: 1.0000 - val_loss: 0.5498 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.39496\n",
      "Epoch 538/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0018 - fbeta: 1.0000 - val_loss: 0.5489 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.39496\n",
      "Epoch 539/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0018 - fbeta: 1.0000 - val_loss: 0.5467 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.39496\n",
      "Epoch 540/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0018 - fbeta: 1.0000 - val_loss: 0.5537 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.39496\n",
      "Epoch 541/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0018 - fbeta: 1.0000 - val_loss: 0.5551 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.39496\n",
      "Epoch 542/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0018 - fbeta: 1.0000 - val_loss: 0.5524 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.39496\n",
      "Epoch 543/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0018 - fbeta: 1.0000 - val_loss: 0.5593 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.39496\n",
      "Epoch 544/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5575 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.39496\n",
      "Epoch 545/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0018 - fbeta: 1.0000 - val_loss: 0.5569 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.39496\n",
      "Epoch 546/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5624 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.39496\n",
      "Epoch 547/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5525 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.39496\n",
      "Epoch 548/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5468 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.39496\n",
      "Epoch 549/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5594 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.39496\n",
      "Epoch 550/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5667 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.39496\n",
      "Epoch 551/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5556 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.39496\n",
      "Epoch 552/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5619 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.39496\n",
      "Epoch 553/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5541 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.39496\n",
      "Epoch 554/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5550 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.39496\n",
      "Epoch 555/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5621 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.39496\n",
      "Epoch 556/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5634 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.39496\n",
      "Epoch 557/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5525 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.39496\n",
      "Epoch 558/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5737 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.39496\n",
      "Epoch 559/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5580 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.39496\n",
      "Epoch 560/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5684 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.39496\n",
      "Epoch 561/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5558 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.39496\n",
      "Epoch 562/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5564 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.39496\n",
      "Epoch 563/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5590 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.39496\n",
      "Epoch 564/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5536 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.39496\n",
      "Epoch 565/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5536 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.39496\n",
      "Epoch 566/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5626 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.39496\n",
      "Epoch 567/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5598 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.39496\n",
      "Epoch 568/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5611 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.39496\n",
      "Epoch 569/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5588 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.39496\n",
      "Epoch 570/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5588 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.39496\n",
      "Epoch 571/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5574 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.39496\n",
      "Epoch 572/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0017 - fbeta: 1.0000 - val_loss: 0.5758 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.39496\n",
      "Epoch 573/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5611 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.39496\n",
      "Epoch 574/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5605 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.39496\n",
      "Epoch 575/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5589 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.39496\n",
      "Epoch 576/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5578 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.39496\n",
      "Epoch 577/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5600 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.39496\n",
      "Epoch 578/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5610 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.39496\n",
      "Epoch 579/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5669 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.39496\n",
      "Epoch 580/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5619 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.39496\n",
      "Epoch 581/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5691 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.39496\n",
      "Epoch 582/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5686 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.39496\n",
      "Epoch 583/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5600 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.39496\n",
      "Epoch 584/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5600 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.39496\n",
      "Epoch 585/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5524 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.39496\n",
      "Epoch 586/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5661 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.39496\n",
      "Epoch 587/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5683 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.39496\n",
      "Epoch 588/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5708 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.39496\n",
      "Epoch 589/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5607 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.39496\n",
      "Epoch 590/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5645 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.39496\n",
      "Epoch 591/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5627 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.39496\n",
      "Epoch 592/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5672 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.39496\n",
      "Epoch 593/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5643 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.39496\n",
      "Epoch 594/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5677 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.39496\n",
      "Epoch 595/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5616 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.39496\n",
      "Epoch 596/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5674 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.39496\n",
      "Epoch 597/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5731 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.39496\n",
      "Epoch 598/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5606 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.39496\n",
      "Epoch 599/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5689 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.39496\n",
      "Epoch 600/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5652 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.39496\n",
      "Epoch 601/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5648 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.39496\n",
      "Epoch 602/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5594 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.39496\n",
      "Epoch 603/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5638 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.39496\n",
      "Epoch 604/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5664 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.39496\n",
      "Epoch 605/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5625 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.39496\n",
      "Epoch 606/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5677 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.39496\n",
      "Epoch 607/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5622 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.39496\n",
      "Epoch 608/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5730 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.39496\n",
      "Epoch 609/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5574 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.39496\n",
      "Epoch 610/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5551 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.39496\n",
      "Epoch 611/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5674 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.39496\n",
      "Epoch 612/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0016 - fbeta: 1.0000 - val_loss: 0.5590 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.39496\n",
      "Epoch 613/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5541 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.39496\n",
      "Epoch 614/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0015 - fbeta: 1.0000 - val_loss: 0.5623 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.39496\n",
      "Epoch 615/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5701 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.39496\n",
      "Epoch 616/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5633 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.39496\n",
      "Epoch 617/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5582 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.39496\n",
      "Epoch 618/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5610 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.39496\n",
      "Epoch 619/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5627 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.39496\n",
      "Epoch 620/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5656 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.39496\n",
      "Epoch 621/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5635 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.39496\n",
      "Epoch 622/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5590 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.39496\n",
      "Epoch 623/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5631 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.39496\n",
      "Epoch 624/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5640 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.39496\n",
      "Epoch 625/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5662 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.39496\n",
      "Epoch 626/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5771 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.39496\n",
      "Epoch 627/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5600 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.39496\n",
      "Epoch 628/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5608 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.39496\n",
      "Epoch 629/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5664 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.39496\n",
      "Epoch 630/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5674 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.39496\n",
      "Epoch 631/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5655 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.39496\n",
      "Epoch 632/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5698 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.39496\n",
      "Epoch 633/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5620 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.39496\n",
      "Epoch 634/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5732 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.39496\n",
      "Epoch 635/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5681 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.39496\n",
      "Epoch 636/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5650 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.39496\n",
      "Epoch 637/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5712 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.39496\n",
      "Epoch 638/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5748 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.39496\n",
      "Epoch 639/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5732 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.39496\n",
      "Epoch 640/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5692 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.39496\n",
      "Epoch 641/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5731 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.39496\n",
      "Epoch 642/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5579 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.39496\n",
      "Epoch 643/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5621 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.39496\n",
      "Epoch 644/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5660 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.39496\n",
      "Epoch 645/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0014 - fbeta: 1.0000 - val_loss: 0.5657 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.39496\n",
      "Epoch 646/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5755 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.39496\n",
      "Epoch 647/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5728 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.39496\n",
      "Epoch 648/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5743 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.39496\n",
      "Epoch 649/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5702 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.39496\n",
      "Epoch 650/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5726 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.39496\n",
      "Epoch 651/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5707 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.39496\n",
      "Epoch 652/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5690 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.39496\n",
      "Epoch 653/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5696 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.39496\n",
      "Epoch 654/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5684 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.39496\n",
      "Epoch 655/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5666 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.39496\n",
      "Epoch 656/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5704 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.39496\n",
      "Epoch 657/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5812 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.39496\n",
      "Epoch 658/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5804 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.39496\n",
      "Epoch 659/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5708 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.39496\n",
      "Epoch 660/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5716 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.39496\n",
      "Epoch 661/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5764 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.39496\n",
      "Epoch 662/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5778 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.39496\n",
      "Epoch 663/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5617 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.39496\n",
      "Epoch 664/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5711 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.39496\n",
      "Epoch 665/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5671 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.39496\n",
      "Epoch 666/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5726 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.39496\n",
      "Epoch 667/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5755 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.39496\n",
      "Epoch 668/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5736 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.39496\n",
      "Epoch 669/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5674 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.39496\n",
      "Epoch 670/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5683 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.39496\n",
      "Epoch 671/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5737 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.39496\n",
      "Epoch 672/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5713 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.39496\n",
      "Epoch 673/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5704 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.39496\n",
      "Epoch 674/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5706 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.39496\n",
      "Epoch 675/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5717 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.39496\n",
      "Epoch 676/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5793 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.39496\n",
      "Epoch 677/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5784 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.39496\n",
      "Epoch 678/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5736 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.39496\n",
      "Epoch 679/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5776 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.39496\n",
      "Epoch 680/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0013 - fbeta: 1.0000 - val_loss: 0.5724 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.39496\n",
      "Epoch 681/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5768 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.39496\n",
      "Epoch 682/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5758 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.39496\n",
      "Epoch 683/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5717 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.39496\n",
      "Epoch 684/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5772 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.39496\n",
      "Epoch 685/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5720 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.39496\n",
      "Epoch 686/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5759 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.39496\n",
      "Epoch 687/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5787 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 0.39496\n",
      "Epoch 688/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5772 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.39496\n",
      "Epoch 689/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5694 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.39496\n",
      "Epoch 690/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5651 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.39496\n",
      "Epoch 691/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5730 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.39496\n",
      "Epoch 692/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5731 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.39496\n",
      "Epoch 693/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5739 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.39496\n",
      "Epoch 694/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5799 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.39496\n",
      "Epoch 695/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5663 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.39496\n",
      "Epoch 696/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5770 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.39496\n",
      "Epoch 697/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5782 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.39496\n",
      "Epoch 698/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5740 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.39496\n",
      "Epoch 699/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5810 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.39496\n",
      "Epoch 700/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5805 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.39496\n",
      "Epoch 701/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5769 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.39496\n",
      "Epoch 702/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5750 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.39496\n",
      "Epoch 703/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5723 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.39496\n",
      "Epoch 704/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5773 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.39496\n",
      "Epoch 705/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5710 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.39496\n",
      "Epoch 706/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5756 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.39496\n",
      "Epoch 707/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5724 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.39496\n",
      "Epoch 708/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5743 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.39496\n",
      "Epoch 709/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5815 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.39496\n",
      "Epoch 710/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5801 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.39496\n",
      "Epoch 711/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5734 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.39496\n",
      "Epoch 712/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5733 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.39496\n",
      "Epoch 713/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5827 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.39496\n",
      "Epoch 714/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5763 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.39496\n",
      "Epoch 715/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5811 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.39496\n",
      "Epoch 716/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5827 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.39496\n",
      "Epoch 717/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5831 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.39496\n",
      "Epoch 718/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5827 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.39496\n",
      "Epoch 719/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5801 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 0.39496\n",
      "Epoch 720/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5715 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 0.39496\n",
      "Epoch 721/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5756 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 0.39496\n",
      "Epoch 722/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5752 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.39496\n",
      "Epoch 723/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5743 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.39496\n",
      "Epoch 724/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5792 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.39496\n",
      "Epoch 725/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5767 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 0.39496\n",
      "Epoch 726/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5783 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 0.39496\n",
      "Epoch 727/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5833 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.39496\n",
      "Epoch 728/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5836 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.39496\n",
      "Epoch 729/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5828 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.39496\n",
      "Epoch 730/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5829 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 0.39496\n",
      "Epoch 731/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5740 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 0.39496\n",
      "Epoch 732/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5848 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.39496\n",
      "Epoch 733/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5829 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.39496\n",
      "Epoch 734/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0012 - fbeta: 1.0000 - val_loss: 0.5769 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.39496\n",
      "Epoch 735/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5825 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.39496\n",
      "Epoch 736/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5815 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.39496\n",
      "Epoch 737/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5778 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.39496\n",
      "Epoch 738/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5758 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.39496\n",
      "Epoch 739/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5831 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.39496\n",
      "Epoch 740/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5867 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 0.39496\n",
      "Epoch 741/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5811 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.39496\n",
      "Epoch 742/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5774 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.39496\n",
      "Epoch 743/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5764 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 0.39496\n",
      "Epoch 744/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5771 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 0.39496\n",
      "Epoch 745/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5853 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 0.39496\n",
      "Epoch 746/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5801 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 0.39496\n",
      "Epoch 747/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5804 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.39496\n",
      "Epoch 748/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5861 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 0.39496\n",
      "Epoch 749/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5799 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.39496\n",
      "Epoch 750/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5829 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.39496\n",
      "Epoch 751/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5899 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.39496\n",
      "Epoch 752/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5859 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.39496\n",
      "Epoch 753/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5809 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 0.39496\n",
      "Epoch 754/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5836 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.39496\n",
      "Epoch 755/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5895 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 0.39496\n",
      "Epoch 756/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5817 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 0.39496\n",
      "Epoch 757/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5805 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.39496\n",
      "Epoch 758/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5872 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.39496\n",
      "Epoch 759/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5818 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.39496\n",
      "Epoch 760/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0011 - fbeta: 1.0000 - val_loss: 0.5859 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 0.39496\n",
      "Epoch 761/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5875 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 0.39496\n",
      "Epoch 762/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5899 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 0.39496\n",
      "Epoch 763/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5841 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 0.39496\n",
      "Epoch 764/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5869 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 0.39496\n",
      "Epoch 765/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5879 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 0.39496\n",
      "Epoch 766/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5839 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 0.39496\n",
      "Epoch 767/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5864 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 0.39496\n",
      "Epoch 768/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5915 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 0.39496\n",
      "Epoch 769/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5894 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 0.39496\n",
      "Epoch 770/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5832 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 0.39496\n",
      "Epoch 771/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5893 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 0.39496\n",
      "Epoch 772/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5881 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 0.39496\n",
      "Epoch 773/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5854 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 0.39496\n",
      "Epoch 774/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5881 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 0.39496\n",
      "Epoch 775/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5853 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 0.39496\n",
      "Epoch 776/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5910 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 0.39496\n",
      "Epoch 777/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5890 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 0.39496\n",
      "Epoch 778/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5884 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 0.39496\n",
      "Epoch 779/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5832 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 0.39496\n",
      "Epoch 780/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9662e-04 - fbeta: 1.0000 - val_loss: 0.5889 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.39496\n",
      "Epoch 781/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9970e-04 - fbeta: 1.0000 - val_loss: 0.5872 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 0.39496\n",
      "Epoch 782/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5878 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 0.39496\n",
      "Epoch 783/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9610e-04 - fbeta: 1.0000 - val_loss: 0.5856 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 0.39496\n",
      "Epoch 784/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9650e-04 - fbeta: 1.0000 - val_loss: 0.5871 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 0.39496\n",
      "Epoch 785/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5853 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 0.39496\n",
      "Epoch 786/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9028e-04 - fbeta: 1.0000 - val_loss: 0.5831 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 0.39496\n",
      "Epoch 787/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9124e-04 - fbeta: 1.0000 - val_loss: 0.5860 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 0.39496\n",
      "Epoch 788/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8767e-04 - fbeta: 1.0000 - val_loss: 0.5913 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 0.39496\n",
      "Epoch 789/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8322e-04 - fbeta: 1.0000 - val_loss: 0.5799 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 0.39496\n",
      "Epoch 790/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 0.0010 - fbeta: 1.0000 - val_loss: 0.5868 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 0.39496\n",
      "Epoch 791/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8124e-04 - fbeta: 1.0000 - val_loss: 0.5929 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 0.39496\n",
      "Epoch 792/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7662e-04 - fbeta: 1.0000 - val_loss: 0.5898 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 0.39496\n",
      "Epoch 793/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7702e-04 - fbeta: 1.0000 - val_loss: 0.5896 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 0.39496\n",
      "Epoch 794/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7366e-04 - fbeta: 1.0000 - val_loss: 0.5933 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 0.39496\n",
      "Epoch 795/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7632e-04 - fbeta: 1.0000 - val_loss: 0.5913 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 0.39496\n",
      "Epoch 796/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7360e-04 - fbeta: 1.0000 - val_loss: 0.5907 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 0.39496\n",
      "Epoch 797/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7226e-04 - fbeta: 1.0000 - val_loss: 0.5847 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 0.39496\n",
      "Epoch 798/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6991e-04 - fbeta: 1.0000 - val_loss: 0.5855 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 0.39496\n",
      "Epoch 799/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7149e-04 - fbeta: 1.0000 - val_loss: 0.5855 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 0.39496\n",
      "Epoch 800/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6788e-04 - fbeta: 1.0000 - val_loss: 0.5931 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 0.39496\n",
      "Epoch 801/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7696e-04 - fbeta: 1.0000 - val_loss: 0.5932 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 0.39496\n",
      "Epoch 802/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6064e-04 - fbeta: 1.0000 - val_loss: 0.5887 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 0.39496\n",
      "Epoch 803/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6226e-04 - fbeta: 1.0000 - val_loss: 0.5894 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 0.39496\n",
      "Epoch 804/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5947e-04 - fbeta: 1.0000 - val_loss: 0.5938 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 0.39496\n",
      "Epoch 805/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5424e-04 - fbeta: 1.0000 - val_loss: 0.5953 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 0.39496\n",
      "Epoch 806/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5263e-04 - fbeta: 1.0000 - val_loss: 0.5846 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 0.39496\n",
      "Epoch 807/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6256e-04 - fbeta: 1.0000 - val_loss: 0.5860 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 0.39496\n",
      "Epoch 808/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5236e-04 - fbeta: 1.0000 - val_loss: 0.5895 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 0.39496\n",
      "Epoch 809/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5350e-04 - fbeta: 1.0000 - val_loss: 0.5885 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 0.39496\n",
      "Epoch 810/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5182e-04 - fbeta: 1.0000 - val_loss: 0.5919 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 0.39496\n",
      "Epoch 811/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4730e-04 - fbeta: 1.0000 - val_loss: 0.5851 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 0.39496\n",
      "Epoch 812/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4577e-04 - fbeta: 1.0000 - val_loss: 0.5891 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 0.39496\n",
      "Epoch 813/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4138e-04 - fbeta: 1.0000 - val_loss: 0.5832 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 0.39496\n",
      "Epoch 814/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3831e-04 - fbeta: 1.0000 - val_loss: 0.5917 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 0.39496\n",
      "Epoch 815/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4524e-04 - fbeta: 1.0000 - val_loss: 0.5907 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 0.39496\n",
      "Epoch 816/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3452e-04 - fbeta: 1.0000 - val_loss: 0.5913 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 0.39496\n",
      "Epoch 817/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3626e-04 - fbeta: 1.0000 - val_loss: 0.5814 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 0.39496\n",
      "Epoch 818/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7034e-04 - fbeta: 1.0000 - val_loss: 0.5844 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 0.39496\n",
      "Epoch 819/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3123e-04 - fbeta: 1.0000 - val_loss: 0.5859 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 0.39496\n",
      "Epoch 820/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4895e-04 - fbeta: 1.0000 - val_loss: 0.5923 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 0.39496\n",
      "Epoch 821/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3146e-04 - fbeta: 1.0000 - val_loss: 0.5933 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 0.39496\n",
      "Epoch 822/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3524e-04 - fbeta: 1.0000 - val_loss: 0.5897 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 0.39496\n",
      "Epoch 823/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3380e-04 - fbeta: 1.0000 - val_loss: 0.5863 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 0.39496\n",
      "Epoch 824/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2214e-04 - fbeta: 1.0000 - val_loss: 0.5933 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 0.39496\n",
      "Epoch 825/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2362e-04 - fbeta: 1.0000 - val_loss: 0.5844 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 0.39496\n",
      "Epoch 826/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2253e-04 - fbeta: 1.0000 - val_loss: 0.5870 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 0.39496\n",
      "Epoch 827/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2498e-04 - fbeta: 1.0000 - val_loss: 0.5921 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 0.39496\n",
      "Epoch 828/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.1512e-04 - fbeta: 1.0000 - val_loss: 0.5856 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 0.39496\n",
      "Epoch 829/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4832e-04 - fbeta: 1.0000 - val_loss: 0.5920 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 0.39496\n",
      "Epoch 830/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2482e-04 - fbeta: 1.0000 - val_loss: 0.5887 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 0.39496\n",
      "Epoch 831/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2595e-04 - fbeta: 1.0000 - val_loss: 0.5909 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 0.39496\n",
      "Epoch 832/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.1206e-04 - fbeta: 1.0000 - val_loss: 0.5937 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 0.39496\n",
      "Epoch 833/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.1013e-04 - fbeta: 1.0000 - val_loss: 0.5976 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 0.39496\n",
      "Epoch 834/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.0847e-04 - fbeta: 1.0000 - val_loss: 0.5917 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 0.39496\n",
      "Epoch 835/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.1121e-04 - fbeta: 1.0000 - val_loss: 0.5931 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 0.39496\n",
      "Epoch 836/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.0672e-04 - fbeta: 1.0000 - val_loss: 0.5905 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 0.39496\n",
      "Epoch 837/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.0146e-04 - fbeta: 1.0000 - val_loss: 0.5985 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 0.39496\n",
      "Epoch 838/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.0595e-04 - fbeta: 1.0000 - val_loss: 0.5942 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 0.39496\n",
      "Epoch 839/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.0260e-04 - fbeta: 1.0000 - val_loss: 0.5915 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 0.39496\n",
      "Epoch 840/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.0707e-04 - fbeta: 1.0000 - val_loss: 0.5924 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 0.39496\n",
      "Epoch 841/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.9766e-04 - fbeta: 1.0000 - val_loss: 0.5885 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 0.39496\n",
      "Epoch 842/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.9668e-04 - fbeta: 1.0000 - val_loss: 0.5853 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 0.39496\n",
      "Epoch 843/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.9818e-04 - fbeta: 1.0000 - val_loss: 0.5921 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 0.39496\n",
      "Epoch 844/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.9461e-04 - fbeta: 1.0000 - val_loss: 0.5954 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 0.39496\n",
      "Epoch 845/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.9605e-04 - fbeta: 1.0000 - val_loss: 0.5997 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 0.39496\n",
      "Epoch 846/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.9213e-04 - fbeta: 1.0000 - val_loss: 0.5979 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 0.39496\n",
      "Epoch 847/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.8807e-04 - fbeta: 1.0000 - val_loss: 0.6021 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 0.39496\n",
      "Epoch 848/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.8679e-04 - fbeta: 1.0000 - val_loss: 0.5949 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00848: val_loss did not improve from 0.39496\n",
      "Epoch 849/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.9173e-04 - fbeta: 1.0000 - val_loss: 0.5939 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 0.39496\n",
      "Epoch 850/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.8581e-04 - fbeta: 1.0000 - val_loss: 0.5947 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 0.39496\n",
      "Epoch 851/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.9031e-04 - fbeta: 1.0000 - val_loss: 0.5967 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 0.39496\n",
      "Epoch 852/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.7994e-04 - fbeta: 1.0000 - val_loss: 0.5902 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 0.39496\n",
      "Epoch 853/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.8206e-04 - fbeta: 1.0000 - val_loss: 0.5914 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 0.39496\n",
      "Epoch 854/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.9684e-04 - fbeta: 1.0000 - val_loss: 0.5965 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 0.39496\n",
      "Epoch 855/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.7616e-04 - fbeta: 1.0000 - val_loss: 0.5961 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 0.39496\n",
      "Epoch 856/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.7676e-04 - fbeta: 1.0000 - val_loss: 0.5927 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 0.39496\n",
      "Epoch 857/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.7614e-04 - fbeta: 1.0000 - val_loss: 0.6012 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 0.39496\n",
      "Epoch 858/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.7751e-04 - fbeta: 1.0000 - val_loss: 0.5938 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 0.39496\n",
      "Epoch 859/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.0537e-04 - fbeta: 1.0000 - val_loss: 0.5901 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 0.39496\n",
      "Epoch 860/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.7112e-04 - fbeta: 1.0000 - val_loss: 0.5929 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 0.39496\n",
      "Epoch 861/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.7403e-04 - fbeta: 1.0000 - val_loss: 0.5876 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 0.39496\n",
      "Epoch 862/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.6540e-04 - fbeta: 1.0000 - val_loss: 0.5933 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 0.39496\n",
      "Epoch 863/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.7031e-04 - fbeta: 1.0000 - val_loss: 0.5975 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 0.39496\n",
      "Epoch 864/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.6308e-04 - fbeta: 1.0000 - val_loss: 0.5912 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 0.39496\n",
      "Epoch 865/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.6411e-04 - fbeta: 1.0000 - val_loss: 0.5963 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 0.39496\n",
      "Epoch 866/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.5996e-04 - fbeta: 1.0000 - val_loss: 0.5933 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 0.39496\n",
      "Epoch 867/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.8469e-04 - fbeta: 1.0000 - val_loss: 0.5970 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 0.39496\n",
      "Epoch 868/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.6341e-04 - fbeta: 1.0000 - val_loss: 0.5959 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 0.39496\n",
      "Epoch 869/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.5674e-04 - fbeta: 1.0000 - val_loss: 0.5975 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 0.39496\n",
      "Epoch 870/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.7459e-04 - fbeta: 1.0000 - val_loss: 0.6002 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 0.39496\n",
      "Epoch 871/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.7911e-04 - fbeta: 1.0000 - val_loss: 0.5981 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 0.39496\n",
      "Epoch 872/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 8.5743e-04 - fbeta: 1.0000 - val_loss: 0.5994 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 0.39496\n",
      "Epoch 873/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.4854e-04 - fbeta: 1.0000 - val_loss: 0.5921 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 0.39496\n",
      "Epoch 874/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.4784e-04 - fbeta: 1.0000 - val_loss: 0.5944 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 0.39496\n",
      "Epoch 875/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.5222e-04 - fbeta: 1.0000 - val_loss: 0.5969 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 0.39496\n",
      "Epoch 876/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.6599e-04 - fbeta: 1.0000 - val_loss: 0.6011 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 0.39496\n",
      "Epoch 877/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.4533e-04 - fbeta: 1.0000 - val_loss: 0.5942 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 0.39496\n",
      "Epoch 878/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.5432e-04 - fbeta: 1.0000 - val_loss: 0.5995 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 0.39496\n",
      "Epoch 879/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.4480e-04 - fbeta: 1.0000 - val_loss: 0.5954 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 0.39496\n",
      "Epoch 880/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.3926e-04 - fbeta: 1.0000 - val_loss: 0.5974 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 0.39496\n",
      "Epoch 881/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.7299e-04 - fbeta: 1.0000 - val_loss: 0.6030 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 0.39496\n",
      "Epoch 882/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.4181e-04 - fbeta: 1.0000 - val_loss: 0.5988 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 0.39496\n",
      "Epoch 883/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.3667e-04 - fbeta: 1.0000 - val_loss: 0.5957 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 0.39496\n",
      "Epoch 884/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.3411e-04 - fbeta: 1.0000 - val_loss: 0.5997 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 0.39496\n",
      "Epoch 885/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.3180e-04 - fbeta: 1.0000 - val_loss: 0.5944 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 0.39496\n",
      "Epoch 886/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.3608e-04 - fbeta: 1.0000 - val_loss: 0.5990 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 0.39496\n",
      "Epoch 887/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.3349e-04 - fbeta: 1.0000 - val_loss: 0.5969 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 0.39496\n",
      "Epoch 888/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.3215e-04 - fbeta: 1.0000 - val_loss: 0.6004 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 0.39496\n",
      "Epoch 889/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.3423e-04 - fbeta: 1.0000 - val_loss: 0.5965 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 0.39496\n",
      "Epoch 890/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.2889e-04 - fbeta: 1.0000 - val_loss: 0.5997 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 0.39496\n",
      "Epoch 891/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.2704e-04 - fbeta: 1.0000 - val_loss: 0.5999 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 0.39496\n",
      "Epoch 892/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.2848e-04 - fbeta: 1.0000 - val_loss: 0.6012 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 0.39496\n",
      "Epoch 893/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.2683e-04 - fbeta: 1.0000 - val_loss: 0.5937 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 0.39496\n",
      "Epoch 894/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.2128e-04 - fbeta: 1.0000 - val_loss: 0.5949 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 0.39496\n",
      "Epoch 895/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.2044e-04 - fbeta: 1.0000 - val_loss: 0.5975 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 0.39496\n",
      "Epoch 896/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.2084e-04 - fbeta: 1.0000 - val_loss: 0.5934 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 0.39496\n",
      "Epoch 897/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.5009e-04 - fbeta: 1.0000 - val_loss: 0.5971 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 0.39496\n",
      "Epoch 898/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.1725e-04 - fbeta: 1.0000 - val_loss: 0.5987 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 0.39496\n",
      "Epoch 899/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.1778e-04 - fbeta: 1.0000 - val_loss: 0.6004 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 0.39496\n",
      "Epoch 900/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.1497e-04 - fbeta: 1.0000 - val_loss: 0.5996 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 0.39496\n",
      "Epoch 901/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.1370e-04 - fbeta: 1.0000 - val_loss: 0.6017 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 0.39496\n",
      "Epoch 902/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.1574e-04 - fbeta: 1.0000 - val_loss: 0.5980 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 0.39496\n",
      "Epoch 903/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.1214e-04 - fbeta: 1.0000 - val_loss: 0.6011 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 0.39496\n",
      "Epoch 904/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.1022e-04 - fbeta: 1.0000 - val_loss: 0.5950 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 0.39496\n",
      "Epoch 905/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.0688e-04 - fbeta: 1.0000 - val_loss: 0.6006 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 0.39496\n",
      "Epoch 906/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.1086e-04 - fbeta: 1.0000 - val_loss: 0.5924 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 0.39496\n",
      "Epoch 907/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.1213e-04 - fbeta: 1.0000 - val_loss: 0.5938 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 0.39496\n",
      "Epoch 908/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.0253e-04 - fbeta: 1.0000 - val_loss: 0.5966 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 0.39496\n",
      "Epoch 909/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.0445e-04 - fbeta: 1.0000 - val_loss: 0.5972 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 0.39496\n",
      "Epoch 910/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.9878e-04 - fbeta: 1.0000 - val_loss: 0.5971 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 0.39496\n",
      "Epoch 911/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.1691e-04 - fbeta: 1.0000 - val_loss: 0.6008 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 0.39496\n",
      "Epoch 912/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.0232e-04 - fbeta: 1.0000 - val_loss: 0.6013 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 0.39496\n",
      "Epoch 913/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 7.9907e-04 - fbeta: 1.0000 - val_loss: 0.6023 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 0.39496\n",
      "Epoch 914/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 8.0101e-04 - fbeta: 1.0000 - val_loss: 0.6060 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 0.39496\n",
      "Epoch 915/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.9883e-04 - fbeta: 1.0000 - val_loss: 0.6032 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 0.39496\n",
      "Epoch 916/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.9205e-04 - fbeta: 1.0000 - val_loss: 0.5967 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 0.39496\n",
      "Epoch 917/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.9048e-04 - fbeta: 1.0000 - val_loss: 0.6020 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 0.39496\n",
      "Epoch 918/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.9234e-04 - fbeta: 1.0000 - val_loss: 0.6022 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 0.39496\n",
      "Epoch 919/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.9195e-04 - fbeta: 1.0000 - val_loss: 0.6090 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 0.39496\n",
      "Epoch 920/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.8934e-04 - fbeta: 1.0000 - val_loss: 0.6056 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 0.39496\n",
      "Epoch 921/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.8765e-04 - fbeta: 1.0000 - val_loss: 0.6018 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 0.39496\n",
      "Epoch 922/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.8950e-04 - fbeta: 1.0000 - val_loss: 0.6022 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 0.39496\n",
      "Epoch 923/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.8764e-04 - fbeta: 1.0000 - val_loss: 0.6019 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 0.39496\n",
      "Epoch 924/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.8648e-04 - fbeta: 1.0000 - val_loss: 0.6021 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 0.39496\n",
      "Epoch 925/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.8950e-04 - fbeta: 1.0000 - val_loss: 0.6037 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 0.39496\n",
      "Epoch 926/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.8923e-04 - fbeta: 1.0000 - val_loss: 0.5997 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 0.39496\n",
      "Epoch 927/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.8431e-04 - fbeta: 1.0000 - val_loss: 0.6011 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 0.39496\n",
      "Epoch 928/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.8097e-04 - fbeta: 1.0000 - val_loss: 0.6015 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 0.39496\n",
      "Epoch 929/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.8157e-04 - fbeta: 1.0000 - val_loss: 0.6038 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 0.39496\n",
      "Epoch 930/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.7825e-04 - fbeta: 1.0000 - val_loss: 0.6051 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 0.39496\n",
      "Epoch 931/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.7844e-04 - fbeta: 1.0000 - val_loss: 0.6015 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 0.39496\n",
      "Epoch 932/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.7460e-04 - fbeta: 1.0000 - val_loss: 0.6027 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 0.39496\n",
      "Epoch 933/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.7584e-04 - fbeta: 1.0000 - val_loss: 0.6009 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 0.39496\n",
      "Epoch 934/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.7757e-04 - fbeta: 1.0000 - val_loss: 0.6009 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 0.39496\n",
      "Epoch 935/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.7514e-04 - fbeta: 1.0000 - val_loss: 0.6076 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 0.39496\n",
      "Epoch 936/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.6818e-04 - fbeta: 1.0000 - val_loss: 0.6002 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 0.39496\n",
      "Epoch 937/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.6872e-04 - fbeta: 1.0000 - val_loss: 0.5983 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 0.39496\n",
      "Epoch 938/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.7000e-04 - fbeta: 1.0000 - val_loss: 0.5973 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 0.39496\n",
      "Epoch 939/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.6875e-04 - fbeta: 1.0000 - val_loss: 0.5939 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 0.39496\n",
      "Epoch 940/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.6816e-04 - fbeta: 1.0000 - val_loss: 0.5966 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 0.39496\n",
      "Epoch 941/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.7053e-04 - fbeta: 1.0000 - val_loss: 0.5955 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 0.39496\n",
      "Epoch 942/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.6939e-04 - fbeta: 1.0000 - val_loss: 0.6022 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 0.39496\n",
      "Epoch 943/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.7578e-04 - fbeta: 1.0000 - val_loss: 0.6024 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 0.39496\n",
      "Epoch 944/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.7258e-04 - fbeta: 1.0000 - val_loss: 0.6014 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 0.39496\n",
      "Epoch 945/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.6190e-04 - fbeta: 1.0000 - val_loss: 0.6017 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 0.39496\n",
      "Epoch 946/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.6491e-04 - fbeta: 1.0000 - val_loss: 0.6030 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 0.39496\n",
      "Epoch 947/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.5866e-04 - fbeta: 1.0000 - val_loss: 0.6012 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 0.39496\n",
      "Epoch 948/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.5603e-04 - fbeta: 1.0000 - val_loss: 0.6028 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 0.39496\n",
      "Epoch 949/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.6031e-04 - fbeta: 1.0000 - val_loss: 0.6021 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 0.39496\n",
      "Epoch 950/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.6359e-04 - fbeta: 1.0000 - val_loss: 0.6033 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 0.39496\n",
      "Epoch 951/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.5446e-04 - fbeta: 1.0000 - val_loss: 0.6065 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 0.39496\n",
      "Epoch 952/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.5696e-04 - fbeta: 1.0000 - val_loss: 0.6037 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 0.39496\n",
      "Epoch 953/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.5095e-04 - fbeta: 1.0000 - val_loss: 0.6010 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 0.39496\n",
      "Epoch 954/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 7.5117e-04 - fbeta: 1.0000 - val_loss: 0.6028 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 0.39496\n",
      "Epoch 955/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.4981e-04 - fbeta: 1.0000 - val_loss: 0.6009 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 0.39496\n",
      "Epoch 956/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.5173e-04 - fbeta: 1.0000 - val_loss: 0.6008 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 0.39496\n",
      "Epoch 957/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.5021e-04 - fbeta: 1.0000 - val_loss: 0.6021 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 0.39496\n",
      "Epoch 958/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.4762e-04 - fbeta: 1.0000 - val_loss: 0.6001 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 0.39496\n",
      "Epoch 959/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.4428e-04 - fbeta: 1.0000 - val_loss: 0.6019 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 0.39496\n",
      "Epoch 960/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.4727e-04 - fbeta: 1.0000 - val_loss: 0.6021 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 0.39496\n",
      "Epoch 961/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.4716e-04 - fbeta: 1.0000 - val_loss: 0.6033 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 0.39496\n",
      "Epoch 962/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.4490e-04 - fbeta: 1.0000 - val_loss: 0.6029 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 0.39496\n",
      "Epoch 963/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.6199e-04 - fbeta: 1.0000 - val_loss: 0.6040 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 0.39496\n",
      "Epoch 964/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.4124e-04 - fbeta: 1.0000 - val_loss: 0.6053 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 0.39496\n",
      "Epoch 965/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.4329e-04 - fbeta: 1.0000 - val_loss: 0.6068 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 0.39496\n",
      "Epoch 966/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.4766e-04 - fbeta: 1.0000 - val_loss: 0.6028 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 0.39496\n",
      "Epoch 967/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.3813e-04 - fbeta: 1.0000 - val_loss: 0.6038 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 0.39496\n",
      "Epoch 968/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.3939e-04 - fbeta: 1.0000 - val_loss: 0.6067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 0.39496\n",
      "Epoch 969/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.4364e-04 - fbeta: 1.0000 - val_loss: 0.6082 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 0.39496\n",
      "Epoch 970/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.3363e-04 - fbeta: 1.0000 - val_loss: 0.6037 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 0.39496\n",
      "Epoch 971/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.3507e-04 - fbeta: 1.0000 - val_loss: 0.6039 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 0.39496\n",
      "Epoch 972/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.3344e-04 - fbeta: 1.0000 - val_loss: 0.6101 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 0.39496\n",
      "Epoch 973/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.2892e-04 - fbeta: 1.0000 - val_loss: 0.6061 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 0.39496\n",
      "Epoch 974/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.2757e-04 - fbeta: 1.0000 - val_loss: 0.6024 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 0.39496\n",
      "Epoch 975/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.3138e-04 - fbeta: 1.0000 - val_loss: 0.6023 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 0.39496\n",
      "Epoch 976/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.2768e-04 - fbeta: 1.0000 - val_loss: 0.5996 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 0.39496\n",
      "Epoch 977/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.3049e-04 - fbeta: 1.0000 - val_loss: 0.5990 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 0.39496\n",
      "Epoch 978/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.2508e-04 - fbeta: 1.0000 - val_loss: 0.6025 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 0.39496\n",
      "Epoch 979/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.2939e-04 - fbeta: 1.0000 - val_loss: 0.6040 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 0.39496\n",
      "Epoch 980/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.2179e-04 - fbeta: 1.0000 - val_loss: 0.6038 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 0.39496\n",
      "Epoch 981/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.2542e-04 - fbeta: 1.0000 - val_loss: 0.6037 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 0.39496\n",
      "Epoch 982/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.1773e-04 - fbeta: 1.0000 - val_loss: 0.6047 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 0.39496\n",
      "Epoch 983/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.1929e-04 - fbeta: 1.0000 - val_loss: 0.6074 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 0.39496\n",
      "Epoch 984/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.1920e-04 - fbeta: 1.0000 - val_loss: 0.6049 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00984: val_loss did not improve from 0.39496\n",
      "Epoch 985/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.1992e-04 - fbeta: 1.0000 - val_loss: 0.6038 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00985: val_loss did not improve from 0.39496\n",
      "Epoch 986/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.1381e-04 - fbeta: 1.0000 - val_loss: 0.6071 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00986: val_loss did not improve from 0.39496\n",
      "Epoch 987/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.1849e-04 - fbeta: 1.0000 - val_loss: 0.6079 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 0.39496\n",
      "Epoch 988/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.1123e-04 - fbeta: 1.0000 - val_loss: 0.6028 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 0.39496\n",
      "Epoch 989/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.1638e-04 - fbeta: 1.0000 - val_loss: 0.6052 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00989: val_loss did not improve from 0.39496\n",
      "Epoch 990/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.1173e-04 - fbeta: 1.0000 - val_loss: 0.6048 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 0.39496\n",
      "Epoch 991/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.1180e-04 - fbeta: 1.0000 - val_loss: 0.6052 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 0.39496\n",
      "Epoch 992/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.0993e-04 - fbeta: 1.0000 - val_loss: 0.6068 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00992: val_loss did not improve from 0.39496\n",
      "Epoch 993/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.1272e-04 - fbeta: 1.0000 - val_loss: 0.6064 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 0.39496\n",
      "Epoch 994/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.1172e-04 - fbeta: 1.0000 - val_loss: 0.6106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 0.39496\n",
      "Epoch 995/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 7.1181e-04 - fbeta: 1.0000 - val_loss: 0.6065 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 0.39496\n",
      "Epoch 996/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.0814e-04 - fbeta: 1.0000 - val_loss: 0.6088 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 0.39496\n",
      "Epoch 997/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.0745e-04 - fbeta: 1.0000 - val_loss: 0.6068 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 0.39496\n",
      "Epoch 998/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.0780e-04 - fbeta: 1.0000 - val_loss: 0.6030 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 0.39496\n",
      "Epoch 999/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.0515e-04 - fbeta: 1.0000 - val_loss: 0.5995 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 0.39496\n",
      "Epoch 1000/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.0366e-04 - fbeta: 1.0000 - val_loss: 0.6067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 0.39496\n",
      "Epoch 1001/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.0195e-04 - fbeta: 1.0000 - val_loss: 0.6050 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01001: val_loss did not improve from 0.39496\n",
      "Epoch 1002/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.0351e-04 - fbeta: 1.0000 - val_loss: 0.6059 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01002: val_loss did not improve from 0.39496\n",
      "Epoch 1003/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.9988e-04 - fbeta: 1.0000 - val_loss: 0.6040 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01003: val_loss did not improve from 0.39496\n",
      "Epoch 1004/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.1721e-04 - fbeta: 1.0000 - val_loss: 0.5963 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01004: val_loss did not improve from 0.39496\n",
      "Epoch 1005/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.0104e-04 - fbeta: 1.0000 - val_loss: 0.6046 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01005: val_loss did not improve from 0.39496\n",
      "Epoch 1006/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.9714e-04 - fbeta: 1.0000 - val_loss: 0.6035 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01006: val_loss did not improve from 0.39496\n",
      "Epoch 1007/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.9495e-04 - fbeta: 1.0000 - val_loss: 0.6026 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01007: val_loss did not improve from 0.39496\n",
      "Epoch 1008/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.0327e-04 - fbeta: 1.0000 - val_loss: 0.6063 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01008: val_loss did not improve from 0.39496\n",
      "Epoch 1009/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.9652e-04 - fbeta: 1.0000 - val_loss: 0.6079 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01009: val_loss did not improve from 0.39496\n",
      "Epoch 1010/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.9329e-04 - fbeta: 1.0000 - val_loss: 0.6094 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01010: val_loss did not improve from 0.39496\n",
      "Epoch 1011/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.9273e-04 - fbeta: 1.0000 - val_loss: 0.6088 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01011: val_loss did not improve from 0.39496\n",
      "Epoch 1012/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.9179e-04 - fbeta: 1.0000 - val_loss: 0.6087 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01012: val_loss did not improve from 0.39496\n",
      "Epoch 1013/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 7.0429e-04 - fbeta: 1.0000 - val_loss: 0.6096 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01013: val_loss did not improve from 0.39496\n",
      "Epoch 1014/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.9110e-04 - fbeta: 1.0000 - val_loss: 0.6030 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01014: val_loss did not improve from 0.39496\n",
      "Epoch 1015/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.9291e-04 - fbeta: 1.0000 - val_loss: 0.6079 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01015: val_loss did not improve from 0.39496\n",
      "Epoch 1016/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.8798e-04 - fbeta: 1.0000 - val_loss: 0.6049 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01016: val_loss did not improve from 0.39496\n",
      "Epoch 1017/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.8744e-04 - fbeta: 1.0000 - val_loss: 0.6083 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01017: val_loss did not improve from 0.39496\n",
      "Epoch 1018/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.8488e-04 - fbeta: 1.0000 - val_loss: 0.6085 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01018: val_loss did not improve from 0.39496\n",
      "Epoch 1019/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.8515e-04 - fbeta: 1.0000 - val_loss: 0.6065 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01019: val_loss did not improve from 0.39496\n",
      "Epoch 1020/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.8444e-04 - fbeta: 1.0000 - val_loss: 0.6078 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01020: val_loss did not improve from 0.39496\n",
      "Epoch 1021/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.8537e-04 - fbeta: 1.0000 - val_loss: 0.6097 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01021: val_loss did not improve from 0.39496\n",
      "Epoch 1022/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.8430e-04 - fbeta: 1.0000 - val_loss: 0.6113 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01022: val_loss did not improve from 0.39496\n",
      "Epoch 1023/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.8139e-04 - fbeta: 1.0000 - val_loss: 0.6121 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01023: val_loss did not improve from 0.39496\n",
      "Epoch 1024/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.8057e-04 - fbeta: 1.0000 - val_loss: 0.6093 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01024: val_loss did not improve from 0.39496\n",
      "Epoch 1025/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.8191e-04 - fbeta: 1.0000 - val_loss: 0.6088 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01025: val_loss did not improve from 0.39496\n",
      "Epoch 1026/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.8002e-04 - fbeta: 1.0000 - val_loss: 0.6039 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01026: val_loss did not improve from 0.39496\n",
      "Epoch 1027/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.8033e-04 - fbeta: 1.0000 - val_loss: 0.6098 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01027: val_loss did not improve from 0.39496\n",
      "Epoch 1028/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.7908e-04 - fbeta: 1.0000 - val_loss: 0.6119 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01028: val_loss did not improve from 0.39496\n",
      "Epoch 1029/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.7684e-04 - fbeta: 1.0000 - val_loss: 0.6113 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01029: val_loss did not improve from 0.39496\n",
      "Epoch 1030/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.7441e-04 - fbeta: 1.0000 - val_loss: 0.6085 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01030: val_loss did not improve from 0.39496\n",
      "Epoch 1031/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.7602e-04 - fbeta: 1.0000 - val_loss: 0.6091 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01031: val_loss did not improve from 0.39496\n",
      "Epoch 1032/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.7638e-04 - fbeta: 1.0000 - val_loss: 0.6073 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01032: val_loss did not improve from 0.39496\n",
      "Epoch 1033/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.7225e-04 - fbeta: 1.0000 - val_loss: 0.6081 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01033: val_loss did not improve from 0.39496\n",
      "Epoch 1034/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.7182e-04 - fbeta: 1.0000 - val_loss: 0.6027 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01034: val_loss did not improve from 0.39496\n",
      "Epoch 1035/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.7086e-04 - fbeta: 1.0000 - val_loss: 0.6043 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01035: val_loss did not improve from 0.39496\n",
      "Epoch 1036/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 6.6955e-04 - fbeta: 1.0000 - val_loss: 0.6068 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01036: val_loss did not improve from 0.39496\n",
      "Epoch 1037/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.6748e-04 - fbeta: 1.0000 - val_loss: 0.6061 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01037: val_loss did not improve from 0.39496\n",
      "Epoch 1038/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.6801e-04 - fbeta: 1.0000 - val_loss: 0.6024 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01038: val_loss did not improve from 0.39496\n",
      "Epoch 1039/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.8112e-04 - fbeta: 1.0000 - val_loss: 0.6031 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01039: val_loss did not improve from 0.39496\n",
      "Epoch 1040/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.6636e-04 - fbeta: 1.0000 - val_loss: 0.6101 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01040: val_loss did not improve from 0.39496\n",
      "Epoch 1041/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.6649e-04 - fbeta: 1.0000 - val_loss: 0.6100 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01041: val_loss did not improve from 0.39496\n",
      "Epoch 1042/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.7035e-04 - fbeta: 1.0000 - val_loss: 0.6092 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01042: val_loss did not improve from 0.39496\n",
      "Epoch 1043/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.6627e-04 - fbeta: 1.0000 - val_loss: 0.6067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01043: val_loss did not improve from 0.39496\n",
      "Epoch 1044/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.6786e-04 - fbeta: 1.0000 - val_loss: 0.6074 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01044: val_loss did not improve from 0.39496\n",
      "Epoch 1045/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.6193e-04 - fbeta: 1.0000 - val_loss: 0.6112 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01045: val_loss did not improve from 0.39496\n",
      "Epoch 1046/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.6075e-04 - fbeta: 1.0000 - val_loss: 0.6098 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01046: val_loss did not improve from 0.39496\n",
      "Epoch 1047/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.6139e-04 - fbeta: 1.0000 - val_loss: 0.6042 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01047: val_loss did not improve from 0.39496\n",
      "Epoch 1048/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.5903e-04 - fbeta: 1.0000 - val_loss: 0.6098 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01048: val_loss did not improve from 0.39496\n",
      "Epoch 1049/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.5962e-04 - fbeta: 1.0000 - val_loss: 0.6110 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01049: val_loss did not improve from 0.39496\n",
      "Epoch 1050/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.6978e-04 - fbeta: 1.0000 - val_loss: 0.6135 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01050: val_loss did not improve from 0.39496\n",
      "Epoch 1051/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.5994e-04 - fbeta: 1.0000 - val_loss: 0.6129 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01051: val_loss did not improve from 0.39496\n",
      "Epoch 1052/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.5442e-04 - fbeta: 1.0000 - val_loss: 0.6099 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01052: val_loss did not improve from 0.39496\n",
      "Epoch 1053/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.5540e-04 - fbeta: 1.0000 - val_loss: 0.6121 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01053: val_loss did not improve from 0.39496\n",
      "Epoch 1054/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.5492e-04 - fbeta: 1.0000 - val_loss: 0.6109 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01054: val_loss did not improve from 0.39496\n",
      "Epoch 1055/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.5488e-04 - fbeta: 1.0000 - val_loss: 0.6109 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01055: val_loss did not improve from 0.39496\n",
      "Epoch 1056/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.5319e-04 - fbeta: 1.0000 - val_loss: 0.6108 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01056: val_loss did not improve from 0.39496\n",
      "Epoch 1057/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.5689e-04 - fbeta: 1.0000 - val_loss: 0.6115 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01057: val_loss did not improve from 0.39496\n",
      "Epoch 1058/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.5330e-04 - fbeta: 1.0000 - val_loss: 0.6118 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01058: val_loss did not improve from 0.39496\n",
      "Epoch 1059/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.5371e-04 - fbeta: 1.0000 - val_loss: 0.6082 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01059: val_loss did not improve from 0.39496\n",
      "Epoch 1060/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.4826e-04 - fbeta: 1.0000 - val_loss: 0.6091 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01060: val_loss did not improve from 0.39496\n",
      "Epoch 1061/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.4919e-04 - fbeta: 1.0000 - val_loss: 0.6054 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01061: val_loss did not improve from 0.39496\n",
      "Epoch 1062/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.4695e-04 - fbeta: 1.0000 - val_loss: 0.6099 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01062: val_loss did not improve from 0.39496\n",
      "Epoch 1063/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.4774e-04 - fbeta: 1.0000 - val_loss: 0.6122 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01063: val_loss did not improve from 0.39496\n",
      "Epoch 1064/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.4499e-04 - fbeta: 1.0000 - val_loss: 0.6109 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01064: val_loss did not improve from 0.39496\n",
      "Epoch 1065/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.4417e-04 - fbeta: 1.0000 - val_loss: 0.6129 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01065: val_loss did not improve from 0.39496\n",
      "Epoch 1066/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.4281e-04 - fbeta: 1.0000 - val_loss: 0.6093 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01066: val_loss did not improve from 0.39496\n",
      "Epoch 1067/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.4231e-04 - fbeta: 1.0000 - val_loss: 0.6093 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01067: val_loss did not improve from 0.39496\n",
      "Epoch 1068/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.4447e-04 - fbeta: 1.0000 - val_loss: 0.6077 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01068: val_loss did not improve from 0.39496\n",
      "Epoch 1069/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.4110e-04 - fbeta: 1.0000 - val_loss: 0.6113 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01069: val_loss did not improve from 0.39496\n",
      "Epoch 1070/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.4131e-04 - fbeta: 1.0000 - val_loss: 0.6103 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01070: val_loss did not improve from 0.39496\n",
      "Epoch 1071/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.4031e-04 - fbeta: 1.0000 - val_loss: 0.6082 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01071: val_loss did not improve from 0.39496\n",
      "Epoch 1072/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.4563e-04 - fbeta: 1.0000 - val_loss: 0.6109 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01072: val_loss did not improve from 0.39496\n",
      "Epoch 1073/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.3900e-04 - fbeta: 1.0000 - val_loss: 0.6136 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01073: val_loss did not improve from 0.39496\n",
      "Epoch 1074/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.3682e-04 - fbeta: 1.0000 - val_loss: 0.6059 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01074: val_loss did not improve from 0.39496\n",
      "Epoch 1075/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.3677e-04 - fbeta: 1.0000 - val_loss: 0.6095 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01075: val_loss did not improve from 0.39496\n",
      "Epoch 1076/5000\n",
      "622/622 [==============================] - 25s 41ms/step - loss: 6.3828e-04 - fbeta: 1.0000 - val_loss: 0.6094 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01076: val_loss did not improve from 0.39496\n",
      "Epoch 1077/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 6.3467e-04 - fbeta: 1.0000 - val_loss: 0.6123 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01077: val_loss did not improve from 0.39496\n",
      "Epoch 1078/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.3499e-04 - fbeta: 1.0000 - val_loss: 0.6131 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01078: val_loss did not improve from 0.39496\n",
      "Epoch 1079/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.3381e-04 - fbeta: 1.0000 - val_loss: 0.6121 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01079: val_loss did not improve from 0.39496\n",
      "Epoch 1080/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.4195e-04 - fbeta: 1.0000 - val_loss: 0.6091 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01080: val_loss did not improve from 0.39496\n",
      "Epoch 1081/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.3305e-04 - fbeta: 1.0000 - val_loss: 0.6057 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01081: val_loss did not improve from 0.39496\n",
      "Epoch 1082/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.3758e-04 - fbeta: 1.0000 - val_loss: 0.6106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01082: val_loss did not improve from 0.39496\n",
      "Epoch 1083/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.2897e-04 - fbeta: 1.0000 - val_loss: 0.6100 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01083: val_loss did not improve from 0.39496\n",
      "Epoch 1084/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.3183e-04 - fbeta: 1.0000 - val_loss: 0.6102 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01084: val_loss did not improve from 0.39496\n",
      "Epoch 1085/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.3049e-04 - fbeta: 1.0000 - val_loss: 0.6126 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01085: val_loss did not improve from 0.39496\n",
      "Epoch 1086/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.2972e-04 - fbeta: 1.0000 - val_loss: 0.6095 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01086: val_loss did not improve from 0.39496\n",
      "Epoch 1087/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.3019e-04 - fbeta: 1.0000 - val_loss: 0.6108 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01087: val_loss did not improve from 0.39496\n",
      "Epoch 1088/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.4749e-04 - fbeta: 1.0000 - val_loss: 0.6099 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01088: val_loss did not improve from 0.39496\n",
      "Epoch 1089/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.2814e-04 - fbeta: 1.0000 - val_loss: 0.6090 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01089: val_loss did not improve from 0.39496\n",
      "Epoch 1090/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.2707e-04 - fbeta: 1.0000 - val_loss: 0.6108 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01090: val_loss did not improve from 0.39496\n",
      "Epoch 1091/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.2356e-04 - fbeta: 1.0000 - val_loss: 0.6102 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01091: val_loss did not improve from 0.39496\n",
      "Epoch 1092/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.2215e-04 - fbeta: 1.0000 - val_loss: 0.6069 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01092: val_loss did not improve from 0.39496\n",
      "Epoch 1093/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.2148e-04 - fbeta: 1.0000 - val_loss: 0.6116 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01093: val_loss did not improve from 0.39496\n",
      "Epoch 1094/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.2207e-04 - fbeta: 1.0000 - val_loss: 0.6095 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01094: val_loss did not improve from 0.39496\n",
      "Epoch 1095/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.3598e-04 - fbeta: 1.0000 - val_loss: 0.6087 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01095: val_loss did not improve from 0.39496\n",
      "Epoch 1096/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.1980e-04 - fbeta: 1.0000 - val_loss: 0.6100 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01096: val_loss did not improve from 0.39496\n",
      "Epoch 1097/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.1875e-04 - fbeta: 1.0000 - val_loss: 0.6112 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01097: val_loss did not improve from 0.39496\n",
      "Epoch 1098/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.1878e-04 - fbeta: 1.0000 - val_loss: 0.6123 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01098: val_loss did not improve from 0.39496\n",
      "Epoch 1099/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.2699e-04 - fbeta: 1.0000 - val_loss: 0.6142 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01099: val_loss did not improve from 0.39496\n",
      "Epoch 1100/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.1709e-04 - fbeta: 1.0000 - val_loss: 0.6107 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01100: val_loss did not improve from 0.39496\n",
      "Epoch 1101/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.1682e-04 - fbeta: 1.0000 - val_loss: 0.6165 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01101: val_loss did not improve from 0.39496\n",
      "Epoch 1102/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.1706e-04 - fbeta: 1.0000 - val_loss: 0.6141 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01102: val_loss did not improve from 0.39496\n",
      "Epoch 1103/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.1422e-04 - fbeta: 1.0000 - val_loss: 0.6131 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01103: val_loss did not improve from 0.39496\n",
      "Epoch 1104/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.1366e-04 - fbeta: 1.0000 - val_loss: 0.6123 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01104: val_loss did not improve from 0.39496\n",
      "Epoch 1105/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.1326e-04 - fbeta: 1.0000 - val_loss: 0.6152 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01105: val_loss did not improve from 0.39496\n",
      "Epoch 1106/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.1488e-04 - fbeta: 1.0000 - val_loss: 0.6096 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01106: val_loss did not improve from 0.39496\n",
      "Epoch 1107/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.1138e-04 - fbeta: 1.0000 - val_loss: 0.6084 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01107: val_loss did not improve from 0.39496\n",
      "Epoch 1108/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.0953e-04 - fbeta: 1.0000 - val_loss: 0.6137 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01108: val_loss did not improve from 0.39496\n",
      "Epoch 1109/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.0934e-04 - fbeta: 1.0000 - val_loss: 0.6150 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01109: val_loss did not improve from 0.39496\n",
      "Epoch 1110/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.1176e-04 - fbeta: 1.0000 - val_loss: 0.6128 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01110: val_loss did not improve from 0.39496\n",
      "Epoch 1111/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.0992e-04 - fbeta: 1.0000 - val_loss: 0.6127 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01111: val_loss did not improve from 0.39496\n",
      "Epoch 1112/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.0809e-04 - fbeta: 1.0000 - val_loss: 0.6157 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01112: val_loss did not improve from 0.39496\n",
      "Epoch 1113/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.1332e-04 - fbeta: 1.0000 - val_loss: 0.6094 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01113: val_loss did not improve from 0.39496\n",
      "Epoch 1114/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.0818e-04 - fbeta: 1.0000 - val_loss: 0.6075 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01114: val_loss did not improve from 0.39496\n",
      "Epoch 1115/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.0869e-04 - fbeta: 1.0000 - val_loss: 0.6074 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01115: val_loss did not improve from 0.39496\n",
      "Epoch 1116/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.0260e-04 - fbeta: 1.0000 - val_loss: 0.6152 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01116: val_loss did not improve from 0.39496\n",
      "Epoch 1117/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.0416e-04 - fbeta: 1.0000 - val_loss: 0.6137 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01117: val_loss did not improve from 0.39496\n",
      "Epoch 1118/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 6.0459e-04 - fbeta: 1.0000 - val_loss: 0.6137 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01118: val_loss did not improve from 0.39496\n",
      "Epoch 1119/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.0388e-04 - fbeta: 1.0000 - val_loss: 0.6184 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01119: val_loss did not improve from 0.39496\n",
      "Epoch 1120/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.0381e-04 - fbeta: 1.0000 - val_loss: 0.6163 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01120: val_loss did not improve from 0.39496\n",
      "Epoch 1121/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.0379e-04 - fbeta: 1.0000 - val_loss: 0.6115 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01121: val_loss did not improve from 0.39496\n",
      "Epoch 1122/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.0456e-04 - fbeta: 1.0000 - val_loss: 0.6162 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01122: val_loss did not improve from 0.39496\n",
      "Epoch 1123/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.0338e-04 - fbeta: 1.0000 - val_loss: 0.6167 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01123: val_loss did not improve from 0.39496\n",
      "Epoch 1124/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.9813e-04 - fbeta: 1.0000 - val_loss: 0.6149 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01124: val_loss did not improve from 0.39496\n",
      "Epoch 1125/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.9742e-04 - fbeta: 1.0000 - val_loss: 0.6151 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01125: val_loss did not improve from 0.39496\n",
      "Epoch 1126/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.9846e-04 - fbeta: 1.0000 - val_loss: 0.6152 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01126: val_loss did not improve from 0.39496\n",
      "Epoch 1127/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.9694e-04 - fbeta: 1.0000 - val_loss: 0.6143 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01127: val_loss did not improve from 0.39496\n",
      "Epoch 1128/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.9549e-04 - fbeta: 1.0000 - val_loss: 0.6132 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01128: val_loss did not improve from 0.39496\n",
      "Epoch 1129/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.9560e-04 - fbeta: 1.0000 - val_loss: 0.6118 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01129: val_loss did not improve from 0.39496\n",
      "Epoch 1130/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.0150e-04 - fbeta: 1.0000 - val_loss: 0.6149 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01130: val_loss did not improve from 0.39496\n",
      "Epoch 1131/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.9802e-04 - fbeta: 1.0000 - val_loss: 0.6152 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01131: val_loss did not improve from 0.39496\n",
      "Epoch 1132/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 6.0271e-04 - fbeta: 1.0000 - val_loss: 0.6194 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01132: val_loss did not improve from 0.39496\n",
      "Epoch 1133/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.9578e-04 - fbeta: 1.0000 - val_loss: 0.6126 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01133: val_loss did not improve from 0.39496\n",
      "Epoch 1134/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.9196e-04 - fbeta: 1.0000 - val_loss: 0.6151 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01134: val_loss did not improve from 0.39496\n",
      "Epoch 1135/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.9387e-04 - fbeta: 1.0000 - val_loss: 0.6138 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01135: val_loss did not improve from 0.39496\n",
      "Epoch 1136/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.9301e-04 - fbeta: 1.0000 - val_loss: 0.6146 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01136: val_loss did not improve from 0.39496\n",
      "Epoch 1137/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.9142e-04 - fbeta: 1.0000 - val_loss: 0.6160 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01137: val_loss did not improve from 0.39496\n",
      "Epoch 1138/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.8855e-04 - fbeta: 1.0000 - val_loss: 0.6177 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01138: val_loss did not improve from 0.39496\n",
      "Epoch 1139/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.8815e-04 - fbeta: 1.0000 - val_loss: 0.6133 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01139: val_loss did not improve from 0.39496\n",
      "Epoch 1140/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.8980e-04 - fbeta: 1.0000 - val_loss: 0.6121 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01140: val_loss did not improve from 0.39496\n",
      "Epoch 1141/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.8969e-04 - fbeta: 1.0000 - val_loss: 0.6118 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01141: val_loss did not improve from 0.39496\n",
      "Epoch 1142/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.9610e-04 - fbeta: 1.0000 - val_loss: 0.6133 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01142: val_loss did not improve from 0.39496\n",
      "Epoch 1143/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.9171e-04 - fbeta: 1.0000 - val_loss: 0.6145 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01143: val_loss did not improve from 0.39496\n",
      "Epoch 1144/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.8779e-04 - fbeta: 1.0000 - val_loss: 0.6162 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01144: val_loss did not improve from 0.39496\n",
      "Epoch 1145/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.8718e-04 - fbeta: 1.0000 - val_loss: 0.6142 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01145: val_loss did not improve from 0.39496\n",
      "Epoch 1146/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.8675e-04 - fbeta: 1.0000 - val_loss: 0.6159 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01146: val_loss did not improve from 0.39496\n",
      "Epoch 1147/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.8368e-04 - fbeta: 1.0000 - val_loss: 0.6156 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01147: val_loss did not improve from 0.39496\n",
      "Epoch 1148/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.8334e-04 - fbeta: 1.0000 - val_loss: 0.6120 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01148: val_loss did not improve from 0.39496\n",
      "Epoch 1149/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.8213e-04 - fbeta: 1.0000 - val_loss: 0.6106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01149: val_loss did not improve from 0.39496\n",
      "Epoch 1150/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.8281e-04 - fbeta: 1.0000 - val_loss: 0.6134 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01150: val_loss did not improve from 0.39496\n",
      "Epoch 1151/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.8053e-04 - fbeta: 1.0000 - val_loss: 0.6132 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01151: val_loss did not improve from 0.39496\n",
      "Epoch 1152/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.8254e-04 - fbeta: 1.0000 - val_loss: 0.6111 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01152: val_loss did not improve from 0.39496\n",
      "Epoch 1153/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.8123e-04 - fbeta: 1.0000 - val_loss: 0.6152 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01153: val_loss did not improve from 0.39496\n",
      "Epoch 1154/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.8086e-04 - fbeta: 1.0000 - val_loss: 0.6153 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01154: val_loss did not improve from 0.39496\n",
      "Epoch 1155/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.8154e-04 - fbeta: 1.0000 - val_loss: 0.6207 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01155: val_loss did not improve from 0.39496\n",
      "Epoch 1156/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.7731e-04 - fbeta: 1.0000 - val_loss: 0.6194 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01156: val_loss did not improve from 0.39496\n",
      "Epoch 1157/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.7795e-04 - fbeta: 1.0000 - val_loss: 0.6205 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01157: val_loss did not improve from 0.39496\n",
      "Epoch 1158/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.7635e-04 - fbeta: 1.0000 - val_loss: 0.6203 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01158: val_loss did not improve from 0.39496\n",
      "Epoch 1159/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 5.7460e-04 - fbeta: 1.0000 - val_loss: 0.6183 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01159: val_loss did not improve from 0.39496\n",
      "Epoch 1160/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.7490e-04 - fbeta: 1.0000 - val_loss: 0.6157 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01160: val_loss did not improve from 0.39496\n",
      "Epoch 1161/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.7236e-04 - fbeta: 1.0000 - val_loss: 0.6140 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01161: val_loss did not improve from 0.39496\n",
      "Epoch 1162/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.7399e-04 - fbeta: 1.0000 - val_loss: 0.6156 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01162: val_loss did not improve from 0.39496\n",
      "Epoch 1163/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.7275e-04 - fbeta: 1.0000 - val_loss: 0.6166 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01163: val_loss did not improve from 0.39496\n",
      "Epoch 1164/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.7060e-04 - fbeta: 1.0000 - val_loss: 0.6183 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01164: val_loss did not improve from 0.39496\n",
      "Epoch 1165/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.7586e-04 - fbeta: 1.0000 - val_loss: 0.6168 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01165: val_loss did not improve from 0.39496\n",
      "Epoch 1166/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.7108e-04 - fbeta: 1.0000 - val_loss: 0.6160 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01166: val_loss did not improve from 0.39496\n",
      "Epoch 1167/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.6960e-04 - fbeta: 1.0000 - val_loss: 0.6141 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01167: val_loss did not improve from 0.39496\n",
      "Epoch 1168/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.6813e-04 - fbeta: 1.0000 - val_loss: 0.6173 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01168: val_loss did not improve from 0.39496\n",
      "Epoch 1169/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.7028e-04 - fbeta: 1.0000 - val_loss: 0.6208 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01169: val_loss did not improve from 0.39496\n",
      "Epoch 1170/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.6917e-04 - fbeta: 1.0000 - val_loss: 0.6198 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01170: val_loss did not improve from 0.39496\n",
      "Epoch 1171/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.6798e-04 - fbeta: 1.0000 - val_loss: 0.6150 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01171: val_loss did not improve from 0.39496\n",
      "Epoch 1172/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.6519e-04 - fbeta: 1.0000 - val_loss: 0.6189 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01172: val_loss did not improve from 0.39496\n",
      "Epoch 1173/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.7048e-04 - fbeta: 1.0000 - val_loss: 0.6162 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01173: val_loss did not improve from 0.39496\n",
      "Epoch 1174/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.6616e-04 - fbeta: 1.0000 - val_loss: 0.6178 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01174: val_loss did not improve from 0.39496\n",
      "Epoch 1175/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.6595e-04 - fbeta: 1.0000 - val_loss: 0.6158 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01175: val_loss did not improve from 0.39496\n",
      "Epoch 1176/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.6877e-04 - fbeta: 1.0000 - val_loss: 0.6179 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01176: val_loss did not improve from 0.39496\n",
      "Epoch 1177/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.6514e-04 - fbeta: 1.0000 - val_loss: 0.6153 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01177: val_loss did not improve from 0.39496\n",
      "Epoch 1178/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.6135e-04 - fbeta: 1.0000 - val_loss: 0.6152 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01178: val_loss did not improve from 0.39496\n",
      "Epoch 1179/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.6068e-04 - fbeta: 1.0000 - val_loss: 0.6145 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01179: val_loss did not improve from 0.39496\n",
      "Epoch 1180/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5977e-04 - fbeta: 1.0000 - val_loss: 0.6169 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01180: val_loss did not improve from 0.39496\n",
      "Epoch 1181/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.6205e-04 - fbeta: 1.0000 - val_loss: 0.6162 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01181: val_loss did not improve from 0.39496\n",
      "Epoch 1182/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5946e-04 - fbeta: 1.0000 - val_loss: 0.6157 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01182: val_loss did not improve from 0.39496\n",
      "Epoch 1183/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5995e-04 - fbeta: 1.0000 - val_loss: 0.6180 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01183: val_loss did not improve from 0.39496\n",
      "Epoch 1184/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5722e-04 - fbeta: 1.0000 - val_loss: 0.6187 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01184: val_loss did not improve from 0.39496\n",
      "Epoch 1185/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5958e-04 - fbeta: 1.0000 - val_loss: 0.6177 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01185: val_loss did not improve from 0.39496\n",
      "Epoch 1186/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5745e-04 - fbeta: 1.0000 - val_loss: 0.6124 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01186: val_loss did not improve from 0.39496\n",
      "Epoch 1187/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5873e-04 - fbeta: 1.0000 - val_loss: 0.6172 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01187: val_loss did not improve from 0.39496\n",
      "Epoch 1188/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5621e-04 - fbeta: 1.0000 - val_loss: 0.6223 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01188: val_loss did not improve from 0.39496\n",
      "Epoch 1189/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.6702e-04 - fbeta: 1.0000 - val_loss: 0.6139 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01189: val_loss did not improve from 0.39496\n",
      "Epoch 1190/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5637e-04 - fbeta: 1.0000 - val_loss: 0.6151 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01190: val_loss did not improve from 0.39496\n",
      "Epoch 1191/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5367e-04 - fbeta: 1.0000 - val_loss: 0.6149 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01191: val_loss did not improve from 0.39496\n",
      "Epoch 1192/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5425e-04 - fbeta: 1.0000 - val_loss: 0.6190 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01192: val_loss did not improve from 0.39496\n",
      "Epoch 1193/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5547e-04 - fbeta: 1.0000 - val_loss: 0.6194 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01193: val_loss did not improve from 0.39496\n",
      "Epoch 1194/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5143e-04 - fbeta: 1.0000 - val_loss: 0.6184 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01194: val_loss did not improve from 0.39496\n",
      "Epoch 1195/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5229e-04 - fbeta: 1.0000 - val_loss: 0.6205 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01195: val_loss did not improve from 0.39496\n",
      "Epoch 1196/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5118e-04 - fbeta: 1.0000 - val_loss: 0.6206 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01196: val_loss did not improve from 0.39496\n",
      "Epoch 1197/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5061e-04 - fbeta: 1.0000 - val_loss: 0.6182 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01197: val_loss did not improve from 0.39496\n",
      "Epoch 1198/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.4868e-04 - fbeta: 1.0000 - val_loss: 0.6167 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01198: val_loss did not improve from 0.39496\n",
      "Epoch 1199/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.4945e-04 - fbeta: 1.0000 - val_loss: 0.6169 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01199: val_loss did not improve from 0.39496\n",
      "Epoch 1200/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 5.4889e-04 - fbeta: 1.0000 - val_loss: 0.6164 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01200: val_loss did not improve from 0.39496\n",
      "Epoch 1201/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.4951e-04 - fbeta: 1.0000 - val_loss: 0.6162 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01201: val_loss did not improve from 0.39496\n",
      "Epoch 1202/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.4752e-04 - fbeta: 1.0000 - val_loss: 0.6226 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01202: val_loss did not improve from 0.39496\n",
      "Epoch 1203/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.4881e-04 - fbeta: 1.0000 - val_loss: 0.6220 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01203: val_loss did not improve from 0.39496\n",
      "Epoch 1204/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5364e-04 - fbeta: 1.0000 - val_loss: 0.6178 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01204: val_loss did not improve from 0.39496\n",
      "Epoch 1205/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.5373e-04 - fbeta: 1.0000 - val_loss: 0.6180 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01205: val_loss did not improve from 0.39496\n",
      "Epoch 1206/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.4568e-04 - fbeta: 1.0000 - val_loss: 0.6198 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01206: val_loss did not improve from 0.39496\n",
      "Epoch 1207/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.4572e-04 - fbeta: 1.0000 - val_loss: 0.6196 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01207: val_loss did not improve from 0.39496\n",
      "Epoch 1208/5000\n",
      "622/622 [==============================] - 25s 41ms/step - loss: 5.4460e-04 - fbeta: 1.0000 - val_loss: 0.6205 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01208: val_loss did not improve from 0.39496\n",
      "Epoch 1209/5000\n",
      "622/622 [==============================] - 25s 41ms/step - loss: 5.4772e-04 - fbeta: 1.0000 - val_loss: 0.6147 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01209: val_loss did not improve from 0.39496\n",
      "Epoch 1210/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.4912e-04 - fbeta: 1.0000 - val_loss: 0.6095 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01210: val_loss did not improve from 0.39496\n",
      "Epoch 1211/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.4762e-04 - fbeta: 1.0000 - val_loss: 0.6208 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01211: val_loss did not improve from 0.39496\n",
      "Epoch 1212/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.4359e-04 - fbeta: 1.0000 - val_loss: 0.6257 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01212: val_loss did not improve from 0.39496\n",
      "Epoch 1213/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.4172e-04 - fbeta: 1.0000 - val_loss: 0.6244 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01213: val_loss did not improve from 0.39496\n",
      "Epoch 1214/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3982e-04 - fbeta: 1.0000 - val_loss: 0.6201 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01214: val_loss did not improve from 0.39496\n",
      "Epoch 1215/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3998e-04 - fbeta: 1.0000 - val_loss: 0.6203 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01215: val_loss did not improve from 0.39496\n",
      "Epoch 1216/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3901e-04 - fbeta: 1.0000 - val_loss: 0.6191 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01216: val_loss did not improve from 0.39496\n",
      "Epoch 1217/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.4002e-04 - fbeta: 1.0000 - val_loss: 0.6159 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01217: val_loss did not improve from 0.39496\n",
      "Epoch 1218/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3898e-04 - fbeta: 1.0000 - val_loss: 0.6203 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01218: val_loss did not improve from 0.39496\n",
      "Epoch 1219/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3876e-04 - fbeta: 1.0000 - val_loss: 0.6249 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01219: val_loss did not improve from 0.39496\n",
      "Epoch 1220/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3731e-04 - fbeta: 1.0000 - val_loss: 0.6242 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01220: val_loss did not improve from 0.39496\n",
      "Epoch 1221/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3712e-04 - fbeta: 1.0000 - val_loss: 0.6255 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01221: val_loss did not improve from 0.39496\n",
      "Epoch 1222/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3685e-04 - fbeta: 1.0000 - val_loss: 0.6186 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01222: val_loss did not improve from 0.39496\n",
      "Epoch 1223/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3475e-04 - fbeta: 1.0000 - val_loss: 0.6234 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01223: val_loss did not improve from 0.39496\n",
      "Epoch 1224/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3659e-04 - fbeta: 1.0000 - val_loss: 0.6250 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01224: val_loss did not improve from 0.39496\n",
      "Epoch 1225/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3352e-04 - fbeta: 1.0000 - val_loss: 0.6226 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01225: val_loss did not improve from 0.39496\n",
      "Epoch 1226/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3452e-04 - fbeta: 1.0000 - val_loss: 0.6220 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01226: val_loss did not improve from 0.39496\n",
      "Epoch 1227/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3485e-04 - fbeta: 1.0000 - val_loss: 0.6169 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01227: val_loss did not improve from 0.39496\n",
      "Epoch 1228/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3174e-04 - fbeta: 1.0000 - val_loss: 0.6148 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01228: val_loss did not improve from 0.39496\n",
      "Epoch 1229/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3193e-04 - fbeta: 1.0000 - val_loss: 0.6136 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01229: val_loss did not improve from 0.39496\n",
      "Epoch 1230/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3016e-04 - fbeta: 1.0000 - val_loss: 0.6148 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01230: val_loss did not improve from 0.39496\n",
      "Epoch 1231/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2984e-04 - fbeta: 1.0000 - val_loss: 0.6136 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01231: val_loss did not improve from 0.39496\n",
      "Epoch 1232/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.3061e-04 - fbeta: 1.0000 - val_loss: 0.6203 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01232: val_loss did not improve from 0.39496\n",
      "Epoch 1233/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2965e-04 - fbeta: 1.0000 - val_loss: 0.6217 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01233: val_loss did not improve from 0.39496\n",
      "Epoch 1234/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2971e-04 - fbeta: 1.0000 - val_loss: 0.6213 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01234: val_loss did not improve from 0.39496\n",
      "Epoch 1235/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2894e-04 - fbeta: 1.0000 - val_loss: 0.6214 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01235: val_loss did not improve from 0.39496\n",
      "Epoch 1236/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2774e-04 - fbeta: 1.0000 - val_loss: 0.6198 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01236: val_loss did not improve from 0.39496\n",
      "Epoch 1237/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2883e-04 - fbeta: 1.0000 - val_loss: 0.6192 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01237: val_loss did not improve from 0.39496\n",
      "Epoch 1238/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2644e-04 - fbeta: 1.0000 - val_loss: 0.6190 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01238: val_loss did not improve from 0.39496\n",
      "Epoch 1239/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2907e-04 - fbeta: 1.0000 - val_loss: 0.6174 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01239: val_loss did not improve from 0.39496\n",
      "Epoch 1240/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2536e-04 - fbeta: 1.0000 - val_loss: 0.6182 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01240: val_loss did not improve from 0.39496\n",
      "Epoch 1241/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2350e-04 - fbeta: 1.0000 - val_loss: 0.6212 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01241: val_loss did not improve from 0.39496\n",
      "Epoch 1242/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2320e-04 - fbeta: 1.0000 - val_loss: 0.6213 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01242: val_loss did not improve from 0.39496\n",
      "Epoch 1243/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2356e-04 - fbeta: 1.0000 - val_loss: 0.6185 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01243: val_loss did not improve from 0.39496\n",
      "Epoch 1244/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2309e-04 - fbeta: 1.0000 - val_loss: 0.6209 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01244: val_loss did not improve from 0.39496\n",
      "Epoch 1245/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2081e-04 - fbeta: 1.0000 - val_loss: 0.6206 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01245: val_loss did not improve from 0.39496\n",
      "Epoch 1246/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2381e-04 - fbeta: 1.0000 - val_loss: 0.6176 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01246: val_loss did not improve from 0.39496\n",
      "Epoch 1247/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2393e-04 - fbeta: 1.0000 - val_loss: 0.6180 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01247: val_loss did not improve from 0.39496\n",
      "Epoch 1248/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1948e-04 - fbeta: 1.0000 - val_loss: 0.6200 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01248: val_loss did not improve from 0.39496\n",
      "Epoch 1249/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1972e-04 - fbeta: 1.0000 - val_loss: 0.6255 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01249: val_loss did not improve from 0.39496\n",
      "Epoch 1250/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.2423e-04 - fbeta: 1.0000 - val_loss: 0.6266 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01250: val_loss did not improve from 0.39496\n",
      "Epoch 1251/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1922e-04 - fbeta: 1.0000 - val_loss: 0.6199 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01251: val_loss did not improve from 0.39496\n",
      "Epoch 1252/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1790e-04 - fbeta: 1.0000 - val_loss: 0.6191 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01252: val_loss did not improve from 0.39496\n",
      "Epoch 1253/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1727e-04 - fbeta: 1.0000 - val_loss: 0.6217 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01253: val_loss did not improve from 0.39496\n",
      "Epoch 1254/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1897e-04 - fbeta: 1.0000 - val_loss: 0.6240 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01254: val_loss did not improve from 0.39496\n",
      "Epoch 1255/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1832e-04 - fbeta: 1.0000 - val_loss: 0.6214 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01255: val_loss did not improve from 0.39496\n",
      "Epoch 1256/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1693e-04 - fbeta: 1.0000 - val_loss: 0.6204 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01256: val_loss did not improve from 0.39496\n",
      "Epoch 1257/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1677e-04 - fbeta: 1.0000 - val_loss: 0.6202 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01257: val_loss did not improve from 0.39496\n",
      "Epoch 1258/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1459e-04 - fbeta: 1.0000 - val_loss: 0.6231 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01258: val_loss did not improve from 0.39496\n",
      "Epoch 1259/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1507e-04 - fbeta: 1.0000 - val_loss: 0.6224 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01259: val_loss did not improve from 0.39496\n",
      "Epoch 1260/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1641e-04 - fbeta: 1.0000 - val_loss: 0.6189 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01260: val_loss did not improve from 0.39496\n",
      "Epoch 1261/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1506e-04 - fbeta: 1.0000 - val_loss: 0.6161 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01261: val_loss did not improve from 0.39496\n",
      "Epoch 1262/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1938e-04 - fbeta: 1.0000 - val_loss: 0.6164 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01262: val_loss did not improve from 0.39496\n",
      "Epoch 1263/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1397e-04 - fbeta: 1.0000 - val_loss: 0.6192 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01263: val_loss did not improve from 0.39496\n",
      "Epoch 1264/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1458e-04 - fbeta: 1.0000 - val_loss: 0.6212 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01264: val_loss did not improve from 0.39496\n",
      "Epoch 1265/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1163e-04 - fbeta: 1.0000 - val_loss: 0.6246 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01265: val_loss did not improve from 0.39496\n",
      "Epoch 1266/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1102e-04 - fbeta: 1.0000 - val_loss: 0.6226 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01266: val_loss did not improve from 0.39496\n",
      "Epoch 1267/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1057e-04 - fbeta: 1.0000 - val_loss: 0.6230 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01267: val_loss did not improve from 0.39496\n",
      "Epoch 1268/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0977e-04 - fbeta: 1.0000 - val_loss: 0.6240 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01268: val_loss did not improve from 0.39496\n",
      "Epoch 1269/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1149e-04 - fbeta: 1.0000 - val_loss: 0.6227 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01269: val_loss did not improve from 0.39496\n",
      "Epoch 1270/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1209e-04 - fbeta: 1.0000 - val_loss: 0.6211 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01270: val_loss did not improve from 0.39496\n",
      "Epoch 1271/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.1071e-04 - fbeta: 1.0000 - val_loss: 0.6213 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01271: val_loss did not improve from 0.39496\n",
      "Epoch 1272/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0786e-04 - fbeta: 1.0000 - val_loss: 0.6229 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01272: val_loss did not improve from 0.39496\n",
      "Epoch 1273/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0848e-04 - fbeta: 1.0000 - val_loss: 0.6232 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01273: val_loss did not improve from 0.39496\n",
      "Epoch 1274/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0792e-04 - fbeta: 1.0000 - val_loss: 0.6233 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01274: val_loss did not improve from 0.39496\n",
      "Epoch 1275/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0738e-04 - fbeta: 1.0000 - val_loss: 0.6239 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01275: val_loss did not improve from 0.39496\n",
      "Epoch 1276/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0544e-04 - fbeta: 1.0000 - val_loss: 0.6226 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01276: val_loss did not improve from 0.39496\n",
      "Epoch 1277/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0744e-04 - fbeta: 1.0000 - val_loss: 0.6207 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01277: val_loss did not improve from 0.39496\n",
      "Epoch 1278/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0688e-04 - fbeta: 1.0000 - val_loss: 0.6192 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01278: val_loss did not improve from 0.39496\n",
      "Epoch 1279/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0828e-04 - fbeta: 1.0000 - val_loss: 0.6239 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01279: val_loss did not improve from 0.39496\n",
      "Epoch 1280/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0504e-04 - fbeta: 1.0000 - val_loss: 0.6237 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01280: val_loss did not improve from 0.39496\n",
      "Epoch 1281/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0348e-04 - fbeta: 1.0000 - val_loss: 0.6204 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01281: val_loss did not improve from 0.39496\n",
      "Epoch 1282/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0266e-04 - fbeta: 1.0000 - val_loss: 0.6200 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01282: val_loss did not improve from 0.39496\n",
      "Epoch 1283/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0135e-04 - fbeta: 1.0000 - val_loss: 0.6233 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01283: val_loss did not improve from 0.39496\n",
      "Epoch 1284/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0520e-04 - fbeta: 1.0000 - val_loss: 0.6273 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01284: val_loss did not improve from 0.39496\n",
      "Epoch 1285/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0179e-04 - fbeta: 1.0000 - val_loss: 0.6254 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01285: val_loss did not improve from 0.39496\n",
      "Epoch 1286/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0392e-04 - fbeta: 1.0000 - val_loss: 0.6211 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01286: val_loss did not improve from 0.39496\n",
      "Epoch 1287/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9964e-04 - fbeta: 1.0000 - val_loss: 0.6237 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01287: val_loss did not improve from 0.39496\n",
      "Epoch 1288/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9979e-04 - fbeta: 1.0000 - val_loss: 0.6205 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01288: val_loss did not improve from 0.39496\n",
      "Epoch 1289/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9756e-04 - fbeta: 1.0000 - val_loss: 0.6230 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01289: val_loss did not improve from 0.39496\n",
      "Epoch 1290/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0704e-04 - fbeta: 1.0000 - val_loss: 0.6224 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01290: val_loss did not improve from 0.39496\n",
      "Epoch 1291/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9776e-04 - fbeta: 1.0000 - val_loss: 0.6226 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01291: val_loss did not improve from 0.39496\n",
      "Epoch 1292/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 5.0063e-04 - fbeta: 1.0000 - val_loss: 0.6233 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01292: val_loss did not improve from 0.39496\n",
      "Epoch 1293/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9749e-04 - fbeta: 1.0000 - val_loss: 0.6226 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01293: val_loss did not improve from 0.39496\n",
      "Epoch 1294/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9555e-04 - fbeta: 1.0000 - val_loss: 0.6207 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01294: val_loss did not improve from 0.39496\n",
      "Epoch 1295/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9565e-04 - fbeta: 1.0000 - val_loss: 0.6231 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01295: val_loss did not improve from 0.39496\n",
      "Epoch 1296/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9471e-04 - fbeta: 1.0000 - val_loss: 0.6246 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01296: val_loss did not improve from 0.39496\n",
      "Epoch 1297/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9397e-04 - fbeta: 1.0000 - val_loss: 0.6216 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01297: val_loss did not improve from 0.39496\n",
      "Epoch 1298/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9424e-04 - fbeta: 1.0000 - val_loss: 0.6233 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01298: val_loss did not improve from 0.39496\n",
      "Epoch 1299/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9459e-04 - fbeta: 1.0000 - val_loss: 0.6241 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01299: val_loss did not improve from 0.39496\n",
      "Epoch 1300/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9311e-04 - fbeta: 1.0000 - val_loss: 0.6261 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01300: val_loss did not improve from 0.39496\n",
      "Epoch 1301/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9389e-04 - fbeta: 1.0000 - val_loss: 0.6286 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01301: val_loss did not improve from 0.39496\n",
      "Epoch 1302/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9733e-04 - fbeta: 1.0000 - val_loss: 0.6302 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01302: val_loss did not improve from 0.39496\n",
      "Epoch 1303/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9334e-04 - fbeta: 1.0000 - val_loss: 0.6281 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01303: val_loss did not improve from 0.39496\n",
      "Epoch 1304/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9086e-04 - fbeta: 1.0000 - val_loss: 0.6246 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01304: val_loss did not improve from 0.39496\n",
      "Epoch 1305/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9019e-04 - fbeta: 1.0000 - val_loss: 0.6244 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01305: val_loss did not improve from 0.39496\n",
      "Epoch 1306/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8902e-04 - fbeta: 1.0000 - val_loss: 0.6235 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01306: val_loss did not improve from 0.39496\n",
      "Epoch 1307/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9546e-04 - fbeta: 1.0000 - val_loss: 0.6237 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01307: val_loss did not improve from 0.39496\n",
      "Epoch 1308/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.9370e-04 - fbeta: 1.0000 - val_loss: 0.6234 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01308: val_loss did not improve from 0.39496\n",
      "Epoch 1309/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8863e-04 - fbeta: 1.0000 - val_loss: 0.6240 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01309: val_loss did not improve from 0.39496\n",
      "Epoch 1310/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8841e-04 - fbeta: 1.0000 - val_loss: 0.6202 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01310: val_loss did not improve from 0.39496\n",
      "Epoch 1311/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8826e-04 - fbeta: 1.0000 - val_loss: 0.6213 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01311: val_loss did not improve from 0.39496\n",
      "Epoch 1312/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8720e-04 - fbeta: 1.0000 - val_loss: 0.6226 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01312: val_loss did not improve from 0.39496\n",
      "Epoch 1313/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8741e-04 - fbeta: 1.0000 - val_loss: 0.6232 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01313: val_loss did not improve from 0.39496\n",
      "Epoch 1314/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8700e-04 - fbeta: 1.0000 - val_loss: 0.6214 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01314: val_loss did not improve from 0.39496\n",
      "Epoch 1315/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8641e-04 - fbeta: 1.0000 - val_loss: 0.6225 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01315: val_loss did not improve from 0.39496\n",
      "Epoch 1316/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8520e-04 - fbeta: 1.0000 - val_loss: 0.6218 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01316: val_loss did not improve from 0.39496\n",
      "Epoch 1317/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8539e-04 - fbeta: 1.0000 - val_loss: 0.6257 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01317: val_loss did not improve from 0.39496\n",
      "Epoch 1318/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8445e-04 - fbeta: 1.0000 - val_loss: 0.6232 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01318: val_loss did not improve from 0.39496\n",
      "Epoch 1319/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8400e-04 - fbeta: 1.0000 - val_loss: 0.6259 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01319: val_loss did not improve from 0.39496\n",
      "Epoch 1320/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8274e-04 - fbeta: 1.0000 - val_loss: 0.6264 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01320: val_loss did not improve from 0.39496\n",
      "Epoch 1321/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8365e-04 - fbeta: 1.0000 - val_loss: 0.6287 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01321: val_loss did not improve from 0.39496\n",
      "Epoch 1322/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8658e-04 - fbeta: 1.0000 - val_loss: 0.6274 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01322: val_loss did not improve from 0.39496\n",
      "Epoch 1323/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8422e-04 - fbeta: 1.0000 - val_loss: 0.6241 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01323: val_loss did not improve from 0.39496\n",
      "Epoch 1324/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8270e-04 - fbeta: 1.0000 - val_loss: 0.6239 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01324: val_loss did not improve from 0.39496\n",
      "Epoch 1325/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8185e-04 - fbeta: 1.0000 - val_loss: 0.6234 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01325: val_loss did not improve from 0.39496\n",
      "Epoch 1326/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8379e-04 - fbeta: 1.0000 - val_loss: 0.6219 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01326: val_loss did not improve from 0.39496\n",
      "Epoch 1327/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8641e-04 - fbeta: 1.0000 - val_loss: 0.6191 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01327: val_loss did not improve from 0.39496\n",
      "Epoch 1328/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7992e-04 - fbeta: 1.0000 - val_loss: 0.6229 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01328: val_loss did not improve from 0.39496\n",
      "Epoch 1329/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8045e-04 - fbeta: 1.0000 - val_loss: 0.6253 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01329: val_loss did not improve from 0.39496\n",
      "Epoch 1330/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7927e-04 - fbeta: 1.0000 - val_loss: 0.6254 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01330: val_loss did not improve from 0.39496\n",
      "Epoch 1331/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7730e-04 - fbeta: 1.0000 - val_loss: 0.6263 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01331: val_loss did not improve from 0.39496\n",
      "Epoch 1332/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7831e-04 - fbeta: 1.0000 - val_loss: 0.6281 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01332: val_loss did not improve from 0.39496\n",
      "Epoch 1333/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7811e-04 - fbeta: 1.0000 - val_loss: 0.6243 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01333: val_loss did not improve from 0.39496\n",
      "Epoch 1334/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7824e-04 - fbeta: 1.0000 - val_loss: 0.6243 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01334: val_loss did not improve from 0.39496\n",
      "Epoch 1335/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7576e-04 - fbeta: 1.0000 - val_loss: 0.6265 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01335: val_loss did not improve from 0.39496\n",
      "Epoch 1336/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7673e-04 - fbeta: 1.0000 - val_loss: 0.6263 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01336: val_loss did not improve from 0.39496\n",
      "Epoch 1337/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7595e-04 - fbeta: 1.0000 - val_loss: 0.6264 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01337: val_loss did not improve from 0.39496\n",
      "Epoch 1338/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7389e-04 - fbeta: 1.0000 - val_loss: 0.6231 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01338: val_loss did not improve from 0.39496\n",
      "Epoch 1339/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.8082e-04 - fbeta: 1.0000 - val_loss: 0.6214 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01339: val_loss did not improve from 0.39496\n",
      "Epoch 1340/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7917e-04 - fbeta: 1.0000 - val_loss: 0.6267 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01340: val_loss did not improve from 0.39496\n",
      "Epoch 1341/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7670e-04 - fbeta: 1.0000 - val_loss: 0.6275 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01341: val_loss did not improve from 0.39496\n",
      "Epoch 1342/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7269e-04 - fbeta: 1.0000 - val_loss: 0.6283 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01342: val_loss did not improve from 0.39496\n",
      "Epoch 1343/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7196e-04 - fbeta: 1.0000 - val_loss: 0.6268 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01343: val_loss did not improve from 0.39496\n",
      "Epoch 1344/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7286e-04 - fbeta: 1.0000 - val_loss: 0.6311 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01344: val_loss did not improve from 0.39496\n",
      "Epoch 1345/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7152e-04 - fbeta: 1.0000 - val_loss: 0.6285 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01345: val_loss did not improve from 0.39496\n",
      "Epoch 1346/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7100e-04 - fbeta: 1.0000 - val_loss: 0.6269 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01346: val_loss did not improve from 0.39496\n",
      "Epoch 1347/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7078e-04 - fbeta: 1.0000 - val_loss: 0.6258 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01347: val_loss did not improve from 0.39496\n",
      "Epoch 1348/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6957e-04 - fbeta: 1.0000 - val_loss: 0.6276 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01348: val_loss did not improve from 0.39496\n",
      "Epoch 1349/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7100e-04 - fbeta: 1.0000 - val_loss: 0.6224 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01349: val_loss did not improve from 0.39496\n",
      "Epoch 1350/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7078e-04 - fbeta: 1.0000 - val_loss: 0.6234 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01350: val_loss did not improve from 0.39496\n",
      "Epoch 1351/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6969e-04 - fbeta: 1.0000 - val_loss: 0.6285 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01351: val_loss did not improve from 0.39496\n",
      "Epoch 1352/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6733e-04 - fbeta: 1.0000 - val_loss: 0.6295 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01352: val_loss did not improve from 0.39496\n",
      "Epoch 1353/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6999e-04 - fbeta: 1.0000 - val_loss: 0.6278 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01353: val_loss did not improve from 0.39496\n",
      "Epoch 1354/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6711e-04 - fbeta: 1.0000 - val_loss: 0.6252 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01354: val_loss did not improve from 0.39496\n",
      "Epoch 1355/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6646e-04 - fbeta: 1.0000 - val_loss: 0.6264 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01355: val_loss did not improve from 0.39496\n",
      "Epoch 1356/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6675e-04 - fbeta: 1.0000 - val_loss: 0.6280 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01356: val_loss did not improve from 0.39496\n",
      "Epoch 1357/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.7058e-04 - fbeta: 1.0000 - val_loss: 0.6282 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01357: val_loss did not improve from 0.39496\n",
      "Epoch 1358/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6562e-04 - fbeta: 1.0000 - val_loss: 0.6290 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01358: val_loss did not improve from 0.39496\n",
      "Epoch 1359/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6554e-04 - fbeta: 1.0000 - val_loss: 0.6273 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01359: val_loss did not improve from 0.39496\n",
      "Epoch 1360/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6388e-04 - fbeta: 1.0000 - val_loss: 0.6255 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01360: val_loss did not improve from 0.39496\n",
      "Epoch 1361/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6415e-04 - fbeta: 1.0000 - val_loss: 0.6255 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01361: val_loss did not improve from 0.39496\n",
      "Epoch 1362/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6306e-04 - fbeta: 1.0000 - val_loss: 0.6281 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01362: val_loss did not improve from 0.39496\n",
      "Epoch 1363/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6319e-04 - fbeta: 1.0000 - val_loss: 0.6272 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01363: val_loss did not improve from 0.39496\n",
      "Epoch 1364/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6379e-04 - fbeta: 1.0000 - val_loss: 0.6293 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01364: val_loss did not improve from 0.39496\n",
      "Epoch 1365/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6323e-04 - fbeta: 1.0000 - val_loss: 0.6281 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01365: val_loss did not improve from 0.39496\n",
      "Epoch 1366/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6192e-04 - fbeta: 1.0000 - val_loss: 0.6280 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01366: val_loss did not improve from 0.39496\n",
      "Epoch 1367/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6349e-04 - fbeta: 1.0000 - val_loss: 0.6258 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01367: val_loss did not improve from 0.39496\n",
      "Epoch 1368/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6121e-04 - fbeta: 1.0000 - val_loss: 0.6256 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01368: val_loss did not improve from 0.39496\n",
      "Epoch 1369/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6064e-04 - fbeta: 1.0000 - val_loss: 0.6257 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01369: val_loss did not improve from 0.39496\n",
      "Epoch 1370/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6024e-04 - fbeta: 1.0000 - val_loss: 0.6260 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01370: val_loss did not improve from 0.39496\n",
      "Epoch 1371/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6099e-04 - fbeta: 1.0000 - val_loss: 0.6268 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01371: val_loss did not improve from 0.39496\n",
      "Epoch 1372/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5854e-04 - fbeta: 1.0000 - val_loss: 0.6252 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01372: val_loss did not improve from 0.39496\n",
      "Epoch 1373/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5958e-04 - fbeta: 1.0000 - val_loss: 0.6270 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01373: val_loss did not improve from 0.39496\n",
      "Epoch 1374/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5863e-04 - fbeta: 1.0000 - val_loss: 0.6284 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01374: val_loss did not improve from 0.39496\n",
      "Epoch 1375/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5697e-04 - fbeta: 1.0000 - val_loss: 0.6271 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01375: val_loss did not improve from 0.39496\n",
      "Epoch 1376/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5686e-04 - fbeta: 1.0000 - val_loss: 0.6279 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01376: val_loss did not improve from 0.39496\n",
      "Epoch 1377/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.6107e-04 - fbeta: 1.0000 - val_loss: 0.6293 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01377: val_loss did not improve from 0.39496\n",
      "Epoch 1378/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5819e-04 - fbeta: 1.0000 - val_loss: 0.6287 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01378: val_loss did not improve from 0.39496\n",
      "Epoch 1379/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5764e-04 - fbeta: 1.0000 - val_loss: 0.6295 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01379: val_loss did not improve from 0.39496\n",
      "Epoch 1380/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5758e-04 - fbeta: 1.0000 - val_loss: 0.6290 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01380: val_loss did not improve from 0.39496\n",
      "Epoch 1381/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5641e-04 - fbeta: 1.0000 - val_loss: 0.6256 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01381: val_loss did not improve from 0.39496\n",
      "Epoch 1382/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5485e-04 - fbeta: 1.0000 - val_loss: 0.6290 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01382: val_loss did not improve from 0.39496\n",
      "Epoch 1383/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5669e-04 - fbeta: 1.0000 - val_loss: 0.6269 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01383: val_loss did not improve from 0.39496\n",
      "Epoch 1384/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5387e-04 - fbeta: 1.0000 - val_loss: 0.6287 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01384: val_loss did not improve from 0.39496\n",
      "Epoch 1385/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5487e-04 - fbeta: 1.0000 - val_loss: 0.6279 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01385: val_loss did not improve from 0.39496\n",
      "Epoch 1386/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5434e-04 - fbeta: 1.0000 - val_loss: 0.6270 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01386: val_loss did not improve from 0.39496\n",
      "Epoch 1387/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5399e-04 - fbeta: 1.0000 - val_loss: 0.6290 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01387: val_loss did not improve from 0.39496\n",
      "Epoch 1388/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5390e-04 - fbeta: 1.0000 - val_loss: 0.6308 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01388: val_loss did not improve from 0.39496\n",
      "Epoch 1389/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5401e-04 - fbeta: 1.0000 - val_loss: 0.6322 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01389: val_loss did not improve from 0.39496\n",
      "Epoch 1390/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5125e-04 - fbeta: 1.0000 - val_loss: 0.6276 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01390: val_loss did not improve from 0.39496\n",
      "Epoch 1391/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5099e-04 - fbeta: 1.0000 - val_loss: 0.6304 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01391: val_loss did not improve from 0.39496\n",
      "Epoch 1392/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4999e-04 - fbeta: 1.0000 - val_loss: 0.6297 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01392: val_loss did not improve from 0.39496\n",
      "Epoch 1393/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5449e-04 - fbeta: 1.0000 - val_loss: 0.6296 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01393: val_loss did not improve from 0.39496\n",
      "Epoch 1394/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.5073e-04 - fbeta: 1.0000 - val_loss: 0.6325 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01394: val_loss did not improve from 0.39496\n",
      "Epoch 1395/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4987e-04 - fbeta: 1.0000 - val_loss: 0.6302 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01395: val_loss did not improve from 0.39496\n",
      "Epoch 1396/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4922e-04 - fbeta: 1.0000 - val_loss: 0.6311 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01396: val_loss did not improve from 0.39496\n",
      "Epoch 1397/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4885e-04 - fbeta: 1.0000 - val_loss: 0.6302 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01397: val_loss did not improve from 0.39496\n",
      "Epoch 1398/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4670e-04 - fbeta: 1.0000 - val_loss: 0.6286 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01398: val_loss did not improve from 0.39496\n",
      "Epoch 1399/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4768e-04 - fbeta: 1.0000 - val_loss: 0.6296 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01399: val_loss did not improve from 0.39496\n",
      "Epoch 1400/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4946e-04 - fbeta: 1.0000 - val_loss: 0.6301 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01400: val_loss did not improve from 0.39496\n",
      "Epoch 1401/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4678e-04 - fbeta: 1.0000 - val_loss: 0.6305 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01401: val_loss did not improve from 0.39496\n",
      "Epoch 1402/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4747e-04 - fbeta: 1.0000 - val_loss: 0.6286 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01402: val_loss did not improve from 0.39496\n",
      "Epoch 1403/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4485e-04 - fbeta: 1.0000 - val_loss: 0.6294 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01403: val_loss did not improve from 0.39496\n",
      "Epoch 1404/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4594e-04 - fbeta: 1.0000 - val_loss: 0.6286 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01404: val_loss did not improve from 0.39496\n",
      "Epoch 1405/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4484e-04 - fbeta: 1.0000 - val_loss: 0.6300 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01405: val_loss did not improve from 0.39496\n",
      "Epoch 1406/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4431e-04 - fbeta: 1.0000 - val_loss: 0.6272 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01406: val_loss did not improve from 0.39496\n",
      "Epoch 1407/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4402e-04 - fbeta: 1.0000 - val_loss: 0.6295 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01407: val_loss did not improve from 0.39496\n",
      "Epoch 1408/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4706e-04 - fbeta: 1.0000 - val_loss: 0.6301 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01408: val_loss did not improve from 0.39496\n",
      "Epoch 1409/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4524e-04 - fbeta: 1.0000 - val_loss: 0.6289 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01409: val_loss did not improve from 0.39496\n",
      "Epoch 1410/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4374e-04 - fbeta: 1.0000 - val_loss: 0.6280 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01410: val_loss did not improve from 0.39496\n",
      "Epoch 1411/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4216e-04 - fbeta: 1.0000 - val_loss: 0.6304 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01411: val_loss did not improve from 0.39496\n",
      "Epoch 1412/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4142e-04 - fbeta: 1.0000 - val_loss: 0.6261 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01412: val_loss did not improve from 0.39496\n",
      "Epoch 1413/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4179e-04 - fbeta: 1.0000 - val_loss: 0.6284 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01413: val_loss did not improve from 0.39496\n",
      "Epoch 1414/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4191e-04 - fbeta: 1.0000 - val_loss: 0.6320 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01414: val_loss did not improve from 0.39496\n",
      "Epoch 1415/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4129e-04 - fbeta: 1.0000 - val_loss: 0.6310 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01415: val_loss did not improve from 0.39496\n",
      "Epoch 1416/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4224e-04 - fbeta: 1.0000 - val_loss: 0.6305 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01416: val_loss did not improve from 0.39496\n",
      "Epoch 1417/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3989e-04 - fbeta: 1.0000 - val_loss: 0.6296 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01417: val_loss did not improve from 0.39496\n",
      "Epoch 1418/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4208e-04 - fbeta: 1.0000 - val_loss: 0.6292 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01418: val_loss did not improve from 0.39496\n",
      "Epoch 1419/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4074e-04 - fbeta: 1.0000 - val_loss: 0.6275 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01419: val_loss did not improve from 0.39496\n",
      "Epoch 1420/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.4050e-04 - fbeta: 1.0000 - val_loss: 0.6311 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01420: val_loss did not improve from 0.39496\n",
      "Epoch 1421/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3919e-04 - fbeta: 1.0000 - val_loss: 0.6313 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01421: val_loss did not improve from 0.39496\n",
      "Epoch 1422/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3741e-04 - fbeta: 1.0000 - val_loss: 0.6291 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01422: val_loss did not improve from 0.39496\n",
      "Epoch 1423/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3775e-04 - fbeta: 1.0000 - val_loss: 0.6300 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01423: val_loss did not improve from 0.39496\n",
      "Epoch 1424/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3775e-04 - fbeta: 1.0000 - val_loss: 0.6299 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01424: val_loss did not improve from 0.39496\n",
      "Epoch 1425/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3629e-04 - fbeta: 1.0000 - val_loss: 0.6304 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01425: val_loss did not improve from 0.39496\n",
      "Epoch 1426/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3847e-04 - fbeta: 1.0000 - val_loss: 0.6300 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01426: val_loss did not improve from 0.39496\n",
      "Epoch 1427/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3671e-04 - fbeta: 1.0000 - val_loss: 0.6307 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01427: val_loss did not improve from 0.39496\n",
      "Epoch 1428/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3506e-04 - fbeta: 1.0000 - val_loss: 0.6310 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01428: val_loss did not improve from 0.39496\n",
      "Epoch 1429/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3614e-04 - fbeta: 1.0000 - val_loss: 0.6316 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01429: val_loss did not improve from 0.39496\n",
      "Epoch 1430/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3544e-04 - fbeta: 1.0000 - val_loss: 0.6317 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01430: val_loss did not improve from 0.39496\n",
      "Epoch 1431/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3394e-04 - fbeta: 1.0000 - val_loss: 0.6309 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01431: val_loss did not improve from 0.39496\n",
      "Epoch 1432/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3367e-04 - fbeta: 1.0000 - val_loss: 0.6292 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01432: val_loss did not improve from 0.39496\n",
      "Epoch 1433/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3342e-04 - fbeta: 1.0000 - val_loss: 0.6313 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01433: val_loss did not improve from 0.39496\n",
      "Epoch 1434/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3259e-04 - fbeta: 1.0000 - val_loss: 0.6299 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01434: val_loss did not improve from 0.39496\n",
      "Epoch 1435/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3314e-04 - fbeta: 1.0000 - val_loss: 0.6305 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01435: val_loss did not improve from 0.39496\n",
      "Epoch 1436/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3521e-04 - fbeta: 1.0000 - val_loss: 0.6319 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01436: val_loss did not improve from 0.39496\n",
      "Epoch 1437/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3489e-04 - fbeta: 1.0000 - val_loss: 0.6321 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01437: val_loss did not improve from 0.39496\n",
      "Epoch 1438/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3322e-04 - fbeta: 1.0000 - val_loss: 0.6290 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01438: val_loss did not improve from 0.39496\n",
      "Epoch 1439/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3250e-04 - fbeta: 1.0000 - val_loss: 0.6309 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01439: val_loss did not improve from 0.39496\n",
      "Epoch 1440/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3130e-04 - fbeta: 1.0000 - val_loss: 0.6321 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01440: val_loss did not improve from 0.39496\n",
      "Epoch 1441/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3019e-04 - fbeta: 1.0000 - val_loss: 0.6307 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01441: val_loss did not improve from 0.39496\n",
      "Epoch 1442/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3109e-04 - fbeta: 1.0000 - val_loss: 0.6280 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01442: val_loss did not improve from 0.39496\n",
      "Epoch 1443/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2959e-04 - fbeta: 1.0000 - val_loss: 0.6325 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01443: val_loss did not improve from 0.39496\n",
      "Epoch 1444/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2870e-04 - fbeta: 1.0000 - val_loss: 0.6312 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01444: val_loss did not improve from 0.39496\n",
      "Epoch 1445/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2969e-04 - fbeta: 1.0000 - val_loss: 0.6310 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01445: val_loss did not improve from 0.39496\n",
      "Epoch 1446/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2980e-04 - fbeta: 1.0000 - val_loss: 0.6306 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01446: val_loss did not improve from 0.39496\n",
      "Epoch 1447/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2921e-04 - fbeta: 1.0000 - val_loss: 0.6360 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01447: val_loss did not improve from 0.39496\n",
      "Epoch 1448/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.3025e-04 - fbeta: 1.0000 - val_loss: 0.6331 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01448: val_loss did not improve from 0.39496\n",
      "Epoch 1449/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2805e-04 - fbeta: 1.0000 - val_loss: 0.6313 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01449: val_loss did not improve from 0.39496\n",
      "Epoch 1450/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2819e-04 - fbeta: 1.0000 - val_loss: 0.6318 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01450: val_loss did not improve from 0.39496\n",
      "Epoch 1451/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2714e-04 - fbeta: 1.0000 - val_loss: 0.6335 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01451: val_loss did not improve from 0.39496\n",
      "Epoch 1452/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2534e-04 - fbeta: 1.0000 - val_loss: 0.6299 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01452: val_loss did not improve from 0.39496\n",
      "Epoch 1453/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2664e-04 - fbeta: 1.0000 - val_loss: 0.6309 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01453: val_loss did not improve from 0.39496\n",
      "Epoch 1454/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2685e-04 - fbeta: 1.0000 - val_loss: 0.6339 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01454: val_loss did not improve from 0.39496\n",
      "Epoch 1455/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2552e-04 - fbeta: 1.0000 - val_loss: 0.6308 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01455: val_loss did not improve from 0.39496\n",
      "Epoch 1456/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2846e-04 - fbeta: 1.0000 - val_loss: 0.6319 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01456: val_loss did not improve from 0.39496\n",
      "Epoch 1457/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2487e-04 - fbeta: 1.0000 - val_loss: 0.6314 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01457: val_loss did not improve from 0.39496\n",
      "Epoch 1458/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2781e-04 - fbeta: 1.0000 - val_loss: 0.6301 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01458: val_loss did not improve from 0.39496\n",
      "Epoch 1459/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2645e-04 - fbeta: 1.0000 - val_loss: 0.6339 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01459: val_loss did not improve from 0.39496\n",
      "Epoch 1460/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2473e-04 - fbeta: 1.0000 - val_loss: 0.6329 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01460: val_loss did not improve from 0.39496\n",
      "Epoch 1461/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2400e-04 - fbeta: 1.0000 - val_loss: 0.6308 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01461: val_loss did not improve from 0.39496\n",
      "Epoch 1462/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2389e-04 - fbeta: 1.0000 - val_loss: 0.6320 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01462: val_loss did not improve from 0.39496\n",
      "Epoch 1463/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2349e-04 - fbeta: 1.0000 - val_loss: 0.6318 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01463: val_loss did not improve from 0.39496\n",
      "Epoch 1464/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2344e-04 - fbeta: 1.0000 - val_loss: 0.6313 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01464: val_loss did not improve from 0.39496\n",
      "Epoch 1465/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2383e-04 - fbeta: 1.0000 - val_loss: 0.6309 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01465: val_loss did not improve from 0.39496\n",
      "Epoch 1466/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2167e-04 - fbeta: 1.0000 - val_loss: 0.6312 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01466: val_loss did not improve from 0.39496\n",
      "Epoch 1467/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2086e-04 - fbeta: 1.0000 - val_loss: 0.6346 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01467: val_loss did not improve from 0.39496\n",
      "Epoch 1468/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2298e-04 - fbeta: 1.0000 - val_loss: 0.6341 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01468: val_loss did not improve from 0.39496\n",
      "Epoch 1469/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2133e-04 - fbeta: 1.0000 - val_loss: 0.6364 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01469: val_loss did not improve from 0.39496\n",
      "Epoch 1470/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2077e-04 - fbeta: 1.0000 - val_loss: 0.6346 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01470: val_loss did not improve from 0.39496\n",
      "Epoch 1471/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1878e-04 - fbeta: 1.0000 - val_loss: 0.6333 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01471: val_loss did not improve from 0.39496\n",
      "Epoch 1472/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1871e-04 - fbeta: 1.0000 - val_loss: 0.6308 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01472: val_loss did not improve from 0.39496\n",
      "Epoch 1473/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1887e-04 - fbeta: 1.0000 - val_loss: 0.6294 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01473: val_loss did not improve from 0.39496\n",
      "Epoch 1474/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1752e-04 - fbeta: 1.0000 - val_loss: 0.6335 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01474: val_loss did not improve from 0.39496\n",
      "Epoch 1475/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1869e-04 - fbeta: 1.0000 - val_loss: 0.6376 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01475: val_loss did not improve from 0.39496\n",
      "Epoch 1476/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1813e-04 - fbeta: 1.0000 - val_loss: 0.6369 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01476: val_loss did not improve from 0.39496\n",
      "Epoch 1477/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1636e-04 - fbeta: 1.0000 - val_loss: 0.6357 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01477: val_loss did not improve from 0.39496\n",
      "Epoch 1478/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1682e-04 - fbeta: 1.0000 - val_loss: 0.6346 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01478: val_loss did not improve from 0.39496\n",
      "Epoch 1479/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1877e-04 - fbeta: 1.0000 - val_loss: 0.6349 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01479: val_loss did not improve from 0.39496\n",
      "Epoch 1480/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1680e-04 - fbeta: 1.0000 - val_loss: 0.6330 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01480: val_loss did not improve from 0.39496\n",
      "Epoch 1481/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1683e-04 - fbeta: 1.0000 - val_loss: 0.6315 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01481: val_loss did not improve from 0.39496\n",
      "Epoch 1482/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.2487e-04 - fbeta: 1.0000 - val_loss: 0.6326 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01482: val_loss did not improve from 0.39496\n",
      "Epoch 1483/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1531e-04 - fbeta: 1.0000 - val_loss: 0.6348 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01483: val_loss did not improve from 0.39496\n",
      "Epoch 1484/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1637e-04 - fbeta: 1.0000 - val_loss: 0.6366 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01484: val_loss did not improve from 0.39496\n",
      "Epoch 1485/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1553e-04 - fbeta: 1.0000 - val_loss: 0.6352 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01485: val_loss did not improve from 0.39496\n",
      "Epoch 1486/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1484e-04 - fbeta: 1.0000 - val_loss: 0.6346 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01486: val_loss did not improve from 0.39496\n",
      "Epoch 1487/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1590e-04 - fbeta: 1.0000 - val_loss: 0.6335 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01487: val_loss did not improve from 0.39496\n",
      "Epoch 1488/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1712e-04 - fbeta: 1.0000 - val_loss: 0.6359 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01488: val_loss did not improve from 0.39496\n",
      "Epoch 1489/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1440e-04 - fbeta: 1.0000 - val_loss: 0.6324 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01489: val_loss did not improve from 0.39496\n",
      "Epoch 1490/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1419e-04 - fbeta: 1.0000 - val_loss: 0.6334 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01490: val_loss did not improve from 0.39496\n",
      "Epoch 1491/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1668e-04 - fbeta: 1.0000 - val_loss: 0.6354 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01491: val_loss did not improve from 0.39496\n",
      "Epoch 1492/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1297e-04 - fbeta: 1.0000 - val_loss: 0.6305 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01492: val_loss did not improve from 0.39496\n",
      "Epoch 1493/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1612e-04 - fbeta: 1.0000 - val_loss: 0.6305 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01493: val_loss did not improve from 0.39496\n",
      "Epoch 1494/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1156e-04 - fbeta: 1.0000 - val_loss: 0.6316 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01494: val_loss did not improve from 0.39496\n",
      "Epoch 1495/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1136e-04 - fbeta: 1.0000 - val_loss: 0.6284 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01495: val_loss did not improve from 0.39496\n",
      "Epoch 1496/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1158e-04 - fbeta: 1.0000 - val_loss: 0.6309 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01496: val_loss did not improve from 0.39496\n",
      "Epoch 1497/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1389e-04 - fbeta: 1.0000 - val_loss: 0.6337 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01497: val_loss did not improve from 0.39496\n",
      "Epoch 1498/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1039e-04 - fbeta: 1.0000 - val_loss: 0.6356 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01498: val_loss did not improve from 0.39496\n",
      "Epoch 1499/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0856e-04 - fbeta: 1.0000 - val_loss: 0.6346 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01499: val_loss did not improve from 0.39496\n",
      "Epoch 1500/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1151e-04 - fbeta: 1.0000 - val_loss: 0.6303 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01500: val_loss did not improve from 0.39496\n",
      "Epoch 1501/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0854e-04 - fbeta: 1.0000 - val_loss: 0.6309 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01501: val_loss did not improve from 0.39496\n",
      "Epoch 1502/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0857e-04 - fbeta: 1.0000 - val_loss: 0.6306 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01502: val_loss did not improve from 0.39496\n",
      "Epoch 1503/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0871e-04 - fbeta: 1.0000 - val_loss: 0.6311 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01503: val_loss did not improve from 0.39496\n",
      "Epoch 1504/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0718e-04 - fbeta: 1.0000 - val_loss: 0.6337 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01504: val_loss did not improve from 0.39496\n",
      "Epoch 1505/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0807e-04 - fbeta: 1.0000 - val_loss: 0.6350 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01505: val_loss did not improve from 0.39496\n",
      "Epoch 1506/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0689e-04 - fbeta: 1.0000 - val_loss: 0.6352 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01506: val_loss did not improve from 0.39496\n",
      "Epoch 1507/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0634e-04 - fbeta: 1.0000 - val_loss: 0.6323 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01507: val_loss did not improve from 0.39496\n",
      "Epoch 1508/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0941e-04 - fbeta: 1.0000 - val_loss: 0.6347 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01508: val_loss did not improve from 0.39496\n",
      "Epoch 1509/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1008e-04 - fbeta: 1.0000 - val_loss: 0.6323 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01509: val_loss did not improve from 0.39496\n",
      "Epoch 1510/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0722e-04 - fbeta: 1.0000 - val_loss: 0.6301 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01510: val_loss did not improve from 0.39496\n",
      "Epoch 1511/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0582e-04 - fbeta: 1.0000 - val_loss: 0.6346 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01511: val_loss did not improve from 0.39496\n",
      "Epoch 1512/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0419e-04 - fbeta: 1.0000 - val_loss: 0.6351 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01512: val_loss did not improve from 0.39496\n",
      "Epoch 1513/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0385e-04 - fbeta: 1.0000 - val_loss: 0.6364 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01513: val_loss did not improve from 0.39496\n",
      "Epoch 1514/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0462e-04 - fbeta: 1.0000 - val_loss: 0.6346 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01514: val_loss did not improve from 0.39496\n",
      "Epoch 1515/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0454e-04 - fbeta: 1.0000 - val_loss: 0.6331 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01515: val_loss did not improve from 0.39496\n",
      "Epoch 1516/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.1020e-04 - fbeta: 1.0000 - val_loss: 0.6296 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01516: val_loss did not improve from 0.39496\n",
      "Epoch 1517/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0303e-04 - fbeta: 1.0000 - val_loss: 0.6327 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01517: val_loss did not improve from 0.39496\n",
      "Epoch 1518/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0256e-04 - fbeta: 1.0000 - val_loss: 0.6327 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01518: val_loss did not improve from 0.39496\n",
      "Epoch 1519/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0243e-04 - fbeta: 1.0000 - val_loss: 0.6339 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01519: val_loss did not improve from 0.39496\n",
      "Epoch 1520/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0357e-04 - fbeta: 1.0000 - val_loss: 0.6337 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01520: val_loss did not improve from 0.39496\n",
      "Epoch 1521/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0103e-04 - fbeta: 1.0000 - val_loss: 0.6352 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01521: val_loss did not improve from 0.39496\n",
      "Epoch 1522/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0059e-04 - fbeta: 1.0000 - val_loss: 0.6363 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01522: val_loss did not improve from 0.39496\n",
      "Epoch 1523/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 4.0083e-04 - fbeta: 1.0000 - val_loss: 0.6374 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01523: val_loss did not improve from 0.39496\n",
      "Epoch 1524/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9998e-04 - fbeta: 1.0000 - val_loss: 0.6359 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01524: val_loss did not improve from 0.39496\n",
      "Epoch 1525/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9987e-04 - fbeta: 1.0000 - val_loss: 0.6366 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01525: val_loss did not improve from 0.39496\n",
      "Epoch 1526/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9986e-04 - fbeta: 1.0000 - val_loss: 0.6346 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01526: val_loss did not improve from 0.39496\n",
      "Epoch 1527/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9901e-04 - fbeta: 1.0000 - val_loss: 0.6370 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01527: val_loss did not improve from 0.39496\n",
      "Epoch 1528/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9873e-04 - fbeta: 1.0000 - val_loss: 0.6361 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01528: val_loss did not improve from 0.39496\n",
      "Epoch 1529/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9939e-04 - fbeta: 1.0000 - val_loss: 0.6363 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01529: val_loss did not improve from 0.39496\n",
      "Epoch 1530/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9922e-04 - fbeta: 1.0000 - val_loss: 0.6334 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01530: val_loss did not improve from 0.39496\n",
      "Epoch 1531/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9811e-04 - fbeta: 1.0000 - val_loss: 0.6355 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01531: val_loss did not improve from 0.39496\n",
      "Epoch 1532/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9945e-04 - fbeta: 1.0000 - val_loss: 0.6353 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01532: val_loss did not improve from 0.39496\n",
      "Epoch 1533/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9770e-04 - fbeta: 1.0000 - val_loss: 0.6344 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01533: val_loss did not improve from 0.39496\n",
      "Epoch 1534/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9733e-04 - fbeta: 1.0000 - val_loss: 0.6358 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01534: val_loss did not improve from 0.39496\n",
      "Epoch 1535/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9679e-04 - fbeta: 1.0000 - val_loss: 0.6368 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01535: val_loss did not improve from 0.39496\n",
      "Epoch 1536/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9479e-04 - fbeta: 1.0000 - val_loss: 0.6358 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01536: val_loss did not improve from 0.39496\n",
      "Epoch 1537/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9673e-04 - fbeta: 1.0000 - val_loss: 0.6329 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01537: val_loss did not improve from 0.39496\n",
      "Epoch 1538/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9870e-04 - fbeta: 1.0000 - val_loss: 0.6338 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01538: val_loss did not improve from 0.39496\n",
      "Epoch 1539/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9686e-04 - fbeta: 1.0000 - val_loss: 0.6361 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01539: val_loss did not improve from 0.39496\n",
      "Epoch 1540/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9550e-04 - fbeta: 1.0000 - val_loss: 0.6352 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01540: val_loss did not improve from 0.39496\n",
      "Epoch 1541/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9409e-04 - fbeta: 1.0000 - val_loss: 0.6350 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01541: val_loss did not improve from 0.39496\n",
      "Epoch 1542/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9349e-04 - fbeta: 1.0000 - val_loss: 0.6333 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01542: val_loss did not improve from 0.39496\n",
      "Epoch 1543/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9463e-04 - fbeta: 1.0000 - val_loss: 0.6336 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01543: val_loss did not improve from 0.39496\n",
      "Epoch 1544/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9462e-04 - fbeta: 1.0000 - val_loss: 0.6344 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01544: val_loss did not improve from 0.39496\n",
      "Epoch 1545/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9444e-04 - fbeta: 1.0000 - val_loss: 0.6343 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01545: val_loss did not improve from 0.39496\n",
      "Epoch 1546/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9326e-04 - fbeta: 1.0000 - val_loss: 0.6361 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01546: val_loss did not improve from 0.39496\n",
      "Epoch 1547/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9218e-04 - fbeta: 1.0000 - val_loss: 0.6363 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01547: val_loss did not improve from 0.39496\n",
      "Epoch 1548/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9326e-04 - fbeta: 1.0000 - val_loss: 0.6352 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01548: val_loss did not improve from 0.39496\n",
      "Epoch 1549/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9200e-04 - fbeta: 1.0000 - val_loss: 0.6361 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01549: val_loss did not improve from 0.39496\n",
      "Epoch 1550/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9239e-04 - fbeta: 1.0000 - val_loss: 0.6399 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01550: val_loss did not improve from 0.39496\n",
      "Epoch 1551/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9188e-04 - fbeta: 1.0000 - val_loss: 0.6398 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01551: val_loss did not improve from 0.39496\n",
      "Epoch 1552/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9150e-04 - fbeta: 1.0000 - val_loss: 0.6356 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01552: val_loss did not improve from 0.39496\n",
      "Epoch 1553/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9231e-04 - fbeta: 1.0000 - val_loss: 0.6381 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01553: val_loss did not improve from 0.39496\n",
      "Epoch 1554/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9113e-04 - fbeta: 1.0000 - val_loss: 0.6389 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01554: val_loss did not improve from 0.39496\n",
      "Epoch 1555/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8967e-04 - fbeta: 1.0000 - val_loss: 0.6379 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01555: val_loss did not improve from 0.39496\n",
      "Epoch 1556/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9128e-04 - fbeta: 1.0000 - val_loss: 0.6424 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01556: val_loss did not improve from 0.39496\n",
      "Epoch 1557/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8963e-04 - fbeta: 1.0000 - val_loss: 0.6371 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01557: val_loss did not improve from 0.39496\n",
      "Epoch 1558/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8896e-04 - fbeta: 1.0000 - val_loss: 0.6380 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01558: val_loss did not improve from 0.39496\n",
      "Epoch 1559/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8936e-04 - fbeta: 1.0000 - val_loss: 0.6411 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01559: val_loss did not improve from 0.39496\n",
      "Epoch 1560/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8951e-04 - fbeta: 1.0000 - val_loss: 0.6382 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01560: val_loss did not improve from 0.39496\n",
      "Epoch 1561/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8863e-04 - fbeta: 1.0000 - val_loss: 0.6377 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01561: val_loss did not improve from 0.39496\n",
      "Epoch 1562/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8801e-04 - fbeta: 1.0000 - val_loss: 0.6383 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01562: val_loss did not improve from 0.39496\n",
      "Epoch 1563/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.9048e-04 - fbeta: 1.0000 - val_loss: 0.6346 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01563: val_loss did not improve from 0.39496\n",
      "Epoch 1564/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8752e-04 - fbeta: 1.0000 - val_loss: 0.6330 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01564: val_loss did not improve from 0.39496\n",
      "Epoch 1565/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8732e-04 - fbeta: 1.0000 - val_loss: 0.6389 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01565: val_loss did not improve from 0.39496\n",
      "Epoch 1566/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8659e-04 - fbeta: 1.0000 - val_loss: 0.6371 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01566: val_loss did not improve from 0.39496\n",
      "Epoch 1567/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8513e-04 - fbeta: 1.0000 - val_loss: 0.6379 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01567: val_loss did not improve from 0.39496\n",
      "Epoch 1568/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8591e-04 - fbeta: 1.0000 - val_loss: 0.6345 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01568: val_loss did not improve from 0.39496\n",
      "Epoch 1569/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8560e-04 - fbeta: 1.0000 - val_loss: 0.6352 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01569: val_loss did not improve from 0.39496\n",
      "Epoch 1570/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8544e-04 - fbeta: 1.0000 - val_loss: 0.6364 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01570: val_loss did not improve from 0.39496\n",
      "Epoch 1571/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8457e-04 - fbeta: 1.0000 - val_loss: 0.6381 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01571: val_loss did not improve from 0.39496\n",
      "Epoch 1572/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8342e-04 - fbeta: 1.0000 - val_loss: 0.6384 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01572: val_loss did not improve from 0.39496\n",
      "Epoch 1573/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8426e-04 - fbeta: 1.0000 - val_loss: 0.6393 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01573: val_loss did not improve from 0.39496\n",
      "Epoch 1574/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8652e-04 - fbeta: 1.0000 - val_loss: 0.6379 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01574: val_loss did not improve from 0.39496\n",
      "Epoch 1575/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8367e-04 - fbeta: 1.0000 - val_loss: 0.6393 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01575: val_loss did not improve from 0.39496\n",
      "Epoch 1576/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8327e-04 - fbeta: 1.0000 - val_loss: 0.6367 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01576: val_loss did not improve from 0.39496\n",
      "Epoch 1577/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8221e-04 - fbeta: 1.0000 - val_loss: 0.6366 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01577: val_loss did not improve from 0.39496\n",
      "Epoch 1578/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8329e-04 - fbeta: 1.0000 - val_loss: 0.6371 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01578: val_loss did not improve from 0.39496\n",
      "Epoch 1579/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8220e-04 - fbeta: 1.0000 - val_loss: 0.6374 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01579: val_loss did not improve from 0.39496\n",
      "Epoch 1580/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8085e-04 - fbeta: 1.0000 - val_loss: 0.6378 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01580: val_loss did not improve from 0.39496\n",
      "Epoch 1581/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8158e-04 - fbeta: 1.0000 - val_loss: 0.6385 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01581: val_loss did not improve from 0.39496\n",
      "Epoch 1582/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8097e-04 - fbeta: 1.0000 - val_loss: 0.6387 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01582: val_loss did not improve from 0.39496\n",
      "Epoch 1583/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8051e-04 - fbeta: 1.0000 - val_loss: 0.6391 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01583: val_loss did not improve from 0.39496\n",
      "Epoch 1584/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8050e-04 - fbeta: 1.0000 - val_loss: 0.6342 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01584: val_loss did not improve from 0.39496\n",
      "Epoch 1585/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8108e-04 - fbeta: 1.0000 - val_loss: 0.6372 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01585: val_loss did not improve from 0.39496\n",
      "Epoch 1586/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7984e-04 - fbeta: 1.0000 - val_loss: 0.6363 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01586: val_loss did not improve from 0.39496\n",
      "Epoch 1587/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8309e-04 - fbeta: 1.0000 - val_loss: 0.6342 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01587: val_loss did not improve from 0.39496\n",
      "Epoch 1588/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7951e-04 - fbeta: 1.0000 - val_loss: 0.6363 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01588: val_loss did not improve from 0.39496\n",
      "Epoch 1589/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7957e-04 - fbeta: 1.0000 - val_loss: 0.6396 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01589: val_loss did not improve from 0.39496\n",
      "Epoch 1590/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7822e-04 - fbeta: 1.0000 - val_loss: 0.6411 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01590: val_loss did not improve from 0.39496\n",
      "Epoch 1591/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7911e-04 - fbeta: 1.0000 - val_loss: 0.6388 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01591: val_loss did not improve from 0.39496\n",
      "Epoch 1592/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7842e-04 - fbeta: 1.0000 - val_loss: 0.6374 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01592: val_loss did not improve from 0.39496\n",
      "Epoch 1593/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.8435e-04 - fbeta: 1.0000 - val_loss: 0.6370 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01593: val_loss did not improve from 0.39496\n",
      "Epoch 1594/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7908e-04 - fbeta: 1.0000 - val_loss: 0.6394 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01594: val_loss did not improve from 0.39496\n",
      "Epoch 1595/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7864e-04 - fbeta: 1.0000 - val_loss: 0.6389 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01595: val_loss did not improve from 0.39496\n",
      "Epoch 1596/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7796e-04 - fbeta: 1.0000 - val_loss: 0.6430 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01596: val_loss did not improve from 0.39496\n",
      "Epoch 1597/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7928e-04 - fbeta: 1.0000 - val_loss: 0.6503 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01597: val_loss did not improve from 0.39496\n",
      "Epoch 1598/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7918e-04 - fbeta: 1.0000 - val_loss: 0.6462 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01598: val_loss did not improve from 0.39496\n",
      "Epoch 1599/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7740e-04 - fbeta: 1.0000 - val_loss: 0.6375 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01599: val_loss did not improve from 0.39496\n",
      "Epoch 1600/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7701e-04 - fbeta: 1.0000 - val_loss: 0.6402 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01600: val_loss did not improve from 0.39496\n",
      "Epoch 1601/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7599e-04 - fbeta: 1.0000 - val_loss: 0.6360 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01601: val_loss did not improve from 0.39496\n",
      "Epoch 1602/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7557e-04 - fbeta: 1.0000 - val_loss: 0.6344 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01602: val_loss did not improve from 0.39496\n",
      "Epoch 1603/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7559e-04 - fbeta: 1.0000 - val_loss: 0.6333 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01603: val_loss did not improve from 0.39496\n",
      "Epoch 1604/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7551e-04 - fbeta: 1.0000 - val_loss: 0.6356 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01604: val_loss did not improve from 0.39496\n",
      "Epoch 1605/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7512e-04 - fbeta: 1.0000 - val_loss: 0.6389 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01605: val_loss did not improve from 0.39496\n",
      "Epoch 1606/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7391e-04 - fbeta: 1.0000 - val_loss: 0.6399 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01606: val_loss did not improve from 0.39496\n",
      "Epoch 1607/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7306e-04 - fbeta: 1.0000 - val_loss: 0.6397 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01607: val_loss did not improve from 0.39496\n",
      "Epoch 1608/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7366e-04 - fbeta: 1.0000 - val_loss: 0.6414 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01608: val_loss did not improve from 0.39496\n",
      "Epoch 1609/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7330e-04 - fbeta: 1.0000 - val_loss: 0.6403 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01609: val_loss did not improve from 0.39496\n",
      "Epoch 1610/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7351e-04 - fbeta: 1.0000 - val_loss: 0.6386 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01610: val_loss did not improve from 0.39496\n",
      "Epoch 1611/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7268e-04 - fbeta: 1.0000 - val_loss: 0.6408 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01611: val_loss did not improve from 0.39496\n",
      "Epoch 1612/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7258e-04 - fbeta: 1.0000 - val_loss: 0.6400 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01612: val_loss did not improve from 0.39496\n",
      "Epoch 1613/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7155e-04 - fbeta: 1.0000 - val_loss: 0.6396 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01613: val_loss did not improve from 0.39496\n",
      "Epoch 1614/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7154e-04 - fbeta: 1.0000 - val_loss: 0.6398 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01614: val_loss did not improve from 0.39496\n",
      "Epoch 1615/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7126e-04 - fbeta: 1.0000 - val_loss: 0.6397 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01615: val_loss did not improve from 0.39496\n",
      "Epoch 1616/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7080e-04 - fbeta: 1.0000 - val_loss: 0.6378 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01616: val_loss did not improve from 0.39496\n",
      "Epoch 1617/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7085e-04 - fbeta: 1.0000 - val_loss: 0.6393 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01617: val_loss did not improve from 0.39496\n",
      "Epoch 1618/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7180e-04 - fbeta: 1.0000 - val_loss: 0.6409 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01618: val_loss did not improve from 0.39496\n",
      "Epoch 1619/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7082e-04 - fbeta: 1.0000 - val_loss: 0.6415 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01619: val_loss did not improve from 0.39496\n",
      "Epoch 1620/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7022e-04 - fbeta: 1.0000 - val_loss: 0.6378 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01620: val_loss did not improve from 0.39496\n",
      "Epoch 1621/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7002e-04 - fbeta: 1.0000 - val_loss: 0.6394 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01621: val_loss did not improve from 0.39496\n",
      "Epoch 1622/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6972e-04 - fbeta: 1.0000 - val_loss: 0.6405 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01622: val_loss did not improve from 0.39496\n",
      "Epoch 1623/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6945e-04 - fbeta: 1.0000 - val_loss: 0.6410 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01623: val_loss did not improve from 0.39496\n",
      "Epoch 1624/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7150e-04 - fbeta: 1.0000 - val_loss: 0.6428 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01624: val_loss did not improve from 0.39496\n",
      "Epoch 1625/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6961e-04 - fbeta: 1.0000 - val_loss: 0.6390 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01625: val_loss did not improve from 0.39496\n",
      "Epoch 1626/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7039e-04 - fbeta: 1.0000 - val_loss: 0.6338 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01626: val_loss did not improve from 0.39496\n",
      "Epoch 1627/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6790e-04 - fbeta: 1.0000 - val_loss: 0.6377 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01627: val_loss did not improve from 0.39496\n",
      "Epoch 1628/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6770e-04 - fbeta: 1.0000 - val_loss: 0.6401 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01628: val_loss did not improve from 0.39496\n",
      "Epoch 1629/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7060e-04 - fbeta: 1.0000 - val_loss: 0.6411 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01629: val_loss did not improve from 0.39496\n",
      "Epoch 1630/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.7027e-04 - fbeta: 1.0000 - val_loss: 0.6406 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01630: val_loss did not improve from 0.39496\n",
      "Epoch 1631/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6790e-04 - fbeta: 1.0000 - val_loss: 0.6389 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01631: val_loss did not improve from 0.39496\n",
      "Epoch 1632/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6647e-04 - fbeta: 1.0000 - val_loss: 0.6406 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01632: val_loss did not improve from 0.39496\n",
      "Epoch 1633/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6703e-04 - fbeta: 1.0000 - val_loss: 0.6407 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01633: val_loss did not improve from 0.39496\n",
      "Epoch 1634/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6689e-04 - fbeta: 1.0000 - val_loss: 0.6402 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01634: val_loss did not improve from 0.39496\n",
      "Epoch 1635/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6610e-04 - fbeta: 1.0000 - val_loss: 0.6404 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01635: val_loss did not improve from 0.39496\n",
      "Epoch 1636/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6818e-04 - fbeta: 1.0000 - val_loss: 0.6460 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01636: val_loss did not improve from 0.39496\n",
      "Epoch 1637/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6592e-04 - fbeta: 1.0000 - val_loss: 0.6424 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01637: val_loss did not improve from 0.39496\n",
      "Epoch 1638/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6488e-04 - fbeta: 1.0000 - val_loss: 0.6424 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01638: val_loss did not improve from 0.39496\n",
      "Epoch 1639/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6490e-04 - fbeta: 1.0000 - val_loss: 0.6413 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01639: val_loss did not improve from 0.39496\n",
      "Epoch 1640/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6448e-04 - fbeta: 1.0000 - val_loss: 0.6426 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01640: val_loss did not improve from 0.39496\n",
      "Epoch 1641/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6333e-04 - fbeta: 1.0000 - val_loss: 0.6415 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01641: val_loss did not improve from 0.39496\n",
      "Epoch 1642/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6331e-04 - fbeta: 1.0000 - val_loss: 0.6398 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01642: val_loss did not improve from 0.39496\n",
      "Epoch 1643/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6386e-04 - fbeta: 1.0000 - val_loss: 0.6405 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01643: val_loss did not improve from 0.39496\n",
      "Epoch 1644/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6257e-04 - fbeta: 1.0000 - val_loss: 0.6399 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01644: val_loss did not improve from 0.39496\n",
      "Epoch 1645/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6281e-04 - fbeta: 1.0000 - val_loss: 0.6406 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01645: val_loss did not improve from 0.39496\n",
      "Epoch 1646/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6298e-04 - fbeta: 1.0000 - val_loss: 0.6423 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01646: val_loss did not improve from 0.39496\n",
      "Epoch 1647/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6279e-04 - fbeta: 1.0000 - val_loss: 0.6422 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01647: val_loss did not improve from 0.39496\n",
      "Epoch 1648/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6224e-04 - fbeta: 1.0000 - val_loss: 0.6407 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01648: val_loss did not improve from 0.39496\n",
      "Epoch 1649/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6219e-04 - fbeta: 1.0000 - val_loss: 0.6396 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01649: val_loss did not improve from 0.39496\n",
      "Epoch 1650/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6215e-04 - fbeta: 1.0000 - val_loss: 0.6375 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01650: val_loss did not improve from 0.39496\n",
      "Epoch 1651/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6074e-04 - fbeta: 1.0000 - val_loss: 0.6400 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01651: val_loss did not improve from 0.39496\n",
      "Epoch 1652/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6066e-04 - fbeta: 1.0000 - val_loss: 0.6429 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01652: val_loss did not improve from 0.39496\n",
      "Epoch 1653/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6029e-04 - fbeta: 1.0000 - val_loss: 0.6428 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01653: val_loss did not improve from 0.39496\n",
      "Epoch 1654/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6049e-04 - fbeta: 1.0000 - val_loss: 0.6420 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01654: val_loss did not improve from 0.39496\n",
      "Epoch 1655/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6052e-04 - fbeta: 1.0000 - val_loss: 0.6434 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01655: val_loss did not improve from 0.39496\n",
      "Epoch 1656/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6049e-04 - fbeta: 1.0000 - val_loss: 0.6403 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01656: val_loss did not improve from 0.39496\n",
      "Epoch 1657/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6091e-04 - fbeta: 1.0000 - val_loss: 0.6390 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01657: val_loss did not improve from 0.39496\n",
      "Epoch 1658/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6031e-04 - fbeta: 1.0000 - val_loss: 0.6401 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01658: val_loss did not improve from 0.39496\n",
      "Epoch 1659/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6094e-04 - fbeta: 1.0000 - val_loss: 0.6415 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01659: val_loss did not improve from 0.39496\n",
      "Epoch 1660/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5910e-04 - fbeta: 1.0000 - val_loss: 0.6404 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01660: val_loss did not improve from 0.39496\n",
      "Epoch 1661/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5894e-04 - fbeta: 1.0000 - val_loss: 0.6423 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01661: val_loss did not improve from 0.39496\n",
      "Epoch 1662/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5818e-04 - fbeta: 1.0000 - val_loss: 0.6435 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01662: val_loss did not improve from 0.39496\n",
      "Epoch 1663/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5929e-04 - fbeta: 1.0000 - val_loss: 0.6431 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01663: val_loss did not improve from 0.39496\n",
      "Epoch 1664/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5884e-04 - fbeta: 1.0000 - val_loss: 0.6459 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01664: val_loss did not improve from 0.39496\n",
      "Epoch 1665/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5800e-04 - fbeta: 1.0000 - val_loss: 0.6452 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01665: val_loss did not improve from 0.39496\n",
      "Epoch 1666/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5701e-04 - fbeta: 1.0000 - val_loss: 0.6401 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01666: val_loss did not improve from 0.39496\n",
      "Epoch 1667/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6461e-04 - fbeta: 1.0000 - val_loss: 0.6349 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01667: val_loss did not improve from 0.39496\n",
      "Epoch 1668/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.6006e-04 - fbeta: 1.0000 - val_loss: 0.6366 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01668: val_loss did not improve from 0.39496\n",
      "Epoch 1669/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5961e-04 - fbeta: 1.0000 - val_loss: 0.6456 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01669: val_loss did not improve from 0.39496\n",
      "Epoch 1670/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5613e-04 - fbeta: 1.0000 - val_loss: 0.6451 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01670: val_loss did not improve from 0.39496\n",
      "Epoch 1671/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5563e-04 - fbeta: 1.0000 - val_loss: 0.6454 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01671: val_loss did not improve from 0.39496\n",
      "Epoch 1672/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5476e-04 - fbeta: 1.0000 - val_loss: 0.6449 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01672: val_loss did not improve from 0.39496\n",
      "Epoch 1673/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5489e-04 - fbeta: 1.0000 - val_loss: 0.6429 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01673: val_loss did not improve from 0.39496\n",
      "Epoch 1674/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5448e-04 - fbeta: 1.0000 - val_loss: 0.6409 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01674: val_loss did not improve from 0.39496\n",
      "Epoch 1675/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5799e-04 - fbeta: 1.0000 - val_loss: 0.6429 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01675: val_loss did not improve from 0.39496\n",
      "Epoch 1676/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5555e-04 - fbeta: 1.0000 - val_loss: 0.6430 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01676: val_loss did not improve from 0.39496\n",
      "Epoch 1677/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5492e-04 - fbeta: 1.0000 - val_loss: 0.6439 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01677: val_loss did not improve from 0.39496\n",
      "Epoch 1678/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5365e-04 - fbeta: 1.0000 - val_loss: 0.6411 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01678: val_loss did not improve from 0.39496\n",
      "Epoch 1679/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5512e-04 - fbeta: 1.0000 - val_loss: 0.6422 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01679: val_loss did not improve from 0.39496\n",
      "Epoch 1680/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5472e-04 - fbeta: 1.0000 - val_loss: 0.6448 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01680: val_loss did not improve from 0.39496\n",
      "Epoch 1681/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5330e-04 - fbeta: 1.0000 - val_loss: 0.6448 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01681: val_loss did not improve from 0.39496\n",
      "Epoch 1682/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5312e-04 - fbeta: 1.0000 - val_loss: 0.6408 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01682: val_loss did not improve from 0.39496\n",
      "Epoch 1683/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5286e-04 - fbeta: 1.0000 - val_loss: 0.6412 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01683: val_loss did not improve from 0.39496\n",
      "Epoch 1684/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5318e-04 - fbeta: 1.0000 - val_loss: 0.6417 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01684: val_loss did not improve from 0.39496\n",
      "Epoch 1685/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5333e-04 - fbeta: 1.0000 - val_loss: 0.6397 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01685: val_loss did not improve from 0.39496\n",
      "Epoch 1686/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5193e-04 - fbeta: 1.0000 - val_loss: 0.6415 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01686: val_loss did not improve from 0.39496\n",
      "Epoch 1687/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5040e-04 - fbeta: 1.0000 - val_loss: 0.6424 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01687: val_loss did not improve from 0.39496\n",
      "Epoch 1688/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5098e-04 - fbeta: 1.0000 - val_loss: 0.6423 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01688: val_loss did not improve from 0.39496\n",
      "Epoch 1689/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5110e-04 - fbeta: 1.0000 - val_loss: 0.6438 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01689: val_loss did not improve from 0.39496\n",
      "Epoch 1690/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5185e-04 - fbeta: 1.0000 - val_loss: 0.6429 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01690: val_loss did not improve from 0.39496\n",
      "Epoch 1691/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5058e-04 - fbeta: 1.0000 - val_loss: 0.6426 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01691: val_loss did not improve from 0.39496\n",
      "Epoch 1692/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4992e-04 - fbeta: 1.0000 - val_loss: 0.6413 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01692: val_loss did not improve from 0.39496\n",
      "Epoch 1693/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.5038e-04 - fbeta: 1.0000 - val_loss: 0.6438 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01693: val_loss did not improve from 0.39496\n",
      "Epoch 1694/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4938e-04 - fbeta: 1.0000 - val_loss: 0.6427 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01694: val_loss did not improve from 0.39496\n",
      "Epoch 1695/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4876e-04 - fbeta: 1.0000 - val_loss: 0.6428 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01695: val_loss did not improve from 0.39496\n",
      "Epoch 1696/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4799e-04 - fbeta: 1.0000 - val_loss: 0.6430 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01696: val_loss did not improve from 0.39496\n",
      "Epoch 1697/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4847e-04 - fbeta: 1.0000 - val_loss: 0.6430 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01697: val_loss did not improve from 0.39496\n",
      "Epoch 1698/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4762e-04 - fbeta: 1.0000 - val_loss: 0.6412 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01698: val_loss did not improve from 0.39496\n",
      "Epoch 1699/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4869e-04 - fbeta: 1.0000 - val_loss: 0.6447 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01699: val_loss did not improve from 0.39496\n",
      "Epoch 1700/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4905e-04 - fbeta: 1.0000 - val_loss: 0.6451 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01700: val_loss did not improve from 0.39496\n",
      "Epoch 1701/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4749e-04 - fbeta: 1.0000 - val_loss: 0.6436 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01701: val_loss did not improve from 0.39496\n",
      "Epoch 1702/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4738e-04 - fbeta: 1.0000 - val_loss: 0.6423 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01702: val_loss did not improve from 0.39496\n",
      "Epoch 1703/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4732e-04 - fbeta: 1.0000 - val_loss: 0.6432 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01703: val_loss did not improve from 0.39496\n",
      "Epoch 1704/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4650e-04 - fbeta: 1.0000 - val_loss: 0.6418 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01704: val_loss did not improve from 0.39496\n",
      "Epoch 1705/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4695e-04 - fbeta: 1.0000 - val_loss: 0.6394 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01705: val_loss did not improve from 0.39496\n",
      "Epoch 1706/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4611e-04 - fbeta: 1.0000 - val_loss: 0.6432 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01706: val_loss did not improve from 0.39496\n",
      "Epoch 1707/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4611e-04 - fbeta: 1.0000 - val_loss: 0.6410 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01707: val_loss did not improve from 0.39496\n",
      "Epoch 1708/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4603e-04 - fbeta: 1.0000 - val_loss: 0.6402 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01708: val_loss did not improve from 0.39496\n",
      "Epoch 1709/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4574e-04 - fbeta: 1.0000 - val_loss: 0.6389 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01709: val_loss did not improve from 0.39496\n",
      "Epoch 1710/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4886e-04 - fbeta: 1.0000 - val_loss: 0.6414 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01710: val_loss did not improve from 0.39496\n",
      "Epoch 1711/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4583e-04 - fbeta: 1.0000 - val_loss: 0.6411 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01711: val_loss did not improve from 0.39496\n",
      "Epoch 1712/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4812e-04 - fbeta: 1.0000 - val_loss: 0.6393 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01712: val_loss did not improve from 0.39496\n",
      "Epoch 1713/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4574e-04 - fbeta: 1.0000 - val_loss: 0.6435 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01713: val_loss did not improve from 0.39496\n",
      "Epoch 1714/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4417e-04 - fbeta: 1.0000 - val_loss: 0.6445 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01714: val_loss did not improve from 0.39496\n",
      "Epoch 1715/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4662e-04 - fbeta: 1.0000 - val_loss: 0.6460 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01715: val_loss did not improve from 0.39496\n",
      "Epoch 1716/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4913e-04 - fbeta: 1.0000 - val_loss: 0.6405 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01716: val_loss did not improve from 0.39496\n",
      "Epoch 1717/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4504e-04 - fbeta: 1.0000 - val_loss: 0.6437 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01717: val_loss did not improve from 0.39496\n",
      "Epoch 1718/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4281e-04 - fbeta: 1.0000 - val_loss: 0.6426 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01718: val_loss did not improve from 0.39496\n",
      "Epoch 1719/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4306e-04 - fbeta: 1.0000 - val_loss: 0.6431 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01719: val_loss did not improve from 0.39496\n",
      "Epoch 1720/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4287e-04 - fbeta: 1.0000 - val_loss: 0.6446 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01720: val_loss did not improve from 0.39496\n",
      "Epoch 1721/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4236e-04 - fbeta: 1.0000 - val_loss: 0.6425 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01721: val_loss did not improve from 0.39496\n",
      "Epoch 1722/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4197e-04 - fbeta: 1.0000 - val_loss: 0.6412 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01722: val_loss did not improve from 0.39496\n",
      "Epoch 1723/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4209e-04 - fbeta: 1.0000 - val_loss: 0.6436 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01723: val_loss did not improve from 0.39496\n",
      "Epoch 1724/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4126e-04 - fbeta: 1.0000 - val_loss: 0.6448 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01724: val_loss did not improve from 0.39496\n",
      "Epoch 1725/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4140e-04 - fbeta: 1.0000 - val_loss: 0.6454 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01725: val_loss did not improve from 0.39496\n",
      "Epoch 1726/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4051e-04 - fbeta: 1.0000 - val_loss: 0.6443 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01726: val_loss did not improve from 0.39496\n",
      "Epoch 1727/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4015e-04 - fbeta: 1.0000 - val_loss: 0.6454 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01727: val_loss did not improve from 0.39496\n",
      "Epoch 1728/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4043e-04 - fbeta: 1.0000 - val_loss: 0.6485 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01728: val_loss did not improve from 0.39496\n",
      "Epoch 1729/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4018e-04 - fbeta: 1.0000 - val_loss: 0.6472 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01729: val_loss did not improve from 0.39496\n",
      "Epoch 1730/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4004e-04 - fbeta: 1.0000 - val_loss: 0.6471 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01730: val_loss did not improve from 0.39496\n",
      "Epoch 1731/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3936e-04 - fbeta: 1.0000 - val_loss: 0.6471 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01731: val_loss did not improve from 0.39496\n",
      "Epoch 1732/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4006e-04 - fbeta: 1.0000 - val_loss: 0.6474 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01732: val_loss did not improve from 0.39496\n",
      "Epoch 1733/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4002e-04 - fbeta: 1.0000 - val_loss: 0.6401 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01733: val_loss did not improve from 0.39496\n",
      "Epoch 1734/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4158e-04 - fbeta: 1.0000 - val_loss: 0.6423 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01734: val_loss did not improve from 0.39496\n",
      "Epoch 1735/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4124e-04 - fbeta: 1.0000 - val_loss: 0.6445 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01735: val_loss did not improve from 0.39496\n",
      "Epoch 1736/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4256e-04 - fbeta: 1.0000 - val_loss: 0.6456 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01736: val_loss did not improve from 0.39496\n",
      "Epoch 1737/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4014e-04 - fbeta: 1.0000 - val_loss: 0.6433 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01737: val_loss did not improve from 0.39496\n",
      "Epoch 1738/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3868e-04 - fbeta: 1.0000 - val_loss: 0.6453 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01738: val_loss did not improve from 0.39496\n",
      "Epoch 1739/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3699e-04 - fbeta: 1.0000 - val_loss: 0.6448 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01739: val_loss did not improve from 0.39496\n",
      "Epoch 1740/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.4024e-04 - fbeta: 1.0000 - val_loss: 0.6449 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01740: val_loss did not improve from 0.39496\n",
      "Epoch 1741/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3823e-04 - fbeta: 1.0000 - val_loss: 0.6432 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01741: val_loss did not improve from 0.39496\n",
      "Epoch 1742/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3783e-04 - fbeta: 1.0000 - val_loss: 0.6419 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01742: val_loss did not improve from 0.39496\n",
      "Epoch 1743/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3744e-04 - fbeta: 1.0000 - val_loss: 0.6455 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01743: val_loss did not improve from 0.39496\n",
      "Epoch 1744/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3675e-04 - fbeta: 1.0000 - val_loss: 0.6458 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01744: val_loss did not improve from 0.39496\n",
      "Epoch 1745/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3729e-04 - fbeta: 1.0000 - val_loss: 0.6459 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01745: val_loss did not improve from 0.39496\n",
      "Epoch 1746/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3624e-04 - fbeta: 1.0000 - val_loss: 0.6455 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01746: val_loss did not improve from 0.39496\n",
      "Epoch 1747/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3622e-04 - fbeta: 1.0000 - val_loss: 0.6468 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01747: val_loss did not improve from 0.39496\n",
      "Epoch 1748/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3544e-04 - fbeta: 1.0000 - val_loss: 0.6463 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01748: val_loss did not improve from 0.39496\n",
      "Epoch 1749/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3508e-04 - fbeta: 1.0000 - val_loss: 0.6466 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01749: val_loss did not improve from 0.39496\n",
      "Epoch 1750/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3495e-04 - fbeta: 1.0000 - val_loss: 0.6438 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01750: val_loss did not improve from 0.39496\n",
      "Epoch 1751/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3520e-04 - fbeta: 1.0000 - val_loss: 0.6466 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01751: val_loss did not improve from 0.39496\n",
      "Epoch 1752/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3512e-04 - fbeta: 1.0000 - val_loss: 0.6466 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01752: val_loss did not improve from 0.39496\n",
      "Epoch 1753/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3684e-04 - fbeta: 1.0000 - val_loss: 0.6468 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01753: val_loss did not improve from 0.39496\n",
      "Epoch 1754/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3438e-04 - fbeta: 1.0000 - val_loss: 0.6453 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01754: val_loss did not improve from 0.39496\n",
      "Epoch 1755/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3538e-04 - fbeta: 1.0000 - val_loss: 0.6409 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01755: val_loss did not improve from 0.39496\n",
      "Epoch 1756/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3470e-04 - fbeta: 1.0000 - val_loss: 0.6419 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01756: val_loss did not improve from 0.39496\n",
      "Epoch 1757/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3370e-04 - fbeta: 1.0000 - val_loss: 0.6452 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01757: val_loss did not improve from 0.39496\n",
      "Epoch 1758/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3336e-04 - fbeta: 1.0000 - val_loss: 0.6447 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01758: val_loss did not improve from 0.39496\n",
      "Epoch 1759/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3375e-04 - fbeta: 1.0000 - val_loss: 0.6447 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01759: val_loss did not improve from 0.39496\n",
      "Epoch 1760/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3349e-04 - fbeta: 1.0000 - val_loss: 0.6439 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01760: val_loss did not improve from 0.39496\n",
      "Epoch 1761/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3344e-04 - fbeta: 1.0000 - val_loss: 0.6479 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01761: val_loss did not improve from 0.39496\n",
      "Epoch 1762/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3246e-04 - fbeta: 1.0000 - val_loss: 0.6479 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01762: val_loss did not improve from 0.39496\n",
      "Epoch 1763/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3243e-04 - fbeta: 1.0000 - val_loss: 0.6493 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01763: val_loss did not improve from 0.39496\n",
      "Epoch 1764/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3215e-04 - fbeta: 1.0000 - val_loss: 0.6498 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01764: val_loss did not improve from 0.39496\n",
      "Epoch 1765/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3214e-04 - fbeta: 1.0000 - val_loss: 0.6441 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01765: val_loss did not improve from 0.39496\n",
      "Epoch 1766/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3150e-04 - fbeta: 1.0000 - val_loss: 0.6460 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01766: val_loss did not improve from 0.39496\n",
      "Epoch 1767/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3207e-04 - fbeta: 1.0000 - val_loss: 0.6474 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01767: val_loss did not improve from 0.39496\n",
      "Epoch 1768/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3151e-04 - fbeta: 1.0000 - val_loss: 0.6458 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01768: val_loss did not improve from 0.39496\n",
      "Epoch 1769/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3199e-04 - fbeta: 1.0000 - val_loss: 0.6462 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01769: val_loss did not improve from 0.39496\n",
      "Epoch 1770/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3166e-04 - fbeta: 1.0000 - val_loss: 0.6470 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01770: val_loss did not improve from 0.39496\n",
      "Epoch 1771/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3027e-04 - fbeta: 1.0000 - val_loss: 0.6459 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01771: val_loss did not improve from 0.39496\n",
      "Epoch 1772/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.3065e-04 - fbeta: 1.0000 - val_loss: 0.6450 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01772: val_loss did not improve from 0.39496\n",
      "Epoch 1773/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2983e-04 - fbeta: 1.0000 - val_loss: 0.6464 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01773: val_loss did not improve from 0.39496\n",
      "Epoch 1774/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2900e-04 - fbeta: 1.0000 - val_loss: 0.6435 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01774: val_loss did not improve from 0.39496\n",
      "Epoch 1775/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2910e-04 - fbeta: 1.0000 - val_loss: 0.6458 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01775: val_loss did not improve from 0.39496\n",
      "Epoch 1776/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2950e-04 - fbeta: 1.0000 - val_loss: 0.6465 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01776: val_loss did not improve from 0.39496\n",
      "Epoch 1777/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2953e-04 - fbeta: 1.0000 - val_loss: 0.6459 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01777: val_loss did not improve from 0.39496\n",
      "Epoch 1778/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2844e-04 - fbeta: 1.0000 - val_loss: 0.6473 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01778: val_loss did not improve from 0.39496\n",
      "Epoch 1779/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2858e-04 - fbeta: 1.0000 - val_loss: 0.6511 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01779: val_loss did not improve from 0.39496\n",
      "Epoch 1780/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2785e-04 - fbeta: 1.0000 - val_loss: 0.6497 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01780: val_loss did not improve from 0.39496\n",
      "Epoch 1781/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2809e-04 - fbeta: 1.0000 - val_loss: 0.6476 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01781: val_loss did not improve from 0.39496\n",
      "Epoch 1782/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2769e-04 - fbeta: 1.0000 - val_loss: 0.6472 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01782: val_loss did not improve from 0.39496\n",
      "Epoch 1783/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2784e-04 - fbeta: 1.0000 - val_loss: 0.6464 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01783: val_loss did not improve from 0.39496\n",
      "Epoch 1784/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2772e-04 - fbeta: 1.0000 - val_loss: 0.6483 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01784: val_loss did not improve from 0.39496\n",
      "Epoch 1785/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2794e-04 - fbeta: 1.0000 - val_loss: 0.6507 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01785: val_loss did not improve from 0.39496\n",
      "Epoch 1786/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2709e-04 - fbeta: 1.0000 - val_loss: 0.6492 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01786: val_loss did not improve from 0.39496\n",
      "Epoch 1787/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2625e-04 - fbeta: 1.0000 - val_loss: 0.6469 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01787: val_loss did not improve from 0.39496\n",
      "Epoch 1788/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2920e-04 - fbeta: 1.0000 - val_loss: 0.6433 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01788: val_loss did not improve from 0.39496\n",
      "Epoch 1789/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2748e-04 - fbeta: 1.0000 - val_loss: 0.6449 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01789: val_loss did not improve from 0.39496\n",
      "Epoch 1790/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2634e-04 - fbeta: 1.0000 - val_loss: 0.6440 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01790: val_loss did not improve from 0.39496\n",
      "Epoch 1791/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2547e-04 - fbeta: 1.0000 - val_loss: 0.6450 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01791: val_loss did not improve from 0.39496\n",
      "Epoch 1792/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2540e-04 - fbeta: 1.0000 - val_loss: 0.6481 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01792: val_loss did not improve from 0.39496\n",
      "Epoch 1793/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2545e-04 - fbeta: 1.0000 - val_loss: 0.6497 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01793: val_loss did not improve from 0.39496\n",
      "Epoch 1794/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2453e-04 - fbeta: 1.0000 - val_loss: 0.6476 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01794: val_loss did not improve from 0.39496\n",
      "Epoch 1795/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2431e-04 - fbeta: 1.0000 - val_loss: 0.6464 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01795: val_loss did not improve from 0.39496\n",
      "Epoch 1796/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2400e-04 - fbeta: 1.0000 - val_loss: 0.6463 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01796: val_loss did not improve from 0.39496\n",
      "Epoch 1797/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2512e-04 - fbeta: 1.0000 - val_loss: 0.6503 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01797: val_loss did not improve from 0.39496\n",
      "Epoch 1798/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2398e-04 - fbeta: 1.0000 - val_loss: 0.6506 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01798: val_loss did not improve from 0.39496\n",
      "Epoch 1799/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2358e-04 - fbeta: 1.0000 - val_loss: 0.6497 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01799: val_loss did not improve from 0.39496\n",
      "Epoch 1800/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2329e-04 - fbeta: 1.0000 - val_loss: 0.6475 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01800: val_loss did not improve from 0.39496\n",
      "Epoch 1801/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2328e-04 - fbeta: 1.0000 - val_loss: 0.6472 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01801: val_loss did not improve from 0.39496\n",
      "Epoch 1802/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2392e-04 - fbeta: 1.0000 - val_loss: 0.6466 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01802: val_loss did not improve from 0.39496\n",
      "Epoch 1803/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2277e-04 - fbeta: 1.0000 - val_loss: 0.6474 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01803: val_loss did not improve from 0.39496\n",
      "Epoch 1804/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2243e-04 - fbeta: 1.0000 - val_loss: 0.6449 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01804: val_loss did not improve from 0.39496\n",
      "Epoch 1805/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2516e-04 - fbeta: 1.0000 - val_loss: 0.6394 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01805: val_loss did not improve from 0.39496\n",
      "Epoch 1806/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2368e-04 - fbeta: 1.0000 - val_loss: 0.6415 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01806: val_loss did not improve from 0.39496\n",
      "Epoch 1807/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2264e-04 - fbeta: 1.0000 - val_loss: 0.6409 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01807: val_loss did not improve from 0.39496\n",
      "Epoch 1808/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2308e-04 - fbeta: 1.0000 - val_loss: 0.6433 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01808: val_loss did not improve from 0.39496\n",
      "Epoch 1809/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2116e-04 - fbeta: 1.0000 - val_loss: 0.6445 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01809: val_loss did not improve from 0.39496\n",
      "Epoch 1810/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2172e-04 - fbeta: 1.0000 - val_loss: 0.6457 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01810: val_loss did not improve from 0.39496\n",
      "Epoch 1811/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2096e-04 - fbeta: 1.0000 - val_loss: 0.6451 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01811: val_loss did not improve from 0.39496\n",
      "Epoch 1812/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2117e-04 - fbeta: 1.0000 - val_loss: 0.6464 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01812: val_loss did not improve from 0.39496\n",
      "Epoch 1813/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1976e-04 - fbeta: 1.0000 - val_loss: 0.6475 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01813: val_loss did not improve from 0.39496\n",
      "Epoch 1814/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2083e-04 - fbeta: 1.0000 - val_loss: 0.6491 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01814: val_loss did not improve from 0.39496\n",
      "Epoch 1815/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1929e-04 - fbeta: 1.0000 - val_loss: 0.6481 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01815: val_loss did not improve from 0.39496\n",
      "Epoch 1816/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1934e-04 - fbeta: 1.0000 - val_loss: 0.6489 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01816: val_loss did not improve from 0.39496\n",
      "Epoch 1817/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1974e-04 - fbeta: 1.0000 - val_loss: 0.6487 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01817: val_loss did not improve from 0.39496\n",
      "Epoch 1818/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.2020e-04 - fbeta: 1.0000 - val_loss: 0.6508 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01818: val_loss did not improve from 0.39496\n",
      "Epoch 1819/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1964e-04 - fbeta: 1.0000 - val_loss: 0.6484 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01819: val_loss did not improve from 0.39496\n",
      "Epoch 1820/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1931e-04 - fbeta: 1.0000 - val_loss: 0.6502 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01820: val_loss did not improve from 0.39496\n",
      "Epoch 1821/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1946e-04 - fbeta: 1.0000 - val_loss: 0.6506 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01821: val_loss did not improve from 0.39496\n",
      "Epoch 1822/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1854e-04 - fbeta: 1.0000 - val_loss: 0.6482 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01822: val_loss did not improve from 0.39496\n",
      "Epoch 1823/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1804e-04 - fbeta: 1.0000 - val_loss: 0.6474 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01823: val_loss did not improve from 0.39496\n",
      "Epoch 1824/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1832e-04 - fbeta: 1.0000 - val_loss: 0.6494 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01824: val_loss did not improve from 0.39496\n",
      "Epoch 1825/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1819e-04 - fbeta: 1.0000 - val_loss: 0.6498 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01825: val_loss did not improve from 0.39496\n",
      "Epoch 1826/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1772e-04 - fbeta: 1.0000 - val_loss: 0.6485 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01826: val_loss did not improve from 0.39496\n",
      "Epoch 1827/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1784e-04 - fbeta: 1.0000 - val_loss: 0.6473 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01827: val_loss did not improve from 0.39496\n",
      "Epoch 1828/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1723e-04 - fbeta: 1.0000 - val_loss: 0.6501 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01828: val_loss did not improve from 0.39496\n",
      "Epoch 1829/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1641e-04 - fbeta: 1.0000 - val_loss: 0.6497 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01829: val_loss did not improve from 0.39496\n",
      "Epoch 1830/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1718e-04 - fbeta: 1.0000 - val_loss: 0.6498 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01830: val_loss did not improve from 0.39496\n",
      "Epoch 1831/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1926e-04 - fbeta: 1.0000 - val_loss: 0.6482 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01831: val_loss did not improve from 0.39496\n",
      "Epoch 1832/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1813e-04 - fbeta: 1.0000 - val_loss: 0.6486 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01832: val_loss did not improve from 0.39496\n",
      "Epoch 1833/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1809e-04 - fbeta: 1.0000 - val_loss: 0.6517 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01833: val_loss did not improve from 0.39496\n",
      "Epoch 1834/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1655e-04 - fbeta: 1.0000 - val_loss: 0.6501 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01834: val_loss did not improve from 0.39496\n",
      "Epoch 1835/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1579e-04 - fbeta: 1.0000 - val_loss: 0.6516 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01835: val_loss did not improve from 0.39496\n",
      "Epoch 1836/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1686e-04 - fbeta: 1.0000 - val_loss: 0.6505 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01836: val_loss did not improve from 0.39496\n",
      "Epoch 1837/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1535e-04 - fbeta: 1.0000 - val_loss: 0.6492 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01837: val_loss did not improve from 0.39496\n",
      "Epoch 1838/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1463e-04 - fbeta: 1.0000 - val_loss: 0.6486 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01838: val_loss did not improve from 0.39496\n",
      "Epoch 1839/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1627e-04 - fbeta: 1.0000 - val_loss: 0.6508 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01839: val_loss did not improve from 0.39496\n",
      "Epoch 1840/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1414e-04 - fbeta: 1.0000 - val_loss: 0.6484 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01840: val_loss did not improve from 0.39496\n",
      "Epoch 1841/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1444e-04 - fbeta: 1.0000 - val_loss: 0.6478 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01841: val_loss did not improve from 0.39496\n",
      "Epoch 1842/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1540e-04 - fbeta: 1.0000 - val_loss: 0.6443 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01842: val_loss did not improve from 0.39496\n",
      "Epoch 1843/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1412e-04 - fbeta: 1.0000 - val_loss: 0.6475 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01843: val_loss did not improve from 0.39496\n",
      "Epoch 1844/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1809e-04 - fbeta: 1.0000 - val_loss: 0.6532 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01844: val_loss did not improve from 0.39496\n",
      "Epoch 1845/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1459e-04 - fbeta: 1.0000 - val_loss: 0.6521 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01845: val_loss did not improve from 0.39496\n",
      "Epoch 1846/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1324e-04 - fbeta: 1.0000 - val_loss: 0.6510 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01846: val_loss did not improve from 0.39496\n",
      "Epoch 1847/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1293e-04 - fbeta: 1.0000 - val_loss: 0.6488 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01847: val_loss did not improve from 0.39496\n",
      "Epoch 1848/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1250e-04 - fbeta: 1.0000 - val_loss: 0.6490 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01848: val_loss did not improve from 0.39496\n",
      "Epoch 1849/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1280e-04 - fbeta: 1.0000 - val_loss: 0.6494 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01849: val_loss did not improve from 0.39496\n",
      "Epoch 1850/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1235e-04 - fbeta: 1.0000 - val_loss: 0.6525 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01850: val_loss did not improve from 0.39496\n",
      "Epoch 1851/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1282e-04 - fbeta: 1.0000 - val_loss: 0.6561 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01851: val_loss did not improve from 0.39496\n",
      "Epoch 1852/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1241e-04 - fbeta: 1.0000 - val_loss: 0.6526 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01852: val_loss did not improve from 0.39496\n",
      "Epoch 1853/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1181e-04 - fbeta: 1.0000 - val_loss: 0.6505 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01853: val_loss did not improve from 0.39496\n",
      "Epoch 1854/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1206e-04 - fbeta: 1.0000 - val_loss: 0.6502 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01854: val_loss did not improve from 0.39496\n",
      "Epoch 1855/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1761e-04 - fbeta: 1.0000 - val_loss: 0.6514 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01855: val_loss did not improve from 0.39496\n",
      "Epoch 1856/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1246e-04 - fbeta: 1.0000 - val_loss: 0.6525 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01856: val_loss did not improve from 0.39496\n",
      "Epoch 1857/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1160e-04 - fbeta: 1.0000 - val_loss: 0.6523 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01857: val_loss did not improve from 0.39496\n",
      "Epoch 1858/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1246e-04 - fbeta: 1.0000 - val_loss: 0.6519 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01858: val_loss did not improve from 0.39496\n",
      "Epoch 1859/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1085e-04 - fbeta: 1.0000 - val_loss: 0.6499 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01859: val_loss did not improve from 0.39496\n",
      "Epoch 1860/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1070e-04 - fbeta: 1.0000 - val_loss: 0.6489 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01860: val_loss did not improve from 0.39496\n",
      "Epoch 1861/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0986e-04 - fbeta: 1.0000 - val_loss: 0.6492 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01861: val_loss did not improve from 0.39496\n",
      "Epoch 1862/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1048e-04 - fbeta: 1.0000 - val_loss: 0.6509 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01862: val_loss did not improve from 0.39496\n",
      "Epoch 1863/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1101e-04 - fbeta: 1.0000 - val_loss: 0.6523 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01863: val_loss did not improve from 0.39496\n",
      "Epoch 1864/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0977e-04 - fbeta: 1.0000 - val_loss: 0.6506 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01864: val_loss did not improve from 0.39496\n",
      "Epoch 1865/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0899e-04 - fbeta: 1.0000 - val_loss: 0.6505 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01865: val_loss did not improve from 0.39496\n",
      "Epoch 1866/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0923e-04 - fbeta: 1.0000 - val_loss: 0.6517 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01866: val_loss did not improve from 0.39496\n",
      "Epoch 1867/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0881e-04 - fbeta: 1.0000 - val_loss: 0.6498 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01867: val_loss did not improve from 0.39496\n",
      "Epoch 1868/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0891e-04 - fbeta: 1.0000 - val_loss: 0.6484 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01868: val_loss did not improve from 0.39496\n",
      "Epoch 1869/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.1161e-04 - fbeta: 1.0000 - val_loss: 0.6429 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01869: val_loss did not improve from 0.39496\n",
      "Epoch 1870/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0926e-04 - fbeta: 1.0000 - val_loss: 0.6449 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01870: val_loss did not improve from 0.39496\n",
      "Epoch 1871/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0841e-04 - fbeta: 1.0000 - val_loss: 0.6469 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01871: val_loss did not improve from 0.39496\n",
      "Epoch 1872/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0851e-04 - fbeta: 1.0000 - val_loss: 0.6478 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01872: val_loss did not improve from 0.39496\n",
      "Epoch 1873/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0768e-04 - fbeta: 1.0000 - val_loss: 0.6502 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01873: val_loss did not improve from 0.39496\n",
      "Epoch 1874/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0704e-04 - fbeta: 1.0000 - val_loss: 0.6504 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01874: val_loss did not improve from 0.39496\n",
      "Epoch 1875/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0761e-04 - fbeta: 1.0000 - val_loss: 0.6506 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01875: val_loss did not improve from 0.39496\n",
      "Epoch 1876/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0753e-04 - fbeta: 1.0000 - val_loss: 0.6536 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01876: val_loss did not improve from 0.39496\n",
      "Epoch 1877/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0716e-04 - fbeta: 1.0000 - val_loss: 0.6534 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01877: val_loss did not improve from 0.39496\n",
      "Epoch 1878/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0634e-04 - fbeta: 1.0000 - val_loss: 0.6536 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01878: val_loss did not improve from 0.39496\n",
      "Epoch 1879/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0652e-04 - fbeta: 1.0000 - val_loss: 0.6536 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01879: val_loss did not improve from 0.39496\n",
      "Epoch 1880/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0523e-04 - fbeta: 1.0000 - val_loss: 0.6535 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01880: val_loss did not improve from 0.39496\n",
      "Epoch 1881/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0623e-04 - fbeta: 1.0000 - val_loss: 0.6501 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01881: val_loss did not improve from 0.39496\n",
      "Epoch 1882/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0553e-04 - fbeta: 1.0000 - val_loss: 0.6503 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01882: val_loss did not improve from 0.39496\n",
      "Epoch 1883/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0509e-04 - fbeta: 1.0000 - val_loss: 0.6506 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01883: val_loss did not improve from 0.39496\n",
      "Epoch 1884/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0437e-04 - fbeta: 1.0000 - val_loss: 0.6522 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01884: val_loss did not improve from 0.39496\n",
      "Epoch 1885/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0462e-04 - fbeta: 1.0000 - val_loss: 0.6511 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01885: val_loss did not improve from 0.39496\n",
      "Epoch 1886/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0414e-04 - fbeta: 1.0000 - val_loss: 0.6501 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01886: val_loss did not improve from 0.39496\n",
      "Epoch 1887/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0470e-04 - fbeta: 1.0000 - val_loss: 0.6510 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01887: val_loss did not improve from 0.39496\n",
      "Epoch 1888/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0460e-04 - fbeta: 1.0000 - val_loss: 0.6470 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01888: val_loss did not improve from 0.39496\n",
      "Epoch 1889/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0389e-04 - fbeta: 1.0000 - val_loss: 0.6484 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01889: val_loss did not improve from 0.39496\n",
      "Epoch 1890/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0426e-04 - fbeta: 1.0000 - val_loss: 0.6515 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01890: val_loss did not improve from 0.39496\n",
      "Epoch 1891/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0446e-04 - fbeta: 1.0000 - val_loss: 0.6550 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01891: val_loss did not improve from 0.39496\n",
      "Epoch 1892/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0424e-04 - fbeta: 1.0000 - val_loss: 0.6522 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01892: val_loss did not improve from 0.39496\n",
      "Epoch 1893/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0279e-04 - fbeta: 1.0000 - val_loss: 0.6522 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01893: val_loss did not improve from 0.39496\n",
      "Epoch 1894/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0286e-04 - fbeta: 1.0000 - val_loss: 0.6520 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01894: val_loss did not improve from 0.39496\n",
      "Epoch 1895/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0339e-04 - fbeta: 1.0000 - val_loss: 0.6522 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01895: val_loss did not improve from 0.39496\n",
      "Epoch 1896/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0236e-04 - fbeta: 1.0000 - val_loss: 0.6511 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01896: val_loss did not improve from 0.39496\n",
      "Epoch 1897/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0201e-04 - fbeta: 1.0000 - val_loss: 0.6486 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01897: val_loss did not improve from 0.39496\n",
      "Epoch 1898/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0300e-04 - fbeta: 1.0000 - val_loss: 0.6461 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01898: val_loss did not improve from 0.39496\n",
      "Epoch 1899/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0249e-04 - fbeta: 1.0000 - val_loss: 0.6475 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01899: val_loss did not improve from 0.39496\n",
      "Epoch 1900/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0301e-04 - fbeta: 1.0000 - val_loss: 0.6554 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01900: val_loss did not improve from 0.39496\n",
      "Epoch 1901/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0333e-04 - fbeta: 1.0000 - val_loss: 0.6542 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01901: val_loss did not improve from 0.39496\n",
      "Epoch 1902/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0226e-04 - fbeta: 1.0000 - val_loss: 0.6552 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01902: val_loss did not improve from 0.39496\n",
      "Epoch 1903/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0206e-04 - fbeta: 1.0000 - val_loss: 0.6547 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01903: val_loss did not improve from 0.39496\n",
      "Epoch 1904/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0127e-04 - fbeta: 1.0000 - val_loss: 0.6511 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01904: val_loss did not improve from 0.39496\n",
      "Epoch 1905/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0079e-04 - fbeta: 1.0000 - val_loss: 0.6493 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01905: val_loss did not improve from 0.39496\n",
      "Epoch 1906/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0044e-04 - fbeta: 1.0000 - val_loss: 0.6463 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01906: val_loss did not improve from 0.39496\n",
      "Epoch 1907/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0048e-04 - fbeta: 1.0000 - val_loss: 0.6485 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01907: val_loss did not improve from 0.39496\n",
      "Epoch 1908/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0154e-04 - fbeta: 1.0000 - val_loss: 0.6478 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01908: val_loss did not improve from 0.39496\n",
      "Epoch 1909/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0390e-04 - fbeta: 1.0000 - val_loss: 0.6490 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01909: val_loss did not improve from 0.39496\n",
      "Epoch 1910/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0117e-04 - fbeta: 1.0000 - val_loss: 0.6481 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01910: val_loss did not improve from 0.39496\n",
      "Epoch 1911/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9953e-04 - fbeta: 1.0000 - val_loss: 0.6492 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01911: val_loss did not improve from 0.39496\n",
      "Epoch 1912/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9998e-04 - fbeta: 1.0000 - val_loss: 0.6498 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01912: val_loss did not improve from 0.39496\n",
      "Epoch 1913/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9886e-04 - fbeta: 1.0000 - val_loss: 0.6505 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01913: val_loss did not improve from 0.39496\n",
      "Epoch 1914/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9880e-04 - fbeta: 1.0000 - val_loss: 0.6506 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01914: val_loss did not improve from 0.39496\n",
      "Epoch 1915/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0087e-04 - fbeta: 1.0000 - val_loss: 0.6550 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01915: val_loss did not improve from 0.39496\n",
      "Epoch 1916/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 3.0003e-04 - fbeta: 1.0000 - val_loss: 0.6535 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01916: val_loss did not improve from 0.39496\n",
      "Epoch 1917/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9848e-04 - fbeta: 1.0000 - val_loss: 0.6509 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01917: val_loss did not improve from 0.39496\n",
      "Epoch 1918/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9766e-04 - fbeta: 1.0000 - val_loss: 0.6516 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01918: val_loss did not improve from 0.39496\n",
      "Epoch 1919/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9839e-04 - fbeta: 1.0000 - val_loss: 0.6566 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01919: val_loss did not improve from 0.39496\n",
      "Epoch 1920/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9921e-04 - fbeta: 1.0000 - val_loss: 0.6611 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01920: val_loss did not improve from 0.39496\n",
      "Epoch 1921/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9907e-04 - fbeta: 1.0000 - val_loss: 0.6576 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01921: val_loss did not improve from 0.39496\n",
      "Epoch 1922/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9834e-04 - fbeta: 1.0000 - val_loss: 0.6578 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01922: val_loss did not improve from 0.39496\n",
      "Epoch 1923/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9780e-04 - fbeta: 1.0000 - val_loss: 0.6567 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01923: val_loss did not improve from 0.39496\n",
      "Epoch 1924/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9734e-04 - fbeta: 1.0000 - val_loss: 0.6529 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01924: val_loss did not improve from 0.39496\n",
      "Epoch 1925/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9728e-04 - fbeta: 1.0000 - val_loss: 0.6530 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01925: val_loss did not improve from 0.39496\n",
      "Epoch 1926/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9705e-04 - fbeta: 1.0000 - val_loss: 0.6512 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01926: val_loss did not improve from 0.39496\n",
      "Epoch 1927/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9658e-04 - fbeta: 1.0000 - val_loss: 0.6521 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01927: val_loss did not improve from 0.39496\n",
      "Epoch 1928/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9665e-04 - fbeta: 1.0000 - val_loss: 0.6509 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01928: val_loss did not improve from 0.39496\n",
      "Epoch 1929/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9672e-04 - fbeta: 1.0000 - val_loss: 0.6512 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01929: val_loss did not improve from 0.39496\n",
      "Epoch 1930/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9595e-04 - fbeta: 1.0000 - val_loss: 0.6493 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01930: val_loss did not improve from 0.39496\n",
      "Epoch 1931/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9743e-04 - fbeta: 1.0000 - val_loss: 0.6512 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01931: val_loss did not improve from 0.39496\n",
      "Epoch 1932/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9832e-04 - fbeta: 1.0000 - val_loss: 0.6521 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01932: val_loss did not improve from 0.39496\n",
      "Epoch 1933/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9635e-04 - fbeta: 1.0000 - val_loss: 0.6565 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01933: val_loss did not improve from 0.39496\n",
      "Epoch 1934/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9705e-04 - fbeta: 1.0000 - val_loss: 0.6527 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01934: val_loss did not improve from 0.39496\n",
      "Epoch 1935/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9654e-04 - fbeta: 1.0000 - val_loss: 0.6521 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01935: val_loss did not improve from 0.39496\n",
      "Epoch 1936/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9500e-04 - fbeta: 1.0000 - val_loss: 0.6537 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01936: val_loss did not improve from 0.39496\n",
      "Epoch 1937/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9513e-04 - fbeta: 1.0000 - val_loss: 0.6515 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01937: val_loss did not improve from 0.39496\n",
      "Epoch 1938/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9447e-04 - fbeta: 1.0000 - val_loss: 0.6533 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01938: val_loss did not improve from 0.39496\n",
      "Epoch 1939/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9563e-04 - fbeta: 1.0000 - val_loss: 0.6534 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01939: val_loss did not improve from 0.39496\n",
      "Epoch 1940/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9439e-04 - fbeta: 1.0000 - val_loss: 0.6542 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01940: val_loss did not improve from 0.39496\n",
      "Epoch 1941/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9433e-04 - fbeta: 1.0000 - val_loss: 0.6549 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01941: val_loss did not improve from 0.39496\n",
      "Epoch 1942/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9367e-04 - fbeta: 1.0000 - val_loss: 0.6514 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01942: val_loss did not improve from 0.39496\n",
      "Epoch 1943/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9452e-04 - fbeta: 1.0000 - val_loss: 0.6541 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01943: val_loss did not improve from 0.39496\n",
      "Epoch 1944/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9333e-04 - fbeta: 1.0000 - val_loss: 0.6547 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01944: val_loss did not improve from 0.39496\n",
      "Epoch 1945/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9317e-04 - fbeta: 1.0000 - val_loss: 0.6546 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01945: val_loss did not improve from 0.39496\n",
      "Epoch 1946/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9373e-04 - fbeta: 1.0000 - val_loss: 0.6551 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01946: val_loss did not improve from 0.39496\n",
      "Epoch 1947/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9277e-04 - fbeta: 1.0000 - val_loss: 0.6559 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01947: val_loss did not improve from 0.39496\n",
      "Epoch 1948/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9288e-04 - fbeta: 1.0000 - val_loss: 0.6567 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01948: val_loss did not improve from 0.39496\n",
      "Epoch 1949/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9496e-04 - fbeta: 1.0000 - val_loss: 0.6594 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01949: val_loss did not improve from 0.39496\n",
      "Epoch 1950/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9224e-04 - fbeta: 1.0000 - val_loss: 0.6562 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01950: val_loss did not improve from 0.39496\n",
      "Epoch 1951/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9249e-04 - fbeta: 1.0000 - val_loss: 0.6546 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01951: val_loss did not improve from 0.39496\n",
      "Epoch 1952/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9206e-04 - fbeta: 1.0000 - val_loss: 0.6565 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01952: val_loss did not improve from 0.39496\n",
      "Epoch 1953/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9152e-04 - fbeta: 1.0000 - val_loss: 0.6559 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01953: val_loss did not improve from 0.39496\n",
      "Epoch 1954/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9147e-04 - fbeta: 1.0000 - val_loss: 0.6544 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01954: val_loss did not improve from 0.39496\n",
      "Epoch 1955/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9124e-04 - fbeta: 1.0000 - val_loss: 0.6558 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01955: val_loss did not improve from 0.39496\n",
      "Epoch 1956/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9133e-04 - fbeta: 1.0000 - val_loss: 0.6537 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01956: val_loss did not improve from 0.39496\n",
      "Epoch 1957/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9096e-04 - fbeta: 1.0000 - val_loss: 0.6514 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01957: val_loss did not improve from 0.39496\n",
      "Epoch 1958/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9097e-04 - fbeta: 1.0000 - val_loss: 0.6523 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01958: val_loss did not improve from 0.39496\n",
      "Epoch 1959/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9006e-04 - fbeta: 1.0000 - val_loss: 0.6541 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01959: val_loss did not improve from 0.39496\n",
      "Epoch 1960/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8961e-04 - fbeta: 1.0000 - val_loss: 0.6524 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01960: val_loss did not improve from 0.39496\n",
      "Epoch 1961/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9158e-04 - fbeta: 1.0000 - val_loss: 0.6501 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01961: val_loss did not improve from 0.39496\n",
      "Epoch 1962/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8980e-04 - fbeta: 1.0000 - val_loss: 0.6509 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01962: val_loss did not improve from 0.39496\n",
      "Epoch 1963/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9015e-04 - fbeta: 1.0000 - val_loss: 0.6519 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01963: val_loss did not improve from 0.39496\n",
      "Epoch 1964/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8944e-04 - fbeta: 1.0000 - val_loss: 0.6531 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01964: val_loss did not improve from 0.39496\n",
      "Epoch 1965/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9035e-04 - fbeta: 1.0000 - val_loss: 0.6537 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01965: val_loss did not improve from 0.39496\n",
      "Epoch 1966/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8950e-04 - fbeta: 1.0000 - val_loss: 0.6550 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01966: val_loss did not improve from 0.39496\n",
      "Epoch 1967/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.9036e-04 - fbeta: 1.0000 - val_loss: 0.6531 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01967: val_loss did not improve from 0.39496\n",
      "Epoch 1968/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8879e-04 - fbeta: 1.0000 - val_loss: 0.6537 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01968: val_loss did not improve from 0.39496\n",
      "Epoch 1969/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8878e-04 - fbeta: 1.0000 - val_loss: 0.6528 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01969: val_loss did not improve from 0.39496\n",
      "Epoch 1970/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8809e-04 - fbeta: 1.0000 - val_loss: 0.6556 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01970: val_loss did not improve from 0.39496\n",
      "Epoch 1971/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8828e-04 - fbeta: 1.0000 - val_loss: 0.6536 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01971: val_loss did not improve from 0.39496\n",
      "Epoch 1972/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8819e-04 - fbeta: 1.0000 - val_loss: 0.6517 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01972: val_loss did not improve from 0.39496\n",
      "Epoch 1973/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8747e-04 - fbeta: 1.0000 - val_loss: 0.6516 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01973: val_loss did not improve from 0.39496\n",
      "Epoch 1974/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8765e-04 - fbeta: 1.0000 - val_loss: 0.6548 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01974: val_loss did not improve from 0.39496\n",
      "Epoch 1975/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8760e-04 - fbeta: 1.0000 - val_loss: 0.6532 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01975: val_loss did not improve from 0.39496\n",
      "Epoch 1976/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8699e-04 - fbeta: 1.0000 - val_loss: 0.6501 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01976: val_loss did not improve from 0.39496\n",
      "Epoch 1977/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8701e-04 - fbeta: 1.0000 - val_loss: 0.6495 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01977: val_loss did not improve from 0.39496\n",
      "Epoch 1978/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8672e-04 - fbeta: 1.0000 - val_loss: 0.6509 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01978: val_loss did not improve from 0.39496\n",
      "Epoch 1979/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8684e-04 - fbeta: 1.0000 - val_loss: 0.6549 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01979: val_loss did not improve from 0.39496\n",
      "Epoch 1980/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8775e-04 - fbeta: 1.0000 - val_loss: 0.6548 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01980: val_loss did not improve from 0.39496\n",
      "Epoch 1981/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8671e-04 - fbeta: 1.0000 - val_loss: 0.6533 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01981: val_loss did not improve from 0.39496\n",
      "Epoch 1982/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8673e-04 - fbeta: 1.0000 - val_loss: 0.6549 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01982: val_loss did not improve from 0.39496\n",
      "Epoch 1983/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8590e-04 - fbeta: 1.0000 - val_loss: 0.6532 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01983: val_loss did not improve from 0.39496\n",
      "Epoch 1984/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8590e-04 - fbeta: 1.0000 - val_loss: 0.6538 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01984: val_loss did not improve from 0.39496\n",
      "Epoch 1985/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8522e-04 - fbeta: 1.0000 - val_loss: 0.6526 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01985: val_loss did not improve from 0.39496\n",
      "Epoch 1986/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8524e-04 - fbeta: 1.0000 - val_loss: 0.6544 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01986: val_loss did not improve from 0.39496\n",
      "Epoch 1987/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8546e-04 - fbeta: 1.0000 - val_loss: 0.6541 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01987: val_loss did not improve from 0.39496\n",
      "Epoch 1988/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8573e-04 - fbeta: 1.0000 - val_loss: 0.6551 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01988: val_loss did not improve from 0.39496\n",
      "Epoch 1989/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8523e-04 - fbeta: 1.0000 - val_loss: 0.6517 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01989: val_loss did not improve from 0.39496\n",
      "Epoch 1990/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8633e-04 - fbeta: 1.0000 - val_loss: 0.6574 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01990: val_loss did not improve from 0.39496\n",
      "Epoch 1991/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8523e-04 - fbeta: 1.0000 - val_loss: 0.6559 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01991: val_loss did not improve from 0.39496\n",
      "Epoch 1992/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8649e-04 - fbeta: 1.0000 - val_loss: 0.6592 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01992: val_loss did not improve from 0.39496\n",
      "Epoch 1993/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8482e-04 - fbeta: 1.0000 - val_loss: 0.6582 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01993: val_loss did not improve from 0.39496\n",
      "Epoch 1994/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8451e-04 - fbeta: 1.0000 - val_loss: 0.6573 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01994: val_loss did not improve from 0.39496\n",
      "Epoch 1995/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8324e-04 - fbeta: 1.0000 - val_loss: 0.6550 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01995: val_loss did not improve from 0.39496\n",
      "Epoch 1996/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8353e-04 - fbeta: 1.0000 - val_loss: 0.6555 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01996: val_loss did not improve from 0.39496\n",
      "Epoch 1997/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8528e-04 - fbeta: 1.0000 - val_loss: 0.6601 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01997: val_loss did not improve from 0.39496\n",
      "Epoch 1998/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8322e-04 - fbeta: 1.0000 - val_loss: 0.6580 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01998: val_loss did not improve from 0.39496\n",
      "Epoch 1999/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8347e-04 - fbeta: 1.0000 - val_loss: 0.6548 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 01999: val_loss did not improve from 0.39496\n",
      "Epoch 2000/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8276e-04 - fbeta: 1.0000 - val_loss: 0.6553 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02000: val_loss did not improve from 0.39496\n",
      "Epoch 2001/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8294e-04 - fbeta: 1.0000 - val_loss: 0.6583 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02001: val_loss did not improve from 0.39496\n",
      "Epoch 2002/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8259e-04 - fbeta: 1.0000 - val_loss: 0.6554 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02002: val_loss did not improve from 0.39496\n",
      "Epoch 2003/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8218e-04 - fbeta: 1.0000 - val_loss: 0.6530 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02003: val_loss did not improve from 0.39496\n",
      "Epoch 2004/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8249e-04 - fbeta: 1.0000 - val_loss: 0.6531 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02004: val_loss did not improve from 0.39496\n",
      "Epoch 2005/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8272e-04 - fbeta: 1.0000 - val_loss: 0.6529 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02005: val_loss did not improve from 0.39496\n",
      "Epoch 2006/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8340e-04 - fbeta: 1.0000 - val_loss: 0.6484 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02006: val_loss did not improve from 0.39496\n",
      "Epoch 2007/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8164e-04 - fbeta: 1.0000 - val_loss: 0.6512 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02007: val_loss did not improve from 0.39496\n",
      "Epoch 2008/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8350e-04 - fbeta: 1.0000 - val_loss: 0.6558 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02008: val_loss did not improve from 0.39496\n",
      "Epoch 2009/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8159e-04 - fbeta: 1.0000 - val_loss: 0.6559 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02009: val_loss did not improve from 0.39496\n",
      "Epoch 2010/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8261e-04 - fbeta: 1.0000 - val_loss: 0.6565 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02010: val_loss did not improve from 0.39496\n",
      "Epoch 2011/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8117e-04 - fbeta: 1.0000 - val_loss: 0.6536 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02011: val_loss did not improve from 0.39496\n",
      "Epoch 2012/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8092e-04 - fbeta: 1.0000 - val_loss: 0.6517 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02012: val_loss did not improve from 0.39496\n",
      "Epoch 2013/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8039e-04 - fbeta: 1.0000 - val_loss: 0.6549 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02013: val_loss did not improve from 0.39496\n",
      "Epoch 2014/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8161e-04 - fbeta: 1.0000 - val_loss: 0.6545 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02014: val_loss did not improve from 0.39496\n",
      "Epoch 2015/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8160e-04 - fbeta: 1.0000 - val_loss: 0.6558 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02015: val_loss did not improve from 0.39496\n",
      "Epoch 2016/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8128e-04 - fbeta: 1.0000 - val_loss: 0.6562 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02016: val_loss did not improve from 0.39496\n",
      "Epoch 2017/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.8010e-04 - fbeta: 1.0000 - val_loss: 0.6586 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02017: val_loss did not improve from 0.39496\n",
      "Epoch 2018/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7935e-04 - fbeta: 1.0000 - val_loss: 0.6578 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02018: val_loss did not improve from 0.39496\n",
      "Epoch 2019/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7937e-04 - fbeta: 1.0000 - val_loss: 0.6571 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02019: val_loss did not improve from 0.39496\n",
      "Epoch 2020/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7950e-04 - fbeta: 1.0000 - val_loss: 0.6539 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02020: val_loss did not improve from 0.39496\n",
      "Epoch 2021/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7876e-04 - fbeta: 1.0000 - val_loss: 0.6537 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02021: val_loss did not improve from 0.39496\n",
      "Epoch 2022/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7943e-04 - fbeta: 1.0000 - val_loss: 0.6579 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02022: val_loss did not improve from 0.39496\n",
      "Epoch 2023/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7835e-04 - fbeta: 1.0000 - val_loss: 0.6569 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02023: val_loss did not improve from 0.39496\n",
      "Epoch 2024/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7869e-04 - fbeta: 1.0000 - val_loss: 0.6581 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02024: val_loss did not improve from 0.39496\n",
      "Epoch 2025/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7799e-04 - fbeta: 1.0000 - val_loss: 0.6571 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02025: val_loss did not improve from 0.39496\n",
      "Epoch 2026/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7869e-04 - fbeta: 1.0000 - val_loss: 0.6584 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02026: val_loss did not improve from 0.39496\n",
      "Epoch 2027/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7793e-04 - fbeta: 1.0000 - val_loss: 0.6562 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02027: val_loss did not improve from 0.39496\n",
      "Epoch 2028/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7715e-04 - fbeta: 1.0000 - val_loss: 0.6574 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02028: val_loss did not improve from 0.39496\n",
      "Epoch 2029/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7830e-04 - fbeta: 1.0000 - val_loss: 0.6568 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02029: val_loss did not improve from 0.39496\n",
      "Epoch 2030/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7742e-04 - fbeta: 1.0000 - val_loss: 0.6584 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02030: val_loss did not improve from 0.39496\n",
      "Epoch 2031/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7692e-04 - fbeta: 1.0000 - val_loss: 0.6561 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02031: val_loss did not improve from 0.39496\n",
      "Epoch 2032/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7743e-04 - fbeta: 1.0000 - val_loss: 0.6560 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02032: val_loss did not improve from 0.39496\n",
      "Epoch 2033/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7704e-04 - fbeta: 1.0000 - val_loss: 0.6565 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02033: val_loss did not improve from 0.39496\n",
      "Epoch 2034/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7741e-04 - fbeta: 1.0000 - val_loss: 0.6598 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02034: val_loss did not improve from 0.39496\n",
      "Epoch 2035/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7656e-04 - fbeta: 1.0000 - val_loss: 0.6583 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02035: val_loss did not improve from 0.39496\n",
      "Epoch 2036/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7638e-04 - fbeta: 1.0000 - val_loss: 0.6597 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02036: val_loss did not improve from 0.39496\n",
      "Epoch 2037/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7645e-04 - fbeta: 1.0000 - val_loss: 0.6576 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02037: val_loss did not improve from 0.39496\n",
      "Epoch 2038/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7615e-04 - fbeta: 1.0000 - val_loss: 0.6582 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02038: val_loss did not improve from 0.39496\n",
      "Epoch 2039/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7653e-04 - fbeta: 1.0000 - val_loss: 0.6577 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02039: val_loss did not improve from 0.39496\n",
      "Epoch 2040/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7606e-04 - fbeta: 1.0000 - val_loss: 0.6555 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02040: val_loss did not improve from 0.39496\n",
      "Epoch 2041/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7556e-04 - fbeta: 1.0000 - val_loss: 0.6547 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02041: val_loss did not improve from 0.39496\n",
      "Epoch 2042/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7580e-04 - fbeta: 1.0000 - val_loss: 0.6553 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02042: val_loss did not improve from 0.39496\n",
      "Epoch 2043/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7580e-04 - fbeta: 1.0000 - val_loss: 0.6578 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02043: val_loss did not improve from 0.39496\n",
      "Epoch 2044/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7530e-04 - fbeta: 1.0000 - val_loss: 0.6546 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02044: val_loss did not improve from 0.39496\n",
      "Epoch 2045/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7557e-04 - fbeta: 1.0000 - val_loss: 0.6550 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02045: val_loss did not improve from 0.39496\n",
      "Epoch 2046/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7501e-04 - fbeta: 1.0000 - val_loss: 0.6566 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02046: val_loss did not improve from 0.39496\n",
      "Epoch 2047/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7470e-04 - fbeta: 1.0000 - val_loss: 0.6565 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02047: val_loss did not improve from 0.39496\n",
      "Epoch 2048/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7537e-04 - fbeta: 1.0000 - val_loss: 0.6568 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02048: val_loss did not improve from 0.39496\n",
      "Epoch 2049/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7400e-04 - fbeta: 1.0000 - val_loss: 0.6576 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02049: val_loss did not improve from 0.39496\n",
      "Epoch 2050/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7465e-04 - fbeta: 1.0000 - val_loss: 0.6529 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02050: val_loss did not improve from 0.39496\n",
      "Epoch 2051/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7412e-04 - fbeta: 1.0000 - val_loss: 0.6528 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02051: val_loss did not improve from 0.39496\n",
      "Epoch 2052/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7421e-04 - fbeta: 1.0000 - val_loss: 0.6553 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02052: val_loss did not improve from 0.39496\n",
      "Epoch 2053/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7348e-04 - fbeta: 1.0000 - val_loss: 0.6541 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02053: val_loss did not improve from 0.39496\n",
      "Epoch 2054/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7308e-04 - fbeta: 1.0000 - val_loss: 0.6560 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02054: val_loss did not improve from 0.39496\n",
      "Epoch 2055/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7342e-04 - fbeta: 1.0000 - val_loss: 0.6583 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02055: val_loss did not improve from 0.39496\n",
      "Epoch 2056/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7364e-04 - fbeta: 1.0000 - val_loss: 0.6576 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02056: val_loss did not improve from 0.39496\n",
      "Epoch 2057/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7334e-04 - fbeta: 1.0000 - val_loss: 0.6586 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02057: val_loss did not improve from 0.39496\n",
      "Epoch 2058/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7265e-04 - fbeta: 1.0000 - val_loss: 0.6569 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02058: val_loss did not improve from 0.39496\n",
      "Epoch 2059/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7248e-04 - fbeta: 1.0000 - val_loss: 0.6557 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02059: val_loss did not improve from 0.39496\n",
      "Epoch 2060/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7254e-04 - fbeta: 1.0000 - val_loss: 0.6573 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02060: val_loss did not improve from 0.39496\n",
      "Epoch 2061/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7222e-04 - fbeta: 1.0000 - val_loss: 0.6575 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02061: val_loss did not improve from 0.39496\n",
      "Epoch 2062/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7223e-04 - fbeta: 1.0000 - val_loss: 0.6563 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02062: val_loss did not improve from 0.39496\n",
      "Epoch 2063/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7169e-04 - fbeta: 1.0000 - val_loss: 0.6567 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02063: val_loss did not improve from 0.39496\n",
      "Epoch 2064/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7232e-04 - fbeta: 1.0000 - val_loss: 0.6573 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02064: val_loss did not improve from 0.39496\n",
      "Epoch 2065/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7268e-04 - fbeta: 1.0000 - val_loss: 0.6577 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02065: val_loss did not improve from 0.39496\n",
      "Epoch 2066/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7197e-04 - fbeta: 1.0000 - val_loss: 0.6563 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02066: val_loss did not improve from 0.39496\n",
      "Epoch 2067/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7143e-04 - fbeta: 1.0000 - val_loss: 0.6575 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02067: val_loss did not improve from 0.39496\n",
      "Epoch 2068/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7094e-04 - fbeta: 1.0000 - val_loss: 0.6569 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02068: val_loss did not improve from 0.39496\n",
      "Epoch 2069/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7073e-04 - fbeta: 1.0000 - val_loss: 0.6579 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02069: val_loss did not improve from 0.39496\n",
      "Epoch 2070/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7067e-04 - fbeta: 1.0000 - val_loss: 0.6582 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02070: val_loss did not improve from 0.39496\n",
      "Epoch 2071/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7031e-04 - fbeta: 1.0000 - val_loss: 0.6586 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02071: val_loss did not improve from 0.39496\n",
      "Epoch 2072/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7091e-04 - fbeta: 1.0000 - val_loss: 0.6572 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02072: val_loss did not improve from 0.39496\n",
      "Epoch 2073/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7017e-04 - fbeta: 1.0000 - val_loss: 0.6590 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02073: val_loss did not improve from 0.39496\n",
      "Epoch 2074/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7016e-04 - fbeta: 1.0000 - val_loss: 0.6559 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02074: val_loss did not improve from 0.39496\n",
      "Epoch 2075/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6977e-04 - fbeta: 1.0000 - val_loss: 0.6579 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02075: val_loss did not improve from 0.39496\n",
      "Epoch 2076/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6943e-04 - fbeta: 1.0000 - val_loss: 0.6598 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02076: val_loss did not improve from 0.39496\n",
      "Epoch 2077/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6966e-04 - fbeta: 1.0000 - val_loss: 0.6572 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02077: val_loss did not improve from 0.39496\n",
      "Epoch 2078/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7005e-04 - fbeta: 1.0000 - val_loss: 0.6567 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02078: val_loss did not improve from 0.39496\n",
      "Epoch 2079/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.7016e-04 - fbeta: 1.0000 - val_loss: 0.6582 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02079: val_loss did not improve from 0.39496\n",
      "Epoch 2080/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6933e-04 - fbeta: 1.0000 - val_loss: 0.6579 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02080: val_loss did not improve from 0.39496\n",
      "Epoch 2081/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6887e-04 - fbeta: 1.0000 - val_loss: 0.6571 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02081: val_loss did not improve from 0.39496\n",
      "Epoch 2082/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6904e-04 - fbeta: 1.0000 - val_loss: 0.6549 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02082: val_loss did not improve from 0.39496\n",
      "Epoch 2083/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6850e-04 - fbeta: 1.0000 - val_loss: 0.6571 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02083: val_loss did not improve from 0.39496\n",
      "Epoch 2084/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6840e-04 - fbeta: 1.0000 - val_loss: 0.6576 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02084: val_loss did not improve from 0.39496\n",
      "Epoch 2085/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6850e-04 - fbeta: 1.0000 - val_loss: 0.6549 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02085: val_loss did not improve from 0.39496\n",
      "Epoch 2086/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6822e-04 - fbeta: 1.0000 - val_loss: 0.6565 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02086: val_loss did not improve from 0.39496\n",
      "Epoch 2087/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6765e-04 - fbeta: 1.0000 - val_loss: 0.6569 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02087: val_loss did not improve from 0.39496\n",
      "Epoch 2088/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6816e-04 - fbeta: 1.0000 - val_loss: 0.6568 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02088: val_loss did not improve from 0.39496\n",
      "Epoch 2089/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6801e-04 - fbeta: 1.0000 - val_loss: 0.6584 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02089: val_loss did not improve from 0.39496\n",
      "Epoch 2090/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6788e-04 - fbeta: 1.0000 - val_loss: 0.6574 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02090: val_loss did not improve from 0.39496\n",
      "Epoch 2091/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6825e-04 - fbeta: 1.0000 - val_loss: 0.6554 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02091: val_loss did not improve from 0.39496\n",
      "Epoch 2092/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6785e-04 - fbeta: 1.0000 - val_loss: 0.6616 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02092: val_loss did not improve from 0.39496\n",
      "Epoch 2093/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6805e-04 - fbeta: 1.0000 - val_loss: 0.6633 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02093: val_loss did not improve from 0.39496\n",
      "Epoch 2094/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6706e-04 - fbeta: 1.0000 - val_loss: 0.6606 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02094: val_loss did not improve from 0.39496\n",
      "Epoch 2095/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6714e-04 - fbeta: 1.0000 - val_loss: 0.6593 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02095: val_loss did not improve from 0.39496\n",
      "Epoch 2096/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6636e-04 - fbeta: 1.0000 - val_loss: 0.6600 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02096: val_loss did not improve from 0.39496\n",
      "Epoch 2097/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6649e-04 - fbeta: 1.0000 - val_loss: 0.6588 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02097: val_loss did not improve from 0.39496\n",
      "Epoch 2098/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6581e-04 - fbeta: 1.0000 - val_loss: 0.6581 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02098: val_loss did not improve from 0.39496\n",
      "Epoch 2099/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6640e-04 - fbeta: 1.0000 - val_loss: 0.6591 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02099: val_loss did not improve from 0.39496\n",
      "Epoch 2100/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6602e-04 - fbeta: 1.0000 - val_loss: 0.6595 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02100: val_loss did not improve from 0.39496\n",
      "Epoch 2101/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6563e-04 - fbeta: 1.0000 - val_loss: 0.6567 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02101: val_loss did not improve from 0.39496\n",
      "Epoch 2102/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6579e-04 - fbeta: 1.0000 - val_loss: 0.6584 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02102: val_loss did not improve from 0.39496\n",
      "Epoch 2103/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6558e-04 - fbeta: 1.0000 - val_loss: 0.6615 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02103: val_loss did not improve from 0.39496\n",
      "Epoch 2104/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6589e-04 - fbeta: 1.0000 - val_loss: 0.6598 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02104: val_loss did not improve from 0.39496\n",
      "Epoch 2105/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6551e-04 - fbeta: 1.0000 - val_loss: 0.6572 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02105: val_loss did not improve from 0.39496\n",
      "Epoch 2106/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6451e-04 - fbeta: 1.0000 - val_loss: 0.6573 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02106: val_loss did not improve from 0.39496\n",
      "Epoch 2107/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6521e-04 - fbeta: 1.0000 - val_loss: 0.6589 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02107: val_loss did not improve from 0.39496\n",
      "Epoch 2108/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6431e-04 - fbeta: 1.0000 - val_loss: 0.6593 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02108: val_loss did not improve from 0.39496\n",
      "Epoch 2109/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6448e-04 - fbeta: 1.0000 - val_loss: 0.6585 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02109: val_loss did not improve from 0.39496\n",
      "Epoch 2110/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6464e-04 - fbeta: 1.0000 - val_loss: 0.6609 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02110: val_loss did not improve from 0.39496\n",
      "Epoch 2111/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6504e-04 - fbeta: 1.0000 - val_loss: 0.6605 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02111: val_loss did not improve from 0.39496\n",
      "Epoch 2112/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6438e-04 - fbeta: 1.0000 - val_loss: 0.6558 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02112: val_loss did not improve from 0.39496\n",
      "Epoch 2113/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6429e-04 - fbeta: 1.0000 - val_loss: 0.6564 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02113: val_loss did not improve from 0.39496\n",
      "Epoch 2114/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6494e-04 - fbeta: 1.0000 - val_loss: 0.6565 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02114: val_loss did not improve from 0.39496\n",
      "Epoch 2115/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6411e-04 - fbeta: 1.0000 - val_loss: 0.6583 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02115: val_loss did not improve from 0.39496\n",
      "Epoch 2116/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6386e-04 - fbeta: 1.0000 - val_loss: 0.6579 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02116: val_loss did not improve from 0.39496\n",
      "Epoch 2117/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6301e-04 - fbeta: 1.0000 - val_loss: 0.6581 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02117: val_loss did not improve from 0.39496\n",
      "Epoch 2118/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6308e-04 - fbeta: 1.0000 - val_loss: 0.6572 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02118: val_loss did not improve from 0.39496\n",
      "Epoch 2119/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6372e-04 - fbeta: 1.0000 - val_loss: 0.6601 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02119: val_loss did not improve from 0.39496\n",
      "Epoch 2120/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6260e-04 - fbeta: 1.0000 - val_loss: 0.6625 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02120: val_loss did not improve from 0.39496\n",
      "Epoch 2121/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6280e-04 - fbeta: 1.0000 - val_loss: 0.6605 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02121: val_loss did not improve from 0.39496\n",
      "Epoch 2122/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6296e-04 - fbeta: 1.0000 - val_loss: 0.6615 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02122: val_loss did not improve from 0.39496\n",
      "Epoch 2123/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6238e-04 - fbeta: 1.0000 - val_loss: 0.6607 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02123: val_loss did not improve from 0.39496\n",
      "Epoch 2124/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6420e-04 - fbeta: 1.0000 - val_loss: 0.6585 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02124: val_loss did not improve from 0.39496\n",
      "Epoch 2125/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6262e-04 - fbeta: 1.0000 - val_loss: 0.6544 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02125: val_loss did not improve from 0.39496\n",
      "Epoch 2126/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6201e-04 - fbeta: 1.0000 - val_loss: 0.6569 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02126: val_loss did not improve from 0.39496\n",
      "Epoch 2127/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6196e-04 - fbeta: 1.0000 - val_loss: 0.6577 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02127: val_loss did not improve from 0.39496\n",
      "Epoch 2128/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6239e-04 - fbeta: 1.0000 - val_loss: 0.6589 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02128: val_loss did not improve from 0.39496\n",
      "Epoch 2129/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6178e-04 - fbeta: 1.0000 - val_loss: 0.6595 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02129: val_loss did not improve from 0.39496\n",
      "Epoch 2130/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6157e-04 - fbeta: 1.0000 - val_loss: 0.6589 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02130: val_loss did not improve from 0.39496\n",
      "Epoch 2131/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6159e-04 - fbeta: 1.0000 - val_loss: 0.6613 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02131: val_loss did not improve from 0.39496\n",
      "Epoch 2132/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6084e-04 - fbeta: 1.0000 - val_loss: 0.6606 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02132: val_loss did not improve from 0.39496\n",
      "Epoch 2133/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6132e-04 - fbeta: 1.0000 - val_loss: 0.6627 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02133: val_loss did not improve from 0.39496\n",
      "Epoch 2134/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6168e-04 - fbeta: 1.0000 - val_loss: 0.6621 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02134: val_loss did not improve from 0.39496\n",
      "Epoch 2135/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6062e-04 - fbeta: 1.0000 - val_loss: 0.6627 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02135: val_loss did not improve from 0.39496\n",
      "Epoch 2136/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6051e-04 - fbeta: 1.0000 - val_loss: 0.6619 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02136: val_loss did not improve from 0.39496\n",
      "Epoch 2137/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6027e-04 - fbeta: 1.0000 - val_loss: 0.6610 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02137: val_loss did not improve from 0.39496\n",
      "Epoch 2138/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5977e-04 - fbeta: 1.0000 - val_loss: 0.6593 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02138: val_loss did not improve from 0.39496\n",
      "Epoch 2139/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6002e-04 - fbeta: 1.0000 - val_loss: 0.6600 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02139: val_loss did not improve from 0.39496\n",
      "Epoch 2140/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6061e-04 - fbeta: 1.0000 - val_loss: 0.6611 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02140: val_loss did not improve from 0.39496\n",
      "Epoch 2141/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6016e-04 - fbeta: 1.0000 - val_loss: 0.6614 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02141: val_loss did not improve from 0.39496\n",
      "Epoch 2142/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5979e-04 - fbeta: 1.0000 - val_loss: 0.6615 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02142: val_loss did not improve from 0.39496\n",
      "Epoch 2143/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5913e-04 - fbeta: 1.0000 - val_loss: 0.6627 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02143: val_loss did not improve from 0.39496\n",
      "Epoch 2144/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5871e-04 - fbeta: 1.0000 - val_loss: 0.6626 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02144: val_loss did not improve from 0.39496\n",
      "Epoch 2145/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.6022e-04 - fbeta: 1.0000 - val_loss: 0.6624 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02145: val_loss did not improve from 0.39496\n",
      "Epoch 2146/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5873e-04 - fbeta: 1.0000 - val_loss: 0.6607 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02146: val_loss did not improve from 0.39496\n",
      "Epoch 2147/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5879e-04 - fbeta: 1.0000 - val_loss: 0.6614 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02147: val_loss did not improve from 0.39496\n",
      "Epoch 2148/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5904e-04 - fbeta: 1.0000 - val_loss: 0.6657 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02148: val_loss did not improve from 0.39496\n",
      "Epoch 2149/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5839e-04 - fbeta: 1.0000 - val_loss: 0.6618 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02149: val_loss did not improve from 0.39496\n",
      "Epoch 2150/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5818e-04 - fbeta: 1.0000 - val_loss: 0.6611 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02150: val_loss did not improve from 0.39496\n",
      "Epoch 2151/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5956e-04 - fbeta: 1.0000 - val_loss: 0.6644 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02151: val_loss did not improve from 0.39496\n",
      "Epoch 2152/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5936e-04 - fbeta: 1.0000 - val_loss: 0.6619 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02152: val_loss did not improve from 0.39496\n",
      "Epoch 2153/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5880e-04 - fbeta: 1.0000 - val_loss: 0.6551 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02153: val_loss did not improve from 0.39496\n",
      "Epoch 2154/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5767e-04 - fbeta: 1.0000 - val_loss: 0.6581 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02154: val_loss did not improve from 0.39496\n",
      "Epoch 2155/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5799e-04 - fbeta: 1.0000 - val_loss: 0.6578 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02155: val_loss did not improve from 0.39496\n",
      "Epoch 2156/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5754e-04 - fbeta: 1.0000 - val_loss: 0.6600 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02156: val_loss did not improve from 0.39496\n",
      "Epoch 2157/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5679e-04 - fbeta: 1.0000 - val_loss: 0.6591 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02157: val_loss did not improve from 0.39496\n",
      "Epoch 2158/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5775e-04 - fbeta: 1.0000 - val_loss: 0.6587 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02158: val_loss did not improve from 0.39496\n",
      "Epoch 2159/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5727e-04 - fbeta: 1.0000 - val_loss: 0.6614 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02159: val_loss did not improve from 0.39496\n",
      "Epoch 2160/5000\n",
      "622/622 [==============================] - 25s 41ms/step - loss: 2.5720e-04 - fbeta: 1.0000 - val_loss: 0.6614 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02160: val_loss did not improve from 0.39496\n",
      "Epoch 2161/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5640e-04 - fbeta: 1.0000 - val_loss: 0.6628 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02161: val_loss did not improve from 0.39496\n",
      "Epoch 2162/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5712e-04 - fbeta: 1.0000 - val_loss: 0.6604 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02162: val_loss did not improve from 0.39496\n",
      "Epoch 2163/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5643e-04 - fbeta: 1.0000 - val_loss: 0.6622 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02163: val_loss did not improve from 0.39496\n",
      "Epoch 2164/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5648e-04 - fbeta: 1.0000 - val_loss: 0.6642 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02164: val_loss did not improve from 0.39496\n",
      "Epoch 2165/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5637e-04 - fbeta: 1.0000 - val_loss: 0.6622 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02165: val_loss did not improve from 0.39496\n",
      "Epoch 2166/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5592e-04 - fbeta: 1.0000 - val_loss: 0.6619 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02166: val_loss did not improve from 0.39496\n",
      "Epoch 2167/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5624e-04 - fbeta: 1.0000 - val_loss: 0.6621 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02167: val_loss did not improve from 0.39496\n",
      "Epoch 2168/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5763e-04 - fbeta: 1.0000 - val_loss: 0.6608 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02168: val_loss did not improve from 0.39496\n",
      "Epoch 2169/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5587e-04 - fbeta: 1.0000 - val_loss: 0.6623 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02169: val_loss did not improve from 0.39496\n",
      "Epoch 2170/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5570e-04 - fbeta: 1.0000 - val_loss: 0.6618 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02170: val_loss did not improve from 0.39496\n",
      "Epoch 2171/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5530e-04 - fbeta: 1.0000 - val_loss: 0.6604 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02171: val_loss did not improve from 0.39496\n",
      "Epoch 2172/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5533e-04 - fbeta: 1.0000 - val_loss: 0.6609 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02172: val_loss did not improve from 0.39496\n",
      "Epoch 2173/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5499e-04 - fbeta: 1.0000 - val_loss: 0.6611 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02173: val_loss did not improve from 0.39496\n",
      "Epoch 2174/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5527e-04 - fbeta: 1.0000 - val_loss: 0.6614 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02174: val_loss did not improve from 0.39496\n",
      "Epoch 2175/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5416e-04 - fbeta: 1.0000 - val_loss: 0.6610 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02175: val_loss did not improve from 0.39496\n",
      "Epoch 2176/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5453e-04 - fbeta: 1.0000 - val_loss: 0.6580 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02176: val_loss did not improve from 0.39496\n",
      "Epoch 2177/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5412e-04 - fbeta: 1.0000 - val_loss: 0.6592 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02177: val_loss did not improve from 0.39496\n",
      "Epoch 2178/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5482e-04 - fbeta: 1.0000 - val_loss: 0.6601 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02178: val_loss did not improve from 0.39496\n",
      "Epoch 2179/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5388e-04 - fbeta: 1.0000 - val_loss: 0.6602 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02179: val_loss did not improve from 0.39496\n",
      "Epoch 2180/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5389e-04 - fbeta: 1.0000 - val_loss: 0.6610 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02180: val_loss did not improve from 0.39496\n",
      "Epoch 2181/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5349e-04 - fbeta: 1.0000 - val_loss: 0.6607 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02181: val_loss did not improve from 0.39496\n",
      "Epoch 2182/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5347e-04 - fbeta: 1.0000 - val_loss: 0.6597 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02182: val_loss did not improve from 0.39496\n",
      "Epoch 2183/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5347e-04 - fbeta: 1.0000 - val_loss: 0.6618 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02183: val_loss did not improve from 0.39496\n",
      "Epoch 2184/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5353e-04 - fbeta: 1.0000 - val_loss: 0.6613 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02184: val_loss did not improve from 0.39496\n",
      "Epoch 2185/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5264e-04 - fbeta: 1.0000 - val_loss: 0.6625 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02185: val_loss did not improve from 0.39496\n",
      "Epoch 2186/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5293e-04 - fbeta: 1.0000 - val_loss: 0.6611 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02186: val_loss did not improve from 0.39496\n",
      "Epoch 2187/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5261e-04 - fbeta: 1.0000 - val_loss: 0.6607 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02187: val_loss did not improve from 0.39496\n",
      "Epoch 2188/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5273e-04 - fbeta: 1.0000 - val_loss: 0.6594 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02188: val_loss did not improve from 0.39496\n",
      "Epoch 2189/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5322e-04 - fbeta: 1.0000 - val_loss: 0.6551 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02189: val_loss did not improve from 0.39496\n",
      "Epoch 2190/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5223e-04 - fbeta: 1.0000 - val_loss: 0.6589 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02190: val_loss did not improve from 0.39496\n",
      "Epoch 2191/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5469e-04 - fbeta: 1.0000 - val_loss: 0.6581 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02191: val_loss did not improve from 0.39496\n",
      "Epoch 2192/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5254e-04 - fbeta: 1.0000 - val_loss: 0.6592 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02192: val_loss did not improve from 0.39496\n",
      "Epoch 2193/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5234e-04 - fbeta: 1.0000 - val_loss: 0.6607 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02193: val_loss did not improve from 0.39496\n",
      "Epoch 2194/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5221e-04 - fbeta: 1.0000 - val_loss: 0.6620 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02194: val_loss did not improve from 0.39496\n",
      "Epoch 2195/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5189e-04 - fbeta: 1.0000 - val_loss: 0.6607 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02195: val_loss did not improve from 0.39496\n",
      "Epoch 2196/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5170e-04 - fbeta: 1.0000 - val_loss: 0.6620 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02196: val_loss did not improve from 0.39496\n",
      "Epoch 2197/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5187e-04 - fbeta: 1.0000 - val_loss: 0.6622 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02197: val_loss did not improve from 0.39496\n",
      "Epoch 2198/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5155e-04 - fbeta: 1.0000 - val_loss: 0.6613 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02198: val_loss did not improve from 0.39496\n",
      "Epoch 2199/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5096e-04 - fbeta: 1.0000 - val_loss: 0.6600 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02199: val_loss did not improve from 0.39496\n",
      "Epoch 2200/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5068e-04 - fbeta: 1.0000 - val_loss: 0.6587 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02200: val_loss did not improve from 0.39496\n",
      "Epoch 2201/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5137e-04 - fbeta: 1.0000 - val_loss: 0.6600 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02201: val_loss did not improve from 0.39496\n",
      "Epoch 2202/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5112e-04 - fbeta: 1.0000 - val_loss: 0.6625 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02202: val_loss did not improve from 0.39496\n",
      "Epoch 2203/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5117e-04 - fbeta: 1.0000 - val_loss: 0.6651 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02203: val_loss did not improve from 0.39496\n",
      "Epoch 2204/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5037e-04 - fbeta: 1.0000 - val_loss: 0.6631 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02204: val_loss did not improve from 0.39496\n",
      "Epoch 2205/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4969e-04 - fbeta: 1.0000 - val_loss: 0.6640 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02205: val_loss did not improve from 0.39496\n",
      "Epoch 2206/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5143e-04 - fbeta: 1.0000 - val_loss: 0.6632 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02206: val_loss did not improve from 0.39496\n",
      "Epoch 2207/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5051e-04 - fbeta: 1.0000 - val_loss: 0.6640 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02207: val_loss did not improve from 0.39496\n",
      "Epoch 2208/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5056e-04 - fbeta: 1.0000 - val_loss: 0.6625 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02208: val_loss did not improve from 0.39496\n",
      "Epoch 2209/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4946e-04 - fbeta: 1.0000 - val_loss: 0.6613 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02209: val_loss did not improve from 0.39496\n",
      "Epoch 2210/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.5009e-04 - fbeta: 1.0000 - val_loss: 0.6610 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02210: val_loss did not improve from 0.39496\n",
      "Epoch 2211/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4958e-04 - fbeta: 1.0000 - val_loss: 0.6608 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02211: val_loss did not improve from 0.39496\n",
      "Epoch 2212/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4895e-04 - fbeta: 1.0000 - val_loss: 0.6615 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02212: val_loss did not improve from 0.39496\n",
      "Epoch 2213/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4948e-04 - fbeta: 1.0000 - val_loss: 0.6603 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02213: val_loss did not improve from 0.39496\n",
      "Epoch 2214/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4978e-04 - fbeta: 1.0000 - val_loss: 0.6576 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02214: val_loss did not improve from 0.39496\n",
      "Epoch 2215/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4927e-04 - fbeta: 1.0000 - val_loss: 0.6606 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02215: val_loss did not improve from 0.39496\n",
      "Epoch 2216/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4845e-04 - fbeta: 1.0000 - val_loss: 0.6631 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02216: val_loss did not improve from 0.39496\n",
      "Epoch 2217/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4913e-04 - fbeta: 1.0000 - val_loss: 0.6609 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02217: val_loss did not improve from 0.39496\n",
      "Epoch 2218/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4808e-04 - fbeta: 1.0000 - val_loss: 0.6632 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02218: val_loss did not improve from 0.39496\n",
      "Epoch 2219/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4850e-04 - fbeta: 1.0000 - val_loss: 0.6629 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02219: val_loss did not improve from 0.39496\n",
      "Epoch 2220/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4805e-04 - fbeta: 1.0000 - val_loss: 0.6628 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02220: val_loss did not improve from 0.39496\n",
      "Epoch 2221/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4747e-04 - fbeta: 1.0000 - val_loss: 0.6629 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02221: val_loss did not improve from 0.39496\n",
      "Epoch 2222/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4873e-04 - fbeta: 1.0000 - val_loss: 0.6643 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02222: val_loss did not improve from 0.39496\n",
      "Epoch 2223/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4826e-04 - fbeta: 1.0000 - val_loss: 0.6644 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02223: val_loss did not improve from 0.39496\n",
      "Epoch 2224/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4785e-04 - fbeta: 1.0000 - val_loss: 0.6646 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02224: val_loss did not improve from 0.39496\n",
      "Epoch 2225/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4739e-04 - fbeta: 1.0000 - val_loss: 0.6656 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02225: val_loss did not improve from 0.39496\n",
      "Epoch 2226/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4755e-04 - fbeta: 1.0000 - val_loss: 0.6648 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02226: val_loss did not improve from 0.39496\n",
      "Epoch 2227/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4848e-04 - fbeta: 1.0000 - val_loss: 0.6666 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02227: val_loss did not improve from 0.39496\n",
      "Epoch 2228/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4741e-04 - fbeta: 1.0000 - val_loss: 0.6629 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02228: val_loss did not improve from 0.39496\n",
      "Epoch 2229/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4668e-04 - fbeta: 1.0000 - val_loss: 0.6632 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02229: val_loss did not improve from 0.39496\n",
      "Epoch 2230/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4669e-04 - fbeta: 1.0000 - val_loss: 0.6635 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02230: val_loss did not improve from 0.39496\n",
      "Epoch 2231/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4754e-04 - fbeta: 1.0000 - val_loss: 0.6621 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02231: val_loss did not improve from 0.39496\n",
      "Epoch 2232/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4660e-04 - fbeta: 1.0000 - val_loss: 0.6617 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02232: val_loss did not improve from 0.39496\n",
      "Epoch 2233/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4634e-04 - fbeta: 1.0000 - val_loss: 0.6622 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02233: val_loss did not improve from 0.39496\n",
      "Epoch 2234/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4683e-04 - fbeta: 1.0000 - val_loss: 0.6641 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02234: val_loss did not improve from 0.39496\n",
      "Epoch 2235/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4593e-04 - fbeta: 1.0000 - val_loss: 0.6639 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02235: val_loss did not improve from 0.39496\n",
      "Epoch 2236/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4588e-04 - fbeta: 1.0000 - val_loss: 0.6622 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02236: val_loss did not improve from 0.39496\n",
      "Epoch 2237/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4551e-04 - fbeta: 1.0000 - val_loss: 0.6616 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02237: val_loss did not improve from 0.39496\n",
      "Epoch 2238/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4592e-04 - fbeta: 1.0000 - val_loss: 0.6610 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02238: val_loss did not improve from 0.39496\n",
      "Epoch 2239/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4623e-04 - fbeta: 1.0000 - val_loss: 0.6589 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02239: val_loss did not improve from 0.39496\n",
      "Epoch 2240/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4556e-04 - fbeta: 1.0000 - val_loss: 0.6623 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02240: val_loss did not improve from 0.39496\n",
      "Epoch 2241/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4544e-04 - fbeta: 1.0000 - val_loss: 0.6595 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02241: val_loss did not improve from 0.39496\n",
      "Epoch 2242/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4657e-04 - fbeta: 1.0000 - val_loss: 0.6615 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02242: val_loss did not improve from 0.39496\n",
      "Epoch 2243/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4568e-04 - fbeta: 1.0000 - val_loss: 0.6641 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02243: val_loss did not improve from 0.39496\n",
      "Epoch 2244/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4496e-04 - fbeta: 1.0000 - val_loss: 0.6629 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02244: val_loss did not improve from 0.39496\n",
      "Epoch 2245/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4573e-04 - fbeta: 1.0000 - val_loss: 0.6650 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02245: val_loss did not improve from 0.39496\n",
      "Epoch 2246/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4474e-04 - fbeta: 1.0000 - val_loss: 0.6664 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02246: val_loss did not improve from 0.39496\n",
      "Epoch 2247/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4617e-04 - fbeta: 1.0000 - val_loss: 0.6681 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02247: val_loss did not improve from 0.39496\n",
      "Epoch 2248/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4495e-04 - fbeta: 1.0000 - val_loss: 0.6665 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02248: val_loss did not improve from 0.39496\n",
      "Epoch 2249/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4400e-04 - fbeta: 1.0000 - val_loss: 0.6661 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02249: val_loss did not improve from 0.39496\n",
      "Epoch 2250/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4416e-04 - fbeta: 1.0000 - val_loss: 0.6663 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02250: val_loss did not improve from 0.39496\n",
      "Epoch 2251/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4417e-04 - fbeta: 1.0000 - val_loss: 0.6655 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02251: val_loss did not improve from 0.39496\n",
      "Epoch 2252/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4370e-04 - fbeta: 1.0000 - val_loss: 0.6659 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02252: val_loss did not improve from 0.39496\n",
      "Epoch 2253/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4441e-04 - fbeta: 1.0000 - val_loss: 0.6705 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02253: val_loss did not improve from 0.39496\n",
      "Epoch 2254/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4401e-04 - fbeta: 1.0000 - val_loss: 0.6667 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02254: val_loss did not improve from 0.39496\n",
      "Epoch 2255/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4429e-04 - fbeta: 1.0000 - val_loss: 0.6603 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02255: val_loss did not improve from 0.39496\n",
      "Epoch 2256/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4308e-04 - fbeta: 1.0000 - val_loss: 0.6622 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02256: val_loss did not improve from 0.39496\n",
      "Epoch 2257/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4303e-04 - fbeta: 1.0000 - val_loss: 0.6627 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02257: val_loss did not improve from 0.39496\n",
      "Epoch 2258/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4319e-04 - fbeta: 1.0000 - val_loss: 0.6651 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02258: val_loss did not improve from 0.39496\n",
      "Epoch 2259/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4285e-04 - fbeta: 1.0000 - val_loss: 0.6648 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02259: val_loss did not improve from 0.39496\n",
      "Epoch 2260/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4241e-04 - fbeta: 1.0000 - val_loss: 0.6633 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02260: val_loss did not improve from 0.39496\n",
      "Epoch 2261/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4245e-04 - fbeta: 1.0000 - val_loss: 0.6647 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02261: val_loss did not improve from 0.39496\n",
      "Epoch 2262/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4245e-04 - fbeta: 1.0000 - val_loss: 0.6661 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02262: val_loss did not improve from 0.39496\n",
      "Epoch 2263/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4274e-04 - fbeta: 1.0000 - val_loss: 0.6658 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02263: val_loss did not improve from 0.39496\n",
      "Epoch 2264/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4295e-04 - fbeta: 1.0000 - val_loss: 0.6677 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02264: val_loss did not improve from 0.39496\n",
      "Epoch 2265/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4241e-04 - fbeta: 1.0000 - val_loss: 0.6635 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02265: val_loss did not improve from 0.39496\n",
      "Epoch 2266/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4174e-04 - fbeta: 1.0000 - val_loss: 0.6631 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02266: val_loss did not improve from 0.39496\n",
      "Epoch 2267/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4173e-04 - fbeta: 1.0000 - val_loss: 0.6624 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02267: val_loss did not improve from 0.39496\n",
      "Epoch 2268/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4130e-04 - fbeta: 1.0000 - val_loss: 0.6669 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02268: val_loss did not improve from 0.39496\n",
      "Epoch 2269/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4338e-04 - fbeta: 1.0000 - val_loss: 0.6695 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02269: val_loss did not improve from 0.39496\n",
      "Epoch 2270/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4180e-04 - fbeta: 1.0000 - val_loss: 0.6647 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02270: val_loss did not improve from 0.39496\n",
      "Epoch 2271/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4110e-04 - fbeta: 1.0000 - val_loss: 0.6653 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02271: val_loss did not improve from 0.39496\n",
      "Epoch 2272/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4124e-04 - fbeta: 1.0000 - val_loss: 0.6660 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02272: val_loss did not improve from 0.39496\n",
      "Epoch 2273/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4206e-04 - fbeta: 1.0000 - val_loss: 0.6653 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02273: val_loss did not improve from 0.39496\n",
      "Epoch 2274/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4082e-04 - fbeta: 1.0000 - val_loss: 0.6651 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02274: val_loss did not improve from 0.39496\n",
      "Epoch 2275/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4048e-04 - fbeta: 1.0000 - val_loss: 0.6634 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02275: val_loss did not improve from 0.39496\n",
      "Epoch 2276/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4112e-04 - fbeta: 1.0000 - val_loss: 0.6649 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02276: val_loss did not improve from 0.39496\n",
      "Epoch 2277/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4042e-04 - fbeta: 1.0000 - val_loss: 0.6646 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02277: val_loss did not improve from 0.39496\n",
      "Epoch 2278/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4057e-04 - fbeta: 1.0000 - val_loss: 0.6660 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02278: val_loss did not improve from 0.39496\n",
      "Epoch 2279/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4031e-04 - fbeta: 1.0000 - val_loss: 0.6654 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02279: val_loss did not improve from 0.39496\n",
      "Epoch 2280/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4020e-04 - fbeta: 1.0000 - val_loss: 0.6629 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02280: val_loss did not improve from 0.39496\n",
      "Epoch 2281/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3986e-04 - fbeta: 1.0000 - val_loss: 0.6629 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02281: val_loss did not improve from 0.39496\n",
      "Epoch 2282/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4002e-04 - fbeta: 1.0000 - val_loss: 0.6628 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02282: val_loss did not improve from 0.39496\n",
      "Epoch 2283/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3979e-04 - fbeta: 1.0000 - val_loss: 0.6627 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02283: val_loss did not improve from 0.39496\n",
      "Epoch 2284/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.4012e-04 - fbeta: 1.0000 - val_loss: 0.6630 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02284: val_loss did not improve from 0.39496\n",
      "Epoch 2285/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3928e-04 - fbeta: 1.0000 - val_loss: 0.6649 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02285: val_loss did not improve from 0.39496\n",
      "Epoch 2286/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3867e-04 - fbeta: 1.0000 - val_loss: 0.6643 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02286: val_loss did not improve from 0.39496\n",
      "Epoch 2287/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3917e-04 - fbeta: 1.0000 - val_loss: 0.6621 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02287: val_loss did not improve from 0.39496\n",
      "Epoch 2288/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3919e-04 - fbeta: 1.0000 - val_loss: 0.6659 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02288: val_loss did not improve from 0.39496\n",
      "Epoch 2289/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3897e-04 - fbeta: 1.0000 - val_loss: 0.6639 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02289: val_loss did not improve from 0.39496\n",
      "Epoch 2290/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3838e-04 - fbeta: 1.0000 - val_loss: 0.6640 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02290: val_loss did not improve from 0.39496\n",
      "Epoch 2291/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3872e-04 - fbeta: 1.0000 - val_loss: 0.6651 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02291: val_loss did not improve from 0.39496\n",
      "Epoch 2292/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3817e-04 - fbeta: 1.0000 - val_loss: 0.6656 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02292: val_loss did not improve from 0.39496\n",
      "Epoch 2293/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3826e-04 - fbeta: 1.0000 - val_loss: 0.6649 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02293: val_loss did not improve from 0.39496\n",
      "Epoch 2294/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3810e-04 - fbeta: 1.0000 - val_loss: 0.6637 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02294: val_loss did not improve from 0.39496\n",
      "Epoch 2295/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3788e-04 - fbeta: 1.0000 - val_loss: 0.6633 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02295: val_loss did not improve from 0.39496\n",
      "Epoch 2296/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3790e-04 - fbeta: 1.0000 - val_loss: 0.6631 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02296: val_loss did not improve from 0.39496\n",
      "Epoch 2297/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3780e-04 - fbeta: 1.0000 - val_loss: 0.6609 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02297: val_loss did not improve from 0.39496\n",
      "Epoch 2298/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3784e-04 - fbeta: 1.0000 - val_loss: 0.6609 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02298: val_loss did not improve from 0.39496\n",
      "Epoch 2299/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3747e-04 - fbeta: 1.0000 - val_loss: 0.6625 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02299: val_loss did not improve from 0.39496\n",
      "Epoch 2300/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3741e-04 - fbeta: 1.0000 - val_loss: 0.6631 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02300: val_loss did not improve from 0.39496\n",
      "Epoch 2301/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3804e-04 - fbeta: 1.0000 - val_loss: 0.6608 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02301: val_loss did not improve from 0.39496\n",
      "Epoch 2302/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3795e-04 - fbeta: 1.0000 - val_loss: 0.6669 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02302: val_loss did not improve from 0.39496\n",
      "Epoch 2303/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3765e-04 - fbeta: 1.0000 - val_loss: 0.6646 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02303: val_loss did not improve from 0.39496\n",
      "Epoch 2304/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3735e-04 - fbeta: 1.0000 - val_loss: 0.6648 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02304: val_loss did not improve from 0.39496\n",
      "Epoch 2305/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3711e-04 - fbeta: 1.0000 - val_loss: 0.6655 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02305: val_loss did not improve from 0.39496\n",
      "Epoch 2306/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3737e-04 - fbeta: 1.0000 - val_loss: 0.6656 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02306: val_loss did not improve from 0.39496\n",
      "Epoch 2307/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3699e-04 - fbeta: 1.0000 - val_loss: 0.6630 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02307: val_loss did not improve from 0.39496\n",
      "Epoch 2308/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3605e-04 - fbeta: 1.0000 - val_loss: 0.6648 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02308: val_loss did not improve from 0.39496\n",
      "Epoch 2309/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3635e-04 - fbeta: 1.0000 - val_loss: 0.6636 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02309: val_loss did not improve from 0.39496\n",
      "Epoch 2310/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3627e-04 - fbeta: 1.0000 - val_loss: 0.6640 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02310: val_loss did not improve from 0.39496\n",
      "Epoch 2311/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3592e-04 - fbeta: 1.0000 - val_loss: 0.6654 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02311: val_loss did not improve from 0.39496\n",
      "Epoch 2312/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3626e-04 - fbeta: 1.0000 - val_loss: 0.6670 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02312: val_loss did not improve from 0.39496\n",
      "Epoch 2313/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3575e-04 - fbeta: 1.0000 - val_loss: 0.6646 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02313: val_loss did not improve from 0.39496\n",
      "Epoch 2314/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3694e-04 - fbeta: 1.0000 - val_loss: 0.6605 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02314: val_loss did not improve from 0.39496\n",
      "Epoch 2315/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3559e-04 - fbeta: 1.0000 - val_loss: 0.6624 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02315: val_loss did not improve from 0.39496\n",
      "Epoch 2316/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3589e-04 - fbeta: 1.0000 - val_loss: 0.6628 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02316: val_loss did not improve from 0.39496\n",
      "Epoch 2317/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3521e-04 - fbeta: 1.0000 - val_loss: 0.6627 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02317: val_loss did not improve from 0.39496\n",
      "Epoch 2318/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3522e-04 - fbeta: 1.0000 - val_loss: 0.6644 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02318: val_loss did not improve from 0.39496\n",
      "Epoch 2319/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3474e-04 - fbeta: 1.0000 - val_loss: 0.6634 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02319: val_loss did not improve from 0.39496\n",
      "Epoch 2320/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3492e-04 - fbeta: 1.0000 - val_loss: 0.6636 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02320: val_loss did not improve from 0.39496\n",
      "Epoch 2321/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3459e-04 - fbeta: 1.0000 - val_loss: 0.6637 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02321: val_loss did not improve from 0.39496\n",
      "Epoch 2322/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3543e-04 - fbeta: 1.0000 - val_loss: 0.6636 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02322: val_loss did not improve from 0.39496\n",
      "Epoch 2323/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3635e-04 - fbeta: 1.0000 - val_loss: 0.6607 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02323: val_loss did not improve from 0.39496\n",
      "Epoch 2324/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3504e-04 - fbeta: 1.0000 - val_loss: 0.6632 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02324: val_loss did not improve from 0.39496\n",
      "Epoch 2325/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3452e-04 - fbeta: 1.0000 - val_loss: 0.6645 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02325: val_loss did not improve from 0.39496\n",
      "Epoch 2326/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3389e-04 - fbeta: 1.0000 - val_loss: 0.6645 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02326: val_loss did not improve from 0.39496\n",
      "Epoch 2327/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3424e-04 - fbeta: 1.0000 - val_loss: 0.6617 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02327: val_loss did not improve from 0.39496\n",
      "Epoch 2328/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3459e-04 - fbeta: 1.0000 - val_loss: 0.6626 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02328: val_loss did not improve from 0.39496\n",
      "Epoch 2329/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3387e-04 - fbeta: 1.0000 - val_loss: 0.6652 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02329: val_loss did not improve from 0.39496\n",
      "Epoch 2330/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3363e-04 - fbeta: 1.0000 - val_loss: 0.6658 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02330: val_loss did not improve from 0.39496\n",
      "Epoch 2331/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3393e-04 - fbeta: 1.0000 - val_loss: 0.6692 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02331: val_loss did not improve from 0.39496\n",
      "Epoch 2332/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3334e-04 - fbeta: 1.0000 - val_loss: 0.6689 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02332: val_loss did not improve from 0.39496\n",
      "Epoch 2333/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3338e-04 - fbeta: 1.0000 - val_loss: 0.6676 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02333: val_loss did not improve from 0.39496\n",
      "Epoch 2334/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3394e-04 - fbeta: 1.0000 - val_loss: 0.6662 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02334: val_loss did not improve from 0.39496\n",
      "Epoch 2335/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3303e-04 - fbeta: 1.0000 - val_loss: 0.6663 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02335: val_loss did not improve from 0.39496\n",
      "Epoch 2336/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3300e-04 - fbeta: 1.0000 - val_loss: 0.6663 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02336: val_loss did not improve from 0.39496\n",
      "Epoch 2337/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3291e-04 - fbeta: 1.0000 - val_loss: 0.6646 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02337: val_loss did not improve from 0.39496\n",
      "Epoch 2338/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3300e-04 - fbeta: 1.0000 - val_loss: 0.6677 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02338: val_loss did not improve from 0.39496\n",
      "Epoch 2339/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3253e-04 - fbeta: 1.0000 - val_loss: 0.6656 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02339: val_loss did not improve from 0.39496\n",
      "Epoch 2340/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3233e-04 - fbeta: 1.0000 - val_loss: 0.6652 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02340: val_loss did not improve from 0.39496\n",
      "Epoch 2341/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3218e-04 - fbeta: 1.0000 - val_loss: 0.6633 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02341: val_loss did not improve from 0.39496\n",
      "Epoch 2342/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3231e-04 - fbeta: 1.0000 - val_loss: 0.6640 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02342: val_loss did not improve from 0.39496\n",
      "Epoch 2343/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3214e-04 - fbeta: 1.0000 - val_loss: 0.6633 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02343: val_loss did not improve from 0.39496\n",
      "Epoch 2344/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3219e-04 - fbeta: 1.0000 - val_loss: 0.6646 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02344: val_loss did not improve from 0.39496\n",
      "Epoch 2345/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3209e-04 - fbeta: 1.0000 - val_loss: 0.6644 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02345: val_loss did not improve from 0.39496\n",
      "Epoch 2346/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3259e-04 - fbeta: 1.0000 - val_loss: 0.6641 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02346: val_loss did not improve from 0.39496\n",
      "Epoch 2347/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3143e-04 - fbeta: 1.0000 - val_loss: 0.6650 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02347: val_loss did not improve from 0.39496\n",
      "Epoch 2348/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3114e-04 - fbeta: 1.0000 - val_loss: 0.6647 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02348: val_loss did not improve from 0.39496\n",
      "Epoch 2349/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3091e-04 - fbeta: 1.0000 - val_loss: 0.6663 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02349: val_loss did not improve from 0.39496\n",
      "Epoch 2350/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3167e-04 - fbeta: 1.0000 - val_loss: 0.6658 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02350: val_loss did not improve from 0.39496\n",
      "Epoch 2351/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3163e-04 - fbeta: 1.0000 - val_loss: 0.6659 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02351: val_loss did not improve from 0.39496\n",
      "Epoch 2352/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3075e-04 - fbeta: 1.0000 - val_loss: 0.6646 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02352: val_loss did not improve from 0.39496\n",
      "Epoch 2353/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3079e-04 - fbeta: 1.0000 - val_loss: 0.6658 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02353: val_loss did not improve from 0.39496\n",
      "Epoch 2354/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3073e-04 - fbeta: 1.0000 - val_loss: 0.6666 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02354: val_loss did not improve from 0.39496\n",
      "Epoch 2355/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3043e-04 - fbeta: 1.0000 - val_loss: 0.6668 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02355: val_loss did not improve from 0.39496\n",
      "Epoch 2356/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3062e-04 - fbeta: 1.0000 - val_loss: 0.6673 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02356: val_loss did not improve from 0.39496\n",
      "Epoch 2357/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3065e-04 - fbeta: 1.0000 - val_loss: 0.6637 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02357: val_loss did not improve from 0.39496\n",
      "Epoch 2358/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3099e-04 - fbeta: 1.0000 - val_loss: 0.6614 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02358: val_loss did not improve from 0.39496\n",
      "Epoch 2359/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3029e-04 - fbeta: 1.0000 - val_loss: 0.6626 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02359: val_loss did not improve from 0.39496\n",
      "Epoch 2360/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2980e-04 - fbeta: 1.0000 - val_loss: 0.6636 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02360: val_loss did not improve from 0.39496\n",
      "Epoch 2361/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2971e-04 - fbeta: 1.0000 - val_loss: 0.6647 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02361: val_loss did not improve from 0.39496\n",
      "Epoch 2362/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2974e-04 - fbeta: 1.0000 - val_loss: 0.6666 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02362: val_loss did not improve from 0.39496\n",
      "Epoch 2363/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2956e-04 - fbeta: 1.0000 - val_loss: 0.6667 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02363: val_loss did not improve from 0.39496\n",
      "Epoch 2364/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2968e-04 - fbeta: 1.0000 - val_loss: 0.6674 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02364: val_loss did not improve from 0.39496\n",
      "Epoch 2365/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2897e-04 - fbeta: 1.0000 - val_loss: 0.6683 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02365: val_loss did not improve from 0.39496\n",
      "Epoch 2366/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2872e-04 - fbeta: 1.0000 - val_loss: 0.6658 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02366: val_loss did not improve from 0.39496\n",
      "Epoch 2367/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2926e-04 - fbeta: 1.0000 - val_loss: 0.6650 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02367: val_loss did not improve from 0.39496\n",
      "Epoch 2368/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2905e-04 - fbeta: 1.0000 - val_loss: 0.6630 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02368: val_loss did not improve from 0.39496\n",
      "Epoch 2369/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.3005e-04 - fbeta: 1.0000 - val_loss: 0.6592 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02369: val_loss did not improve from 0.39496\n",
      "Epoch 2370/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2911e-04 - fbeta: 1.0000 - val_loss: 0.6616 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02370: val_loss did not improve from 0.39496\n",
      "Epoch 2371/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2910e-04 - fbeta: 1.0000 - val_loss: 0.6633 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02371: val_loss did not improve from 0.39496\n",
      "Epoch 2372/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2846e-04 - fbeta: 1.0000 - val_loss: 0.6656 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02372: val_loss did not improve from 0.39496\n",
      "Epoch 2373/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2875e-04 - fbeta: 1.0000 - val_loss: 0.6718 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02373: val_loss did not improve from 0.39496\n",
      "Epoch 2374/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2897e-04 - fbeta: 1.0000 - val_loss: 0.6689 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02374: val_loss did not improve from 0.39496\n",
      "Epoch 2375/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2858e-04 - fbeta: 1.0000 - val_loss: 0.6677 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02375: val_loss did not improve from 0.39496\n",
      "Epoch 2376/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2805e-04 - fbeta: 1.0000 - val_loss: 0.6637 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02376: val_loss did not improve from 0.39496\n",
      "Epoch 2377/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2758e-04 - fbeta: 1.0000 - val_loss: 0.6652 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02377: val_loss did not improve from 0.39496\n",
      "Epoch 2378/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2787e-04 - fbeta: 1.0000 - val_loss: 0.6658 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02378: val_loss did not improve from 0.39496\n",
      "Epoch 2379/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2747e-04 - fbeta: 1.0000 - val_loss: 0.6658 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02379: val_loss did not improve from 0.39496\n",
      "Epoch 2380/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2773e-04 - fbeta: 1.0000 - val_loss: 0.6653 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02380: val_loss did not improve from 0.39496\n",
      "Epoch 2381/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2704e-04 - fbeta: 1.0000 - val_loss: 0.6670 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02381: val_loss did not improve from 0.39496\n",
      "Epoch 2382/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2706e-04 - fbeta: 1.0000 - val_loss: 0.6670 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02382: val_loss did not improve from 0.39496\n",
      "Epoch 2383/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2739e-04 - fbeta: 1.0000 - val_loss: 0.6675 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02383: val_loss did not improve from 0.39496\n",
      "Epoch 2384/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2694e-04 - fbeta: 1.0000 - val_loss: 0.6658 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02384: val_loss did not improve from 0.39496\n",
      "Epoch 2385/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2665e-04 - fbeta: 1.0000 - val_loss: 0.6673 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02385: val_loss did not improve from 0.39496\n",
      "Epoch 2386/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2652e-04 - fbeta: 1.0000 - val_loss: 0.6671 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02386: val_loss did not improve from 0.39496\n",
      "Epoch 2387/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2631e-04 - fbeta: 1.0000 - val_loss: 0.6675 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02387: val_loss did not improve from 0.39496\n",
      "Epoch 2388/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2638e-04 - fbeta: 1.0000 - val_loss: 0.6680 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02388: val_loss did not improve from 0.39496\n",
      "Epoch 2389/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2656e-04 - fbeta: 1.0000 - val_loss: 0.6671 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02389: val_loss did not improve from 0.39496\n",
      "Epoch 2390/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2637e-04 - fbeta: 1.0000 - val_loss: 0.6672 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02390: val_loss did not improve from 0.39496\n",
      "Epoch 2391/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2650e-04 - fbeta: 1.0000 - val_loss: 0.6706 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02391: val_loss did not improve from 0.39496\n",
      "Epoch 2392/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2779e-04 - fbeta: 1.0000 - val_loss: 0.6733 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02392: val_loss did not improve from 0.39496\n",
      "Epoch 2393/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2661e-04 - fbeta: 1.0000 - val_loss: 0.6689 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02393: val_loss did not improve from 0.39496\n",
      "Epoch 2394/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2598e-04 - fbeta: 1.0000 - val_loss: 0.6687 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02394: val_loss did not improve from 0.39496\n",
      "Epoch 2395/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2538e-04 - fbeta: 1.0000 - val_loss: 0.6688 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02395: val_loss did not improve from 0.39496\n",
      "Epoch 2396/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2568e-04 - fbeta: 1.0000 - val_loss: 0.6689 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02396: val_loss did not improve from 0.39496\n",
      "Epoch 2397/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2527e-04 - fbeta: 1.0000 - val_loss: 0.6695 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02397: val_loss did not improve from 0.39496\n",
      "Epoch 2398/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2514e-04 - fbeta: 1.0000 - val_loss: 0.6685 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02398: val_loss did not improve from 0.39496\n",
      "Epoch 2399/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2545e-04 - fbeta: 1.0000 - val_loss: 0.6698 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02399: val_loss did not improve from 0.39496\n",
      "Epoch 2400/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2490e-04 - fbeta: 1.0000 - val_loss: 0.6692 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02400: val_loss did not improve from 0.39496\n",
      "Epoch 2401/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2566e-04 - fbeta: 1.0000 - val_loss: 0.6692 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02401: val_loss did not improve from 0.39496\n",
      "Epoch 2402/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2617e-04 - fbeta: 1.0000 - val_loss: 0.6648 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02402: val_loss did not improve from 0.39496\n",
      "Epoch 2403/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2523e-04 - fbeta: 1.0000 - val_loss: 0.6655 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02403: val_loss did not improve from 0.39496\n",
      "Epoch 2404/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2506e-04 - fbeta: 1.0000 - val_loss: 0.6665 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02404: val_loss did not improve from 0.39496\n",
      "Epoch 2405/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2446e-04 - fbeta: 1.0000 - val_loss: 0.6691 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02405: val_loss did not improve from 0.39496\n",
      "Epoch 2406/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2469e-04 - fbeta: 1.0000 - val_loss: 0.6677 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02406: val_loss did not improve from 0.39496\n",
      "Epoch 2407/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2447e-04 - fbeta: 1.0000 - val_loss: 0.6690 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02407: val_loss did not improve from 0.39496\n",
      "Epoch 2408/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2430e-04 - fbeta: 1.0000 - val_loss: 0.6694 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02408: val_loss did not improve from 0.39496\n",
      "Epoch 2409/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2476e-04 - fbeta: 1.0000 - val_loss: 0.6722 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02409: val_loss did not improve from 0.39496\n",
      "Epoch 2410/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2387e-04 - fbeta: 1.0000 - val_loss: 0.6702 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02410: val_loss did not improve from 0.39496\n",
      "Epoch 2411/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2397e-04 - fbeta: 1.0000 - val_loss: 0.6702 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02411: val_loss did not improve from 0.39496\n",
      "Epoch 2412/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2360e-04 - fbeta: 1.0000 - val_loss: 0.6674 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02412: val_loss did not improve from 0.39496\n",
      "Epoch 2413/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2327e-04 - fbeta: 1.0000 - val_loss: 0.6678 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02413: val_loss did not improve from 0.39496\n",
      "Epoch 2414/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2371e-04 - fbeta: 1.0000 - val_loss: 0.6664 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02414: val_loss did not improve from 0.39496\n",
      "Epoch 2415/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2369e-04 - fbeta: 1.0000 - val_loss: 0.6674 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02415: val_loss did not improve from 0.39496\n",
      "Epoch 2416/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2409e-04 - fbeta: 1.0000 - val_loss: 0.6680 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02416: val_loss did not improve from 0.39496\n",
      "Epoch 2417/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2361e-04 - fbeta: 1.0000 - val_loss: 0.6656 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02417: val_loss did not improve from 0.39496\n",
      "Epoch 2418/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2312e-04 - fbeta: 1.0000 - val_loss: 0.6664 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02418: val_loss did not improve from 0.39496\n",
      "Epoch 2419/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2397e-04 - fbeta: 1.0000 - val_loss: 0.6683 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02419: val_loss did not improve from 0.39496\n",
      "Epoch 2420/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2350e-04 - fbeta: 1.0000 - val_loss: 0.6652 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02420: val_loss did not improve from 0.39496\n",
      "Epoch 2421/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2264e-04 - fbeta: 1.0000 - val_loss: 0.6674 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02421: val_loss did not improve from 0.39496\n",
      "Epoch 2422/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2246e-04 - fbeta: 1.0000 - val_loss: 0.6678 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02422: val_loss did not improve from 0.39496\n",
      "Epoch 2423/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2283e-04 - fbeta: 1.0000 - val_loss: 0.6685 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02423: val_loss did not improve from 0.39496\n",
      "Epoch 2424/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2230e-04 - fbeta: 1.0000 - val_loss: 0.6680 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02424: val_loss did not improve from 0.39496\n",
      "Epoch 2425/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2227e-04 - fbeta: 1.0000 - val_loss: 0.6684 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02425: val_loss did not improve from 0.39496\n",
      "Epoch 2426/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2235e-04 - fbeta: 1.0000 - val_loss: 0.6674 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02426: val_loss did not improve from 0.39496\n",
      "Epoch 2427/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2216e-04 - fbeta: 1.0000 - val_loss: 0.6693 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02427: val_loss did not improve from 0.39496\n",
      "Epoch 2428/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2199e-04 - fbeta: 1.0000 - val_loss: 0.6699 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02428: val_loss did not improve from 0.39496\n",
      "Epoch 2429/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2161e-04 - fbeta: 1.0000 - val_loss: 0.6681 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02429: val_loss did not improve from 0.39496\n",
      "Epoch 2430/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2179e-04 - fbeta: 1.0000 - val_loss: 0.6685 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02430: val_loss did not improve from 0.39496\n",
      "Epoch 2431/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2159e-04 - fbeta: 1.0000 - val_loss: 0.6686 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02431: val_loss did not improve from 0.39496\n",
      "Epoch 2432/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2136e-04 - fbeta: 1.0000 - val_loss: 0.6684 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02432: val_loss did not improve from 0.39496\n",
      "Epoch 2433/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2127e-04 - fbeta: 1.0000 - val_loss: 0.6652 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02433: val_loss did not improve from 0.39496\n",
      "Epoch 2434/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2133e-04 - fbeta: 1.0000 - val_loss: 0.6654 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02434: val_loss did not improve from 0.39496\n",
      "Epoch 2435/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2123e-04 - fbeta: 1.0000 - val_loss: 0.6670 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02435: val_loss did not improve from 0.39496\n",
      "Epoch 2436/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2123e-04 - fbeta: 1.0000 - val_loss: 0.6681 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02436: val_loss did not improve from 0.39496\n",
      "Epoch 2437/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2090e-04 - fbeta: 1.0000 - val_loss: 0.6691 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02437: val_loss did not improve from 0.39496\n",
      "Epoch 2438/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2087e-04 - fbeta: 1.0000 - val_loss: 0.6720 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02438: val_loss did not improve from 0.39496\n",
      "Epoch 2439/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2136e-04 - fbeta: 1.0000 - val_loss: 0.6729 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02439: val_loss did not improve from 0.39496\n",
      "Epoch 2440/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2085e-04 - fbeta: 1.0000 - val_loss: 0.6713 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02440: val_loss did not improve from 0.39496\n",
      "Epoch 2441/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2050e-04 - fbeta: 1.0000 - val_loss: 0.6705 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02441: val_loss did not improve from 0.39496\n",
      "Epoch 2442/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2037e-04 - fbeta: 1.0000 - val_loss: 0.6701 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02442: val_loss did not improve from 0.39496\n",
      "Epoch 2443/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2036e-04 - fbeta: 1.0000 - val_loss: 0.6697 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02443: val_loss did not improve from 0.39496\n",
      "Epoch 2444/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2061e-04 - fbeta: 1.0000 - val_loss: 0.6691 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02444: val_loss did not improve from 0.39496\n",
      "Epoch 2445/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1996e-04 - fbeta: 1.0000 - val_loss: 0.6693 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02445: val_loss did not improve from 0.39496\n",
      "Epoch 2446/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2028e-04 - fbeta: 1.0000 - val_loss: 0.6700 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02446: val_loss did not improve from 0.39496\n",
      "Epoch 2447/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1957e-04 - fbeta: 1.0000 - val_loss: 0.6698 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02447: val_loss did not improve from 0.39496\n",
      "Epoch 2448/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1986e-04 - fbeta: 1.0000 - val_loss: 0.6703 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02448: val_loss did not improve from 0.39496\n",
      "Epoch 2449/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1964e-04 - fbeta: 1.0000 - val_loss: 0.6676 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02449: val_loss did not improve from 0.39496\n",
      "Epoch 2450/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1927e-04 - fbeta: 1.0000 - val_loss: 0.6674 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02450: val_loss did not improve from 0.39496\n",
      "Epoch 2451/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1901e-04 - fbeta: 1.0000 - val_loss: 0.6688 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02451: val_loss did not improve from 0.39496\n",
      "Epoch 2452/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1915e-04 - fbeta: 1.0000 - val_loss: 0.6689 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02452: val_loss did not improve from 0.39496\n",
      "Epoch 2453/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1901e-04 - fbeta: 1.0000 - val_loss: 0.6691 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02453: val_loss did not improve from 0.39496\n",
      "Epoch 2454/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1944e-04 - fbeta: 1.0000 - val_loss: 0.6690 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02454: val_loss did not improve from 0.39496\n",
      "Epoch 2455/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1937e-04 - fbeta: 1.0000 - val_loss: 0.6701 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02455: val_loss did not improve from 0.39496\n",
      "Epoch 2456/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.2095e-04 - fbeta: 1.0000 - val_loss: 0.6718 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02456: val_loss did not improve from 0.39496\n",
      "Epoch 2457/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1914e-04 - fbeta: 1.0000 - val_loss: 0.6719 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02457: val_loss did not improve from 0.39496\n",
      "Epoch 2458/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1877e-04 - fbeta: 1.0000 - val_loss: 0.6737 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02458: val_loss did not improve from 0.39496\n",
      "Epoch 2459/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1839e-04 - fbeta: 1.0000 - val_loss: 0.6703 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02459: val_loss did not improve from 0.39496\n",
      "Epoch 2460/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1821e-04 - fbeta: 1.0000 - val_loss: 0.6688 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02460: val_loss did not improve from 0.39496\n",
      "Epoch 2461/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1858e-04 - fbeta: 1.0000 - val_loss: 0.6702 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02461: val_loss did not improve from 0.39496\n",
      "Epoch 2462/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1828e-04 - fbeta: 1.0000 - val_loss: 0.6699 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02462: val_loss did not improve from 0.39496\n",
      "Epoch 2463/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1784e-04 - fbeta: 1.0000 - val_loss: 0.6691 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02463: val_loss did not improve from 0.39496\n",
      "Epoch 2464/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1793e-04 - fbeta: 1.0000 - val_loss: 0.6689 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02464: val_loss did not improve from 0.39496\n",
      "Epoch 2465/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1762e-04 - fbeta: 1.0000 - val_loss: 0.6686 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02465: val_loss did not improve from 0.39496\n",
      "Epoch 2466/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1835e-04 - fbeta: 1.0000 - val_loss: 0.6678 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02466: val_loss did not improve from 0.39496\n",
      "Epoch 2467/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1772e-04 - fbeta: 1.0000 - val_loss: 0.6688 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02467: val_loss did not improve from 0.39496\n",
      "Epoch 2468/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1825e-04 - fbeta: 1.0000 - val_loss: 0.6695 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02468: val_loss did not improve from 0.39496\n",
      "Epoch 2469/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1808e-04 - fbeta: 1.0000 - val_loss: 0.6703 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02469: val_loss did not improve from 0.39496\n",
      "Epoch 2470/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1759e-04 - fbeta: 1.0000 - val_loss: 0.6702 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02470: val_loss did not improve from 0.39496\n",
      "Epoch 2471/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1717e-04 - fbeta: 1.0000 - val_loss: 0.6705 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02471: val_loss did not improve from 0.39496\n",
      "Epoch 2472/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1694e-04 - fbeta: 1.0000 - val_loss: 0.6709 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02472: val_loss did not improve from 0.39496\n",
      "Epoch 2473/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1731e-04 - fbeta: 1.0000 - val_loss: 0.6693 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02473: val_loss did not improve from 0.39496\n",
      "Epoch 2474/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1679e-04 - fbeta: 1.0000 - val_loss: 0.6704 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02474: val_loss did not improve from 0.39496\n",
      "Epoch 2475/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1686e-04 - fbeta: 1.0000 - val_loss: 0.6686 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02475: val_loss did not improve from 0.39496\n",
      "Epoch 2476/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1666e-04 - fbeta: 1.0000 - val_loss: 0.6691 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02476: val_loss did not improve from 0.39496\n",
      "Epoch 2477/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1678e-04 - fbeta: 1.0000 - val_loss: 0.6696 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02477: val_loss did not improve from 0.39496\n",
      "Epoch 2478/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1684e-04 - fbeta: 1.0000 - val_loss: 0.6679 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02478: val_loss did not improve from 0.39496\n",
      "Epoch 2479/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1646e-04 - fbeta: 1.0000 - val_loss: 0.6685 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02479: val_loss did not improve from 0.39496\n",
      "Epoch 2480/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1655e-04 - fbeta: 1.0000 - val_loss: 0.6687 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02480: val_loss did not improve from 0.39496\n",
      "Epoch 2481/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1683e-04 - fbeta: 1.0000 - val_loss: 0.6689 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02481: val_loss did not improve from 0.39496\n",
      "Epoch 2482/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1587e-04 - fbeta: 1.0000 - val_loss: 0.6696 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02482: val_loss did not improve from 0.39496\n",
      "Epoch 2483/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1598e-04 - fbeta: 1.0000 - val_loss: 0.6691 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02483: val_loss did not improve from 0.39496\n",
      "Epoch 2484/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1587e-04 - fbeta: 1.0000 - val_loss: 0.6692 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02484: val_loss did not improve from 0.39496\n",
      "Epoch 2485/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1559e-04 - fbeta: 1.0000 - val_loss: 0.6685 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02485: val_loss did not improve from 0.39496\n",
      "Epoch 2486/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1559e-04 - fbeta: 1.0000 - val_loss: 0.6689 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02486: val_loss did not improve from 0.39496\n",
      "Epoch 2487/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1531e-04 - fbeta: 1.0000 - val_loss: 0.6702 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02487: val_loss did not improve from 0.39496\n",
      "Epoch 2488/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1626e-04 - fbeta: 1.0000 - val_loss: 0.6706 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02488: val_loss did not improve from 0.39496\n",
      "Epoch 2489/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1525e-04 - fbeta: 1.0000 - val_loss: 0.6698 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02489: val_loss did not improve from 0.39496\n",
      "Epoch 2490/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1509e-04 - fbeta: 1.0000 - val_loss: 0.6691 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02490: val_loss did not improve from 0.39496\n",
      "Epoch 2491/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1560e-04 - fbeta: 1.0000 - val_loss: 0.6695 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02491: val_loss did not improve from 0.39496\n",
      "Epoch 2492/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1527e-04 - fbeta: 1.0000 - val_loss: 0.6712 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02492: val_loss did not improve from 0.39496\n",
      "Epoch 2493/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1512e-04 - fbeta: 1.0000 - val_loss: 0.6713 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02493: val_loss did not improve from 0.39496\n",
      "Epoch 2494/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1469e-04 - fbeta: 1.0000 - val_loss: 0.6698 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02494: val_loss did not improve from 0.39496\n",
      "Epoch 2495/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1433e-04 - fbeta: 1.0000 - val_loss: 0.6691 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02495: val_loss did not improve from 0.39496\n",
      "Epoch 2496/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1448e-04 - fbeta: 1.0000 - val_loss: 0.6675 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02496: val_loss did not improve from 0.39496\n",
      "Epoch 2497/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1490e-04 - fbeta: 1.0000 - val_loss: 0.6682 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02497: val_loss did not improve from 0.39496\n",
      "Epoch 2498/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1452e-04 - fbeta: 1.0000 - val_loss: 0.6688 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02498: val_loss did not improve from 0.39496\n",
      "Epoch 2499/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1465e-04 - fbeta: 1.0000 - val_loss: 0.6693 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02499: val_loss did not improve from 0.39496\n",
      "Epoch 2500/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1420e-04 - fbeta: 1.0000 - val_loss: 0.6699 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02500: val_loss did not improve from 0.39496\n",
      "Epoch 2501/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1384e-04 - fbeta: 1.0000 - val_loss: 0.6695 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02501: val_loss did not improve from 0.39496\n",
      "Epoch 2502/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1398e-04 - fbeta: 1.0000 - val_loss: 0.6689 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02502: val_loss did not improve from 0.39496\n",
      "Epoch 2503/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1591e-04 - fbeta: 1.0000 - val_loss: 0.6617 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02503: val_loss did not improve from 0.39496\n",
      "Epoch 2504/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1454e-04 - fbeta: 1.0000 - val_loss: 0.6661 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02504: val_loss did not improve from 0.39496\n",
      "Epoch 2505/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1342e-04 - fbeta: 1.0000 - val_loss: 0.6692 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02505: val_loss did not improve from 0.39496\n",
      "Epoch 2506/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1371e-04 - fbeta: 1.0000 - val_loss: 0.6695 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02506: val_loss did not improve from 0.39496\n",
      "Epoch 2507/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1340e-04 - fbeta: 1.0000 - val_loss: 0.6689 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02507: val_loss did not improve from 0.39496\n",
      "Epoch 2508/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1360e-04 - fbeta: 1.0000 - val_loss: 0.6673 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02508: val_loss did not improve from 0.39496\n",
      "Epoch 2509/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1308e-04 - fbeta: 1.0000 - val_loss: 0.6694 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02509: val_loss did not improve from 0.39496\n",
      "Epoch 2510/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1358e-04 - fbeta: 1.0000 - val_loss: 0.6709 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02510: val_loss did not improve from 0.39496\n",
      "Epoch 2511/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1299e-04 - fbeta: 1.0000 - val_loss: 0.6716 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02511: val_loss did not improve from 0.39496\n",
      "Epoch 2512/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1378e-04 - fbeta: 1.0000 - val_loss: 0.6726 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02512: val_loss did not improve from 0.39496\n",
      "Epoch 2513/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1444e-04 - fbeta: 1.0000 - val_loss: 0.6717 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02513: val_loss did not improve from 0.39496\n",
      "Epoch 2514/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1294e-04 - fbeta: 1.0000 - val_loss: 0.6694 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02514: val_loss did not improve from 0.39496\n",
      "Epoch 2515/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1256e-04 - fbeta: 1.0000 - val_loss: 0.6714 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02515: val_loss did not improve from 0.39496\n",
      "Epoch 2516/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1288e-04 - fbeta: 1.0000 - val_loss: 0.6730 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02516: val_loss did not improve from 0.39496\n",
      "Epoch 2517/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1200e-04 - fbeta: 1.0000 - val_loss: 0.6714 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02517: val_loss did not improve from 0.39496\n",
      "Epoch 2518/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1213e-04 - fbeta: 1.0000 - val_loss: 0.6713 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02518: val_loss did not improve from 0.39496\n",
      "Epoch 2519/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1213e-04 - fbeta: 1.0000 - val_loss: 0.6708 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02519: val_loss did not improve from 0.39496\n",
      "Epoch 2520/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1212e-04 - fbeta: 1.0000 - val_loss: 0.6721 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02520: val_loss did not improve from 0.39496\n",
      "Epoch 2521/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1245e-04 - fbeta: 1.0000 - val_loss: 0.6719 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02521: val_loss did not improve from 0.39496\n",
      "Epoch 2522/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1216e-04 - fbeta: 1.0000 - val_loss: 0.6722 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02522: val_loss did not improve from 0.39496\n",
      "Epoch 2523/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1183e-04 - fbeta: 1.0000 - val_loss: 0.6736 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02523: val_loss did not improve from 0.39496\n",
      "Epoch 2524/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1182e-04 - fbeta: 1.0000 - val_loss: 0.6718 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02524: val_loss did not improve from 0.39496\n",
      "Epoch 2525/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1186e-04 - fbeta: 1.0000 - val_loss: 0.6722 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02525: val_loss did not improve from 0.39496\n",
      "Epoch 2526/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1150e-04 - fbeta: 1.0000 - val_loss: 0.6718 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02526: val_loss did not improve from 0.39496\n",
      "Epoch 2527/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1118e-04 - fbeta: 1.0000 - val_loss: 0.6719 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02527: val_loss did not improve from 0.39496\n",
      "Epoch 2528/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1117e-04 - fbeta: 1.0000 - val_loss: 0.6685 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02528: val_loss did not improve from 0.39496\n",
      "Epoch 2529/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1114e-04 - fbeta: 1.0000 - val_loss: 0.6679 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02529: val_loss did not improve from 0.39496\n",
      "Epoch 2530/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1139e-04 - fbeta: 1.0000 - val_loss: 0.6686 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02530: val_loss did not improve from 0.39496\n",
      "Epoch 2531/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1100e-04 - fbeta: 1.0000 - val_loss: 0.6683 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02531: val_loss did not improve from 0.39496\n",
      "Epoch 2532/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1077e-04 - fbeta: 1.0000 - val_loss: 0.6688 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02532: val_loss did not improve from 0.39496\n",
      "Epoch 2533/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1083e-04 - fbeta: 1.0000 - val_loss: 0.6697 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02533: val_loss did not improve from 0.39496\n",
      "Epoch 2534/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1027e-04 - fbeta: 1.0000 - val_loss: 0.6697 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02534: val_loss did not improve from 0.39496\n",
      "Epoch 2535/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1065e-04 - fbeta: 1.0000 - val_loss: 0.6702 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02535: val_loss did not improve from 0.39496\n",
      "Epoch 2536/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1065e-04 - fbeta: 1.0000 - val_loss: 0.6705 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02536: val_loss did not improve from 0.39496\n",
      "Epoch 2537/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1011e-04 - fbeta: 1.0000 - val_loss: 0.6705 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02537: val_loss did not improve from 0.39496\n",
      "Epoch 2538/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1020e-04 - fbeta: 1.0000 - val_loss: 0.6720 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02538: val_loss did not improve from 0.39496\n",
      "Epoch 2539/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0983e-04 - fbeta: 1.0000 - val_loss: 0.6722 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02539: val_loss did not improve from 0.39496\n",
      "Epoch 2540/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0983e-04 - fbeta: 1.0000 - val_loss: 0.6732 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02540: val_loss did not improve from 0.39496\n",
      "Epoch 2541/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1116e-04 - fbeta: 1.0000 - val_loss: 0.6728 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02541: val_loss did not improve from 0.39496\n",
      "Epoch 2542/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1049e-04 - fbeta: 1.0000 - val_loss: 0.6713 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02542: val_loss did not improve from 0.39496\n",
      "Epoch 2543/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0989e-04 - fbeta: 1.0000 - val_loss: 0.6711 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02543: val_loss did not improve from 0.39496\n",
      "Epoch 2544/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.1015e-04 - fbeta: 1.0000 - val_loss: 0.6717 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02544: val_loss did not improve from 0.39496\n",
      "Epoch 2545/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0965e-04 - fbeta: 1.0000 - val_loss: 0.6747 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02545: val_loss did not improve from 0.39496\n",
      "Epoch 2546/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0956e-04 - fbeta: 1.0000 - val_loss: 0.6726 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02546: val_loss did not improve from 0.39496\n",
      "Epoch 2547/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0950e-04 - fbeta: 1.0000 - val_loss: 0.6712 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02547: val_loss did not improve from 0.39496\n",
      "Epoch 2548/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0927e-04 - fbeta: 1.0000 - val_loss: 0.6715 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02548: val_loss did not improve from 0.39496\n",
      "Epoch 2549/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0920e-04 - fbeta: 1.0000 - val_loss: 0.6717 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02549: val_loss did not improve from 0.39496\n",
      "Epoch 2550/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0952e-04 - fbeta: 1.0000 - val_loss: 0.6735 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02550: val_loss did not improve from 0.39496\n",
      "Epoch 2551/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0877e-04 - fbeta: 1.0000 - val_loss: 0.6741 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02551: val_loss did not improve from 0.39496\n",
      "Epoch 2552/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0865e-04 - fbeta: 1.0000 - val_loss: 0.6751 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02552: val_loss did not improve from 0.39496\n",
      "Epoch 2553/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0888e-04 - fbeta: 1.0000 - val_loss: 0.6732 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02553: val_loss did not improve from 0.39496\n",
      "Epoch 2554/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0866e-04 - fbeta: 1.0000 - val_loss: 0.6742 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02554: val_loss did not improve from 0.39496\n",
      "Epoch 2555/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0851e-04 - fbeta: 1.0000 - val_loss: 0.6739 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02555: val_loss did not improve from 0.39496\n",
      "Epoch 2556/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0839e-04 - fbeta: 1.0000 - val_loss: 0.6725 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02556: val_loss did not improve from 0.39496\n",
      "Epoch 2557/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0842e-04 - fbeta: 1.0000 - val_loss: 0.6756 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02557: val_loss did not improve from 0.39496\n",
      "Epoch 2558/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0830e-04 - fbeta: 1.0000 - val_loss: 0.6734 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02558: val_loss did not improve from 0.39496\n",
      "Epoch 2559/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0807e-04 - fbeta: 1.0000 - val_loss: 0.6742 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02559: val_loss did not improve from 0.39496\n",
      "Epoch 2560/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0785e-04 - fbeta: 1.0000 - val_loss: 0.6746 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02560: val_loss did not improve from 0.39496\n",
      "Epoch 2561/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0845e-04 - fbeta: 1.0000 - val_loss: 0.6744 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02561: val_loss did not improve from 0.39496\n",
      "Epoch 2562/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0772e-04 - fbeta: 1.0000 - val_loss: 0.6741 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02562: val_loss did not improve from 0.39496\n",
      "Epoch 2563/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0770e-04 - fbeta: 1.0000 - val_loss: 0.6749 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02563: val_loss did not improve from 0.39496\n",
      "Epoch 2564/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0765e-04 - fbeta: 1.0000 - val_loss: 0.6742 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02564: val_loss did not improve from 0.39496\n",
      "Epoch 2565/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0730e-04 - fbeta: 1.0000 - val_loss: 0.6729 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02565: val_loss did not improve from 0.39496\n",
      "Epoch 2566/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0721e-04 - fbeta: 1.0000 - val_loss: 0.6730 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02566: val_loss did not improve from 0.39496\n",
      "Epoch 2567/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0763e-04 - fbeta: 1.0000 - val_loss: 0.6741 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02567: val_loss did not improve from 0.39496\n",
      "Epoch 2568/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0705e-04 - fbeta: 1.0000 - val_loss: 0.6753 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02568: val_loss did not improve from 0.39496\n",
      "Epoch 2569/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0702e-04 - fbeta: 1.0000 - val_loss: 0.6729 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02569: val_loss did not improve from 0.39496\n",
      "Epoch 2570/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0711e-04 - fbeta: 1.0000 - val_loss: 0.6711 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02570: val_loss did not improve from 0.39496\n",
      "Epoch 2571/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0699e-04 - fbeta: 1.0000 - val_loss: 0.6706 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02571: val_loss did not improve from 0.39496\n",
      "Epoch 2572/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0653e-04 - fbeta: 1.0000 - val_loss: 0.6716 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02572: val_loss did not improve from 0.39496\n",
      "Epoch 2573/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0703e-04 - fbeta: 1.0000 - val_loss: 0.6732 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02573: val_loss did not improve from 0.39496\n",
      "Epoch 2574/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0630e-04 - fbeta: 1.0000 - val_loss: 0.6715 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02574: val_loss did not improve from 0.39496\n",
      "Epoch 2575/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0645e-04 - fbeta: 1.0000 - val_loss: 0.6729 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02575: val_loss did not improve from 0.39496\n",
      "Epoch 2576/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0631e-04 - fbeta: 1.0000 - val_loss: 0.6725 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02576: val_loss did not improve from 0.39496\n",
      "Epoch 2577/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0611e-04 - fbeta: 1.0000 - val_loss: 0.6692 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02577: val_loss did not improve from 0.39496\n",
      "Epoch 2578/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0618e-04 - fbeta: 1.0000 - val_loss: 0.6727 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02578: val_loss did not improve from 0.39496\n",
      "Epoch 2579/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0622e-04 - fbeta: 1.0000 - val_loss: 0.6727 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02579: val_loss did not improve from 0.39496\n",
      "Epoch 2580/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0605e-04 - fbeta: 1.0000 - val_loss: 0.6720 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02580: val_loss did not improve from 0.39496\n",
      "Epoch 2581/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0600e-04 - fbeta: 1.0000 - val_loss: 0.6742 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02581: val_loss did not improve from 0.39496\n",
      "Epoch 2582/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0698e-04 - fbeta: 1.0000 - val_loss: 0.6768 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02582: val_loss did not improve from 0.39496\n",
      "Epoch 2583/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0646e-04 - fbeta: 1.0000 - val_loss: 0.6748 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02583: val_loss did not improve from 0.39496\n",
      "Epoch 2584/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0610e-04 - fbeta: 1.0000 - val_loss: 0.6749 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02584: val_loss did not improve from 0.39496\n",
      "Epoch 2585/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0546e-04 - fbeta: 1.0000 - val_loss: 0.6728 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02585: val_loss did not improve from 0.39496\n",
      "Epoch 2586/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0541e-04 - fbeta: 1.0000 - val_loss: 0.6738 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02586: val_loss did not improve from 0.39496\n",
      "Epoch 2587/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0500e-04 - fbeta: 1.0000 - val_loss: 0.6722 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02587: val_loss did not improve from 0.39496\n",
      "Epoch 2588/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0506e-04 - fbeta: 1.0000 - val_loss: 0.6727 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02588: val_loss did not improve from 0.39496\n",
      "Epoch 2589/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0521e-04 - fbeta: 1.0000 - val_loss: 0.6726 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02589: val_loss did not improve from 0.39496\n",
      "Epoch 2590/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0487e-04 - fbeta: 1.0000 - val_loss: 0.6733 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02590: val_loss did not improve from 0.39496\n",
      "Epoch 2591/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0459e-04 - fbeta: 1.0000 - val_loss: 0.6711 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02591: val_loss did not improve from 0.39496\n",
      "Epoch 2592/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0479e-04 - fbeta: 1.0000 - val_loss: 0.6701 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02592: val_loss did not improve from 0.39496\n",
      "Epoch 2593/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0488e-04 - fbeta: 1.0000 - val_loss: 0.6715 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02593: val_loss did not improve from 0.39496\n",
      "Epoch 2594/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0439e-04 - fbeta: 1.0000 - val_loss: 0.6718 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02594: val_loss did not improve from 0.39496\n",
      "Epoch 2595/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0456e-04 - fbeta: 1.0000 - val_loss: 0.6722 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02595: val_loss did not improve from 0.39496\n",
      "Epoch 2596/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0423e-04 - fbeta: 1.0000 - val_loss: 0.6745 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02596: val_loss did not improve from 0.39496\n",
      "Epoch 2597/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0492e-04 - fbeta: 1.0000 - val_loss: 0.6745 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02597: val_loss did not improve from 0.39496\n",
      "Epoch 2598/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0449e-04 - fbeta: 1.0000 - val_loss: 0.6725 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02598: val_loss did not improve from 0.39496\n",
      "Epoch 2599/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0444e-04 - fbeta: 1.0000 - val_loss: 0.6725 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02599: val_loss did not improve from 0.39496\n",
      "Epoch 2600/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0444e-04 - fbeta: 1.0000 - val_loss: 0.6722 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02600: val_loss did not improve from 0.39496\n",
      "Epoch 2601/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0447e-04 - fbeta: 1.0000 - val_loss: 0.6681 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02601: val_loss did not improve from 0.39496\n",
      "Epoch 2602/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0455e-04 - fbeta: 1.0000 - val_loss: 0.6699 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02602: val_loss did not improve from 0.39496\n",
      "Epoch 2603/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0673e-04 - fbeta: 1.0000 - val_loss: 0.6680 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02603: val_loss did not improve from 0.39496\n",
      "Epoch 2604/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0443e-04 - fbeta: 1.0000 - val_loss: 0.6695 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02604: val_loss did not improve from 0.39496\n",
      "Epoch 2605/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0349e-04 - fbeta: 1.0000 - val_loss: 0.6709 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02605: val_loss did not improve from 0.39496\n",
      "Epoch 2606/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0364e-04 - fbeta: 1.0000 - val_loss: 0.6728 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02606: val_loss did not improve from 0.39496\n",
      "Epoch 2607/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0310e-04 - fbeta: 1.0000 - val_loss: 0.6730 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02607: val_loss did not improve from 0.39496\n",
      "Epoch 2608/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0306e-04 - fbeta: 1.0000 - val_loss: 0.6745 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02608: val_loss did not improve from 0.39496\n",
      "Epoch 2609/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0309e-04 - fbeta: 1.0000 - val_loss: 0.6774 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02609: val_loss did not improve from 0.39496\n",
      "Epoch 2610/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0297e-04 - fbeta: 1.0000 - val_loss: 0.6754 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02610: val_loss did not improve from 0.39496\n",
      "Epoch 2611/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0316e-04 - fbeta: 1.0000 - val_loss: 0.6756 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02611: val_loss did not improve from 0.39496\n",
      "Epoch 2612/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0278e-04 - fbeta: 1.0000 - val_loss: 0.6740 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02612: val_loss did not improve from 0.39496\n",
      "Epoch 2613/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0270e-04 - fbeta: 1.0000 - val_loss: 0.6739 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02613: val_loss did not improve from 0.39496\n",
      "Epoch 2614/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0267e-04 - fbeta: 1.0000 - val_loss: 0.6734 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02614: val_loss did not improve from 0.39496\n",
      "Epoch 2615/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0283e-04 - fbeta: 1.0000 - val_loss: 0.6730 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02615: val_loss did not improve from 0.39496\n",
      "Epoch 2616/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0247e-04 - fbeta: 1.0000 - val_loss: 0.6738 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02616: val_loss did not improve from 0.39496\n",
      "Epoch 2617/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0212e-04 - fbeta: 1.0000 - val_loss: 0.6735 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02617: val_loss did not improve from 0.39496\n",
      "Epoch 2618/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0265e-04 - fbeta: 1.0000 - val_loss: 0.6743 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02618: val_loss did not improve from 0.39496\n",
      "Epoch 2619/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0239e-04 - fbeta: 1.0000 - val_loss: 0.6736 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02619: val_loss did not improve from 0.39496\n",
      "Epoch 2620/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0174e-04 - fbeta: 1.0000 - val_loss: 0.6728 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02620: val_loss did not improve from 0.39496\n",
      "Epoch 2621/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0185e-04 - fbeta: 1.0000 - val_loss: 0.6734 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02621: val_loss did not improve from 0.39496\n",
      "Epoch 2622/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0199e-04 - fbeta: 1.0000 - val_loss: 0.6752 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02622: val_loss did not improve from 0.39496\n",
      "Epoch 2623/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0235e-04 - fbeta: 1.0000 - val_loss: 0.6743 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02623: val_loss did not improve from 0.39496\n",
      "Epoch 2624/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0285e-04 - fbeta: 1.0000 - val_loss: 0.6716 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02624: val_loss did not improve from 0.39496\n",
      "Epoch 2625/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0190e-04 - fbeta: 1.0000 - val_loss: 0.6642 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02625: val_loss did not improve from 0.39496\n",
      "Epoch 2626/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0188e-04 - fbeta: 1.0000 - val_loss: 0.6683 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02626: val_loss did not improve from 0.39496\n",
      "Epoch 2627/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0144e-04 - fbeta: 1.0000 - val_loss: 0.6727 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02627: val_loss did not improve from 0.39496\n",
      "Epoch 2628/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0142e-04 - fbeta: 1.0000 - val_loss: 0.6727 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02628: val_loss did not improve from 0.39496\n",
      "Epoch 2629/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0119e-04 - fbeta: 1.0000 - val_loss: 0.6710 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02629: val_loss did not improve from 0.39496\n",
      "Epoch 2630/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0114e-04 - fbeta: 1.0000 - val_loss: 0.6706 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02630: val_loss did not improve from 0.39496\n",
      "Epoch 2631/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0099e-04 - fbeta: 1.0000 - val_loss: 0.6715 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02631: val_loss did not improve from 0.39496\n",
      "Epoch 2632/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0113e-04 - fbeta: 1.0000 - val_loss: 0.6709 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02632: val_loss did not improve from 0.39496\n",
      "Epoch 2633/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0097e-04 - fbeta: 1.0000 - val_loss: 0.6721 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02633: val_loss did not improve from 0.39496\n",
      "Epoch 2634/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0097e-04 - fbeta: 1.0000 - val_loss: 0.6720 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02634: val_loss did not improve from 0.39496\n",
      "Epoch 2635/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0088e-04 - fbeta: 1.0000 - val_loss: 0.6719 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02635: val_loss did not improve from 0.39496\n",
      "Epoch 2636/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0059e-04 - fbeta: 1.0000 - val_loss: 0.6730 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02636: val_loss did not improve from 0.39496\n",
      "Epoch 2637/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0048e-04 - fbeta: 1.0000 - val_loss: 0.6728 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02637: val_loss did not improve from 0.39496\n",
      "Epoch 2638/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0013e-04 - fbeta: 1.0000 - val_loss: 0.6740 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02638: val_loss did not improve from 0.39496\n",
      "Epoch 2639/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0052e-04 - fbeta: 1.0000 - val_loss: 0.6750 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02639: val_loss did not improve from 0.39496\n",
      "Epoch 2640/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0023e-04 - fbeta: 1.0000 - val_loss: 0.6745 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02640: val_loss did not improve from 0.39496\n",
      "Epoch 2641/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9984e-04 - fbeta: 1.0000 - val_loss: 0.6747 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02641: val_loss did not improve from 0.39496\n",
      "Epoch 2642/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0004e-04 - fbeta: 1.0000 - val_loss: 0.6743 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02642: val_loss did not improve from 0.39496\n",
      "Epoch 2643/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9953e-04 - fbeta: 1.0000 - val_loss: 0.6733 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02643: val_loss did not improve from 0.39496\n",
      "Epoch 2644/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9990e-04 - fbeta: 1.0000 - val_loss: 0.6727 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02644: val_loss did not improve from 0.39496\n",
      "Epoch 2645/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9952e-04 - fbeta: 1.0000 - val_loss: 0.6745 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02645: val_loss did not improve from 0.39496\n",
      "Epoch 2646/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9961e-04 - fbeta: 1.0000 - val_loss: 0.6744 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02646: val_loss did not improve from 0.39496\n",
      "Epoch 2647/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9929e-04 - fbeta: 1.0000 - val_loss: 0.6750 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02647: val_loss did not improve from 0.39496\n",
      "Epoch 2648/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9918e-04 - fbeta: 1.0000 - val_loss: 0.6754 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02648: val_loss did not improve from 0.39496\n",
      "Epoch 2649/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9933e-04 - fbeta: 1.0000 - val_loss: 0.6764 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02649: val_loss did not improve from 0.39496\n",
      "Epoch 2650/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9931e-04 - fbeta: 1.0000 - val_loss: 0.6775 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02650: val_loss did not improve from 0.39496\n",
      "Epoch 2651/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 2.0011e-04 - fbeta: 1.0000 - val_loss: 0.6774 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02651: val_loss did not improve from 0.39496\n",
      "Epoch 2652/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9936e-04 - fbeta: 1.0000 - val_loss: 0.6756 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02652: val_loss did not improve from 0.39496\n",
      "Epoch 2653/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9872e-04 - fbeta: 1.0000 - val_loss: 0.6756 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02653: val_loss did not improve from 0.39496\n",
      "Epoch 2654/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9891e-04 - fbeta: 1.0000 - val_loss: 0.6746 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02654: val_loss did not improve from 0.39496\n",
      "Epoch 2655/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9885e-04 - fbeta: 1.0000 - val_loss: 0.6747 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02655: val_loss did not improve from 0.39496\n",
      "Epoch 2656/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9860e-04 - fbeta: 1.0000 - val_loss: 0.6746 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02656: val_loss did not improve from 0.39496\n",
      "Epoch 2657/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9843e-04 - fbeta: 1.0000 - val_loss: 0.6753 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02657: val_loss did not improve from 0.39496\n",
      "Epoch 2658/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9865e-04 - fbeta: 1.0000 - val_loss: 0.6756 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02658: val_loss did not improve from 0.39496\n",
      "Epoch 2659/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9868e-04 - fbeta: 1.0000 - val_loss: 0.6757 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02659: val_loss did not improve from 0.39496\n",
      "Epoch 2660/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9895e-04 - fbeta: 1.0000 - val_loss: 0.6739 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02660: val_loss did not improve from 0.39496\n",
      "Epoch 2661/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9876e-04 - fbeta: 1.0000 - val_loss: 0.6733 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02661: val_loss did not improve from 0.39496\n",
      "Epoch 2662/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9816e-04 - fbeta: 1.0000 - val_loss: 0.6722 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02662: val_loss did not improve from 0.39496\n",
      "Epoch 2663/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9805e-04 - fbeta: 1.0000 - val_loss: 0.6715 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02663: val_loss did not improve from 0.39496\n",
      "Epoch 2664/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9807e-04 - fbeta: 1.0000 - val_loss: 0.6746 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02664: val_loss did not improve from 0.39496\n",
      "Epoch 2665/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9822e-04 - fbeta: 1.0000 - val_loss: 0.6741 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02665: val_loss did not improve from 0.39496\n",
      "Epoch 2666/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9798e-04 - fbeta: 1.0000 - val_loss: 0.6736 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02666: val_loss did not improve from 0.39496\n",
      "Epoch 2667/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9769e-04 - fbeta: 1.0000 - val_loss: 0.6748 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02667: val_loss did not improve from 0.39496\n",
      "Epoch 2668/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9831e-04 - fbeta: 1.0000 - val_loss: 0.6750 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02668: val_loss did not improve from 0.39496\n",
      "Epoch 2669/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9763e-04 - fbeta: 1.0000 - val_loss: 0.6749 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02669: val_loss did not improve from 0.39496\n",
      "Epoch 2670/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9737e-04 - fbeta: 1.0000 - val_loss: 0.6754 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02670: val_loss did not improve from 0.39496\n",
      "Epoch 2671/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9751e-04 - fbeta: 1.0000 - val_loss: 0.6745 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02671: val_loss did not improve from 0.39496\n",
      "Epoch 2672/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9749e-04 - fbeta: 1.0000 - val_loss: 0.6751 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02672: val_loss did not improve from 0.39496\n",
      "Epoch 2673/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9703e-04 - fbeta: 1.0000 - val_loss: 0.6739 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02673: val_loss did not improve from 0.39496\n",
      "Epoch 2674/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9692e-04 - fbeta: 1.0000 - val_loss: 0.6731 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02674: val_loss did not improve from 0.39496\n",
      "Epoch 2675/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9726e-04 - fbeta: 1.0000 - val_loss: 0.6706 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02675: val_loss did not improve from 0.39496\n",
      "Epoch 2676/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9729e-04 - fbeta: 1.0000 - val_loss: 0.6724 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02676: val_loss did not improve from 0.39496\n",
      "Epoch 2677/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9680e-04 - fbeta: 1.0000 - val_loss: 0.6728 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02677: val_loss did not improve from 0.39496\n",
      "Epoch 2678/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9685e-04 - fbeta: 1.0000 - val_loss: 0.6752 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02678: val_loss did not improve from 0.39496\n",
      "Epoch 2679/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9655e-04 - fbeta: 1.0000 - val_loss: 0.6749 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02679: val_loss did not improve from 0.39496\n",
      "Epoch 2680/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9661e-04 - fbeta: 1.0000 - val_loss: 0.6728 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02680: val_loss did not improve from 0.39496\n",
      "Epoch 2681/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9636e-04 - fbeta: 1.0000 - val_loss: 0.6735 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02681: val_loss did not improve from 0.39496\n",
      "Epoch 2682/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9638e-04 - fbeta: 1.0000 - val_loss: 0.6751 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02682: val_loss did not improve from 0.39496\n",
      "Epoch 2683/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9609e-04 - fbeta: 1.0000 - val_loss: 0.6742 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02683: val_loss did not improve from 0.39496\n",
      "Epoch 2684/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9642e-04 - fbeta: 1.0000 - val_loss: 0.6739 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02684: val_loss did not improve from 0.39496\n",
      "Epoch 2685/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9605e-04 - fbeta: 1.0000 - val_loss: 0.6765 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02685: val_loss did not improve from 0.39496\n",
      "Epoch 2686/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9601e-04 - fbeta: 1.0000 - val_loss: 0.6776 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02686: val_loss did not improve from 0.39496\n",
      "Epoch 2687/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9611e-04 - fbeta: 1.0000 - val_loss: 0.6766 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02687: val_loss did not improve from 0.39496\n",
      "Epoch 2688/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9568e-04 - fbeta: 1.0000 - val_loss: 0.6778 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02688: val_loss did not improve from 0.39496\n",
      "Epoch 2689/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9605e-04 - fbeta: 1.0000 - val_loss: 0.6785 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02689: val_loss did not improve from 0.39496\n",
      "Epoch 2690/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9556e-04 - fbeta: 1.0000 - val_loss: 0.6756 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02690: val_loss did not improve from 0.39496\n",
      "Epoch 2691/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9551e-04 - fbeta: 1.0000 - val_loss: 0.6748 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02691: val_loss did not improve from 0.39496\n",
      "Epoch 2692/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9522e-04 - fbeta: 1.0000 - val_loss: 0.6742 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02692: val_loss did not improve from 0.39496\n",
      "Epoch 2693/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9553e-04 - fbeta: 1.0000 - val_loss: 0.6739 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02693: val_loss did not improve from 0.39496\n",
      "Epoch 2694/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9553e-04 - fbeta: 1.0000 - val_loss: 0.6744 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02694: val_loss did not improve from 0.39496\n",
      "Epoch 2695/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9662e-04 - fbeta: 1.0000 - val_loss: 0.6794 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02695: val_loss did not improve from 0.39496\n",
      "Epoch 2696/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9592e-04 - fbeta: 1.0000 - val_loss: 0.6793 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02696: val_loss did not improve from 0.39496\n",
      "Epoch 2697/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9512e-04 - fbeta: 1.0000 - val_loss: 0.6781 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02697: val_loss did not improve from 0.39496\n",
      "Epoch 2698/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9496e-04 - fbeta: 1.0000 - val_loss: 0.6793 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02698: val_loss did not improve from 0.39496\n",
      "Epoch 2699/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9516e-04 - fbeta: 1.0000 - val_loss: 0.6794 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02699: val_loss did not improve from 0.39496\n",
      "Epoch 2700/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9568e-04 - fbeta: 1.0000 - val_loss: 0.6729 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02700: val_loss did not improve from 0.39496\n",
      "Epoch 2701/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9544e-04 - fbeta: 1.0000 - val_loss: 0.6701 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02701: val_loss did not improve from 0.39496\n",
      "Epoch 2702/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9508e-04 - fbeta: 1.0000 - val_loss: 0.6735 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02702: val_loss did not improve from 0.39496\n",
      "Epoch 2703/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9464e-04 - fbeta: 1.0000 - val_loss: 0.6749 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02703: val_loss did not improve from 0.39496\n",
      "Epoch 2704/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9492e-04 - fbeta: 1.0000 - val_loss: 0.6766 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02704: val_loss did not improve from 0.39496\n",
      "Epoch 2705/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9453e-04 - fbeta: 1.0000 - val_loss: 0.6753 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02705: val_loss did not improve from 0.39496\n",
      "Epoch 2706/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9394e-04 - fbeta: 1.0000 - val_loss: 0.6753 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02706: val_loss did not improve from 0.39496\n",
      "Epoch 2707/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9420e-04 - fbeta: 1.0000 - val_loss: 0.6756 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02707: val_loss did not improve from 0.39496\n",
      "Epoch 2708/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9382e-04 - fbeta: 1.0000 - val_loss: 0.6760 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02708: val_loss did not improve from 0.39496\n",
      "Epoch 2709/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9386e-04 - fbeta: 1.0000 - val_loss: 0.6752 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02709: val_loss did not improve from 0.39496\n",
      "Epoch 2710/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9389e-04 - fbeta: 1.0000 - val_loss: 0.6749 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02710: val_loss did not improve from 0.39496\n",
      "Epoch 2711/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9382e-04 - fbeta: 1.0000 - val_loss: 0.6757 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02711: val_loss did not improve from 0.39496\n",
      "Epoch 2712/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9350e-04 - fbeta: 1.0000 - val_loss: 0.6756 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02712: val_loss did not improve from 0.39496\n",
      "Epoch 2713/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9375e-04 - fbeta: 1.0000 - val_loss: 0.6747 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02713: val_loss did not improve from 0.39496\n",
      "Epoch 2714/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9400e-04 - fbeta: 1.0000 - val_loss: 0.6786 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02714: val_loss did not improve from 0.39496\n",
      "Epoch 2715/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9380e-04 - fbeta: 1.0000 - val_loss: 0.6785 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02715: val_loss did not improve from 0.39496\n",
      "Epoch 2716/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9354e-04 - fbeta: 1.0000 - val_loss: 0.6771 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02716: val_loss did not improve from 0.39496\n",
      "Epoch 2717/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9340e-04 - fbeta: 1.0000 - val_loss: 0.6757 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02717: val_loss did not improve from 0.39496\n",
      "Epoch 2718/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9344e-04 - fbeta: 1.0000 - val_loss: 0.6764 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02718: val_loss did not improve from 0.39496\n",
      "Epoch 2719/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9290e-04 - fbeta: 1.0000 - val_loss: 0.6780 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02719: val_loss did not improve from 0.39496\n",
      "Epoch 2720/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9285e-04 - fbeta: 1.0000 - val_loss: 0.6775 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02720: val_loss did not improve from 0.39496\n",
      "Epoch 2721/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9296e-04 - fbeta: 1.0000 - val_loss: 0.6778 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02721: val_loss did not improve from 0.39496\n",
      "Epoch 2722/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9286e-04 - fbeta: 1.0000 - val_loss: 0.6784 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02722: val_loss did not improve from 0.39496\n",
      "Epoch 2723/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9294e-04 - fbeta: 1.0000 - val_loss: 0.6798 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02723: val_loss did not improve from 0.39496\n",
      "Epoch 2724/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9328e-04 - fbeta: 1.0000 - val_loss: 0.6809 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02724: val_loss did not improve from 0.39496\n",
      "Epoch 2725/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9284e-04 - fbeta: 1.0000 - val_loss: 0.6798 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02725: val_loss did not improve from 0.39496\n",
      "Epoch 2726/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9288e-04 - fbeta: 1.0000 - val_loss: 0.6786 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02726: val_loss did not improve from 0.39496\n",
      "Epoch 2727/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9234e-04 - fbeta: 1.0000 - val_loss: 0.6795 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02727: val_loss did not improve from 0.39496\n",
      "Epoch 2728/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9320e-04 - fbeta: 1.0000 - val_loss: 0.6805 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02728: val_loss did not improve from 0.39496\n",
      "Epoch 2729/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9249e-04 - fbeta: 1.0000 - val_loss: 0.6805 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02729: val_loss did not improve from 0.39496\n",
      "Epoch 2730/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9230e-04 - fbeta: 1.0000 - val_loss: 0.6800 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02730: val_loss did not improve from 0.39496\n",
      "Epoch 2731/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9214e-04 - fbeta: 1.0000 - val_loss: 0.6792 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02731: val_loss did not improve from 0.39496\n",
      "Epoch 2732/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9178e-04 - fbeta: 1.0000 - val_loss: 0.6788 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02732: val_loss did not improve from 0.39496\n",
      "Epoch 2733/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9211e-04 - fbeta: 1.0000 - val_loss: 0.6777 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02733: val_loss did not improve from 0.39496\n",
      "Epoch 2734/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9151e-04 - fbeta: 1.0000 - val_loss: 0.6774 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02734: val_loss did not improve from 0.39496\n",
      "Epoch 2735/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9192e-04 - fbeta: 1.0000 - val_loss: 0.6727 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02735: val_loss did not improve from 0.39496\n",
      "Epoch 2736/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9178e-04 - fbeta: 1.0000 - val_loss: 0.6741 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02736: val_loss did not improve from 0.39496\n",
      "Epoch 2737/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9210e-04 - fbeta: 1.0000 - val_loss: 0.6744 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02737: val_loss did not improve from 0.39496\n",
      "Epoch 2738/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9181e-04 - fbeta: 1.0000 - val_loss: 0.6756 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02738: val_loss did not improve from 0.39496\n",
      "Epoch 2739/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9189e-04 - fbeta: 1.0000 - val_loss: 0.6756 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02739: val_loss did not improve from 0.39496\n",
      "Epoch 2740/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9144e-04 - fbeta: 1.0000 - val_loss: 0.6770 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02740: val_loss did not improve from 0.39496\n",
      "Epoch 2741/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9132e-04 - fbeta: 1.0000 - val_loss: 0.6781 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02741: val_loss did not improve from 0.39496\n",
      "Epoch 2742/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9121e-04 - fbeta: 1.0000 - val_loss: 0.6783 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02742: val_loss did not improve from 0.39496\n",
      "Epoch 2743/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9133e-04 - fbeta: 1.0000 - val_loss: 0.6794 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02743: val_loss did not improve from 0.39496\n",
      "Epoch 2744/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9086e-04 - fbeta: 1.0000 - val_loss: 0.6779 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02744: val_loss did not improve from 0.39496\n",
      "Epoch 2745/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9081e-04 - fbeta: 1.0000 - val_loss: 0.6785 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02745: val_loss did not improve from 0.39496\n",
      "Epoch 2746/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9061e-04 - fbeta: 1.0000 - val_loss: 0.6769 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02746: val_loss did not improve from 0.39496\n",
      "Epoch 2747/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9057e-04 - fbeta: 1.0000 - val_loss: 0.6756 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02747: val_loss did not improve from 0.39496\n",
      "Epoch 2748/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9049e-04 - fbeta: 1.0000 - val_loss: 0.6751 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02748: val_loss did not improve from 0.39496\n",
      "Epoch 2749/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9019e-04 - fbeta: 1.0000 - val_loss: 0.6761 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02749: val_loss did not improve from 0.39496\n",
      "Epoch 2750/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9035e-04 - fbeta: 1.0000 - val_loss: 0.6760 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02750: val_loss did not improve from 0.39496\n",
      "Epoch 2751/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9054e-04 - fbeta: 1.0000 - val_loss: 0.6753 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02751: val_loss did not improve from 0.39496\n",
      "Epoch 2752/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9045e-04 - fbeta: 1.0000 - val_loss: 0.6762 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02752: val_loss did not improve from 0.39496\n",
      "Epoch 2753/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9030e-04 - fbeta: 1.0000 - val_loss: 0.6741 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02753: val_loss did not improve from 0.39496\n",
      "Epoch 2754/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9004e-04 - fbeta: 1.0000 - val_loss: 0.6758 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02754: val_loss did not improve from 0.39496\n",
      "Epoch 2755/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9018e-04 - fbeta: 1.0000 - val_loss: 0.6763 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02755: val_loss did not improve from 0.39496\n",
      "Epoch 2756/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.9001e-04 - fbeta: 1.0000 - val_loss: 0.6759 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02756: val_loss did not improve from 0.39496\n",
      "Epoch 2757/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8978e-04 - fbeta: 1.0000 - val_loss: 0.6753 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02757: val_loss did not improve from 0.39496\n",
      "Epoch 2758/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8998e-04 - fbeta: 1.0000 - val_loss: 0.6718 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02758: val_loss did not improve from 0.39496\n",
      "Epoch 2759/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8969e-04 - fbeta: 1.0000 - val_loss: 0.6745 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02759: val_loss did not improve from 0.39496\n",
      "Epoch 2760/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8996e-04 - fbeta: 1.0000 - val_loss: 0.6760 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02760: val_loss did not improve from 0.39496\n",
      "Epoch 2761/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8930e-04 - fbeta: 1.0000 - val_loss: 0.6750 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02761: val_loss did not improve from 0.39496\n",
      "Epoch 2762/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8930e-04 - fbeta: 1.0000 - val_loss: 0.6767 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02762: val_loss did not improve from 0.39496\n",
      "Epoch 2763/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8939e-04 - fbeta: 1.0000 - val_loss: 0.6768 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02763: val_loss did not improve from 0.39496\n",
      "Epoch 2764/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8953e-04 - fbeta: 1.0000 - val_loss: 0.6773 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02764: val_loss did not improve from 0.39496\n",
      "Epoch 2765/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8995e-04 - fbeta: 1.0000 - val_loss: 0.6758 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02765: val_loss did not improve from 0.39496\n",
      "Epoch 2766/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8891e-04 - fbeta: 1.0000 - val_loss: 0.6751 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02766: val_loss did not improve from 0.39496\n",
      "Epoch 2767/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8900e-04 - fbeta: 1.0000 - val_loss: 0.6763 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02767: val_loss did not improve from 0.39496\n",
      "Epoch 2768/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8895e-04 - fbeta: 1.0000 - val_loss: 0.6767 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02768: val_loss did not improve from 0.39496\n",
      "Epoch 2769/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8859e-04 - fbeta: 1.0000 - val_loss: 0.6774 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02769: val_loss did not improve from 0.39496\n",
      "Epoch 2770/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8857e-04 - fbeta: 1.0000 - val_loss: 0.6777 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02770: val_loss did not improve from 0.39496\n",
      "Epoch 2771/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8844e-04 - fbeta: 1.0000 - val_loss: 0.6777 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02771: val_loss did not improve from 0.39496\n",
      "Epoch 2772/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8840e-04 - fbeta: 1.0000 - val_loss: 0.6778 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02772: val_loss did not improve from 0.39496\n",
      "Epoch 2773/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8838e-04 - fbeta: 1.0000 - val_loss: 0.6775 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02773: val_loss did not improve from 0.39496\n",
      "Epoch 2774/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8832e-04 - fbeta: 1.0000 - val_loss: 0.6771 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02774: val_loss did not improve from 0.39496\n",
      "Epoch 2775/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8808e-04 - fbeta: 1.0000 - val_loss: 0.6771 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02775: val_loss did not improve from 0.39496\n",
      "Epoch 2776/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8812e-04 - fbeta: 1.0000 - val_loss: 0.6785 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02776: val_loss did not improve from 0.39496\n",
      "Epoch 2777/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8799e-04 - fbeta: 1.0000 - val_loss: 0.6788 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02777: val_loss did not improve from 0.39496\n",
      "Epoch 2778/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8793e-04 - fbeta: 1.0000 - val_loss: 0.6785 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02778: val_loss did not improve from 0.39496\n",
      "Epoch 2779/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8792e-04 - fbeta: 1.0000 - val_loss: 0.6776 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02779: val_loss did not improve from 0.39496\n",
      "Epoch 2780/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8804e-04 - fbeta: 1.0000 - val_loss: 0.6775 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02780: val_loss did not improve from 0.39496\n",
      "Epoch 2781/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8790e-04 - fbeta: 1.0000 - val_loss: 0.6777 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02781: val_loss did not improve from 0.39496\n",
      "Epoch 2782/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8777e-04 - fbeta: 1.0000 - val_loss: 0.6786 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02782: val_loss did not improve from 0.39496\n",
      "Epoch 2783/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8768e-04 - fbeta: 1.0000 - val_loss: 0.6797 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02783: val_loss did not improve from 0.39496\n",
      "Epoch 2784/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8744e-04 - fbeta: 1.0000 - val_loss: 0.6789 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02784: val_loss did not improve from 0.39496\n",
      "Epoch 2785/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8766e-04 - fbeta: 1.0000 - val_loss: 0.6752 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02785: val_loss did not improve from 0.39496\n",
      "Epoch 2786/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8739e-04 - fbeta: 1.0000 - val_loss: 0.6763 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02786: val_loss did not improve from 0.39496\n",
      "Epoch 2787/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8733e-04 - fbeta: 1.0000 - val_loss: 0.6772 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02787: val_loss did not improve from 0.39496\n",
      "Epoch 2788/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8733e-04 - fbeta: 1.0000 - val_loss: 0.6778 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02788: val_loss did not improve from 0.39496\n",
      "Epoch 2789/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8703e-04 - fbeta: 1.0000 - val_loss: 0.6785 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02789: val_loss did not improve from 0.39496\n",
      "Epoch 2790/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8703e-04 - fbeta: 1.0000 - val_loss: 0.6783 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02790: val_loss did not improve from 0.39496\n",
      "Epoch 2791/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8694e-04 - fbeta: 1.0000 - val_loss: 0.6803 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02791: val_loss did not improve from 0.39496\n",
      "Epoch 2792/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8705e-04 - fbeta: 1.0000 - val_loss: 0.6806 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02792: val_loss did not improve from 0.39496\n",
      "Epoch 2793/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8696e-04 - fbeta: 1.0000 - val_loss: 0.6801 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02793: val_loss did not improve from 0.39496\n",
      "Epoch 2794/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8647e-04 - fbeta: 1.0000 - val_loss: 0.6799 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02794: val_loss did not improve from 0.39496\n",
      "Epoch 2795/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8666e-04 - fbeta: 1.0000 - val_loss: 0.6798 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02795: val_loss did not improve from 0.39496\n",
      "Epoch 2796/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8666e-04 - fbeta: 1.0000 - val_loss: 0.6758 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02796: val_loss did not improve from 0.39496\n",
      "Epoch 2797/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8678e-04 - fbeta: 1.0000 - val_loss: 0.6767 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02797: val_loss did not improve from 0.39496\n",
      "Epoch 2798/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8656e-04 - fbeta: 1.0000 - val_loss: 0.6778 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02798: val_loss did not improve from 0.39496\n",
      "Epoch 2799/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8629e-04 - fbeta: 1.0000 - val_loss: 0.6767 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02799: val_loss did not improve from 0.39496\n",
      "Epoch 2800/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8663e-04 - fbeta: 1.0000 - val_loss: 0.6766 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02800: val_loss did not improve from 0.39496\n",
      "Epoch 2801/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8633e-04 - fbeta: 1.0000 - val_loss: 0.6771 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02801: val_loss did not improve from 0.39496\n",
      "Epoch 2802/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8606e-04 - fbeta: 1.0000 - val_loss: 0.6785 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02802: val_loss did not improve from 0.39496\n",
      "Epoch 2803/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8673e-04 - fbeta: 1.0000 - val_loss: 0.6820 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02803: val_loss did not improve from 0.39496\n",
      "Epoch 2804/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8630e-04 - fbeta: 1.0000 - val_loss: 0.6803 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02804: val_loss did not improve from 0.39496\n",
      "Epoch 2805/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8585e-04 - fbeta: 1.0000 - val_loss: 0.6813 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02805: val_loss did not improve from 0.39496\n",
      "Epoch 2806/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8591e-04 - fbeta: 1.0000 - val_loss: 0.6798 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02806: val_loss did not improve from 0.39496\n",
      "Epoch 2807/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8566e-04 - fbeta: 1.0000 - val_loss: 0.6793 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02807: val_loss did not improve from 0.39496\n",
      "Epoch 2808/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8571e-04 - fbeta: 1.0000 - val_loss: 0.6796 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02808: val_loss did not improve from 0.39496\n",
      "Epoch 2809/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8532e-04 - fbeta: 1.0000 - val_loss: 0.6791 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02809: val_loss did not improve from 0.39496\n",
      "Epoch 2810/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8541e-04 - fbeta: 1.0000 - val_loss: 0.6791 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02810: val_loss did not improve from 0.39496\n",
      "Epoch 2811/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8517e-04 - fbeta: 1.0000 - val_loss: 0.6799 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02811: val_loss did not improve from 0.39496\n",
      "Epoch 2812/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8504e-04 - fbeta: 1.0000 - val_loss: 0.6803 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02812: val_loss did not improve from 0.39496\n",
      "Epoch 2813/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8539e-04 - fbeta: 1.0000 - val_loss: 0.6790 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02813: val_loss did not improve from 0.39496\n",
      "Epoch 2814/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8503e-04 - fbeta: 1.0000 - val_loss: 0.6790 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02814: val_loss did not improve from 0.39496\n",
      "Epoch 2815/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8520e-04 - fbeta: 1.0000 - val_loss: 0.6801 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02815: val_loss did not improve from 0.39496\n",
      "Epoch 2816/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8477e-04 - fbeta: 1.0000 - val_loss: 0.6793 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02816: val_loss did not improve from 0.39496\n",
      "Epoch 2817/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8458e-04 - fbeta: 1.0000 - val_loss: 0.6792 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02817: val_loss did not improve from 0.39496\n",
      "Epoch 2818/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8463e-04 - fbeta: 1.0000 - val_loss: 0.6783 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02818: val_loss did not improve from 0.39496\n",
      "Epoch 2819/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8487e-04 - fbeta: 1.0000 - val_loss: 0.6788 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02819: val_loss did not improve from 0.39496\n",
      "Epoch 2820/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8502e-04 - fbeta: 1.0000 - val_loss: 0.6794 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02820: val_loss did not improve from 0.39496\n",
      "Epoch 2821/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8440e-04 - fbeta: 1.0000 - val_loss: 0.6790 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02821: val_loss did not improve from 0.39496\n",
      "Epoch 2822/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8451e-04 - fbeta: 1.0000 - val_loss: 0.6777 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02822: val_loss did not improve from 0.39496\n",
      "Epoch 2823/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8412e-04 - fbeta: 1.0000 - val_loss: 0.6788 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02823: val_loss did not improve from 0.39496\n",
      "Epoch 2824/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8457e-04 - fbeta: 1.0000 - val_loss: 0.6776 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02824: val_loss did not improve from 0.39496\n",
      "Epoch 2825/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8410e-04 - fbeta: 1.0000 - val_loss: 0.6787 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02825: val_loss did not improve from 0.39496\n",
      "Epoch 2826/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8547e-04 - fbeta: 1.0000 - val_loss: 0.6759 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02826: val_loss did not improve from 0.39496\n",
      "Epoch 2827/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8468e-04 - fbeta: 1.0000 - val_loss: 0.6769 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02827: val_loss did not improve from 0.39496\n",
      "Epoch 2828/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8378e-04 - fbeta: 1.0000 - val_loss: 0.6793 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02828: val_loss did not improve from 0.39496\n",
      "Epoch 2829/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8453e-04 - fbeta: 1.0000 - val_loss: 0.6821 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02829: val_loss did not improve from 0.39496\n",
      "Epoch 2830/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8418e-04 - fbeta: 1.0000 - val_loss: 0.6811 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02830: val_loss did not improve from 0.39496\n",
      "Epoch 2831/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8388e-04 - fbeta: 1.0000 - val_loss: 0.6803 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02831: val_loss did not improve from 0.39496\n",
      "Epoch 2832/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8373e-04 - fbeta: 1.0000 - val_loss: 0.6807 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02832: val_loss did not improve from 0.39496\n",
      "Epoch 2833/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8377e-04 - fbeta: 1.0000 - val_loss: 0.6806 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02833: val_loss did not improve from 0.39496\n",
      "Epoch 2834/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8355e-04 - fbeta: 1.0000 - val_loss: 0.6793 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02834: val_loss did not improve from 0.39496\n",
      "Epoch 2835/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8343e-04 - fbeta: 1.0000 - val_loss: 0.6799 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02835: val_loss did not improve from 0.39496\n",
      "Epoch 2836/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8345e-04 - fbeta: 1.0000 - val_loss: 0.6806 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02836: val_loss did not improve from 0.39496\n",
      "Epoch 2837/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8303e-04 - fbeta: 1.0000 - val_loss: 0.6806 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02837: val_loss did not improve from 0.39496\n",
      "Epoch 2838/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8341e-04 - fbeta: 1.0000 - val_loss: 0.6814 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02838: val_loss did not improve from 0.39496\n",
      "Epoch 2839/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8327e-04 - fbeta: 1.0000 - val_loss: 0.6809 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02839: val_loss did not improve from 0.39496\n",
      "Epoch 2840/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8298e-04 - fbeta: 1.0000 - val_loss: 0.6791 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02840: val_loss did not improve from 0.39496\n",
      "Epoch 2841/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8293e-04 - fbeta: 1.0000 - val_loss: 0.6793 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02841: val_loss did not improve from 0.39496\n",
      "Epoch 2842/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8306e-04 - fbeta: 1.0000 - val_loss: 0.6805 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02842: val_loss did not improve from 0.39496\n",
      "Epoch 2843/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8244e-04 - fbeta: 1.0000 - val_loss: 0.6805 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02843: val_loss did not improve from 0.39496\n",
      "Epoch 2844/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8277e-04 - fbeta: 1.0000 - val_loss: 0.6809 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02844: val_loss did not improve from 0.39496\n",
      "Epoch 2845/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8240e-04 - fbeta: 1.0000 - val_loss: 0.6805 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02845: val_loss did not improve from 0.39496\n",
      "Epoch 2846/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8240e-04 - fbeta: 1.0000 - val_loss: 0.6795 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02846: val_loss did not improve from 0.39496\n",
      "Epoch 2847/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8243e-04 - fbeta: 1.0000 - val_loss: 0.6810 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02847: val_loss did not improve from 0.39496\n",
      "Epoch 2848/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8294e-04 - fbeta: 1.0000 - val_loss: 0.6797 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02848: val_loss did not improve from 0.39496\n",
      "Epoch 2849/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8291e-04 - fbeta: 1.0000 - val_loss: 0.6799 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02849: val_loss did not improve from 0.39496\n",
      "Epoch 2850/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8229e-04 - fbeta: 1.0000 - val_loss: 0.6799 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02850: val_loss did not improve from 0.39496\n",
      "Epoch 2851/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8223e-04 - fbeta: 1.0000 - val_loss: 0.6790 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02851: val_loss did not improve from 0.39496\n",
      "Epoch 2852/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8209e-04 - fbeta: 1.0000 - val_loss: 0.6785 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02852: val_loss did not improve from 0.39496\n",
      "Epoch 2853/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8195e-04 - fbeta: 1.0000 - val_loss: 0.6791 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02853: val_loss did not improve from 0.39496\n",
      "Epoch 2854/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8166e-04 - fbeta: 1.0000 - val_loss: 0.6799 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02854: val_loss did not improve from 0.39496\n",
      "Epoch 2855/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8215e-04 - fbeta: 1.0000 - val_loss: 0.6816 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02855: val_loss did not improve from 0.39496\n",
      "Epoch 2856/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8204e-04 - fbeta: 1.0000 - val_loss: 0.6807 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02856: val_loss did not improve from 0.39496\n",
      "Epoch 2857/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8150e-04 - fbeta: 1.0000 - val_loss: 0.6807 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02857: val_loss did not improve from 0.39496\n",
      "Epoch 2858/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8136e-04 - fbeta: 1.0000 - val_loss: 0.6807 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02858: val_loss did not improve from 0.39496\n",
      "Epoch 2859/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8137e-04 - fbeta: 1.0000 - val_loss: 0.6806 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02859: val_loss did not improve from 0.39496\n",
      "Epoch 2860/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8142e-04 - fbeta: 1.0000 - val_loss: 0.6800 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02860: val_loss did not improve from 0.39496\n",
      "Epoch 2861/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8159e-04 - fbeta: 1.0000 - val_loss: 0.6821 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02861: val_loss did not improve from 0.39496\n",
      "Epoch 2862/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8147e-04 - fbeta: 1.0000 - val_loss: 0.6811 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02862: val_loss did not improve from 0.39496\n",
      "Epoch 2863/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8150e-04 - fbeta: 1.0000 - val_loss: 0.6809 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02863: val_loss did not improve from 0.39496\n",
      "Epoch 2864/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8141e-04 - fbeta: 1.0000 - val_loss: 0.6811 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02864: val_loss did not improve from 0.39496\n",
      "Epoch 2865/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8126e-04 - fbeta: 1.0000 - val_loss: 0.6808 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02865: val_loss did not improve from 0.39496\n",
      "Epoch 2866/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8114e-04 - fbeta: 1.0000 - val_loss: 0.6808 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02866: val_loss did not improve from 0.39496\n",
      "Epoch 2867/5000\n",
      "622/622 [==============================] - 25s 41ms/step - loss: 1.8089e-04 - fbeta: 1.0000 - val_loss: 0.6767 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02867: val_loss did not improve from 0.39496\n",
      "Epoch 2868/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8078e-04 - fbeta: 1.0000 - val_loss: 0.6774 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02868: val_loss did not improve from 0.39496\n",
      "Epoch 2869/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8095e-04 - fbeta: 1.0000 - val_loss: 0.6792 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02869: val_loss did not improve from 0.39496\n",
      "Epoch 2870/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8111e-04 - fbeta: 1.0000 - val_loss: 0.6801 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02870: val_loss did not improve from 0.39496\n",
      "Epoch 2871/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8123e-04 - fbeta: 1.0000 - val_loss: 0.6776 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02871: val_loss did not improve from 0.39496\n",
      "Epoch 2872/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8086e-04 - fbeta: 1.0000 - val_loss: 0.6788 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02872: val_loss did not improve from 0.39496\n",
      "Epoch 2873/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8065e-04 - fbeta: 1.0000 - val_loss: 0.6808 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02873: val_loss did not improve from 0.39496\n",
      "Epoch 2874/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8035e-04 - fbeta: 1.0000 - val_loss: 0.6804 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02874: val_loss did not improve from 0.39496\n",
      "Epoch 2875/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8042e-04 - fbeta: 1.0000 - val_loss: 0.6796 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02875: val_loss did not improve from 0.39496\n",
      "Epoch 2876/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8031e-04 - fbeta: 1.0000 - val_loss: 0.6787 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02876: val_loss did not improve from 0.39496\n",
      "Epoch 2877/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7979e-04 - fbeta: 1.0000 - val_loss: 0.6810 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02877: val_loss did not improve from 0.39496\n",
      "Epoch 2878/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8015e-04 - fbeta: 1.0000 - val_loss: 0.6813 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02878: val_loss did not improve from 0.39496\n",
      "Epoch 2879/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7996e-04 - fbeta: 1.0000 - val_loss: 0.6799 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02879: val_loss did not improve from 0.39496\n",
      "Epoch 2880/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.8001e-04 - fbeta: 1.0000 - val_loss: 0.6822 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02880: val_loss did not improve from 0.39496\n",
      "Epoch 2881/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7984e-04 - fbeta: 1.0000 - val_loss: 0.6806 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02881: val_loss did not improve from 0.39496\n",
      "Epoch 2882/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7963e-04 - fbeta: 1.0000 - val_loss: 0.6799 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02882: val_loss did not improve from 0.39496\n",
      "Epoch 2883/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7983e-04 - fbeta: 1.0000 - val_loss: 0.6795 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02883: val_loss did not improve from 0.39496\n",
      "Epoch 2884/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7946e-04 - fbeta: 1.0000 - val_loss: 0.6789 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02884: val_loss did not improve from 0.39496\n",
      "Epoch 2885/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7950e-04 - fbeta: 1.0000 - val_loss: 0.6795 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02885: val_loss did not improve from 0.39496\n",
      "Epoch 2886/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7959e-04 - fbeta: 1.0000 - val_loss: 0.6801 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02886: val_loss did not improve from 0.39496\n",
      "Epoch 2887/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7996e-04 - fbeta: 1.0000 - val_loss: 0.6836 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02887: val_loss did not improve from 0.39496\n",
      "Epoch 2888/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7984e-04 - fbeta: 1.0000 - val_loss: 0.6836 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02888: val_loss did not improve from 0.39496\n",
      "Epoch 2889/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7933e-04 - fbeta: 1.0000 - val_loss: 0.6827 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02889: val_loss did not improve from 0.39496\n",
      "Epoch 2890/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7971e-04 - fbeta: 1.0000 - val_loss: 0.6838 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02890: val_loss did not improve from 0.39496\n",
      "Epoch 2891/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7944e-04 - fbeta: 1.0000 - val_loss: 0.6823 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02891: val_loss did not improve from 0.39496\n",
      "Epoch 2892/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7906e-04 - fbeta: 1.0000 - val_loss: 0.6820 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02892: val_loss did not improve from 0.39496\n",
      "Epoch 2893/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7894e-04 - fbeta: 1.0000 - val_loss: 0.6817 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02893: val_loss did not improve from 0.39496\n",
      "Epoch 2894/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7916e-04 - fbeta: 1.0000 - val_loss: 0.6822 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02894: val_loss did not improve from 0.39496\n",
      "Epoch 2895/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7881e-04 - fbeta: 1.0000 - val_loss: 0.6823 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02895: val_loss did not improve from 0.39496\n",
      "Epoch 2896/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7875e-04 - fbeta: 1.0000 - val_loss: 0.6773 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02896: val_loss did not improve from 0.39496\n",
      "Epoch 2897/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7902e-04 - fbeta: 1.0000 - val_loss: 0.6773 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02897: val_loss did not improve from 0.39496\n",
      "Epoch 2898/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7863e-04 - fbeta: 1.0000 - val_loss: 0.6778 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02898: val_loss did not improve from 0.39496\n",
      "Epoch 2899/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7824e-04 - fbeta: 1.0000 - val_loss: 0.6797 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02899: val_loss did not improve from 0.39496\n",
      "Epoch 2900/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7843e-04 - fbeta: 1.0000 - val_loss: 0.6796 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02900: val_loss did not improve from 0.39496\n",
      "Epoch 2901/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7847e-04 - fbeta: 1.0000 - val_loss: 0.6812 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02901: val_loss did not improve from 0.39496\n",
      "Epoch 2902/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7814e-04 - fbeta: 1.0000 - val_loss: 0.6813 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02902: val_loss did not improve from 0.39496\n",
      "Epoch 2903/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7813e-04 - fbeta: 1.0000 - val_loss: 0.6810 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02903: val_loss did not improve from 0.39496\n",
      "Epoch 2904/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7814e-04 - fbeta: 1.0000 - val_loss: 0.6815 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02904: val_loss did not improve from 0.39496\n",
      "Epoch 2905/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7798e-04 - fbeta: 1.0000 - val_loss: 0.6800 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02905: val_loss did not improve from 0.39496\n",
      "Epoch 2906/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7786e-04 - fbeta: 1.0000 - val_loss: 0.6801 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02906: val_loss did not improve from 0.39496\n",
      "Epoch 2907/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7780e-04 - fbeta: 1.0000 - val_loss: 0.6802 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02907: val_loss did not improve from 0.39496\n",
      "Epoch 2908/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7782e-04 - fbeta: 1.0000 - val_loss: 0.6827 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02908: val_loss did not improve from 0.39496\n",
      "Epoch 2909/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7801e-04 - fbeta: 1.0000 - val_loss: 0.6830 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02909: val_loss did not improve from 0.39496\n",
      "Epoch 2910/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7774e-04 - fbeta: 1.0000 - val_loss: 0.6822 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02910: val_loss did not improve from 0.39496\n",
      "Epoch 2911/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7772e-04 - fbeta: 1.0000 - val_loss: 0.6802 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02911: val_loss did not improve from 0.39496\n",
      "Epoch 2912/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7743e-04 - fbeta: 1.0000 - val_loss: 0.6794 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02912: val_loss did not improve from 0.39496\n",
      "Epoch 2913/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7734e-04 - fbeta: 1.0000 - val_loss: 0.6798 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02913: val_loss did not improve from 0.39496\n",
      "Epoch 2914/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7729e-04 - fbeta: 1.0000 - val_loss: 0.6790 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02914: val_loss did not improve from 0.39496\n",
      "Epoch 2915/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7762e-04 - fbeta: 1.0000 - val_loss: 0.6798 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02915: val_loss did not improve from 0.39496\n",
      "Epoch 2916/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7751e-04 - fbeta: 1.0000 - val_loss: 0.6807 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02916: val_loss did not improve from 0.39496\n",
      "Epoch 2917/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7741e-04 - fbeta: 1.0000 - val_loss: 0.6813 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02917: val_loss did not improve from 0.39496\n",
      "Epoch 2918/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7781e-04 - fbeta: 1.0000 - val_loss: 0.6806 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02918: val_loss did not improve from 0.39496\n",
      "Epoch 2919/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7747e-04 - fbeta: 1.0000 - val_loss: 0.6806 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02919: val_loss did not improve from 0.39496\n",
      "Epoch 2920/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7710e-04 - fbeta: 1.0000 - val_loss: 0.6816 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02920: val_loss did not improve from 0.39496\n",
      "Epoch 2921/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7704e-04 - fbeta: 1.0000 - val_loss: 0.6813 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02921: val_loss did not improve from 0.39496\n",
      "Epoch 2922/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7721e-04 - fbeta: 1.0000 - val_loss: 0.6825 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02922: val_loss did not improve from 0.39496\n",
      "Epoch 2923/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7688e-04 - fbeta: 1.0000 - val_loss: 0.6822 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02923: val_loss did not improve from 0.39496\n",
      "Epoch 2924/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7713e-04 - fbeta: 1.0000 - val_loss: 0.6808 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02924: val_loss did not improve from 0.39496\n",
      "Epoch 2925/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7682e-04 - fbeta: 1.0000 - val_loss: 0.6814 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02925: val_loss did not improve from 0.39496\n",
      "Epoch 2926/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7655e-04 - fbeta: 1.0000 - val_loss: 0.6819 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02926: val_loss did not improve from 0.39496\n",
      "Epoch 2927/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7654e-04 - fbeta: 1.0000 - val_loss: 0.6771 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02927: val_loss did not improve from 0.39496\n",
      "Epoch 2928/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7650e-04 - fbeta: 1.0000 - val_loss: 0.6784 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02928: val_loss did not improve from 0.39496\n",
      "Epoch 2929/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7623e-04 - fbeta: 1.0000 - val_loss: 0.6807 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02929: val_loss did not improve from 0.39496\n",
      "Epoch 2930/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7618e-04 - fbeta: 1.0000 - val_loss: 0.6797 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02930: val_loss did not improve from 0.39496\n",
      "Epoch 2931/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7595e-04 - fbeta: 1.0000 - val_loss: 0.6814 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02931: val_loss did not improve from 0.39496\n",
      "Epoch 2932/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7615e-04 - fbeta: 1.0000 - val_loss: 0.6814 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02932: val_loss did not improve from 0.39496\n",
      "Epoch 2933/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7604e-04 - fbeta: 1.0000 - val_loss: 0.6819 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02933: val_loss did not improve from 0.39496\n",
      "Epoch 2934/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7614e-04 - fbeta: 1.0000 - val_loss: 0.6824 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02934: val_loss did not improve from 0.39496\n",
      "Epoch 2935/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7589e-04 - fbeta: 1.0000 - val_loss: 0.6802 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02935: val_loss did not improve from 0.39496\n",
      "Epoch 2936/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7567e-04 - fbeta: 1.0000 - val_loss: 0.6794 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02936: val_loss did not improve from 0.39496\n",
      "Epoch 2937/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7557e-04 - fbeta: 1.0000 - val_loss: 0.6803 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02937: val_loss did not improve from 0.39496\n",
      "Epoch 2938/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7605e-04 - fbeta: 1.0000 - val_loss: 0.6826 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02938: val_loss did not improve from 0.39496\n",
      "Epoch 2939/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7568e-04 - fbeta: 1.0000 - val_loss: 0.6819 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02939: val_loss did not improve from 0.39496\n",
      "Epoch 2940/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7522e-04 - fbeta: 1.0000 - val_loss: 0.6828 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02940: val_loss did not improve from 0.39496\n",
      "Epoch 2941/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7527e-04 - fbeta: 1.0000 - val_loss: 0.6834 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02941: val_loss did not improve from 0.39496\n",
      "Epoch 2942/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7535e-04 - fbeta: 1.0000 - val_loss: 0.6815 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02942: val_loss did not improve from 0.39496\n",
      "Epoch 2943/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7520e-04 - fbeta: 1.0000 - val_loss: 0.6811 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02943: val_loss did not improve from 0.39496\n",
      "Epoch 2944/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7522e-04 - fbeta: 1.0000 - val_loss: 0.6795 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02944: val_loss did not improve from 0.39496\n",
      "Epoch 2945/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7504e-04 - fbeta: 1.0000 - val_loss: 0.6810 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02945: val_loss did not improve from 0.39496\n",
      "Epoch 2946/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7479e-04 - fbeta: 1.0000 - val_loss: 0.6815 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02946: val_loss did not improve from 0.39496\n",
      "Epoch 2947/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7480e-04 - fbeta: 1.0000 - val_loss: 0.6804 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02947: val_loss did not improve from 0.39496\n",
      "Epoch 2948/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7484e-04 - fbeta: 1.0000 - val_loss: 0.6804 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02948: val_loss did not improve from 0.39496\n",
      "Epoch 2949/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7469e-04 - fbeta: 1.0000 - val_loss: 0.6806 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02949: val_loss did not improve from 0.39496\n",
      "Epoch 2950/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7470e-04 - fbeta: 1.0000 - val_loss: 0.6805 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02950: val_loss did not improve from 0.39496\n",
      "Epoch 2951/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7444e-04 - fbeta: 1.0000 - val_loss: 0.6812 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02951: val_loss did not improve from 0.39496\n",
      "Epoch 2952/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7437e-04 - fbeta: 1.0000 - val_loss: 0.6814 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02952: val_loss did not improve from 0.39496\n",
      "Epoch 2953/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7432e-04 - fbeta: 1.0000 - val_loss: 0.6820 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02953: val_loss did not improve from 0.39496\n",
      "Epoch 2954/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7429e-04 - fbeta: 1.0000 - val_loss: 0.6851 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02954: val_loss did not improve from 0.39496\n",
      "Epoch 2955/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7449e-04 - fbeta: 1.0000 - val_loss: 0.6856 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02955: val_loss did not improve from 0.39496\n",
      "Epoch 2956/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7433e-04 - fbeta: 1.0000 - val_loss: 0.6841 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02956: val_loss did not improve from 0.39496\n",
      "Epoch 2957/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7441e-04 - fbeta: 1.0000 - val_loss: 0.6821 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02957: val_loss did not improve from 0.39496\n",
      "Epoch 2958/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7408e-04 - fbeta: 1.0000 - val_loss: 0.6826 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02958: val_loss did not improve from 0.39496\n",
      "Epoch 2959/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7413e-04 - fbeta: 1.0000 - val_loss: 0.6838 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02959: val_loss did not improve from 0.39496\n",
      "Epoch 2960/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7403e-04 - fbeta: 1.0000 - val_loss: 0.6825 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02960: val_loss did not improve from 0.39496\n",
      "Epoch 2961/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7390e-04 - fbeta: 1.0000 - val_loss: 0.6842 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02961: val_loss did not improve from 0.39496\n",
      "Epoch 2962/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7388e-04 - fbeta: 1.0000 - val_loss: 0.6838 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02962: val_loss did not improve from 0.39496\n",
      "Epoch 2963/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7370e-04 - fbeta: 1.0000 - val_loss: 0.6834 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02963: val_loss did not improve from 0.39496\n",
      "Epoch 2964/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7365e-04 - fbeta: 1.0000 - val_loss: 0.6822 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02964: val_loss did not improve from 0.39496\n",
      "Epoch 2965/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7351e-04 - fbeta: 1.0000 - val_loss: 0.6832 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02965: val_loss did not improve from 0.39496\n",
      "Epoch 2966/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7345e-04 - fbeta: 1.0000 - val_loss: 0.6839 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02966: val_loss did not improve from 0.39496\n",
      "Epoch 2967/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7376e-04 - fbeta: 1.0000 - val_loss: 0.6841 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02967: val_loss did not improve from 0.39496\n",
      "Epoch 2968/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7424e-04 - fbeta: 1.0000 - val_loss: 0.6838 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02968: val_loss did not improve from 0.39496\n",
      "Epoch 2969/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7351e-04 - fbeta: 1.0000 - val_loss: 0.6882 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02969: val_loss did not improve from 0.39496\n",
      "Epoch 2970/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7355e-04 - fbeta: 1.0000 - val_loss: 0.6846 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02970: val_loss did not improve from 0.39496\n",
      "Epoch 2971/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7347e-04 - fbeta: 1.0000 - val_loss: 0.6784 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02971: val_loss did not improve from 0.39496\n",
      "Epoch 2972/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7316e-04 - fbeta: 1.0000 - val_loss: 0.6785 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02972: val_loss did not improve from 0.39496\n",
      "Epoch 2973/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7300e-04 - fbeta: 1.0000 - val_loss: 0.6810 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02973: val_loss did not improve from 0.39496\n",
      "Epoch 2974/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7290e-04 - fbeta: 1.0000 - val_loss: 0.6809 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02974: val_loss did not improve from 0.39496\n",
      "Epoch 2975/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7284e-04 - fbeta: 1.0000 - val_loss: 0.6830 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02975: val_loss did not improve from 0.39496\n",
      "Epoch 2976/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7283e-04 - fbeta: 1.0000 - val_loss: 0.6839 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02976: val_loss did not improve from 0.39496\n",
      "Epoch 2977/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7271e-04 - fbeta: 1.0000 - val_loss: 0.6836 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02977: val_loss did not improve from 0.39496\n",
      "Epoch 2978/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7285e-04 - fbeta: 1.0000 - val_loss: 0.6818 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02978: val_loss did not improve from 0.39496\n",
      "Epoch 2979/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7273e-04 - fbeta: 1.0000 - val_loss: 0.6826 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02979: val_loss did not improve from 0.39496\n",
      "Epoch 2980/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7260e-04 - fbeta: 1.0000 - val_loss: 0.6826 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02980: val_loss did not improve from 0.39496\n",
      "Epoch 2981/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7244e-04 - fbeta: 1.0000 - val_loss: 0.6829 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02981: val_loss did not improve from 0.39496\n",
      "Epoch 2982/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7255e-04 - fbeta: 1.0000 - val_loss: 0.6822 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02982: val_loss did not improve from 0.39496\n",
      "Epoch 2983/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7243e-04 - fbeta: 1.0000 - val_loss: 0.6800 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02983: val_loss did not improve from 0.39496\n",
      "Epoch 2984/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7260e-04 - fbeta: 1.0000 - val_loss: 0.6776 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02984: val_loss did not improve from 0.39496\n",
      "Epoch 2985/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7225e-04 - fbeta: 1.0000 - val_loss: 0.6815 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02985: val_loss did not improve from 0.39496\n",
      "Epoch 2986/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7209e-04 - fbeta: 1.0000 - val_loss: 0.6820 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02986: val_loss did not improve from 0.39496\n",
      "Epoch 2987/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7219e-04 - fbeta: 1.0000 - val_loss: 0.6821 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02987: val_loss did not improve from 0.39496\n",
      "Epoch 2988/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7221e-04 - fbeta: 1.0000 - val_loss: 0.6848 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02988: val_loss did not improve from 0.39496\n",
      "Epoch 2989/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7215e-04 - fbeta: 1.0000 - val_loss: 0.6846 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02989: val_loss did not improve from 0.39496\n",
      "Epoch 2990/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7188e-04 - fbeta: 1.0000 - val_loss: 0.6851 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02990: val_loss did not improve from 0.39496\n",
      "Epoch 2991/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7183e-04 - fbeta: 1.0000 - val_loss: 0.6844 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02991: val_loss did not improve from 0.39496\n",
      "Epoch 2992/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7177e-04 - fbeta: 1.0000 - val_loss: 0.6862 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02992: val_loss did not improve from 0.39496\n",
      "Epoch 2993/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7159e-04 - fbeta: 1.0000 - val_loss: 0.6857 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02993: val_loss did not improve from 0.39496\n",
      "Epoch 2994/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7148e-04 - fbeta: 1.0000 - val_loss: 0.6849 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02994: val_loss did not improve from 0.39496\n",
      "Epoch 2995/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7140e-04 - fbeta: 1.0000 - val_loss: 0.6850 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02995: val_loss did not improve from 0.39496\n",
      "Epoch 2996/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7176e-04 - fbeta: 1.0000 - val_loss: 0.6844 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02996: val_loss did not improve from 0.39496\n",
      "Epoch 2997/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7142e-04 - fbeta: 1.0000 - val_loss: 0.6846 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02997: val_loss did not improve from 0.39496\n",
      "Epoch 2998/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7128e-04 - fbeta: 1.0000 - val_loss: 0.6842 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02998: val_loss did not improve from 0.39496\n",
      "Epoch 2999/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7121e-04 - fbeta: 1.0000 - val_loss: 0.6835 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 02999: val_loss did not improve from 0.39496\n",
      "Epoch 3000/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7119e-04 - fbeta: 1.0000 - val_loss: 0.6824 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03000: val_loss did not improve from 0.39496\n",
      "Epoch 3001/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7083e-04 - fbeta: 1.0000 - val_loss: 0.6825 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03001: val_loss did not improve from 0.39496\n",
      "Epoch 3002/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7102e-04 - fbeta: 1.0000 - val_loss: 0.6835 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03002: val_loss did not improve from 0.39496\n",
      "Epoch 3003/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7095e-04 - fbeta: 1.0000 - val_loss: 0.6835 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03003: val_loss did not improve from 0.39496\n",
      "Epoch 3004/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7078e-04 - fbeta: 1.0000 - val_loss: 0.6814 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03004: val_loss did not improve from 0.39496\n",
      "Epoch 3005/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7110e-04 - fbeta: 1.0000 - val_loss: 0.6839 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03005: val_loss did not improve from 0.39496\n",
      "Epoch 3006/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7084e-04 - fbeta: 1.0000 - val_loss: 0.6836 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03006: val_loss did not improve from 0.39496\n",
      "Epoch 3007/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7069e-04 - fbeta: 1.0000 - val_loss: 0.6832 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03007: val_loss did not improve from 0.39496\n",
      "Epoch 3008/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7068e-04 - fbeta: 1.0000 - val_loss: 0.6826 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03008: val_loss did not improve from 0.39496\n",
      "Epoch 3009/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7055e-04 - fbeta: 1.0000 - val_loss: 0.6814 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03009: val_loss did not improve from 0.39496\n",
      "Epoch 3010/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7060e-04 - fbeta: 1.0000 - val_loss: 0.6829 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03010: val_loss did not improve from 0.39496\n",
      "Epoch 3011/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7038e-04 - fbeta: 1.0000 - val_loss: 0.6840 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03011: val_loss did not improve from 0.39496\n",
      "Epoch 3012/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7059e-04 - fbeta: 1.0000 - val_loss: 0.6846 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03012: val_loss did not improve from 0.39496\n",
      "Epoch 3013/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7046e-04 - fbeta: 1.0000 - val_loss: 0.6855 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03013: val_loss did not improve from 0.39496\n",
      "Epoch 3014/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7035e-04 - fbeta: 1.0000 - val_loss: 0.6833 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03014: val_loss did not improve from 0.39496\n",
      "Epoch 3015/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7011e-04 - fbeta: 1.0000 - val_loss: 0.6831 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03015: val_loss did not improve from 0.39496\n",
      "Epoch 3016/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7007e-04 - fbeta: 1.0000 - val_loss: 0.6834 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03016: val_loss did not improve from 0.39496\n",
      "Epoch 3017/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.7002e-04 - fbeta: 1.0000 - val_loss: 0.6842 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03017: val_loss did not improve from 0.39496\n",
      "Epoch 3018/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6984e-04 - fbeta: 1.0000 - val_loss: 0.6842 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03018: val_loss did not improve from 0.39496\n",
      "Epoch 3019/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6978e-04 - fbeta: 1.0000 - val_loss: 0.6844 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03019: val_loss did not improve from 0.39496\n",
      "Epoch 3020/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6986e-04 - fbeta: 1.0000 - val_loss: 0.6843 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03020: val_loss did not improve from 0.39496\n",
      "Epoch 3021/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6985e-04 - fbeta: 1.0000 - val_loss: 0.6837 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03021: val_loss did not improve from 0.39496\n",
      "Epoch 3022/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6973e-04 - fbeta: 1.0000 - val_loss: 0.6844 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03022: val_loss did not improve from 0.39496\n",
      "Epoch 3023/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6949e-04 - fbeta: 1.0000 - val_loss: 0.6836 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03023: val_loss did not improve from 0.39496\n",
      "Epoch 3024/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6976e-04 - fbeta: 1.0000 - val_loss: 0.6863 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03024: val_loss did not improve from 0.39496\n",
      "Epoch 3025/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6934e-04 - fbeta: 1.0000 - val_loss: 0.6842 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03025: val_loss did not improve from 0.39496\n",
      "Epoch 3026/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6935e-04 - fbeta: 1.0000 - val_loss: 0.6825 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03026: val_loss did not improve from 0.39496\n",
      "Epoch 3027/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6975e-04 - fbeta: 1.0000 - val_loss: 0.6855 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03027: val_loss did not improve from 0.39496\n",
      "Epoch 3028/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6947e-04 - fbeta: 1.0000 - val_loss: 0.6843 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03028: val_loss did not improve from 0.39496\n",
      "Epoch 3029/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6912e-04 - fbeta: 1.0000 - val_loss: 0.6846 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03029: val_loss did not improve from 0.39496\n",
      "Epoch 3030/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6891e-04 - fbeta: 1.0000 - val_loss: 0.6845 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03030: val_loss did not improve from 0.39496\n",
      "Epoch 3031/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6952e-04 - fbeta: 1.0000 - val_loss: 0.6839 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03031: val_loss did not improve from 0.39496\n",
      "Epoch 3032/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6939e-04 - fbeta: 1.0000 - val_loss: 0.6824 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03032: val_loss did not improve from 0.39496\n",
      "Epoch 3033/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6889e-04 - fbeta: 1.0000 - val_loss: 0.6826 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03033: val_loss did not improve from 0.39496\n",
      "Epoch 3034/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6899e-04 - fbeta: 1.0000 - val_loss: 0.6828 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03034: val_loss did not improve from 0.39496\n",
      "Epoch 3035/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6916e-04 - fbeta: 1.0000 - val_loss: 0.6801 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03035: val_loss did not improve from 0.39496\n",
      "Epoch 3036/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6877e-04 - fbeta: 1.0000 - val_loss: 0.6808 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03036: val_loss did not improve from 0.39496\n",
      "Epoch 3037/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6872e-04 - fbeta: 1.0000 - val_loss: 0.6818 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03037: val_loss did not improve from 0.39496\n",
      "Epoch 3038/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6830e-04 - fbeta: 1.0000 - val_loss: 0.6841 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03038: val_loss did not improve from 0.39496\n",
      "Epoch 3039/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6849e-04 - fbeta: 1.0000 - val_loss: 0.6851 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03039: val_loss did not improve from 0.39496\n",
      "Epoch 3040/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6848e-04 - fbeta: 1.0000 - val_loss: 0.6841 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03040: val_loss did not improve from 0.39496\n",
      "Epoch 3041/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6829e-04 - fbeta: 1.0000 - val_loss: 0.6846 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03041: val_loss did not improve from 0.39496\n",
      "Epoch 3042/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6827e-04 - fbeta: 1.0000 - val_loss: 0.6841 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03042: val_loss did not improve from 0.39496\n",
      "Epoch 3043/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6815e-04 - fbeta: 1.0000 - val_loss: 0.6837 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03043: val_loss did not improve from 0.39496\n",
      "Epoch 3044/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6823e-04 - fbeta: 1.0000 - val_loss: 0.6829 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03044: val_loss did not improve from 0.39496\n",
      "Epoch 3045/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6803e-04 - fbeta: 1.0000 - val_loss: 0.6834 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03045: val_loss did not improve from 0.39496\n",
      "Epoch 3046/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6814e-04 - fbeta: 1.0000 - val_loss: 0.6835 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03046: val_loss did not improve from 0.39496\n",
      "Epoch 3047/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6782e-04 - fbeta: 1.0000 - val_loss: 0.6846 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03047: val_loss did not improve from 0.39496\n",
      "Epoch 3048/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6814e-04 - fbeta: 1.0000 - val_loss: 0.6807 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03048: val_loss did not improve from 0.39496\n",
      "Epoch 3049/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6798e-04 - fbeta: 1.0000 - val_loss: 0.6826 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03049: val_loss did not improve from 0.39496\n",
      "Epoch 3050/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6774e-04 - fbeta: 1.0000 - val_loss: 0.6816 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03050: val_loss did not improve from 0.39496\n",
      "Epoch 3051/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6916e-04 - fbeta: 1.0000 - val_loss: 0.6807 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03051: val_loss did not improve from 0.39496\n",
      "Epoch 3052/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6795e-04 - fbeta: 1.0000 - val_loss: 0.6815 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03052: val_loss did not improve from 0.39496\n",
      "Epoch 3053/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6734e-04 - fbeta: 1.0000 - val_loss: 0.6824 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03053: val_loss did not improve from 0.39496\n",
      "Epoch 3054/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6727e-04 - fbeta: 1.0000 - val_loss: 0.6823 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03054: val_loss did not improve from 0.39496\n",
      "Epoch 3055/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6753e-04 - fbeta: 1.0000 - val_loss: 0.6832 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03055: val_loss did not improve from 0.39496\n",
      "Epoch 3056/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6728e-04 - fbeta: 1.0000 - val_loss: 0.6829 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03056: val_loss did not improve from 0.39496\n",
      "Epoch 3057/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6761e-04 - fbeta: 1.0000 - val_loss: 0.6823 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03057: val_loss did not improve from 0.39496\n",
      "Epoch 3058/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6729e-04 - fbeta: 1.0000 - val_loss: 0.6829 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03058: val_loss did not improve from 0.39496\n",
      "Epoch 3059/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6716e-04 - fbeta: 1.0000 - val_loss: 0.6850 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03059: val_loss did not improve from 0.39496\n",
      "Epoch 3060/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6730e-04 - fbeta: 1.0000 - val_loss: 0.6832 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03060: val_loss did not improve from 0.39496\n",
      "Epoch 3061/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6714e-04 - fbeta: 1.0000 - val_loss: 0.6805 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03061: val_loss did not improve from 0.39496\n",
      "Epoch 3062/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6715e-04 - fbeta: 1.0000 - val_loss: 0.6835 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03062: val_loss did not improve from 0.39496\n",
      "Epoch 3063/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6683e-04 - fbeta: 1.0000 - val_loss: 0.6836 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03063: val_loss did not improve from 0.39496\n",
      "Epoch 3064/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6663e-04 - fbeta: 1.0000 - val_loss: 0.6832 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03064: val_loss did not improve from 0.39496\n",
      "Epoch 3065/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6681e-04 - fbeta: 1.0000 - val_loss: 0.6853 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03065: val_loss did not improve from 0.39496\n",
      "Epoch 3066/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6642e-04 - fbeta: 1.0000 - val_loss: 0.6838 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03066: val_loss did not improve from 0.39496\n",
      "Epoch 3067/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6659e-04 - fbeta: 1.0000 - val_loss: 0.6847 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03067: val_loss did not improve from 0.39496\n",
      "Epoch 3068/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6645e-04 - fbeta: 1.0000 - val_loss: 0.6857 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03068: val_loss did not improve from 0.39496\n",
      "Epoch 3069/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6638e-04 - fbeta: 1.0000 - val_loss: 0.6867 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03069: val_loss did not improve from 0.39496\n",
      "Epoch 3070/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6635e-04 - fbeta: 1.0000 - val_loss: 0.6861 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03070: val_loss did not improve from 0.39496\n",
      "Epoch 3071/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6628e-04 - fbeta: 1.0000 - val_loss: 0.6857 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03071: val_loss did not improve from 0.39496\n",
      "Epoch 3072/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6610e-04 - fbeta: 1.0000 - val_loss: 0.6861 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03072: val_loss did not improve from 0.39496\n",
      "Epoch 3073/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6644e-04 - fbeta: 1.0000 - val_loss: 0.6863 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03073: val_loss did not improve from 0.39496\n",
      "Epoch 3074/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6634e-04 - fbeta: 1.0000 - val_loss: 0.6872 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03074: val_loss did not improve from 0.39496\n",
      "Epoch 3075/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6652e-04 - fbeta: 1.0000 - val_loss: 0.6844 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03075: val_loss did not improve from 0.39496\n",
      "Epoch 3076/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6591e-04 - fbeta: 1.0000 - val_loss: 0.6844 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03076: val_loss did not improve from 0.39496\n",
      "Epoch 3077/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6610e-04 - fbeta: 1.0000 - val_loss: 0.6844 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03077: val_loss did not improve from 0.39496\n",
      "Epoch 3078/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6588e-04 - fbeta: 1.0000 - val_loss: 0.6829 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03078: val_loss did not improve from 0.39496\n",
      "Epoch 3079/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6599e-04 - fbeta: 1.0000 - val_loss: 0.6852 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03079: val_loss did not improve from 0.39496\n",
      "Epoch 3080/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6601e-04 - fbeta: 1.0000 - val_loss: 0.6851 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03080: val_loss did not improve from 0.39496\n",
      "Epoch 3081/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6559e-04 - fbeta: 1.0000 - val_loss: 0.6848 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03081: val_loss did not improve from 0.39496\n",
      "Epoch 3082/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6564e-04 - fbeta: 1.0000 - val_loss: 0.6847 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03082: val_loss did not improve from 0.39496\n",
      "Epoch 3083/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6543e-04 - fbeta: 1.0000 - val_loss: 0.6854 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03083: val_loss did not improve from 0.39496\n",
      "Epoch 3084/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6570e-04 - fbeta: 1.0000 - val_loss: 0.6859 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03084: val_loss did not improve from 0.39496\n",
      "Epoch 3085/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6549e-04 - fbeta: 1.0000 - val_loss: 0.6854 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03085: val_loss did not improve from 0.39496\n",
      "Epoch 3086/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6535e-04 - fbeta: 1.0000 - val_loss: 0.6850 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03086: val_loss did not improve from 0.39496\n",
      "Epoch 3087/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6548e-04 - fbeta: 1.0000 - val_loss: 0.6842 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03087: val_loss did not improve from 0.39496\n",
      "Epoch 3088/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6564e-04 - fbeta: 1.0000 - val_loss: 0.6831 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03088: val_loss did not improve from 0.39496\n",
      "Epoch 3089/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6533e-04 - fbeta: 1.0000 - val_loss: 0.6831 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03089: val_loss did not improve from 0.39496\n",
      "Epoch 3090/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6548e-04 - fbeta: 1.0000 - val_loss: 0.6843 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03090: val_loss did not improve from 0.39496\n",
      "Epoch 3091/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6518e-04 - fbeta: 1.0000 - val_loss: 0.6864 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03091: val_loss did not improve from 0.39496\n",
      "Epoch 3092/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6517e-04 - fbeta: 1.0000 - val_loss: 0.6861 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03092: val_loss did not improve from 0.39496\n",
      "Epoch 3093/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6490e-04 - fbeta: 1.0000 - val_loss: 0.6859 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03093: val_loss did not improve from 0.39496\n",
      "Epoch 3094/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6511e-04 - fbeta: 1.0000 - val_loss: 0.6858 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03094: val_loss did not improve from 0.39496\n",
      "Epoch 3095/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6498e-04 - fbeta: 1.0000 - val_loss: 0.6854 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03095: val_loss did not improve from 0.39496\n",
      "Epoch 3096/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6503e-04 - fbeta: 1.0000 - val_loss: 0.6850 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03096: val_loss did not improve from 0.39496\n",
      "Epoch 3097/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6494e-04 - fbeta: 1.0000 - val_loss: 0.6856 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03097: val_loss did not improve from 0.39496\n",
      "Epoch 3098/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6480e-04 - fbeta: 1.0000 - val_loss: 0.6866 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03098: val_loss did not improve from 0.39496\n",
      "Epoch 3099/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6447e-04 - fbeta: 1.0000 - val_loss: 0.6864 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03099: val_loss did not improve from 0.39496\n",
      "Epoch 3100/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6449e-04 - fbeta: 1.0000 - val_loss: 0.6876 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03100: val_loss did not improve from 0.39496\n",
      "Epoch 3101/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6438e-04 - fbeta: 1.0000 - val_loss: 0.6866 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03101: val_loss did not improve from 0.39496\n",
      "Epoch 3102/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6442e-04 - fbeta: 1.0000 - val_loss: 0.6871 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03102: val_loss did not improve from 0.39496\n",
      "Epoch 3103/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6435e-04 - fbeta: 1.0000 - val_loss: 0.6878 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03103: val_loss did not improve from 0.39496\n",
      "Epoch 3104/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6524e-04 - fbeta: 1.0000 - val_loss: 0.6856 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03104: val_loss did not improve from 0.39496\n",
      "Epoch 3105/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6435e-04 - fbeta: 1.0000 - val_loss: 0.6860 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03105: val_loss did not improve from 0.39496\n",
      "Epoch 3106/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6401e-04 - fbeta: 1.0000 - val_loss: 0.6858 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03106: val_loss did not improve from 0.39496\n",
      "Epoch 3107/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6412e-04 - fbeta: 1.0000 - val_loss: 0.6848 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03107: val_loss did not improve from 0.39496\n",
      "Epoch 3108/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6388e-04 - fbeta: 1.0000 - val_loss: 0.6868 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03108: val_loss did not improve from 0.39496\n",
      "Epoch 3109/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6417e-04 - fbeta: 1.0000 - val_loss: 0.6866 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03109: val_loss did not improve from 0.39496\n",
      "Epoch 3110/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6431e-04 - fbeta: 1.0000 - val_loss: 0.6858 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03110: val_loss did not improve from 0.39496\n",
      "Epoch 3111/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6417e-04 - fbeta: 1.0000 - val_loss: 0.6823 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03111: val_loss did not improve from 0.39496\n",
      "Epoch 3112/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6392e-04 - fbeta: 1.0000 - val_loss: 0.6840 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03112: val_loss did not improve from 0.39496\n",
      "Epoch 3113/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6373e-04 - fbeta: 1.0000 - val_loss: 0.6847 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03113: val_loss did not improve from 0.39496\n",
      "Epoch 3114/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6366e-04 - fbeta: 1.0000 - val_loss: 0.6860 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03114: val_loss did not improve from 0.39496\n",
      "Epoch 3115/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6341e-04 - fbeta: 1.0000 - val_loss: 0.6857 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03115: val_loss did not improve from 0.39496\n",
      "Epoch 3116/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6363e-04 - fbeta: 1.0000 - val_loss: 0.6864 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03116: val_loss did not improve from 0.39496\n",
      "Epoch 3117/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6344e-04 - fbeta: 1.0000 - val_loss: 0.6854 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03117: val_loss did not improve from 0.39496\n",
      "Epoch 3118/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6335e-04 - fbeta: 1.0000 - val_loss: 0.6873 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03118: val_loss did not improve from 0.39496\n",
      "Epoch 3119/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6350e-04 - fbeta: 1.0000 - val_loss: 0.6855 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03119: val_loss did not improve from 0.39496\n",
      "Epoch 3120/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6347e-04 - fbeta: 1.0000 - val_loss: 0.6852 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03120: val_loss did not improve from 0.39496\n",
      "Epoch 3121/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6318e-04 - fbeta: 1.0000 - val_loss: 0.6848 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03121: val_loss did not improve from 0.39496\n",
      "Epoch 3122/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6297e-04 - fbeta: 1.0000 - val_loss: 0.6865 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03122: val_loss did not improve from 0.39496\n",
      "Epoch 3123/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6282e-04 - fbeta: 1.0000 - val_loss: 0.6863 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03123: val_loss did not improve from 0.39496\n",
      "Epoch 3124/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6284e-04 - fbeta: 1.0000 - val_loss: 0.6868 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03124: val_loss did not improve from 0.39496\n",
      "Epoch 3125/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6267e-04 - fbeta: 1.0000 - val_loss: 0.6865 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03125: val_loss did not improve from 0.39496\n",
      "Epoch 3126/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6289e-04 - fbeta: 1.0000 - val_loss: 0.6863 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03126: val_loss did not improve from 0.39496\n",
      "Epoch 3127/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6297e-04 - fbeta: 1.0000 - val_loss: 0.6873 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03127: val_loss did not improve from 0.39496\n",
      "Epoch 3128/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6306e-04 - fbeta: 1.0000 - val_loss: 0.6886 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03128: val_loss did not improve from 0.39496\n",
      "Epoch 3129/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6276e-04 - fbeta: 1.0000 - val_loss: 0.6867 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03129: val_loss did not improve from 0.39496\n",
      "Epoch 3130/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6287e-04 - fbeta: 1.0000 - val_loss: 0.6841 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03130: val_loss did not improve from 0.39496\n",
      "Epoch 3131/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6240e-04 - fbeta: 1.0000 - val_loss: 0.6863 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03131: val_loss did not improve from 0.39496\n",
      "Epoch 3132/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6237e-04 - fbeta: 1.0000 - val_loss: 0.6868 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03132: val_loss did not improve from 0.39496\n",
      "Epoch 3133/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6224e-04 - fbeta: 1.0000 - val_loss: 0.6875 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03133: val_loss did not improve from 0.39496\n",
      "Epoch 3134/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6232e-04 - fbeta: 1.0000 - val_loss: 0.6874 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03134: val_loss did not improve from 0.39496\n",
      "Epoch 3135/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6199e-04 - fbeta: 1.0000 - val_loss: 0.6864 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03135: val_loss did not improve from 0.39496\n",
      "Epoch 3136/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6221e-04 - fbeta: 1.0000 - val_loss: 0.6866 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03136: val_loss did not improve from 0.39496\n",
      "Epoch 3137/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6199e-04 - fbeta: 1.0000 - val_loss: 0.6875 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03137: val_loss did not improve from 0.39496\n",
      "Epoch 3138/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6178e-04 - fbeta: 1.0000 - val_loss: 0.6865 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03138: val_loss did not improve from 0.39496\n",
      "Epoch 3139/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6192e-04 - fbeta: 1.0000 - val_loss: 0.6876 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03139: val_loss did not improve from 0.39496\n",
      "Epoch 3140/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6180e-04 - fbeta: 1.0000 - val_loss: 0.6869 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03140: val_loss did not improve from 0.39496\n",
      "Epoch 3141/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6173e-04 - fbeta: 1.0000 - val_loss: 0.6861 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03141: val_loss did not improve from 0.39496\n",
      "Epoch 3142/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6197e-04 - fbeta: 1.0000 - val_loss: 0.6835 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03142: val_loss did not improve from 0.39496\n",
      "Epoch 3143/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6192e-04 - fbeta: 1.0000 - val_loss: 0.6852 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03143: val_loss did not improve from 0.39496\n",
      "Epoch 3144/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6178e-04 - fbeta: 1.0000 - val_loss: 0.6856 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03144: val_loss did not improve from 0.39496\n",
      "Epoch 3145/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6164e-04 - fbeta: 1.0000 - val_loss: 0.6861 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03145: val_loss did not improve from 0.39496\n",
      "Epoch 3146/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6163e-04 - fbeta: 1.0000 - val_loss: 0.6858 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03146: val_loss did not improve from 0.39496\n",
      "Epoch 3147/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6148e-04 - fbeta: 1.0000 - val_loss: 0.6847 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03147: val_loss did not improve from 0.39496\n",
      "Epoch 3148/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6153e-04 - fbeta: 1.0000 - val_loss: 0.6849 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03148: val_loss did not improve from 0.39496\n",
      "Epoch 3149/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6119e-04 - fbeta: 1.0000 - val_loss: 0.6836 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03149: val_loss did not improve from 0.39496\n",
      "Epoch 3150/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6134e-04 - fbeta: 1.0000 - val_loss: 0.6848 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03150: val_loss did not improve from 0.39496\n",
      "Epoch 3151/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6135e-04 - fbeta: 1.0000 - val_loss: 0.6837 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03151: val_loss did not improve from 0.39496\n",
      "Epoch 3152/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6135e-04 - fbeta: 1.0000 - val_loss: 0.6831 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03152: val_loss did not improve from 0.39496\n",
      "Epoch 3153/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6117e-04 - fbeta: 1.0000 - val_loss: 0.6851 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03153: val_loss did not improve from 0.39496\n",
      "Epoch 3154/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6104e-04 - fbeta: 1.0000 - val_loss: 0.6872 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03154: val_loss did not improve from 0.39496\n",
      "Epoch 3155/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6118e-04 - fbeta: 1.0000 - val_loss: 0.6880 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03155: val_loss did not improve from 0.39496\n",
      "Epoch 3156/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6093e-04 - fbeta: 1.0000 - val_loss: 0.6858 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03156: val_loss did not improve from 0.39496\n",
      "Epoch 3157/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6092e-04 - fbeta: 1.0000 - val_loss: 0.6875 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03157: val_loss did not improve from 0.39496\n",
      "Epoch 3158/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6078e-04 - fbeta: 1.0000 - val_loss: 0.6875 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03158: val_loss did not improve from 0.39496\n",
      "Epoch 3159/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6079e-04 - fbeta: 1.0000 - val_loss: 0.6881 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03159: val_loss did not improve from 0.39496\n",
      "Epoch 3160/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6069e-04 - fbeta: 1.0000 - val_loss: 0.6887 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03160: val_loss did not improve from 0.39496\n",
      "Epoch 3161/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6059e-04 - fbeta: 1.0000 - val_loss: 0.6853 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03161: val_loss did not improve from 0.39496\n",
      "Epoch 3162/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6031e-04 - fbeta: 1.0000 - val_loss: 0.6850 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03162: val_loss did not improve from 0.39496\n",
      "Epoch 3163/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6038e-04 - fbeta: 1.0000 - val_loss: 0.6872 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03163: val_loss did not improve from 0.39496\n",
      "Epoch 3164/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6041e-04 - fbeta: 1.0000 - val_loss: 0.6867 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03164: val_loss did not improve from 0.39496\n",
      "Epoch 3165/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6047e-04 - fbeta: 1.0000 - val_loss: 0.6872 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03165: val_loss did not improve from 0.39496\n",
      "Epoch 3166/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6049e-04 - fbeta: 1.0000 - val_loss: 0.6882 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03166: val_loss did not improve from 0.39496\n",
      "Epoch 3167/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6026e-04 - fbeta: 1.0000 - val_loss: 0.6875 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03167: val_loss did not improve from 0.39496\n",
      "Epoch 3168/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6004e-04 - fbeta: 1.0000 - val_loss: 0.6873 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03168: val_loss did not improve from 0.39496\n",
      "Epoch 3169/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6022e-04 - fbeta: 1.0000 - val_loss: 0.6884 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03169: val_loss did not improve from 0.39496\n",
      "Epoch 3170/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5981e-04 - fbeta: 1.0000 - val_loss: 0.6867 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03170: val_loss did not improve from 0.39496\n",
      "Epoch 3171/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5998e-04 - fbeta: 1.0000 - val_loss: 0.6875 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03171: val_loss did not improve from 0.39496\n",
      "Epoch 3172/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6002e-04 - fbeta: 1.0000 - val_loss: 0.6877 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03172: val_loss did not improve from 0.39496\n",
      "Epoch 3173/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.6006e-04 - fbeta: 1.0000 - val_loss: 0.6869 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03173: val_loss did not improve from 0.39496\n",
      "Epoch 3174/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5981e-04 - fbeta: 1.0000 - val_loss: 0.6880 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03174: val_loss did not improve from 0.39496\n",
      "Epoch 3175/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5980e-04 - fbeta: 1.0000 - val_loss: 0.6873 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03175: val_loss did not improve from 0.39496\n",
      "Epoch 3176/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5947e-04 - fbeta: 1.0000 - val_loss: 0.6866 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03176: val_loss did not improve from 0.39496\n",
      "Epoch 3177/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5966e-04 - fbeta: 1.0000 - val_loss: 0.6862 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03177: val_loss did not improve from 0.39496\n",
      "Epoch 3178/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5947e-04 - fbeta: 1.0000 - val_loss: 0.6880 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03178: val_loss did not improve from 0.39496\n",
      "Epoch 3179/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5969e-04 - fbeta: 1.0000 - val_loss: 0.6885 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03179: val_loss did not improve from 0.39496\n",
      "Epoch 3180/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5943e-04 - fbeta: 1.0000 - val_loss: 0.6889 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03180: val_loss did not improve from 0.39496\n",
      "Epoch 3181/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5940e-04 - fbeta: 1.0000 - val_loss: 0.6877 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03181: val_loss did not improve from 0.39496\n",
      "Epoch 3182/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5926e-04 - fbeta: 1.0000 - val_loss: 0.6876 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03182: val_loss did not improve from 0.39496\n",
      "Epoch 3183/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5924e-04 - fbeta: 1.0000 - val_loss: 0.6872 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03183: val_loss did not improve from 0.39496\n",
      "Epoch 3184/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5911e-04 - fbeta: 1.0000 - val_loss: 0.6874 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03184: val_loss did not improve from 0.39496\n",
      "Epoch 3185/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5927e-04 - fbeta: 1.0000 - val_loss: 0.6869 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03185: val_loss did not improve from 0.39496\n",
      "Epoch 3186/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5897e-04 - fbeta: 1.0000 - val_loss: 0.6878 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03186: val_loss did not improve from 0.39496\n",
      "Epoch 3187/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5899e-04 - fbeta: 1.0000 - val_loss: 0.6881 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03187: val_loss did not improve from 0.39496\n",
      "Epoch 3188/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5888e-04 - fbeta: 1.0000 - val_loss: 0.6871 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03188: val_loss did not improve from 0.39496\n",
      "Epoch 3189/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5912e-04 - fbeta: 1.0000 - val_loss: 0.6860 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03189: val_loss did not improve from 0.39496\n",
      "Epoch 3190/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5902e-04 - fbeta: 1.0000 - val_loss: 0.6874 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03190: val_loss did not improve from 0.39496\n",
      "Epoch 3191/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5866e-04 - fbeta: 1.0000 - val_loss: 0.6864 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03191: val_loss did not improve from 0.39496\n",
      "Epoch 3192/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5863e-04 - fbeta: 1.0000 - val_loss: 0.6866 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03192: val_loss did not improve from 0.39496\n",
      "Epoch 3193/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5857e-04 - fbeta: 1.0000 - val_loss: 0.6867 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03193: val_loss did not improve from 0.39496\n",
      "Epoch 3194/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5866e-04 - fbeta: 1.0000 - val_loss: 0.6867 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03194: val_loss did not improve from 0.39496\n",
      "Epoch 3195/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5846e-04 - fbeta: 1.0000 - val_loss: 0.6873 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03195: val_loss did not improve from 0.39496\n",
      "Epoch 3196/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5847e-04 - fbeta: 1.0000 - val_loss: 0.6890 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03196: val_loss did not improve from 0.39496\n",
      "Epoch 3197/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5843e-04 - fbeta: 1.0000 - val_loss: 0.6880 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03197: val_loss did not improve from 0.39496\n",
      "Epoch 3198/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5838e-04 - fbeta: 1.0000 - val_loss: 0.6879 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03198: val_loss did not improve from 0.39496\n",
      "Epoch 3199/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5825e-04 - fbeta: 1.0000 - val_loss: 0.6873 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03199: val_loss did not improve from 0.39496\n",
      "Epoch 3200/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5811e-04 - fbeta: 1.0000 - val_loss: 0.6880 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03200: val_loss did not improve from 0.39496\n",
      "Epoch 3201/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5825e-04 - fbeta: 1.0000 - val_loss: 0.6875 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03201: val_loss did not improve from 0.39496\n",
      "Epoch 3202/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5831e-04 - fbeta: 1.0000 - val_loss: 0.6891 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03202: val_loss did not improve from 0.39496\n",
      "Epoch 3203/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5807e-04 - fbeta: 1.0000 - val_loss: 0.6882 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03203: val_loss did not improve from 0.39496\n",
      "Epoch 3204/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5802e-04 - fbeta: 1.0000 - val_loss: 0.6889 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03204: val_loss did not improve from 0.39496\n",
      "Epoch 3205/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5794e-04 - fbeta: 1.0000 - val_loss: 0.6900 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03205: val_loss did not improve from 0.39496\n",
      "Epoch 3206/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5797e-04 - fbeta: 1.0000 - val_loss: 0.6886 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03206: val_loss did not improve from 0.39496\n",
      "Epoch 3207/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5796e-04 - fbeta: 1.0000 - val_loss: 0.6876 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03207: val_loss did not improve from 0.39496\n",
      "Epoch 3208/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5750e-04 - fbeta: 1.0000 - val_loss: 0.6878 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03208: val_loss did not improve from 0.39496\n",
      "Epoch 3209/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5771e-04 - fbeta: 1.0000 - val_loss: 0.6875 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03209: val_loss did not improve from 0.39496\n",
      "Epoch 3210/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5758e-04 - fbeta: 1.0000 - val_loss: 0.6882 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03210: val_loss did not improve from 0.39496\n",
      "Epoch 3211/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5758e-04 - fbeta: 1.0000 - val_loss: 0.6874 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03211: val_loss did not improve from 0.39496\n",
      "Epoch 3212/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5773e-04 - fbeta: 1.0000 - val_loss: 0.6863 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03212: val_loss did not improve from 0.39496\n",
      "Epoch 3213/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5755e-04 - fbeta: 1.0000 - val_loss: 0.6868 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03213: val_loss did not improve from 0.39496\n",
      "Epoch 3214/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5746e-04 - fbeta: 1.0000 - val_loss: 0.6870 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03214: val_loss did not improve from 0.39496\n",
      "Epoch 3215/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5722e-04 - fbeta: 1.0000 - val_loss: 0.6880 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03215: val_loss did not improve from 0.39496\n",
      "Epoch 3216/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5720e-04 - fbeta: 1.0000 - val_loss: 0.6886 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03216: val_loss did not improve from 0.39496\n",
      "Epoch 3217/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5731e-04 - fbeta: 1.0000 - val_loss: 0.6889 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03217: val_loss did not improve from 0.39496\n",
      "Epoch 3218/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5710e-04 - fbeta: 1.0000 - val_loss: 0.6886 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03218: val_loss did not improve from 0.39496\n",
      "Epoch 3219/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5712e-04 - fbeta: 1.0000 - val_loss: 0.6851 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03219: val_loss did not improve from 0.39496\n",
      "Epoch 3220/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5700e-04 - fbeta: 1.0000 - val_loss: 0.6870 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03220: val_loss did not improve from 0.39496\n",
      "Epoch 3221/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5706e-04 - fbeta: 1.0000 - val_loss: 0.6877 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03221: val_loss did not improve from 0.39496\n",
      "Epoch 3222/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5726e-04 - fbeta: 1.0000 - val_loss: 0.6868 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03222: val_loss did not improve from 0.39496\n",
      "Epoch 3223/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5729e-04 - fbeta: 1.0000 - val_loss: 0.6887 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03223: val_loss did not improve from 0.39496\n",
      "Epoch 3224/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5698e-04 - fbeta: 1.0000 - val_loss: 0.6877 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03224: val_loss did not improve from 0.39496\n",
      "Epoch 3225/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5685e-04 - fbeta: 1.0000 - val_loss: 0.6870 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03225: val_loss did not improve from 0.39496\n",
      "Epoch 3226/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5693e-04 - fbeta: 1.0000 - val_loss: 0.6880 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03226: val_loss did not improve from 0.39496\n",
      "Epoch 3227/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5671e-04 - fbeta: 1.0000 - val_loss: 0.6872 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03227: val_loss did not improve from 0.39496\n",
      "Epoch 3228/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5657e-04 - fbeta: 1.0000 - val_loss: 0.6872 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03228: val_loss did not improve from 0.39496\n",
      "Epoch 3229/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5664e-04 - fbeta: 1.0000 - val_loss: 0.6865 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03229: val_loss did not improve from 0.39496\n",
      "Epoch 3230/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5648e-04 - fbeta: 1.0000 - val_loss: 0.6840 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03230: val_loss did not improve from 0.39496\n",
      "Epoch 3231/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5659e-04 - fbeta: 1.0000 - val_loss: 0.6847 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03231: val_loss did not improve from 0.39496\n",
      "Epoch 3232/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5631e-04 - fbeta: 1.0000 - val_loss: 0.6857 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03232: val_loss did not improve from 0.39496\n",
      "Epoch 3233/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5625e-04 - fbeta: 1.0000 - val_loss: 0.6861 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03233: val_loss did not improve from 0.39496\n",
      "Epoch 3234/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5646e-04 - fbeta: 1.0000 - val_loss: 0.6875 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03234: val_loss did not improve from 0.39496\n",
      "Epoch 3235/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5639e-04 - fbeta: 1.0000 - val_loss: 0.6888 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03235: val_loss did not improve from 0.39496\n",
      "Epoch 3236/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5627e-04 - fbeta: 1.0000 - val_loss: 0.6897 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03236: val_loss did not improve from 0.39496\n",
      "Epoch 3237/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5642e-04 - fbeta: 1.0000 - val_loss: 0.6926 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03237: val_loss did not improve from 0.39496\n",
      "Epoch 3238/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5591e-04 - fbeta: 1.0000 - val_loss: 0.6911 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03238: val_loss did not improve from 0.39496\n",
      "Epoch 3239/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5590e-04 - fbeta: 1.0000 - val_loss: 0.6898 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03239: val_loss did not improve from 0.39496\n",
      "Epoch 3240/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5587e-04 - fbeta: 1.0000 - val_loss: 0.6884 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03240: val_loss did not improve from 0.39496\n",
      "Epoch 3241/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5579e-04 - fbeta: 1.0000 - val_loss: 0.6904 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03241: val_loss did not improve from 0.39496\n",
      "Epoch 3242/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5576e-04 - fbeta: 1.0000 - val_loss: 0.6890 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03242: val_loss did not improve from 0.39496\n",
      "Epoch 3243/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5577e-04 - fbeta: 1.0000 - val_loss: 0.6877 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03243: val_loss did not improve from 0.39496\n",
      "Epoch 3244/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5574e-04 - fbeta: 1.0000 - val_loss: 0.6876 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03244: val_loss did not improve from 0.39496\n",
      "Epoch 3245/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5555e-04 - fbeta: 1.0000 - val_loss: 0.6882 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03245: val_loss did not improve from 0.39496\n",
      "Epoch 3246/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5556e-04 - fbeta: 1.0000 - val_loss: 0.6895 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03246: val_loss did not improve from 0.39496\n",
      "Epoch 3247/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5546e-04 - fbeta: 1.0000 - val_loss: 0.6882 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03247: val_loss did not improve from 0.39496\n",
      "Epoch 3248/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5543e-04 - fbeta: 1.0000 - val_loss: 0.6856 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03248: val_loss did not improve from 0.39496\n",
      "Epoch 3249/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5533e-04 - fbeta: 1.0000 - val_loss: 0.6874 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03249: val_loss did not improve from 0.39496\n",
      "Epoch 3250/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5526e-04 - fbeta: 1.0000 - val_loss: 0.6882 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03250: val_loss did not improve from 0.39496\n",
      "Epoch 3251/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5519e-04 - fbeta: 1.0000 - val_loss: 0.6896 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03251: val_loss did not improve from 0.39496\n",
      "Epoch 3252/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5525e-04 - fbeta: 1.0000 - val_loss: 0.6889 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03252: val_loss did not improve from 0.39496\n",
      "Epoch 3253/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5514e-04 - fbeta: 1.0000 - val_loss: 0.6867 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03253: val_loss did not improve from 0.39496\n",
      "Epoch 3254/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5513e-04 - fbeta: 1.0000 - val_loss: 0.6875 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03254: val_loss did not improve from 0.39496\n",
      "Epoch 3255/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5503e-04 - fbeta: 1.0000 - val_loss: 0.6852 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03255: val_loss did not improve from 0.39496\n",
      "Epoch 3256/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5504e-04 - fbeta: 1.0000 - val_loss: 0.6865 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03256: val_loss did not improve from 0.39496\n",
      "Epoch 3257/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5471e-04 - fbeta: 1.0000 - val_loss: 0.6883 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03257: val_loss did not improve from 0.39496\n",
      "Epoch 3258/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5490e-04 - fbeta: 1.0000 - val_loss: 0.6895 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03258: val_loss did not improve from 0.39496\n",
      "Epoch 3259/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5470e-04 - fbeta: 1.0000 - val_loss: 0.6890 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03259: val_loss did not improve from 0.39496\n",
      "Epoch 3260/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5463e-04 - fbeta: 1.0000 - val_loss: 0.6890 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03260: val_loss did not improve from 0.39496\n",
      "Epoch 3261/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5499e-04 - fbeta: 1.0000 - val_loss: 0.6879 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03261: val_loss did not improve from 0.39496\n",
      "Epoch 3262/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5457e-04 - fbeta: 1.0000 - val_loss: 0.6888 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03262: val_loss did not improve from 0.39496\n",
      "Epoch 3263/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5455e-04 - fbeta: 1.0000 - val_loss: 0.6888 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03263: val_loss did not improve from 0.39496\n",
      "Epoch 3264/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5431e-04 - fbeta: 1.0000 - val_loss: 0.6878 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03264: val_loss did not improve from 0.39496\n",
      "Epoch 3265/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5443e-04 - fbeta: 1.0000 - val_loss: 0.6870 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03265: val_loss did not improve from 0.39496\n",
      "Epoch 3266/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5438e-04 - fbeta: 1.0000 - val_loss: 0.6885 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03266: val_loss did not improve from 0.39496\n",
      "Epoch 3267/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5418e-04 - fbeta: 1.0000 - val_loss: 0.6894 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03267: val_loss did not improve from 0.39496\n",
      "Epoch 3268/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5427e-04 - fbeta: 1.0000 - val_loss: 0.6891 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03268: val_loss did not improve from 0.39496\n",
      "Epoch 3269/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5412e-04 - fbeta: 1.0000 - val_loss: 0.6900 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03269: val_loss did not improve from 0.39496\n",
      "Epoch 3270/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5398e-04 - fbeta: 1.0000 - val_loss: 0.6891 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03270: val_loss did not improve from 0.39496\n",
      "Epoch 3271/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5421e-04 - fbeta: 1.0000 - val_loss: 0.6899 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03271: val_loss did not improve from 0.39496\n",
      "Epoch 3272/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5398e-04 - fbeta: 1.0000 - val_loss: 0.6896 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03272: val_loss did not improve from 0.39496\n",
      "Epoch 3273/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5392e-04 - fbeta: 1.0000 - val_loss: 0.6889 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03273: val_loss did not improve from 0.39496\n",
      "Epoch 3274/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5378e-04 - fbeta: 1.0000 - val_loss: 0.6908 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03274: val_loss did not improve from 0.39496\n",
      "Epoch 3275/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5382e-04 - fbeta: 1.0000 - val_loss: 0.6891 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03275: val_loss did not improve from 0.39496\n",
      "Epoch 3276/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5383e-04 - fbeta: 1.0000 - val_loss: 0.6878 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03276: val_loss did not improve from 0.39496\n",
      "Epoch 3277/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5403e-04 - fbeta: 1.0000 - val_loss: 0.6864 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03277: val_loss did not improve from 0.39496\n",
      "Epoch 3278/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5419e-04 - fbeta: 1.0000 - val_loss: 0.6868 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03278: val_loss did not improve from 0.39496\n",
      "Epoch 3279/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5411e-04 - fbeta: 1.0000 - val_loss: 0.6860 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03279: val_loss did not improve from 0.39496\n",
      "Epoch 3280/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5438e-04 - fbeta: 1.0000 - val_loss: 0.6851 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03280: val_loss did not improve from 0.39496\n",
      "Epoch 3281/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5406e-04 - fbeta: 1.0000 - val_loss: 0.6875 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03281: val_loss did not improve from 0.39496\n",
      "Epoch 3282/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5355e-04 - fbeta: 1.0000 - val_loss: 0.6878 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03282: val_loss did not improve from 0.39496\n",
      "Epoch 3283/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5350e-04 - fbeta: 1.0000 - val_loss: 0.6880 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03283: val_loss did not improve from 0.39496\n",
      "Epoch 3284/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5333e-04 - fbeta: 1.0000 - val_loss: 0.6875 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03284: val_loss did not improve from 0.39496\n",
      "Epoch 3285/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5308e-04 - fbeta: 1.0000 - val_loss: 0.6889 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03285: val_loss did not improve from 0.39496\n",
      "Epoch 3286/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5310e-04 - fbeta: 1.0000 - val_loss: 0.6888 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03286: val_loss did not improve from 0.39496\n",
      "Epoch 3287/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5326e-04 - fbeta: 1.0000 - val_loss: 0.6905 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03287: val_loss did not improve from 0.39496\n",
      "Epoch 3288/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5328e-04 - fbeta: 1.0000 - val_loss: 0.6907 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03288: val_loss did not improve from 0.39496\n",
      "Epoch 3289/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5293e-04 - fbeta: 1.0000 - val_loss: 0.6909 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03289: val_loss did not improve from 0.39496\n",
      "Epoch 3290/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5303e-04 - fbeta: 1.0000 - val_loss: 0.6905 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03290: val_loss did not improve from 0.39496\n",
      "Epoch 3291/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5335e-04 - fbeta: 1.0000 - val_loss: 0.6937 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03291: val_loss did not improve from 0.39496\n",
      "Epoch 3292/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5294e-04 - fbeta: 1.0000 - val_loss: 0.6922 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03292: val_loss did not improve from 0.39496\n",
      "Epoch 3293/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5287e-04 - fbeta: 1.0000 - val_loss: 0.6916 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03293: val_loss did not improve from 0.39496\n",
      "Epoch 3294/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5279e-04 - fbeta: 1.0000 - val_loss: 0.6919 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03294: val_loss did not improve from 0.39496\n",
      "Epoch 3295/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5282e-04 - fbeta: 1.0000 - val_loss: 0.6918 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03295: val_loss did not improve from 0.39496\n",
      "Epoch 3296/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5262e-04 - fbeta: 1.0000 - val_loss: 0.6906 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03296: val_loss did not improve from 0.39496\n",
      "Epoch 3297/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5253e-04 - fbeta: 1.0000 - val_loss: 0.6895 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03297: val_loss did not improve from 0.39496\n",
      "Epoch 3298/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5236e-04 - fbeta: 1.0000 - val_loss: 0.6907 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03298: val_loss did not improve from 0.39496\n",
      "Epoch 3299/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5271e-04 - fbeta: 1.0000 - val_loss: 0.6921 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03299: val_loss did not improve from 0.39496\n",
      "Epoch 3300/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5261e-04 - fbeta: 1.0000 - val_loss: 0.6912 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03300: val_loss did not improve from 0.39496\n",
      "Epoch 3301/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5240e-04 - fbeta: 1.0000 - val_loss: 0.6887 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03301: val_loss did not improve from 0.39496\n",
      "Epoch 3302/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5218e-04 - fbeta: 1.0000 - val_loss: 0.6884 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03302: val_loss did not improve from 0.39496\n",
      "Epoch 3303/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5230e-04 - fbeta: 1.0000 - val_loss: 0.6892 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03303: val_loss did not improve from 0.39496\n",
      "Epoch 3304/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5231e-04 - fbeta: 1.0000 - val_loss: 0.6909 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03304: val_loss did not improve from 0.39496\n",
      "Epoch 3305/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5232e-04 - fbeta: 1.0000 - val_loss: 0.6904 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03305: val_loss did not improve from 0.39496\n",
      "Epoch 3306/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5191e-04 - fbeta: 1.0000 - val_loss: 0.6904 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03306: val_loss did not improve from 0.39496\n",
      "Epoch 3307/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5179e-04 - fbeta: 1.0000 - val_loss: 0.6910 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03307: val_loss did not improve from 0.39496\n",
      "Epoch 3308/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5195e-04 - fbeta: 1.0000 - val_loss: 0.6911 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03308: val_loss did not improve from 0.39496\n",
      "Epoch 3309/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5200e-04 - fbeta: 1.0000 - val_loss: 0.6917 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03309: val_loss did not improve from 0.39496\n",
      "Epoch 3310/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5195e-04 - fbeta: 1.0000 - val_loss: 0.6908 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03310: val_loss did not improve from 0.39496\n",
      "Epoch 3311/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5175e-04 - fbeta: 1.0000 - val_loss: 0.6897 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03311: val_loss did not improve from 0.39496\n",
      "Epoch 3312/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5153e-04 - fbeta: 1.0000 - val_loss: 0.6884 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03312: val_loss did not improve from 0.39496\n",
      "Epoch 3313/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5168e-04 - fbeta: 1.0000 - val_loss: 0.6899 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03313: val_loss did not improve from 0.39496\n",
      "Epoch 3314/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5177e-04 - fbeta: 1.0000 - val_loss: 0.6895 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03314: val_loss did not improve from 0.39496\n",
      "Epoch 3315/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5167e-04 - fbeta: 1.0000 - val_loss: 0.6876 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03315: val_loss did not improve from 0.39496\n",
      "Epoch 3316/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5147e-04 - fbeta: 1.0000 - val_loss: 0.6903 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03316: val_loss did not improve from 0.39496\n",
      "Epoch 3317/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5150e-04 - fbeta: 1.0000 - val_loss: 0.6889 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03317: val_loss did not improve from 0.39496\n",
      "Epoch 3318/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5131e-04 - fbeta: 1.0000 - val_loss: 0.6889 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03318: val_loss did not improve from 0.39496\n",
      "Epoch 3319/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5147e-04 - fbeta: 1.0000 - val_loss: 0.6906 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03319: val_loss did not improve from 0.39496\n",
      "Epoch 3320/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5149e-04 - fbeta: 1.0000 - val_loss: 0.6902 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03320: val_loss did not improve from 0.39496\n",
      "Epoch 3321/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5145e-04 - fbeta: 1.0000 - val_loss: 0.6900 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03321: val_loss did not improve from 0.39496\n",
      "Epoch 3322/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5103e-04 - fbeta: 1.0000 - val_loss: 0.6890 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03322: val_loss did not improve from 0.39496\n",
      "Epoch 3323/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5108e-04 - fbeta: 1.0000 - val_loss: 0.6886 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03323: val_loss did not improve from 0.39496\n",
      "Epoch 3324/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5117e-04 - fbeta: 1.0000 - val_loss: 0.6899 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03324: val_loss did not improve from 0.39496\n",
      "Epoch 3325/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5104e-04 - fbeta: 1.0000 - val_loss: 0.6898 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03325: val_loss did not improve from 0.39496\n",
      "Epoch 3326/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5090e-04 - fbeta: 1.0000 - val_loss: 0.6893 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03326: val_loss did not improve from 0.39496\n",
      "Epoch 3327/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5102e-04 - fbeta: 1.0000 - val_loss: 0.6895 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03327: val_loss did not improve from 0.39496\n",
      "Epoch 3328/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5087e-04 - fbeta: 1.0000 - val_loss: 0.6899 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03328: val_loss did not improve from 0.39496\n",
      "Epoch 3329/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5079e-04 - fbeta: 1.0000 - val_loss: 0.6903 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03329: val_loss did not improve from 0.39496\n",
      "Epoch 3330/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5062e-04 - fbeta: 1.0000 - val_loss: 0.6890 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03330: val_loss did not improve from 0.39496\n",
      "Epoch 3331/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5067e-04 - fbeta: 1.0000 - val_loss: 0.6892 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03331: val_loss did not improve from 0.39496\n",
      "Epoch 3332/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5070e-04 - fbeta: 1.0000 - val_loss: 0.6900 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03332: val_loss did not improve from 0.39496\n",
      "Epoch 3333/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5048e-04 - fbeta: 1.0000 - val_loss: 0.6915 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03333: val_loss did not improve from 0.39496\n",
      "Epoch 3334/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5069e-04 - fbeta: 1.0000 - val_loss: 0.6905 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03334: val_loss did not improve from 0.39496\n",
      "Epoch 3335/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5055e-04 - fbeta: 1.0000 - val_loss: 0.6914 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03335: val_loss did not improve from 0.39496\n",
      "Epoch 3336/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5059e-04 - fbeta: 1.0000 - val_loss: 0.6953 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03336: val_loss did not improve from 0.39496\n",
      "Epoch 3337/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5065e-04 - fbeta: 1.0000 - val_loss: 0.6943 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03337: val_loss did not improve from 0.39496\n",
      "Epoch 3338/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5043e-04 - fbeta: 1.0000 - val_loss: 0.6934 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03338: val_loss did not improve from 0.39496\n",
      "Epoch 3339/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5033e-04 - fbeta: 1.0000 - val_loss: 0.6926 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03339: val_loss did not improve from 0.39496\n",
      "Epoch 3340/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5045e-04 - fbeta: 1.0000 - val_loss: 0.6924 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03340: val_loss did not improve from 0.39496\n",
      "Epoch 3341/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5012e-04 - fbeta: 1.0000 - val_loss: 0.6918 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03341: val_loss did not improve from 0.39496\n",
      "Epoch 3342/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5006e-04 - fbeta: 1.0000 - val_loss: 0.6914 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03342: val_loss did not improve from 0.39496\n",
      "Epoch 3343/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5073e-04 - fbeta: 1.0000 - val_loss: 0.6899 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03343: val_loss did not improve from 0.39496\n",
      "Epoch 3344/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5032e-04 - fbeta: 1.0000 - val_loss: 0.6918 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03344: val_loss did not improve from 0.39496\n",
      "Epoch 3345/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5027e-04 - fbeta: 1.0000 - val_loss: 0.6904 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03345: val_loss did not improve from 0.39496\n",
      "Epoch 3346/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4983e-04 - fbeta: 1.0000 - val_loss: 0.6920 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03346: val_loss did not improve from 0.39496\n",
      "Epoch 3347/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4992e-04 - fbeta: 1.0000 - val_loss: 0.6931 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03347: val_loss did not improve from 0.39496\n",
      "Epoch 3348/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4977e-04 - fbeta: 1.0000 - val_loss: 0.6928 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03348: val_loss did not improve from 0.39496\n",
      "Epoch 3349/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.5021e-04 - fbeta: 1.0000 - val_loss: 0.6940 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03349: val_loss did not improve from 0.39496\n",
      "Epoch 3350/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4974e-04 - fbeta: 1.0000 - val_loss: 0.6943 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03350: val_loss did not improve from 0.39496\n",
      "Epoch 3351/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4995e-04 - fbeta: 1.0000 - val_loss: 0.6929 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03351: val_loss did not improve from 0.39496\n",
      "Epoch 3352/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4966e-04 - fbeta: 1.0000 - val_loss: 0.6929 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03352: val_loss did not improve from 0.39496\n",
      "Epoch 3353/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4946e-04 - fbeta: 1.0000 - val_loss: 0.6927 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03353: val_loss did not improve from 0.39496\n",
      "Epoch 3354/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4944e-04 - fbeta: 1.0000 - val_loss: 0.6923 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03354: val_loss did not improve from 0.39496\n",
      "Epoch 3355/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4953e-04 - fbeta: 1.0000 - val_loss: 0.6911 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03355: val_loss did not improve from 0.39496\n",
      "Epoch 3356/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4936e-04 - fbeta: 1.0000 - val_loss: 0.6906 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03356: val_loss did not improve from 0.39496\n",
      "Epoch 3357/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4914e-04 - fbeta: 1.0000 - val_loss: 0.6905 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03357: val_loss did not improve from 0.39496\n",
      "Epoch 3358/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4927e-04 - fbeta: 1.0000 - val_loss: 0.6873 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03358: val_loss did not improve from 0.39496\n",
      "Epoch 3359/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4907e-04 - fbeta: 1.0000 - val_loss: 0.6884 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03359: val_loss did not improve from 0.39496\n",
      "Epoch 3360/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4904e-04 - fbeta: 1.0000 - val_loss: 0.6911 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03360: val_loss did not improve from 0.39496\n",
      "Epoch 3361/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4902e-04 - fbeta: 1.0000 - val_loss: 0.6909 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03361: val_loss did not improve from 0.39496\n",
      "Epoch 3362/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4898e-04 - fbeta: 1.0000 - val_loss: 0.6901 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03362: val_loss did not improve from 0.39496\n",
      "Epoch 3363/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4900e-04 - fbeta: 1.0000 - val_loss: 0.6900 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03363: val_loss did not improve from 0.39496\n",
      "Epoch 3364/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4899e-04 - fbeta: 1.0000 - val_loss: 0.6887 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03364: val_loss did not improve from 0.39496\n",
      "Epoch 3365/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4882e-04 - fbeta: 1.0000 - val_loss: 0.6887 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03365: val_loss did not improve from 0.39496\n",
      "Epoch 3366/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4875e-04 - fbeta: 1.0000 - val_loss: 0.6894 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03366: val_loss did not improve from 0.39496\n",
      "Epoch 3367/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4862e-04 - fbeta: 1.0000 - val_loss: 0.6911 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03367: val_loss did not improve from 0.39496\n",
      "Epoch 3368/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4863e-04 - fbeta: 1.0000 - val_loss: 0.6883 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03368: val_loss did not improve from 0.39496\n",
      "Epoch 3369/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4863e-04 - fbeta: 1.0000 - val_loss: 0.6903 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03369: val_loss did not improve from 0.39496\n",
      "Epoch 3370/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4858e-04 - fbeta: 1.0000 - val_loss: 0.6918 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03370: val_loss did not improve from 0.39496\n",
      "Epoch 3371/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4860e-04 - fbeta: 1.0000 - val_loss: 0.6922 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03371: val_loss did not improve from 0.39496\n",
      "Epoch 3372/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4829e-04 - fbeta: 1.0000 - val_loss: 0.6889 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03372: val_loss did not improve from 0.39496\n",
      "Epoch 3373/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4852e-04 - fbeta: 1.0000 - val_loss: 0.6896 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03373: val_loss did not improve from 0.39496\n",
      "Epoch 3374/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4839e-04 - fbeta: 1.0000 - val_loss: 0.6902 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03374: val_loss did not improve from 0.39496\n",
      "Epoch 3375/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4848e-04 - fbeta: 1.0000 - val_loss: 0.6914 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03375: val_loss did not improve from 0.39496\n",
      "Epoch 3376/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4830e-04 - fbeta: 1.0000 - val_loss: 0.6925 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03376: val_loss did not improve from 0.39496\n",
      "Epoch 3377/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4834e-04 - fbeta: 1.0000 - val_loss: 0.6903 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03377: val_loss did not improve from 0.39496\n",
      "Epoch 3378/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4807e-04 - fbeta: 1.0000 - val_loss: 0.6903 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03378: val_loss did not improve from 0.39496\n",
      "Epoch 3379/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4808e-04 - fbeta: 1.0000 - val_loss: 0.6906 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03379: val_loss did not improve from 0.39496\n",
      "Epoch 3380/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4818e-04 - fbeta: 1.0000 - val_loss: 0.6910 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03380: val_loss did not improve from 0.39496\n",
      "Epoch 3381/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4786e-04 - fbeta: 1.0000 - val_loss: 0.6903 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03381: val_loss did not improve from 0.39496\n",
      "Epoch 3382/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4813e-04 - fbeta: 1.0000 - val_loss: 0.6915 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03382: val_loss did not improve from 0.39496\n",
      "Epoch 3383/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4795e-04 - fbeta: 1.0000 - val_loss: 0.6909 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03383: val_loss did not improve from 0.39496\n",
      "Epoch 3384/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4783e-04 - fbeta: 1.0000 - val_loss: 0.6897 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03384: val_loss did not improve from 0.39496\n",
      "Epoch 3385/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4814e-04 - fbeta: 1.0000 - val_loss: 0.6912 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03385: val_loss did not improve from 0.39496\n",
      "Epoch 3386/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4803e-04 - fbeta: 1.0000 - val_loss: 0.6918 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03386: val_loss did not improve from 0.39496\n",
      "Epoch 3387/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4774e-04 - fbeta: 1.0000 - val_loss: 0.6920 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03387: val_loss did not improve from 0.39496\n",
      "Epoch 3388/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4849e-04 - fbeta: 1.0000 - val_loss: 0.6897 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03388: val_loss did not improve from 0.39496\n",
      "Epoch 3389/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4834e-04 - fbeta: 1.0000 - val_loss: 0.6903 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03389: val_loss did not improve from 0.39496\n",
      "Epoch 3390/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4769e-04 - fbeta: 1.0000 - val_loss: 0.6892 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03390: val_loss did not improve from 0.39496\n",
      "Epoch 3391/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4773e-04 - fbeta: 1.0000 - val_loss: 0.6920 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03391: val_loss did not improve from 0.39496\n",
      "Epoch 3392/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4728e-04 - fbeta: 1.0000 - val_loss: 0.6922 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03392: val_loss did not improve from 0.39496\n",
      "Epoch 3393/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4731e-04 - fbeta: 1.0000 - val_loss: 0.6923 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03393: val_loss did not improve from 0.39496\n",
      "Epoch 3394/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4723e-04 - fbeta: 1.0000 - val_loss: 0.6917 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03394: val_loss did not improve from 0.39496\n",
      "Epoch 3395/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4719e-04 - fbeta: 1.0000 - val_loss: 0.6917 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03395: val_loss did not improve from 0.39496\n",
      "Epoch 3396/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4720e-04 - fbeta: 1.0000 - val_loss: 0.6916 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03396: val_loss did not improve from 0.39496\n",
      "Epoch 3397/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4718e-04 - fbeta: 1.0000 - val_loss: 0.6914 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03397: val_loss did not improve from 0.39496\n",
      "Epoch 3398/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4695e-04 - fbeta: 1.0000 - val_loss: 0.6916 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03398: val_loss did not improve from 0.39496\n",
      "Epoch 3399/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4702e-04 - fbeta: 1.0000 - val_loss: 0.6909 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03399: val_loss did not improve from 0.39496\n",
      "Epoch 3400/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4691e-04 - fbeta: 1.0000 - val_loss: 0.6924 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03400: val_loss did not improve from 0.39496\n",
      "Epoch 3401/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4683e-04 - fbeta: 1.0000 - val_loss: 0.6920 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03401: val_loss did not improve from 0.39496\n",
      "Epoch 3402/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4688e-04 - fbeta: 1.0000 - val_loss: 0.6913 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03402: val_loss did not improve from 0.39496\n",
      "Epoch 3403/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4707e-04 - fbeta: 1.0000 - val_loss: 0.6912 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03403: val_loss did not improve from 0.39496\n",
      "Epoch 3404/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4693e-04 - fbeta: 1.0000 - val_loss: 0.6925 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03404: val_loss did not improve from 0.39496\n",
      "Epoch 3405/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4701e-04 - fbeta: 1.0000 - val_loss: 0.6958 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03405: val_loss did not improve from 0.39496\n",
      "Epoch 3406/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4694e-04 - fbeta: 1.0000 - val_loss: 0.6936 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03406: val_loss did not improve from 0.39496\n",
      "Epoch 3407/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4645e-04 - fbeta: 1.0000 - val_loss: 0.6934 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03407: val_loss did not improve from 0.39496\n",
      "Epoch 3408/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4705e-04 - fbeta: 1.0000 - val_loss: 0.6943 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03408: val_loss did not improve from 0.39496\n",
      "Epoch 3409/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4651e-04 - fbeta: 1.0000 - val_loss: 0.6941 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03409: val_loss did not improve from 0.39496\n",
      "Epoch 3410/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4679e-04 - fbeta: 1.0000 - val_loss: 0.6949 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03410: val_loss did not improve from 0.39496\n",
      "Epoch 3411/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4643e-04 - fbeta: 1.0000 - val_loss: 0.6936 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03411: val_loss did not improve from 0.39496\n",
      "Epoch 3412/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4660e-04 - fbeta: 1.0000 - val_loss: 0.6921 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03412: val_loss did not improve from 0.39496\n",
      "Epoch 3413/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4641e-04 - fbeta: 1.0000 - val_loss: 0.6915 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03413: val_loss did not improve from 0.39496\n",
      "Epoch 3414/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4614e-04 - fbeta: 1.0000 - val_loss: 0.6911 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03414: val_loss did not improve from 0.39496\n",
      "Epoch 3415/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4640e-04 - fbeta: 1.0000 - val_loss: 0.6924 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03415: val_loss did not improve from 0.39496\n",
      "Epoch 3416/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4666e-04 - fbeta: 1.0000 - val_loss: 0.6918 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03416: val_loss did not improve from 0.39496\n",
      "Epoch 3417/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4628e-04 - fbeta: 1.0000 - val_loss: 0.6926 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03417: val_loss did not improve from 0.39496\n",
      "Epoch 3418/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4597e-04 - fbeta: 1.0000 - val_loss: 0.6919 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03418: val_loss did not improve from 0.39496\n",
      "Epoch 3419/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4621e-04 - fbeta: 1.0000 - val_loss: 0.6917 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03419: val_loss did not improve from 0.39496\n",
      "Epoch 3420/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4609e-04 - fbeta: 1.0000 - val_loss: 0.6917 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03420: val_loss did not improve from 0.39496\n",
      "Epoch 3421/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4575e-04 - fbeta: 1.0000 - val_loss: 0.6916 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03421: val_loss did not improve from 0.39496\n",
      "Epoch 3422/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4594e-04 - fbeta: 1.0000 - val_loss: 0.6935 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03422: val_loss did not improve from 0.39496\n",
      "Epoch 3423/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4566e-04 - fbeta: 1.0000 - val_loss: 0.6929 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03423: val_loss did not improve from 0.39496\n",
      "Epoch 3424/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4566e-04 - fbeta: 1.0000 - val_loss: 0.6932 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03424: val_loss did not improve from 0.39496\n",
      "Epoch 3425/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4564e-04 - fbeta: 1.0000 - val_loss: 0.6946 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03425: val_loss did not improve from 0.39496\n",
      "Epoch 3426/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4574e-04 - fbeta: 1.0000 - val_loss: 0.6938 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03426: val_loss did not improve from 0.39496\n",
      "Epoch 3427/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4573e-04 - fbeta: 1.0000 - val_loss: 0.6933 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03427: val_loss did not improve from 0.39496\n",
      "Epoch 3428/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4553e-04 - fbeta: 1.0000 - val_loss: 0.6934 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03428: val_loss did not improve from 0.39496\n",
      "Epoch 3429/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4555e-04 - fbeta: 1.0000 - val_loss: 0.6932 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03429: val_loss did not improve from 0.39496\n",
      "Epoch 3430/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4557e-04 - fbeta: 1.0000 - val_loss: 0.6937 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03430: val_loss did not improve from 0.39496\n",
      "Epoch 3431/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4541e-04 - fbeta: 1.0000 - val_loss: 0.6925 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03431: val_loss did not improve from 0.39496\n",
      "Epoch 3432/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4548e-04 - fbeta: 1.0000 - val_loss: 0.6939 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03432: val_loss did not improve from 0.39496\n",
      "Epoch 3433/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4510e-04 - fbeta: 1.0000 - val_loss: 0.6931 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03433: val_loss did not improve from 0.39496\n",
      "Epoch 3434/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4517e-04 - fbeta: 1.0000 - val_loss: 0.6933 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03434: val_loss did not improve from 0.39496\n",
      "Epoch 3435/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4516e-04 - fbeta: 1.0000 - val_loss: 0.6939 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03435: val_loss did not improve from 0.39496\n",
      "Epoch 3436/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4517e-04 - fbeta: 1.0000 - val_loss: 0.6922 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03436: val_loss did not improve from 0.39496\n",
      "Epoch 3437/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4528e-04 - fbeta: 1.0000 - val_loss: 0.6915 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03437: val_loss did not improve from 0.39496\n",
      "Epoch 3438/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4505e-04 - fbeta: 1.0000 - val_loss: 0.6919 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03438: val_loss did not improve from 0.39496\n",
      "Epoch 3439/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4515e-04 - fbeta: 1.0000 - val_loss: 0.6912 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03439: val_loss did not improve from 0.39496\n",
      "Epoch 3440/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4515e-04 - fbeta: 1.0000 - val_loss: 0.6929 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03440: val_loss did not improve from 0.39496\n",
      "Epoch 3441/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4490e-04 - fbeta: 1.0000 - val_loss: 0.6940 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03441: val_loss did not improve from 0.39496\n",
      "Epoch 3442/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4475e-04 - fbeta: 1.0000 - val_loss: 0.6940 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03442: val_loss did not improve from 0.39496\n",
      "Epoch 3443/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4520e-04 - fbeta: 1.0000 - val_loss: 0.6940 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03443: val_loss did not improve from 0.39496\n",
      "Epoch 3444/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4480e-04 - fbeta: 1.0000 - val_loss: 0.6928 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03444: val_loss did not improve from 0.39496\n",
      "Epoch 3445/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4504e-04 - fbeta: 1.0000 - val_loss: 0.6899 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03445: val_loss did not improve from 0.39496\n",
      "Epoch 3446/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4494e-04 - fbeta: 1.0000 - val_loss: 0.6912 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03446: val_loss did not improve from 0.39496\n",
      "Epoch 3447/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4480e-04 - fbeta: 1.0000 - val_loss: 0.6925 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03447: val_loss did not improve from 0.39496\n",
      "Epoch 3448/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4448e-04 - fbeta: 1.0000 - val_loss: 0.6934 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03448: val_loss did not improve from 0.39496\n",
      "Epoch 3449/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4448e-04 - fbeta: 1.0000 - val_loss: 0.6936 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03449: val_loss did not improve from 0.39496\n",
      "Epoch 3450/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4427e-04 - fbeta: 1.0000 - val_loss: 0.6939 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03450: val_loss did not improve from 0.39496\n",
      "Epoch 3451/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4439e-04 - fbeta: 1.0000 - val_loss: 0.6928 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03451: val_loss did not improve from 0.39496\n",
      "Epoch 3452/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4439e-04 - fbeta: 1.0000 - val_loss: 0.6935 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03452: val_loss did not improve from 0.39496\n",
      "Epoch 3453/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4411e-04 - fbeta: 1.0000 - val_loss: 0.6923 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03453: val_loss did not improve from 0.39496\n",
      "Epoch 3454/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4419e-04 - fbeta: 1.0000 - val_loss: 0.6940 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03454: val_loss did not improve from 0.39496\n",
      "Epoch 3455/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4430e-04 - fbeta: 1.0000 - val_loss: 0.6940 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03455: val_loss did not improve from 0.39496\n",
      "Epoch 3456/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4412e-04 - fbeta: 1.0000 - val_loss: 0.6932 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03456: val_loss did not improve from 0.39496\n",
      "Epoch 3457/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4392e-04 - fbeta: 1.0000 - val_loss: 0.6943 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03457: val_loss did not improve from 0.39496\n",
      "Epoch 3458/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4385e-04 - fbeta: 1.0000 - val_loss: 0.6930 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03458: val_loss did not improve from 0.39496\n",
      "Epoch 3459/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4396e-04 - fbeta: 1.0000 - val_loss: 0.6894 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03459: val_loss did not improve from 0.39496\n",
      "Epoch 3460/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4391e-04 - fbeta: 1.0000 - val_loss: 0.6910 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03460: val_loss did not improve from 0.39496\n",
      "Epoch 3461/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4389e-04 - fbeta: 1.0000 - val_loss: 0.6917 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03461: val_loss did not improve from 0.39496\n",
      "Epoch 3462/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4379e-04 - fbeta: 1.0000 - val_loss: 0.6925 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03462: val_loss did not improve from 0.39496\n",
      "Epoch 3463/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4382e-04 - fbeta: 1.0000 - val_loss: 0.6935 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03463: val_loss did not improve from 0.39496\n",
      "Epoch 3464/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4391e-04 - fbeta: 1.0000 - val_loss: 0.6920 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03464: val_loss did not improve from 0.39496\n",
      "Epoch 3465/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4361e-04 - fbeta: 1.0000 - val_loss: 0.6927 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03465: val_loss did not improve from 0.39496\n",
      "Epoch 3466/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4370e-04 - fbeta: 1.0000 - val_loss: 0.6907 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03466: val_loss did not improve from 0.39496\n",
      "Epoch 3467/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4380e-04 - fbeta: 1.0000 - val_loss: 0.6920 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03467: val_loss did not improve from 0.39496\n",
      "Epoch 3468/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4355e-04 - fbeta: 1.0000 - val_loss: 0.6918 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03468: val_loss did not improve from 0.39496\n",
      "Epoch 3469/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4350e-04 - fbeta: 1.0000 - val_loss: 0.6927 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03469: val_loss did not improve from 0.39496\n",
      "Epoch 3470/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4350e-04 - fbeta: 1.0000 - val_loss: 0.6942 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03470: val_loss did not improve from 0.39496\n",
      "Epoch 3471/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4344e-04 - fbeta: 1.0000 - val_loss: 0.6936 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03471: val_loss did not improve from 0.39496\n",
      "Epoch 3472/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4332e-04 - fbeta: 1.0000 - val_loss: 0.6912 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03472: val_loss did not improve from 0.39496\n",
      "Epoch 3473/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4323e-04 - fbeta: 1.0000 - val_loss: 0.6925 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03473: val_loss did not improve from 0.39496\n",
      "Epoch 3474/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4309e-04 - fbeta: 1.0000 - val_loss: 0.6934 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03474: val_loss did not improve from 0.39496\n",
      "Epoch 3475/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4330e-04 - fbeta: 1.0000 - val_loss: 0.6919 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03475: val_loss did not improve from 0.39496\n",
      "Epoch 3476/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4315e-04 - fbeta: 1.0000 - val_loss: 0.6927 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03476: val_loss did not improve from 0.39496\n",
      "Epoch 3477/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4315e-04 - fbeta: 1.0000 - val_loss: 0.6924 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03477: val_loss did not improve from 0.39496\n",
      "Epoch 3478/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4347e-04 - fbeta: 1.0000 - val_loss: 0.6936 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03478: val_loss did not improve from 0.39496\n",
      "Epoch 3479/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4305e-04 - fbeta: 1.0000 - val_loss: 0.6934 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03479: val_loss did not improve from 0.39496\n",
      "Epoch 3480/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4323e-04 - fbeta: 1.0000 - val_loss: 0.6927 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03480: val_loss did not improve from 0.39496\n",
      "Epoch 3481/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4276e-04 - fbeta: 1.0000 - val_loss: 0.6939 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03481: val_loss did not improve from 0.39496\n",
      "Epoch 3482/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4279e-04 - fbeta: 1.0000 - val_loss: 0.6930 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03482: val_loss did not improve from 0.39496\n",
      "Epoch 3483/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4262e-04 - fbeta: 1.0000 - val_loss: 0.6933 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03483: val_loss did not improve from 0.39496\n",
      "Epoch 3484/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4274e-04 - fbeta: 1.0000 - val_loss: 0.6931 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03484: val_loss did not improve from 0.39496\n",
      "Epoch 3485/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4268e-04 - fbeta: 1.0000 - val_loss: 0.6953 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03485: val_loss did not improve from 0.39496\n",
      "Epoch 3486/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4256e-04 - fbeta: 1.0000 - val_loss: 0.6982 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03486: val_loss did not improve from 0.39496\n",
      "Epoch 3487/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4287e-04 - fbeta: 1.0000 - val_loss: 0.6979 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03487: val_loss did not improve from 0.39496\n",
      "Epoch 3488/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4279e-04 - fbeta: 1.0000 - val_loss: 0.6975 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03488: val_loss did not improve from 0.39496\n",
      "Epoch 3489/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4249e-04 - fbeta: 1.0000 - val_loss: 0.6965 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03489: val_loss did not improve from 0.39496\n",
      "Epoch 3490/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4258e-04 - fbeta: 1.0000 - val_loss: 0.6959 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03490: val_loss did not improve from 0.39496\n",
      "Epoch 3491/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4239e-04 - fbeta: 1.0000 - val_loss: 0.6962 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03491: val_loss did not improve from 0.39496\n",
      "Epoch 3492/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4240e-04 - fbeta: 1.0000 - val_loss: 0.6971 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03492: val_loss did not improve from 0.39496\n",
      "Epoch 3493/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4232e-04 - fbeta: 1.0000 - val_loss: 0.6969 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03493: val_loss did not improve from 0.39496\n",
      "Epoch 3494/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4225e-04 - fbeta: 1.0000 - val_loss: 0.6970 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03494: val_loss did not improve from 0.39496\n",
      "Epoch 3495/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4227e-04 - fbeta: 1.0000 - val_loss: 0.6937 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03495: val_loss did not improve from 0.39496\n",
      "Epoch 3496/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4244e-04 - fbeta: 1.0000 - val_loss: 0.6923 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03496: val_loss did not improve from 0.39496\n",
      "Epoch 3497/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4226e-04 - fbeta: 1.0000 - val_loss: 0.6928 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03497: val_loss did not improve from 0.39496\n",
      "Epoch 3498/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4218e-04 - fbeta: 1.0000 - val_loss: 0.6941 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03498: val_loss did not improve from 0.39496\n",
      "Epoch 3499/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4203e-04 - fbeta: 1.0000 - val_loss: 0.6927 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03499: val_loss did not improve from 0.39496\n",
      "Epoch 3500/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4218e-04 - fbeta: 1.0000 - val_loss: 0.6929 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03500: val_loss did not improve from 0.39496\n",
      "Epoch 3501/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4201e-04 - fbeta: 1.0000 - val_loss: 0.6922 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03501: val_loss did not improve from 0.39496\n",
      "Epoch 3502/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4181e-04 - fbeta: 1.0000 - val_loss: 0.6923 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03502: val_loss did not improve from 0.39496\n",
      "Epoch 3503/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4166e-04 - fbeta: 1.0000 - val_loss: 0.6933 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03503: val_loss did not improve from 0.39496\n",
      "Epoch 3504/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4174e-04 - fbeta: 1.0000 - val_loss: 0.6940 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03504: val_loss did not improve from 0.39496\n",
      "Epoch 3505/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4164e-04 - fbeta: 1.0000 - val_loss: 0.6946 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03505: val_loss did not improve from 0.39496\n",
      "Epoch 3506/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4157e-04 - fbeta: 1.0000 - val_loss: 0.6941 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03506: val_loss did not improve from 0.39496\n",
      "Epoch 3507/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4166e-04 - fbeta: 1.0000 - val_loss: 0.6945 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03507: val_loss did not improve from 0.39496\n",
      "Epoch 3508/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4172e-04 - fbeta: 1.0000 - val_loss: 0.6950 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03508: val_loss did not improve from 0.39496\n",
      "Epoch 3509/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4156e-04 - fbeta: 1.0000 - val_loss: 0.6945 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03509: val_loss did not improve from 0.39496\n",
      "Epoch 3510/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4134e-04 - fbeta: 1.0000 - val_loss: 0.6936 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03510: val_loss did not improve from 0.39496\n",
      "Epoch 3511/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4175e-04 - fbeta: 1.0000 - val_loss: 0.6915 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03511: val_loss did not improve from 0.39496\n",
      "Epoch 3512/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4154e-04 - fbeta: 1.0000 - val_loss: 0.6915 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03512: val_loss did not improve from 0.39496\n",
      "Epoch 3513/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4136e-04 - fbeta: 1.0000 - val_loss: 0.6936 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03513: val_loss did not improve from 0.39496\n",
      "Epoch 3514/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4153e-04 - fbeta: 1.0000 - val_loss: 0.6937 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03514: val_loss did not improve from 0.39496\n",
      "Epoch 3515/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4132e-04 - fbeta: 1.0000 - val_loss: 0.6948 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03515: val_loss did not improve from 0.39496\n",
      "Epoch 3516/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4137e-04 - fbeta: 1.0000 - val_loss: 0.6946 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03516: val_loss did not improve from 0.39496\n",
      "Epoch 3517/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4105e-04 - fbeta: 1.0000 - val_loss: 0.6947 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03517: val_loss did not improve from 0.39496\n",
      "Epoch 3518/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4099e-04 - fbeta: 1.0000 - val_loss: 0.6936 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03518: val_loss did not improve from 0.39496\n",
      "Epoch 3519/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4089e-04 - fbeta: 1.0000 - val_loss: 0.6942 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03519: val_loss did not improve from 0.39496\n",
      "Epoch 3520/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4082e-04 - fbeta: 1.0000 - val_loss: 0.6941 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03520: val_loss did not improve from 0.39496\n",
      "Epoch 3521/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4123e-04 - fbeta: 1.0000 - val_loss: 0.6949 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03521: val_loss did not improve from 0.39496\n",
      "Epoch 3522/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4086e-04 - fbeta: 1.0000 - val_loss: 0.6952 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03522: val_loss did not improve from 0.39496\n",
      "Epoch 3523/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4075e-04 - fbeta: 1.0000 - val_loss: 0.6968 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03523: val_loss did not improve from 0.39496\n",
      "Epoch 3524/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4073e-04 - fbeta: 1.0000 - val_loss: 0.6967 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03524: val_loss did not improve from 0.39496\n",
      "Epoch 3525/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4097e-04 - fbeta: 1.0000 - val_loss: 0.6944 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03525: val_loss did not improve from 0.39496\n",
      "Epoch 3526/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4066e-04 - fbeta: 1.0000 - val_loss: 0.6950 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03526: val_loss did not improve from 0.39496\n",
      "Epoch 3527/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4070e-04 - fbeta: 1.0000 - val_loss: 0.6946 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03527: val_loss did not improve from 0.39496\n",
      "Epoch 3528/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4050e-04 - fbeta: 1.0000 - val_loss: 0.6942 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03528: val_loss did not improve from 0.39496\n",
      "Epoch 3529/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4060e-04 - fbeta: 1.0000 - val_loss: 0.6949 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03529: val_loss did not improve from 0.39496\n",
      "Epoch 3530/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4043e-04 - fbeta: 1.0000 - val_loss: 0.6922 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03530: val_loss did not improve from 0.39496\n",
      "Epoch 3531/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4040e-04 - fbeta: 1.0000 - val_loss: 0.6951 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03531: val_loss did not improve from 0.39496\n",
      "Epoch 3532/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4038e-04 - fbeta: 1.0000 - val_loss: 0.6953 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03532: val_loss did not improve from 0.39496\n",
      "Epoch 3533/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4029e-04 - fbeta: 1.0000 - val_loss: 0.6951 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03533: val_loss did not improve from 0.39496\n",
      "Epoch 3534/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4032e-04 - fbeta: 1.0000 - val_loss: 0.6952 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03534: val_loss did not improve from 0.39496\n",
      "Epoch 3535/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4028e-04 - fbeta: 1.0000 - val_loss: 0.6949 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03535: val_loss did not improve from 0.39496\n",
      "Epoch 3536/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3992e-04 - fbeta: 1.0000 - val_loss: 0.6943 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03536: val_loss did not improve from 0.39496\n",
      "Epoch 3537/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4009e-04 - fbeta: 1.0000 - val_loss: 0.6956 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03537: val_loss did not improve from 0.39496\n",
      "Epoch 3538/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4007e-04 - fbeta: 1.0000 - val_loss: 0.6945 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03538: val_loss did not improve from 0.39496\n",
      "Epoch 3539/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4000e-04 - fbeta: 1.0000 - val_loss: 0.6952 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03539: val_loss did not improve from 0.39496\n",
      "Epoch 3540/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.4008e-04 - fbeta: 1.0000 - val_loss: 0.6944 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03540: val_loss did not improve from 0.39496\n",
      "Epoch 3541/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3986e-04 - fbeta: 1.0000 - val_loss: 0.6946 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03541: val_loss did not improve from 0.39496\n",
      "Epoch 3542/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3987e-04 - fbeta: 1.0000 - val_loss: 0.6949 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03542: val_loss did not improve from 0.39496\n",
      "Epoch 3543/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3984e-04 - fbeta: 1.0000 - val_loss: 0.6957 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03543: val_loss did not improve from 0.39496\n",
      "Epoch 3544/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3967e-04 - fbeta: 1.0000 - val_loss: 0.6946 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03544: val_loss did not improve from 0.39496\n",
      "Epoch 3545/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3985e-04 - fbeta: 1.0000 - val_loss: 0.6943 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03545: val_loss did not improve from 0.39496\n",
      "Epoch 3546/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3992e-04 - fbeta: 1.0000 - val_loss: 0.6953 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03546: val_loss did not improve from 0.39496\n",
      "Epoch 3547/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3987e-04 - fbeta: 1.0000 - val_loss: 0.6956 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03547: val_loss did not improve from 0.39496\n",
      "Epoch 3548/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3974e-04 - fbeta: 1.0000 - val_loss: 0.6949 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03548: val_loss did not improve from 0.39496\n",
      "Epoch 3549/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3959e-04 - fbeta: 1.0000 - val_loss: 0.6948 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03549: val_loss did not improve from 0.39496\n",
      "Epoch 3550/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3951e-04 - fbeta: 1.0000 - val_loss: 0.6942 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03550: val_loss did not improve from 0.39496\n",
      "Epoch 3551/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3940e-04 - fbeta: 1.0000 - val_loss: 0.6940 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03551: val_loss did not improve from 0.39496\n",
      "Epoch 3552/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3955e-04 - fbeta: 1.0000 - val_loss: 0.6896 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03552: val_loss did not improve from 0.39496\n",
      "Epoch 3553/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3950e-04 - fbeta: 1.0000 - val_loss: 0.6917 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03553: val_loss did not improve from 0.39496\n",
      "Epoch 3554/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3929e-04 - fbeta: 1.0000 - val_loss: 0.6933 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03554: val_loss did not improve from 0.39496\n",
      "Epoch 3555/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3914e-04 - fbeta: 1.0000 - val_loss: 0.6932 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03555: val_loss did not improve from 0.39496\n",
      "Epoch 3556/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3912e-04 - fbeta: 1.0000 - val_loss: 0.6939 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03556: val_loss did not improve from 0.39496\n",
      "Epoch 3557/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3913e-04 - fbeta: 1.0000 - val_loss: 0.6949 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03557: val_loss did not improve from 0.39496\n",
      "Epoch 3558/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3909e-04 - fbeta: 1.0000 - val_loss: 0.6953 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03558: val_loss did not improve from 0.39496\n",
      "Epoch 3559/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3903e-04 - fbeta: 1.0000 - val_loss: 0.6953 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03559: val_loss did not improve from 0.39496\n",
      "Epoch 3560/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3910e-04 - fbeta: 1.0000 - val_loss: 0.6963 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03560: val_loss did not improve from 0.39496\n",
      "Epoch 3561/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3892e-04 - fbeta: 1.0000 - val_loss: 0.6955 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03561: val_loss did not improve from 0.39496\n",
      "Epoch 3562/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3885e-04 - fbeta: 1.0000 - val_loss: 0.6945 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03562: val_loss did not improve from 0.39496\n",
      "Epoch 3563/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3900e-04 - fbeta: 1.0000 - val_loss: 0.6947 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03563: val_loss did not improve from 0.39496\n",
      "Epoch 3564/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3875e-04 - fbeta: 1.0000 - val_loss: 0.6942 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03564: val_loss did not improve from 0.39496\n",
      "Epoch 3565/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3878e-04 - fbeta: 1.0000 - val_loss: 0.6937 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03565: val_loss did not improve from 0.39496\n",
      "Epoch 3566/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3868e-04 - fbeta: 1.0000 - val_loss: 0.6941 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03566: val_loss did not improve from 0.39496\n",
      "Epoch 3567/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3874e-04 - fbeta: 1.0000 - val_loss: 0.6950 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03567: val_loss did not improve from 0.39496\n",
      "Epoch 3568/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3875e-04 - fbeta: 1.0000 - val_loss: 0.6964 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03568: val_loss did not improve from 0.39496\n",
      "Epoch 3569/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3887e-04 - fbeta: 1.0000 - val_loss: 0.6986 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03569: val_loss did not improve from 0.39496\n",
      "Epoch 3570/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3862e-04 - fbeta: 1.0000 - val_loss: 0.6982 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03570: val_loss did not improve from 0.39496\n",
      "Epoch 3571/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3872e-04 - fbeta: 1.0000 - val_loss: 0.6977 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03571: val_loss did not improve from 0.39496\n",
      "Epoch 3572/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3866e-04 - fbeta: 1.0000 - val_loss: 0.6970 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03572: val_loss did not improve from 0.39496\n",
      "Epoch 3573/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3848e-04 - fbeta: 1.0000 - val_loss: 0.6948 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03573: val_loss did not improve from 0.39496\n",
      "Epoch 3574/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3852e-04 - fbeta: 1.0000 - val_loss: 0.6918 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03574: val_loss did not improve from 0.39496\n",
      "Epoch 3575/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3848e-04 - fbeta: 1.0000 - val_loss: 0.6931 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03575: val_loss did not improve from 0.39496\n",
      "Epoch 3576/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3843e-04 - fbeta: 1.0000 - val_loss: 0.6939 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03576: val_loss did not improve from 0.39496\n",
      "Epoch 3577/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3838e-04 - fbeta: 1.0000 - val_loss: 0.6942 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03577: val_loss did not improve from 0.39496\n",
      "Epoch 3578/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3847e-04 - fbeta: 1.0000 - val_loss: 0.6955 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03578: val_loss did not improve from 0.39496\n",
      "Epoch 3579/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3821e-04 - fbeta: 1.0000 - val_loss: 0.6944 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03579: val_loss did not improve from 0.39496\n",
      "Epoch 3580/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3816e-04 - fbeta: 1.0000 - val_loss: 0.6955 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03580: val_loss did not improve from 0.39496\n",
      "Epoch 3581/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3789e-04 - fbeta: 1.0000 - val_loss: 0.6948 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03581: val_loss did not improve from 0.39496\n",
      "Epoch 3582/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3862e-04 - fbeta: 1.0000 - val_loss: 0.6884 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03582: val_loss did not improve from 0.39496\n",
      "Epoch 3583/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3818e-04 - fbeta: 1.0000 - val_loss: 0.6922 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03583: val_loss did not improve from 0.39496\n",
      "Epoch 3584/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3812e-04 - fbeta: 1.0000 - val_loss: 0.6941 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03584: val_loss did not improve from 0.39496\n",
      "Epoch 3585/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3793e-04 - fbeta: 1.0000 - val_loss: 0.6940 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03585: val_loss did not improve from 0.39496\n",
      "Epoch 3586/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3786e-04 - fbeta: 1.0000 - val_loss: 0.6949 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03586: val_loss did not improve from 0.39496\n",
      "Epoch 3587/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3777e-04 - fbeta: 1.0000 - val_loss: 0.6965 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03587: val_loss did not improve from 0.39496\n",
      "Epoch 3588/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3775e-04 - fbeta: 1.0000 - val_loss: 0.6965 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03588: val_loss did not improve from 0.39496\n",
      "Epoch 3589/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3765e-04 - fbeta: 1.0000 - val_loss: 0.6956 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03589: val_loss did not improve from 0.39496\n",
      "Epoch 3590/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3848e-04 - fbeta: 1.0000 - val_loss: 0.6974 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03590: val_loss did not improve from 0.39496\n",
      "Epoch 3591/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3785e-04 - fbeta: 1.0000 - val_loss: 0.6975 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03591: val_loss did not improve from 0.39496\n",
      "Epoch 3592/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3811e-04 - fbeta: 1.0000 - val_loss: 0.7001 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03592: val_loss did not improve from 0.39496\n",
      "Epoch 3593/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3766e-04 - fbeta: 1.0000 - val_loss: 0.6979 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03593: val_loss did not improve from 0.39496\n",
      "Epoch 3594/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3740e-04 - fbeta: 1.0000 - val_loss: 0.6977 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03594: val_loss did not improve from 0.39496\n",
      "Epoch 3595/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3764e-04 - fbeta: 1.0000 - val_loss: 0.6984 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03595: val_loss did not improve from 0.39496\n",
      "Epoch 3596/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3736e-04 - fbeta: 1.0000 - val_loss: 0.6972 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03596: val_loss did not improve from 0.39496\n",
      "Epoch 3597/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3733e-04 - fbeta: 1.0000 - val_loss: 0.6964 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03597: val_loss did not improve from 0.39496\n",
      "Epoch 3598/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3723e-04 - fbeta: 1.0000 - val_loss: 0.6967 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03598: val_loss did not improve from 0.39496\n",
      "Epoch 3599/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3735e-04 - fbeta: 1.0000 - val_loss: 0.6963 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03599: val_loss did not improve from 0.39496\n",
      "Epoch 3600/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3720e-04 - fbeta: 1.0000 - val_loss: 0.6978 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03600: val_loss did not improve from 0.39496\n",
      "Epoch 3601/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3715e-04 - fbeta: 1.0000 - val_loss: 0.6965 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03601: val_loss did not improve from 0.39496\n",
      "Epoch 3602/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3693e-04 - fbeta: 1.0000 - val_loss: 0.6968 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03602: val_loss did not improve from 0.39496\n",
      "Epoch 3603/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3698e-04 - fbeta: 1.0000 - val_loss: 0.6964 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03603: val_loss did not improve from 0.39496\n",
      "Epoch 3604/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3693e-04 - fbeta: 1.0000 - val_loss: 0.6964 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03604: val_loss did not improve from 0.39496\n",
      "Epoch 3605/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3704e-04 - fbeta: 1.0000 - val_loss: 0.6956 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03605: val_loss did not improve from 0.39496\n",
      "Epoch 3606/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3680e-04 - fbeta: 1.0000 - val_loss: 0.6956 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03606: val_loss did not improve from 0.39496\n",
      "Epoch 3607/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3673e-04 - fbeta: 1.0000 - val_loss: 0.6963 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03607: val_loss did not improve from 0.39496\n",
      "Epoch 3608/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3681e-04 - fbeta: 1.0000 - val_loss: 0.6973 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03608: val_loss did not improve from 0.39496\n",
      "Epoch 3609/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3667e-04 - fbeta: 1.0000 - val_loss: 0.6968 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03609: val_loss did not improve from 0.39496\n",
      "Epoch 3610/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3664e-04 - fbeta: 1.0000 - val_loss: 0.6965 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03610: val_loss did not improve from 0.39496\n",
      "Epoch 3611/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3672e-04 - fbeta: 1.0000 - val_loss: 0.6979 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03611: val_loss did not improve from 0.39496\n",
      "Epoch 3612/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3646e-04 - fbeta: 1.0000 - val_loss: 0.6975 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03612: val_loss did not improve from 0.39496\n",
      "Epoch 3613/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3666e-04 - fbeta: 1.0000 - val_loss: 0.6970 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03613: val_loss did not improve from 0.39496\n",
      "Epoch 3614/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3661e-04 - fbeta: 1.0000 - val_loss: 0.6975 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03614: val_loss did not improve from 0.39496\n",
      "Epoch 3615/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3656e-04 - fbeta: 1.0000 - val_loss: 0.6966 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03615: val_loss did not improve from 0.39496\n",
      "Epoch 3616/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3640e-04 - fbeta: 1.0000 - val_loss: 0.6966 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03616: val_loss did not improve from 0.39496\n",
      "Epoch 3617/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3641e-04 - fbeta: 1.0000 - val_loss: 0.6969 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03617: val_loss did not improve from 0.39496\n",
      "Epoch 3618/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3634e-04 - fbeta: 1.0000 - val_loss: 0.6969 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03618: val_loss did not improve from 0.39496\n",
      "Epoch 3619/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3635e-04 - fbeta: 1.0000 - val_loss: 0.6956 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03619: val_loss did not improve from 0.39496\n",
      "Epoch 3620/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3623e-04 - fbeta: 1.0000 - val_loss: 0.6923 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03620: val_loss did not improve from 0.39496\n",
      "Epoch 3621/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3653e-04 - fbeta: 1.0000 - val_loss: 0.6917 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03621: val_loss did not improve from 0.39496\n",
      "Epoch 3622/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3616e-04 - fbeta: 1.0000 - val_loss: 0.6939 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03622: val_loss did not improve from 0.39496\n",
      "Epoch 3623/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3606e-04 - fbeta: 1.0000 - val_loss: 0.6935 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03623: val_loss did not improve from 0.39496\n",
      "Epoch 3624/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3606e-04 - fbeta: 1.0000 - val_loss: 0.6916 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03624: val_loss did not improve from 0.39496\n",
      "Epoch 3625/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3608e-04 - fbeta: 1.0000 - val_loss: 0.6930 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03625: val_loss did not improve from 0.39496\n",
      "Epoch 3626/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3592e-04 - fbeta: 1.0000 - val_loss: 0.6940 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03626: val_loss did not improve from 0.39496\n",
      "Epoch 3627/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3609e-04 - fbeta: 1.0000 - val_loss: 0.6952 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03627: val_loss did not improve from 0.39496\n",
      "Epoch 3628/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3591e-04 - fbeta: 1.0000 - val_loss: 0.6961 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03628: val_loss did not improve from 0.39496\n",
      "Epoch 3629/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3588e-04 - fbeta: 1.0000 - val_loss: 0.6960 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03629: val_loss did not improve from 0.39496\n",
      "Epoch 3630/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3570e-04 - fbeta: 1.0000 - val_loss: 0.6959 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03630: val_loss did not improve from 0.39496\n",
      "Epoch 3631/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3574e-04 - fbeta: 1.0000 - val_loss: 0.6942 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03631: val_loss did not improve from 0.39496\n",
      "Epoch 3632/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3565e-04 - fbeta: 1.0000 - val_loss: 0.6951 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03632: val_loss did not improve from 0.39496\n",
      "Epoch 3633/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3564e-04 - fbeta: 1.0000 - val_loss: 0.6954 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03633: val_loss did not improve from 0.39496\n",
      "Epoch 3634/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3553e-04 - fbeta: 1.0000 - val_loss: 0.6962 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03634: val_loss did not improve from 0.39496\n",
      "Epoch 3635/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3558e-04 - fbeta: 1.0000 - val_loss: 0.6962 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03635: val_loss did not improve from 0.39496\n",
      "Epoch 3636/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3566e-04 - fbeta: 1.0000 - val_loss: 0.6964 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03636: val_loss did not improve from 0.39496\n",
      "Epoch 3637/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3581e-04 - fbeta: 1.0000 - val_loss: 0.6907 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03637: val_loss did not improve from 0.39496\n",
      "Epoch 3638/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3576e-04 - fbeta: 1.0000 - val_loss: 0.6936 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03638: val_loss did not improve from 0.39496\n",
      "Epoch 3639/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3559e-04 - fbeta: 1.0000 - val_loss: 0.6943 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03639: val_loss did not improve from 0.39496\n",
      "Epoch 3640/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3541e-04 - fbeta: 1.0000 - val_loss: 0.6957 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03640: val_loss did not improve from 0.39496\n",
      "Epoch 3641/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3532e-04 - fbeta: 1.0000 - val_loss: 0.6965 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03641: val_loss did not improve from 0.39496\n",
      "Epoch 3642/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3520e-04 - fbeta: 1.0000 - val_loss: 0.6972 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03642: val_loss did not improve from 0.39496\n",
      "Epoch 3643/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3516e-04 - fbeta: 1.0000 - val_loss: 0.6970 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03643: val_loss did not improve from 0.39496\n",
      "Epoch 3644/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3517e-04 - fbeta: 1.0000 - val_loss: 0.6970 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03644: val_loss did not improve from 0.39496\n",
      "Epoch 3645/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3494e-04 - fbeta: 1.0000 - val_loss: 0.6968 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03645: val_loss did not improve from 0.39496\n",
      "Epoch 3646/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3509e-04 - fbeta: 1.0000 - val_loss: 0.6968 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03646: val_loss did not improve from 0.39496\n",
      "Epoch 3647/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3511e-04 - fbeta: 1.0000 - val_loss: 0.6984 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03647: val_loss did not improve from 0.39496\n",
      "Epoch 3648/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3498e-04 - fbeta: 1.0000 - val_loss: 0.6979 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03648: val_loss did not improve from 0.39496\n",
      "Epoch 3649/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3505e-04 - fbeta: 1.0000 - val_loss: 0.6969 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03649: val_loss did not improve from 0.39496\n",
      "Epoch 3650/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3496e-04 - fbeta: 1.0000 - val_loss: 0.6977 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03650: val_loss did not improve from 0.39496\n",
      "Epoch 3651/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3485e-04 - fbeta: 1.0000 - val_loss: 0.6964 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03651: val_loss did not improve from 0.39496\n",
      "Epoch 3652/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3496e-04 - fbeta: 1.0000 - val_loss: 0.6960 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03652: val_loss did not improve from 0.39496\n",
      "Epoch 3653/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3536e-04 - fbeta: 1.0000 - val_loss: 0.6941 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03653: val_loss did not improve from 0.39496\n",
      "Epoch 3654/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3502e-04 - fbeta: 1.0000 - val_loss: 0.6950 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03654: val_loss did not improve from 0.39496\n",
      "Epoch 3655/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3490e-04 - fbeta: 1.0000 - val_loss: 0.6969 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03655: val_loss did not improve from 0.39496\n",
      "Epoch 3656/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3485e-04 - fbeta: 1.0000 - val_loss: 0.6960 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03656: val_loss did not improve from 0.39496\n",
      "Epoch 3657/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3482e-04 - fbeta: 1.0000 - val_loss: 0.6946 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03657: val_loss did not improve from 0.39496\n",
      "Epoch 3658/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3452e-04 - fbeta: 1.0000 - val_loss: 0.6948 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03658: val_loss did not improve from 0.39496\n",
      "Epoch 3659/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3441e-04 - fbeta: 1.0000 - val_loss: 0.6962 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03659: val_loss did not improve from 0.39496\n",
      "Epoch 3660/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3436e-04 - fbeta: 1.0000 - val_loss: 0.6957 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03660: val_loss did not improve from 0.39496\n",
      "Epoch 3661/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3447e-04 - fbeta: 1.0000 - val_loss: 0.6964 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03661: val_loss did not improve from 0.39496\n",
      "Epoch 3662/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3426e-04 - fbeta: 1.0000 - val_loss: 0.6979 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03662: val_loss did not improve from 0.39496\n",
      "Epoch 3663/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3436e-04 - fbeta: 1.0000 - val_loss: 0.6984 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03663: val_loss did not improve from 0.39496\n",
      "Epoch 3664/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3432e-04 - fbeta: 1.0000 - val_loss: 0.6986 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03664: val_loss did not improve from 0.39496\n",
      "Epoch 3665/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3430e-04 - fbeta: 1.0000 - val_loss: 0.6985 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03665: val_loss did not improve from 0.39496\n",
      "Epoch 3666/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3431e-04 - fbeta: 1.0000 - val_loss: 0.6977 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03666: val_loss did not improve from 0.39496\n",
      "Epoch 3667/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3414e-04 - fbeta: 1.0000 - val_loss: 0.6980 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03667: val_loss did not improve from 0.39496\n",
      "Epoch 3668/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3414e-04 - fbeta: 1.0000 - val_loss: 0.6983 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03668: val_loss did not improve from 0.39496\n",
      "Epoch 3669/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3409e-04 - fbeta: 1.0000 - val_loss: 0.6985 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03669: val_loss did not improve from 0.39496\n",
      "Epoch 3670/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3405e-04 - fbeta: 1.0000 - val_loss: 0.6984 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03670: val_loss did not improve from 0.39496\n",
      "Epoch 3671/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3403e-04 - fbeta: 1.0000 - val_loss: 0.6983 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03671: val_loss did not improve from 0.39496\n",
      "Epoch 3672/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3448e-04 - fbeta: 1.0000 - val_loss: 0.6880 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03672: val_loss did not improve from 0.39496\n",
      "Epoch 3673/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3426e-04 - fbeta: 1.0000 - val_loss: 0.6928 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03673: val_loss did not improve from 0.39496\n",
      "Epoch 3674/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3442e-04 - fbeta: 1.0000 - val_loss: 0.6970 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03674: val_loss did not improve from 0.39496\n",
      "Epoch 3675/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3404e-04 - fbeta: 1.0000 - val_loss: 0.6979 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03675: val_loss did not improve from 0.39496\n",
      "Epoch 3676/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3392e-04 - fbeta: 1.0000 - val_loss: 0.6977 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03676: val_loss did not improve from 0.39496\n",
      "Epoch 3677/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3394e-04 - fbeta: 1.0000 - val_loss: 0.6957 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03677: val_loss did not improve from 0.39496\n",
      "Epoch 3678/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3419e-04 - fbeta: 1.0000 - val_loss: 0.6961 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03678: val_loss did not improve from 0.39496\n",
      "Epoch 3679/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3385e-04 - fbeta: 1.0000 - val_loss: 0.6955 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03679: val_loss did not improve from 0.39496\n",
      "Epoch 3680/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3369e-04 - fbeta: 1.0000 - val_loss: 0.6972 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03680: val_loss did not improve from 0.39496\n",
      "Epoch 3681/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3403e-04 - fbeta: 1.0000 - val_loss: 0.7001 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03681: val_loss did not improve from 0.39496\n",
      "Epoch 3682/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3363e-04 - fbeta: 1.0000 - val_loss: 0.7003 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03682: val_loss did not improve from 0.39496\n",
      "Epoch 3683/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3360e-04 - fbeta: 1.0000 - val_loss: 0.6996 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03683: val_loss did not improve from 0.39496\n",
      "Epoch 3684/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3372e-04 - fbeta: 1.0000 - val_loss: 0.6986 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03684: val_loss did not improve from 0.39496\n",
      "Epoch 3685/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3339e-04 - fbeta: 1.0000 - val_loss: 0.6989 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03685: val_loss did not improve from 0.39496\n",
      "Epoch 3686/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3341e-04 - fbeta: 1.0000 - val_loss: 0.6983 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03686: val_loss did not improve from 0.39496\n",
      "Epoch 3687/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3343e-04 - fbeta: 1.0000 - val_loss: 0.6968 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03687: val_loss did not improve from 0.39496\n",
      "Epoch 3688/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3327e-04 - fbeta: 1.0000 - val_loss: 0.6970 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03688: val_loss did not improve from 0.39496\n",
      "Epoch 3689/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3314e-04 - fbeta: 1.0000 - val_loss: 0.6972 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03689: val_loss did not improve from 0.39496\n",
      "Epoch 3690/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3301e-04 - fbeta: 1.0000 - val_loss: 0.6984 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03690: val_loss did not improve from 0.39496\n",
      "Epoch 3691/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3312e-04 - fbeta: 1.0000 - val_loss: 0.6983 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03691: val_loss did not improve from 0.39496\n",
      "Epoch 3692/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3311e-04 - fbeta: 1.0000 - val_loss: 0.7000 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03692: val_loss did not improve from 0.39496\n",
      "Epoch 3693/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3306e-04 - fbeta: 1.0000 - val_loss: 0.7003 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03693: val_loss did not improve from 0.39496\n",
      "Epoch 3694/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3305e-04 - fbeta: 1.0000 - val_loss: 0.6999 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03694: val_loss did not improve from 0.39496\n",
      "Epoch 3695/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3291e-04 - fbeta: 1.0000 - val_loss: 0.6993 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03695: val_loss did not improve from 0.39496\n",
      "Epoch 3696/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3286e-04 - fbeta: 1.0000 - val_loss: 0.6990 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03696: val_loss did not improve from 0.39496\n",
      "Epoch 3697/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3277e-04 - fbeta: 1.0000 - val_loss: 0.6996 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03697: val_loss did not improve from 0.39496\n",
      "Epoch 3698/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3275e-04 - fbeta: 1.0000 - val_loss: 0.6990 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03698: val_loss did not improve from 0.39496\n",
      "Epoch 3699/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3268e-04 - fbeta: 1.0000 - val_loss: 0.7003 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03699: val_loss did not improve from 0.39496\n",
      "Epoch 3700/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3274e-04 - fbeta: 1.0000 - val_loss: 0.6992 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03700: val_loss did not improve from 0.39496\n",
      "Epoch 3701/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3272e-04 - fbeta: 1.0000 - val_loss: 0.6999 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03701: val_loss did not improve from 0.39496\n",
      "Epoch 3702/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3271e-04 - fbeta: 1.0000 - val_loss: 0.7005 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03702: val_loss did not improve from 0.39496\n",
      "Epoch 3703/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3243e-04 - fbeta: 1.0000 - val_loss: 0.7000 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03703: val_loss did not improve from 0.39496\n",
      "Epoch 3704/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3279e-04 - fbeta: 1.0000 - val_loss: 0.7005 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03704: val_loss did not improve from 0.39496\n",
      "Epoch 3705/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3270e-04 - fbeta: 1.0000 - val_loss: 0.7015 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03705: val_loss did not improve from 0.39496\n",
      "Epoch 3706/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3256e-04 - fbeta: 1.0000 - val_loss: 0.7014 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03706: val_loss did not improve from 0.39496\n",
      "Epoch 3707/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3246e-04 - fbeta: 1.0000 - val_loss: 0.6986 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03707: val_loss did not improve from 0.39496\n",
      "Epoch 3708/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3249e-04 - fbeta: 1.0000 - val_loss: 0.6973 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03708: val_loss did not improve from 0.39496\n",
      "Epoch 3709/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3233e-04 - fbeta: 1.0000 - val_loss: 0.6951 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03709: val_loss did not improve from 0.39496\n",
      "Epoch 3710/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3227e-04 - fbeta: 1.0000 - val_loss: 0.6979 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03710: val_loss did not improve from 0.39496\n",
      "Epoch 3711/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3228e-04 - fbeta: 1.0000 - val_loss: 0.6987 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03711: val_loss did not improve from 0.39496\n",
      "Epoch 3712/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3230e-04 - fbeta: 1.0000 - val_loss: 0.6986 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03712: val_loss did not improve from 0.39496\n",
      "Epoch 3713/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3214e-04 - fbeta: 1.0000 - val_loss: 0.7012 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03713: val_loss did not improve from 0.39496\n",
      "Epoch 3714/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3226e-04 - fbeta: 1.0000 - val_loss: 0.7015 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03714: val_loss did not improve from 0.39496\n",
      "Epoch 3715/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3234e-04 - fbeta: 1.0000 - val_loss: 0.7000 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03715: val_loss did not improve from 0.39496\n",
      "Epoch 3716/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3201e-04 - fbeta: 1.0000 - val_loss: 0.6982 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03716: val_loss did not improve from 0.39496\n",
      "Epoch 3717/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3213e-04 - fbeta: 1.0000 - val_loss: 0.6988 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03717: val_loss did not improve from 0.39496\n",
      "Epoch 3718/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3201e-04 - fbeta: 1.0000 - val_loss: 0.6981 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03718: val_loss did not improve from 0.39496\n",
      "Epoch 3719/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3199e-04 - fbeta: 1.0000 - val_loss: 0.6993 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03719: val_loss did not improve from 0.39496\n",
      "Epoch 3720/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3199e-04 - fbeta: 1.0000 - val_loss: 0.7004 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03720: val_loss did not improve from 0.39496\n",
      "Epoch 3721/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3172e-04 - fbeta: 1.0000 - val_loss: 0.6984 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03721: val_loss did not improve from 0.39496\n",
      "Epoch 3722/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3183e-04 - fbeta: 1.0000 - val_loss: 0.6983 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03722: val_loss did not improve from 0.39496\n",
      "Epoch 3723/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3181e-04 - fbeta: 1.0000 - val_loss: 0.6978 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03723: val_loss did not improve from 0.39496\n",
      "Epoch 3724/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3172e-04 - fbeta: 1.0000 - val_loss: 0.6988 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03724: val_loss did not improve from 0.39496\n",
      "Epoch 3725/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3178e-04 - fbeta: 1.0000 - val_loss: 0.6980 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03725: val_loss did not improve from 0.39496\n",
      "Epoch 3726/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3151e-04 - fbeta: 1.0000 - val_loss: 0.6981 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03726: val_loss did not improve from 0.39496\n",
      "Epoch 3727/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3158e-04 - fbeta: 1.0000 - val_loss: 0.6980 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03727: val_loss did not improve from 0.39496\n",
      "Epoch 3728/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3134e-04 - fbeta: 1.0000 - val_loss: 0.6984 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03728: val_loss did not improve from 0.39496\n",
      "Epoch 3729/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3143e-04 - fbeta: 1.0000 - val_loss: 0.6978 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03729: val_loss did not improve from 0.39496\n",
      "Epoch 3730/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3137e-04 - fbeta: 1.0000 - val_loss: 0.6984 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03730: val_loss did not improve from 0.39496\n",
      "Epoch 3731/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3139e-04 - fbeta: 1.0000 - val_loss: 0.6986 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03731: val_loss did not improve from 0.39496\n",
      "Epoch 3732/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3142e-04 - fbeta: 1.0000 - val_loss: 0.7012 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03732: val_loss did not improve from 0.39496\n",
      "Epoch 3733/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3129e-04 - fbeta: 1.0000 - val_loss: 0.6989 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03733: val_loss did not improve from 0.39496\n",
      "Epoch 3734/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3115e-04 - fbeta: 1.0000 - val_loss: 0.6995 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03734: val_loss did not improve from 0.39496\n",
      "Epoch 3735/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3128e-04 - fbeta: 1.0000 - val_loss: 0.7015 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03735: val_loss did not improve from 0.39496\n",
      "Epoch 3736/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3124e-04 - fbeta: 1.0000 - val_loss: 0.6997 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03736: val_loss did not improve from 0.39496\n",
      "Epoch 3737/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3118e-04 - fbeta: 1.0000 - val_loss: 0.7005 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03737: val_loss did not improve from 0.39496\n",
      "Epoch 3738/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3099e-04 - fbeta: 1.0000 - val_loss: 0.7002 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03738: val_loss did not improve from 0.39496\n",
      "Epoch 3739/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3112e-04 - fbeta: 1.0000 - val_loss: 0.6996 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03739: val_loss did not improve from 0.39496\n",
      "Epoch 3740/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3093e-04 - fbeta: 1.0000 - val_loss: 0.6995 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03740: val_loss did not improve from 0.39496\n",
      "Epoch 3741/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3107e-04 - fbeta: 1.0000 - val_loss: 0.6972 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03741: val_loss did not improve from 0.39496\n",
      "Epoch 3742/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3108e-04 - fbeta: 1.0000 - val_loss: 0.6973 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03742: val_loss did not improve from 0.39496\n",
      "Epoch 3743/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3092e-04 - fbeta: 1.0000 - val_loss: 0.6990 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03743: val_loss did not improve from 0.39496\n",
      "Epoch 3744/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3086e-04 - fbeta: 1.0000 - val_loss: 0.6989 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03744: val_loss did not improve from 0.39496\n",
      "Epoch 3745/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3073e-04 - fbeta: 1.0000 - val_loss: 0.7007 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03745: val_loss did not improve from 0.39496\n",
      "Epoch 3746/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3085e-04 - fbeta: 1.0000 - val_loss: 0.7016 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03746: val_loss did not improve from 0.39496\n",
      "Epoch 3747/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3070e-04 - fbeta: 1.0000 - val_loss: 0.7001 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03747: val_loss did not improve from 0.39496\n",
      "Epoch 3748/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3049e-04 - fbeta: 1.0000 - val_loss: 0.6982 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03748: val_loss did not improve from 0.39496\n",
      "Epoch 3749/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3070e-04 - fbeta: 1.0000 - val_loss: 0.6996 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03749: val_loss did not improve from 0.39496\n",
      "Epoch 3750/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3049e-04 - fbeta: 1.0000 - val_loss: 0.6989 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03750: val_loss did not improve from 0.39496\n",
      "Epoch 3751/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3041e-04 - fbeta: 1.0000 - val_loss: 0.6989 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03751: val_loss did not improve from 0.39496\n",
      "Epoch 3752/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3047e-04 - fbeta: 1.0000 - val_loss: 0.6973 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03752: val_loss did not improve from 0.39496\n",
      "Epoch 3753/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3038e-04 - fbeta: 1.0000 - val_loss: 0.6980 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03753: val_loss did not improve from 0.39496\n",
      "Epoch 3754/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3035e-04 - fbeta: 1.0000 - val_loss: 0.6978 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03754: val_loss did not improve from 0.39496\n",
      "Epoch 3755/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3034e-04 - fbeta: 1.0000 - val_loss: 0.6986 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03755: val_loss did not improve from 0.39496\n",
      "Epoch 3756/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3029e-04 - fbeta: 1.0000 - val_loss: 0.6991 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03756: val_loss did not improve from 0.39496\n",
      "Epoch 3757/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3039e-04 - fbeta: 1.0000 - val_loss: 0.7012 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03757: val_loss did not improve from 0.39496\n",
      "Epoch 3758/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3046e-04 - fbeta: 1.0000 - val_loss: 0.7009 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03758: val_loss did not improve from 0.39496\n",
      "Epoch 3759/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3019e-04 - fbeta: 1.0000 - val_loss: 0.6991 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03759: val_loss did not improve from 0.39496\n",
      "Epoch 3760/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3020e-04 - fbeta: 1.0000 - val_loss: 0.6984 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03760: val_loss did not improve from 0.39496\n",
      "Epoch 3761/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3006e-04 - fbeta: 1.0000 - val_loss: 0.6987 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03761: val_loss did not improve from 0.39496\n",
      "Epoch 3762/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3009e-04 - fbeta: 1.0000 - val_loss: 0.6981 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03762: val_loss did not improve from 0.39496\n",
      "Epoch 3763/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3006e-04 - fbeta: 1.0000 - val_loss: 0.6979 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03763: val_loss did not improve from 0.39496\n",
      "Epoch 3764/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3026e-04 - fbeta: 1.0000 - val_loss: 0.6988 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03764: val_loss did not improve from 0.39496\n",
      "Epoch 3765/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3000e-04 - fbeta: 1.0000 - val_loss: 0.6991 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03765: val_loss did not improve from 0.39496\n",
      "Epoch 3766/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2989e-04 - fbeta: 1.0000 - val_loss: 0.6991 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03766: val_loss did not improve from 0.39496\n",
      "Epoch 3767/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3027e-04 - fbeta: 1.0000 - val_loss: 0.6976 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03767: val_loss did not improve from 0.39496\n",
      "Epoch 3768/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2973e-04 - fbeta: 1.0000 - val_loss: 0.6973 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03768: val_loss did not improve from 0.39496\n",
      "Epoch 3769/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2995e-04 - fbeta: 1.0000 - val_loss: 0.6978 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03769: val_loss did not improve from 0.39496\n",
      "Epoch 3770/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2992e-04 - fbeta: 1.0000 - val_loss: 0.6987 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03770: val_loss did not improve from 0.39496\n",
      "Epoch 3771/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2974e-04 - fbeta: 1.0000 - val_loss: 0.6985 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03771: val_loss did not improve from 0.39496\n",
      "Epoch 3772/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2961e-04 - fbeta: 1.0000 - val_loss: 0.6989 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03772: val_loss did not improve from 0.39496\n",
      "Epoch 3773/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2975e-04 - fbeta: 1.0000 - val_loss: 0.6995 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03773: val_loss did not improve from 0.39496\n",
      "Epoch 3774/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2955e-04 - fbeta: 1.0000 - val_loss: 0.7016 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03774: val_loss did not improve from 0.39496\n",
      "Epoch 3775/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2981e-04 - fbeta: 1.0000 - val_loss: 0.7016 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03775: val_loss did not improve from 0.39496\n",
      "Epoch 3776/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.3009e-04 - fbeta: 1.0000 - val_loss: 0.7021 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03776: val_loss did not improve from 0.39496\n",
      "Epoch 3777/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2951e-04 - fbeta: 1.0000 - val_loss: 0.7023 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03777: val_loss did not improve from 0.39496\n",
      "Epoch 3778/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2946e-04 - fbeta: 1.0000 - val_loss: 0.7006 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03778: val_loss did not improve from 0.39496\n",
      "Epoch 3779/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2930e-04 - fbeta: 1.0000 - val_loss: 0.7006 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03779: val_loss did not improve from 0.39496\n",
      "Epoch 3780/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2927e-04 - fbeta: 1.0000 - val_loss: 0.7012 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03780: val_loss did not improve from 0.39496\n",
      "Epoch 3781/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2928e-04 - fbeta: 1.0000 - val_loss: 0.6994 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03781: val_loss did not improve from 0.39496\n",
      "Epoch 3782/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2961e-04 - fbeta: 1.0000 - val_loss: 0.6979 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03782: val_loss did not improve from 0.39496\n",
      "Epoch 3783/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2931e-04 - fbeta: 1.0000 - val_loss: 0.6985 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03783: val_loss did not improve from 0.39496\n",
      "Epoch 3784/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2939e-04 - fbeta: 1.0000 - val_loss: 0.6991 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03784: val_loss did not improve from 0.39496\n",
      "Epoch 3785/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2929e-04 - fbeta: 1.0000 - val_loss: 0.6972 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03785: val_loss did not improve from 0.39496\n",
      "Epoch 3786/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2917e-04 - fbeta: 1.0000 - val_loss: 0.6937 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03786: val_loss did not improve from 0.39496\n",
      "Epoch 3787/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2912e-04 - fbeta: 1.0000 - val_loss: 0.6961 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03787: val_loss did not improve from 0.39496\n",
      "Epoch 3788/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2905e-04 - fbeta: 1.0000 - val_loss: 0.6974 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03788: val_loss did not improve from 0.39496\n",
      "Epoch 3789/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2912e-04 - fbeta: 1.0000 - val_loss: 0.7005 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03789: val_loss did not improve from 0.39496\n",
      "Epoch 3790/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2904e-04 - fbeta: 1.0000 - val_loss: 0.7032 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03790: val_loss did not improve from 0.39496\n",
      "Epoch 3791/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2895e-04 - fbeta: 1.0000 - val_loss: 0.7017 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03791: val_loss did not improve from 0.39496\n",
      "Epoch 3792/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2891e-04 - fbeta: 1.0000 - val_loss: 0.7007 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03792: val_loss did not improve from 0.39496\n",
      "Epoch 3793/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2887e-04 - fbeta: 1.0000 - val_loss: 0.7016 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03793: val_loss did not improve from 0.39496\n",
      "Epoch 3794/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2888e-04 - fbeta: 1.0000 - val_loss: 0.7007 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03794: val_loss did not improve from 0.39496\n",
      "Epoch 3795/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2873e-04 - fbeta: 1.0000 - val_loss: 0.7024 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03795: val_loss did not improve from 0.39496\n",
      "Epoch 3796/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2882e-04 - fbeta: 1.0000 - val_loss: 0.7014 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03796: val_loss did not improve from 0.39496\n",
      "Epoch 3797/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2876e-04 - fbeta: 1.0000 - val_loss: 0.7020 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03797: val_loss did not improve from 0.39496\n",
      "Epoch 3798/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2864e-04 - fbeta: 1.0000 - val_loss: 0.7017 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03798: val_loss did not improve from 0.39496\n",
      "Epoch 3799/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2872e-04 - fbeta: 1.0000 - val_loss: 0.7016 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03799: val_loss did not improve from 0.39496\n",
      "Epoch 3800/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2858e-04 - fbeta: 1.0000 - val_loss: 0.7014 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03800: val_loss did not improve from 0.39496\n",
      "Epoch 3801/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2849e-04 - fbeta: 1.0000 - val_loss: 0.7006 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03801: val_loss did not improve from 0.39496\n",
      "Epoch 3802/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2858e-04 - fbeta: 1.0000 - val_loss: 0.7006 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03802: val_loss did not improve from 0.39496\n",
      "Epoch 3803/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2833e-04 - fbeta: 1.0000 - val_loss: 0.7014 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03803: val_loss did not improve from 0.39496\n",
      "Epoch 3804/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2847e-04 - fbeta: 1.0000 - val_loss: 0.7010 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03804: val_loss did not improve from 0.39496\n",
      "Epoch 3805/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2862e-04 - fbeta: 1.0000 - val_loss: 0.6954 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03805: val_loss did not improve from 0.39496\n",
      "Epoch 3806/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2834e-04 - fbeta: 1.0000 - val_loss: 0.6979 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03806: val_loss did not improve from 0.39496\n",
      "Epoch 3807/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2832e-04 - fbeta: 1.0000 - val_loss: 0.6975 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03807: val_loss did not improve from 0.39496\n",
      "Epoch 3808/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2819e-04 - fbeta: 1.0000 - val_loss: 0.6994 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03808: val_loss did not improve from 0.39496\n",
      "Epoch 3809/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2825e-04 - fbeta: 1.0000 - val_loss: 0.7010 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03809: val_loss did not improve from 0.39496\n",
      "Epoch 3810/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2814e-04 - fbeta: 1.0000 - val_loss: 0.7008 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03810: val_loss did not improve from 0.39496\n",
      "Epoch 3811/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2796e-04 - fbeta: 1.0000 - val_loss: 0.7002 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03811: val_loss did not improve from 0.39496\n",
      "Epoch 3812/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2801e-04 - fbeta: 1.0000 - val_loss: 0.6998 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03812: val_loss did not improve from 0.39496\n",
      "Epoch 3813/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2796e-04 - fbeta: 1.0000 - val_loss: 0.6997 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03813: val_loss did not improve from 0.39496\n",
      "Epoch 3814/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2783e-04 - fbeta: 1.0000 - val_loss: 0.7004 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03814: val_loss did not improve from 0.39496\n",
      "Epoch 3815/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2796e-04 - fbeta: 1.0000 - val_loss: 0.7006 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03815: val_loss did not improve from 0.39496\n",
      "Epoch 3816/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2792e-04 - fbeta: 1.0000 - val_loss: 0.7012 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03816: val_loss did not improve from 0.39496\n",
      "Epoch 3817/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2811e-04 - fbeta: 1.0000 - val_loss: 0.7006 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03817: val_loss did not improve from 0.39496\n",
      "Epoch 3818/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2777e-04 - fbeta: 1.0000 - val_loss: 0.7009 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03818: val_loss did not improve from 0.39496\n",
      "Epoch 3819/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2771e-04 - fbeta: 1.0000 - val_loss: 0.7017 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03819: val_loss did not improve from 0.39496\n",
      "Epoch 3820/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2760e-04 - fbeta: 1.0000 - val_loss: 0.7019 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03820: val_loss did not improve from 0.39496\n",
      "Epoch 3821/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2767e-04 - fbeta: 1.0000 - val_loss: 0.7000 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03821: val_loss did not improve from 0.39496\n",
      "Epoch 3822/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2761e-04 - fbeta: 1.0000 - val_loss: 0.7010 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03822: val_loss did not improve from 0.39496\n",
      "Epoch 3823/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2771e-04 - fbeta: 1.0000 - val_loss: 0.7017 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03823: val_loss did not improve from 0.39496\n",
      "Epoch 3824/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2759e-04 - fbeta: 1.0000 - val_loss: 0.7044 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03824: val_loss did not improve from 0.39496\n",
      "Epoch 3825/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2742e-04 - fbeta: 1.0000 - val_loss: 0.7033 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03825: val_loss did not improve from 0.39496\n",
      "Epoch 3826/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2754e-04 - fbeta: 1.0000 - val_loss: 0.7029 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03826: val_loss did not improve from 0.39496\n",
      "Epoch 3827/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2751e-04 - fbeta: 1.0000 - val_loss: 0.7038 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03827: val_loss did not improve from 0.39496\n",
      "Epoch 3828/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2747e-04 - fbeta: 1.0000 - val_loss: 0.7014 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03828: val_loss did not improve from 0.39496\n",
      "Epoch 3829/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2727e-04 - fbeta: 1.0000 - val_loss: 0.7012 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03829: val_loss did not improve from 0.39496\n",
      "Epoch 3830/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2717e-04 - fbeta: 1.0000 - val_loss: 0.7011 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03830: val_loss did not improve from 0.39496\n",
      "Epoch 3831/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2730e-04 - fbeta: 1.0000 - val_loss: 0.6981 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03831: val_loss did not improve from 0.39496\n",
      "Epoch 3832/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2720e-04 - fbeta: 1.0000 - val_loss: 0.6994 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03832: val_loss did not improve from 0.39496\n",
      "Epoch 3833/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2721e-04 - fbeta: 1.0000 - val_loss: 0.7000 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03833: val_loss did not improve from 0.39496\n",
      "Epoch 3834/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2723e-04 - fbeta: 1.0000 - val_loss: 0.7010 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03834: val_loss did not improve from 0.39496\n",
      "Epoch 3835/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2721e-04 - fbeta: 1.0000 - val_loss: 0.7028 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03835: val_loss did not improve from 0.39496\n",
      "Epoch 3836/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2702e-04 - fbeta: 1.0000 - val_loss: 0.7017 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03836: val_loss did not improve from 0.39496\n",
      "Epoch 3837/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2696e-04 - fbeta: 1.0000 - val_loss: 0.7006 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03837: val_loss did not improve from 0.39496\n",
      "Epoch 3838/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2699e-04 - fbeta: 1.0000 - val_loss: 0.7004 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03838: val_loss did not improve from 0.39496\n",
      "Epoch 3839/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2712e-04 - fbeta: 1.0000 - val_loss: 0.6989 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03839: val_loss did not improve from 0.39496\n",
      "Epoch 3840/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2700e-04 - fbeta: 1.0000 - val_loss: 0.6990 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03840: val_loss did not improve from 0.39496\n",
      "Epoch 3841/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2684e-04 - fbeta: 1.0000 - val_loss: 0.6996 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03841: val_loss did not improve from 0.39496\n",
      "Epoch 3842/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2672e-04 - fbeta: 1.0000 - val_loss: 0.6993 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03842: val_loss did not improve from 0.39496\n",
      "Epoch 3843/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2675e-04 - fbeta: 1.0000 - val_loss: 0.6984 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03843: val_loss did not improve from 0.39496\n",
      "Epoch 3844/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2664e-04 - fbeta: 1.0000 - val_loss: 0.6997 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03844: val_loss did not improve from 0.39496\n",
      "Epoch 3845/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2665e-04 - fbeta: 1.0000 - val_loss: 0.6997 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03845: val_loss did not improve from 0.39496\n",
      "Epoch 3846/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2671e-04 - fbeta: 1.0000 - val_loss: 0.6997 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03846: val_loss did not improve from 0.39496\n",
      "Epoch 3847/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2677e-04 - fbeta: 1.0000 - val_loss: 0.7002 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03847: val_loss did not improve from 0.39496\n",
      "Epoch 3848/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2647e-04 - fbeta: 1.0000 - val_loss: 0.6997 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03848: val_loss did not improve from 0.39496\n",
      "Epoch 3849/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2661e-04 - fbeta: 1.0000 - val_loss: 0.7002 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03849: val_loss did not improve from 0.39496\n",
      "Epoch 3850/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2666e-04 - fbeta: 1.0000 - val_loss: 0.7000 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03850: val_loss did not improve from 0.39496\n",
      "Epoch 3851/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2647e-04 - fbeta: 1.0000 - val_loss: 0.7004 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03851: val_loss did not improve from 0.39496\n",
      "Epoch 3852/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2644e-04 - fbeta: 1.0000 - val_loss: 0.7005 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03852: val_loss did not improve from 0.39496\n",
      "Epoch 3853/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2636e-04 - fbeta: 1.0000 - val_loss: 0.7000 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03853: val_loss did not improve from 0.39496\n",
      "Epoch 3854/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2649e-04 - fbeta: 1.0000 - val_loss: 0.6992 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03854: val_loss did not improve from 0.39496\n",
      "Epoch 3855/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2635e-04 - fbeta: 1.0000 - val_loss: 0.6994 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03855: val_loss did not improve from 0.39496\n",
      "Epoch 3856/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2621e-04 - fbeta: 1.0000 - val_loss: 0.6993 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03856: val_loss did not improve from 0.39496\n",
      "Epoch 3857/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2617e-04 - fbeta: 1.0000 - val_loss: 0.6994 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03857: val_loss did not improve from 0.39496\n",
      "Epoch 3858/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2616e-04 - fbeta: 1.0000 - val_loss: 0.7006 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03858: val_loss did not improve from 0.39496\n",
      "Epoch 3859/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2611e-04 - fbeta: 1.0000 - val_loss: 0.7013 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03859: val_loss did not improve from 0.39496\n",
      "Epoch 3860/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2612e-04 - fbeta: 1.0000 - val_loss: 0.7011 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03860: val_loss did not improve from 0.39496\n",
      "Epoch 3861/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2619e-04 - fbeta: 1.0000 - val_loss: 0.6989 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03861: val_loss did not improve from 0.39496\n",
      "Epoch 3862/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2616e-04 - fbeta: 1.0000 - val_loss: 0.6998 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03862: val_loss did not improve from 0.39496\n",
      "Epoch 3863/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2613e-04 - fbeta: 1.0000 - val_loss: 0.6995 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03863: val_loss did not improve from 0.39496\n",
      "Epoch 3864/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2611e-04 - fbeta: 1.0000 - val_loss: 0.7002 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03864: val_loss did not improve from 0.39496\n",
      "Epoch 3865/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2579e-04 - fbeta: 1.0000 - val_loss: 0.7006 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03865: val_loss did not improve from 0.39496\n",
      "Epoch 3866/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2597e-04 - fbeta: 1.0000 - val_loss: 0.7019 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03866: val_loss did not improve from 0.39496\n",
      "Epoch 3867/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2581e-04 - fbeta: 1.0000 - val_loss: 0.6990 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03867: val_loss did not improve from 0.39496\n",
      "Epoch 3868/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2573e-04 - fbeta: 1.0000 - val_loss: 0.6994 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03868: val_loss did not improve from 0.39496\n",
      "Epoch 3869/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2572e-04 - fbeta: 1.0000 - val_loss: 0.6996 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03869: val_loss did not improve from 0.39496\n",
      "Epoch 3870/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2577e-04 - fbeta: 1.0000 - val_loss: 0.7002 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03870: val_loss did not improve from 0.39496\n",
      "Epoch 3871/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2578e-04 - fbeta: 1.0000 - val_loss: 0.7010 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03871: val_loss did not improve from 0.39496\n",
      "Epoch 3872/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2564e-04 - fbeta: 1.0000 - val_loss: 0.7008 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03872: val_loss did not improve from 0.39496\n",
      "Epoch 3873/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2556e-04 - fbeta: 1.0000 - val_loss: 0.7010 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03873: val_loss did not improve from 0.39496\n",
      "Epoch 3874/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2547e-04 - fbeta: 1.0000 - val_loss: 0.6999 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03874: val_loss did not improve from 0.39496\n",
      "Epoch 3875/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2539e-04 - fbeta: 1.0000 - val_loss: 0.7008 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03875: val_loss did not improve from 0.39496\n",
      "Epoch 3876/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2532e-04 - fbeta: 1.0000 - val_loss: 0.7009 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03876: val_loss did not improve from 0.39496\n",
      "Epoch 3877/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2538e-04 - fbeta: 1.0000 - val_loss: 0.6977 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03877: val_loss did not improve from 0.39496\n",
      "Epoch 3878/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2533e-04 - fbeta: 1.0000 - val_loss: 0.6994 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03878: val_loss did not improve from 0.39496\n",
      "Epoch 3879/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2545e-04 - fbeta: 1.0000 - val_loss: 0.6975 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03879: val_loss did not improve from 0.39496\n",
      "Epoch 3880/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2539e-04 - fbeta: 1.0000 - val_loss: 0.6965 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03880: val_loss did not improve from 0.39496\n",
      "Epoch 3881/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2534e-04 - fbeta: 1.0000 - val_loss: 0.6988 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03881: val_loss did not improve from 0.39496\n",
      "Epoch 3882/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2522e-04 - fbeta: 1.0000 - val_loss: 0.6993 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03882: val_loss did not improve from 0.39496\n",
      "Epoch 3883/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2517e-04 - fbeta: 1.0000 - val_loss: 0.6983 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03883: val_loss did not improve from 0.39496\n",
      "Epoch 3884/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2521e-04 - fbeta: 1.0000 - val_loss: 0.6979 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03884: val_loss did not improve from 0.39496\n",
      "Epoch 3885/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2507e-04 - fbeta: 1.0000 - val_loss: 0.6990 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03885: val_loss did not improve from 0.39496\n",
      "Epoch 3886/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2520e-04 - fbeta: 1.0000 - val_loss: 0.7009 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03886: val_loss did not improve from 0.39496\n",
      "Epoch 3887/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2578e-04 - fbeta: 1.0000 - val_loss: 0.7001 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03887: val_loss did not improve from 0.39496\n",
      "Epoch 3888/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2530e-04 - fbeta: 1.0000 - val_loss: 0.6995 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03888: val_loss did not improve from 0.39496\n",
      "Epoch 3889/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2506e-04 - fbeta: 1.0000 - val_loss: 0.6993 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03889: val_loss did not improve from 0.39496\n",
      "Epoch 3890/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2497e-04 - fbeta: 1.0000 - val_loss: 0.6985 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03890: val_loss did not improve from 0.39496\n",
      "Epoch 3891/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2488e-04 - fbeta: 1.0000 - val_loss: 0.6993 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03891: val_loss did not improve from 0.39496\n",
      "Epoch 3892/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2481e-04 - fbeta: 1.0000 - val_loss: 0.6996 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03892: val_loss did not improve from 0.39496\n",
      "Epoch 3893/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2485e-04 - fbeta: 1.0000 - val_loss: 0.6978 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03893: val_loss did not improve from 0.39496\n",
      "Epoch 3894/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2474e-04 - fbeta: 1.0000 - val_loss: 0.6991 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03894: val_loss did not improve from 0.39496\n",
      "Epoch 3895/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2470e-04 - fbeta: 1.0000 - val_loss: 0.7000 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03895: val_loss did not improve from 0.39496\n",
      "Epoch 3896/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2469e-04 - fbeta: 1.0000 - val_loss: 0.7002 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03896: val_loss did not improve from 0.39496\n",
      "Epoch 3897/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2465e-04 - fbeta: 1.0000 - val_loss: 0.7004 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03897: val_loss did not improve from 0.39496\n",
      "Epoch 3898/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2462e-04 - fbeta: 1.0000 - val_loss: 0.7010 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03898: val_loss did not improve from 0.39496\n",
      "Epoch 3899/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2473e-04 - fbeta: 1.0000 - val_loss: 0.7009 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03899: val_loss did not improve from 0.39496\n",
      "Epoch 3900/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2444e-04 - fbeta: 1.0000 - val_loss: 0.7006 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03900: val_loss did not improve from 0.39496\n",
      "Epoch 3901/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2445e-04 - fbeta: 1.0000 - val_loss: 0.7013 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03901: val_loss did not improve from 0.39496\n",
      "Epoch 3902/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2453e-04 - fbeta: 1.0000 - val_loss: 0.7014 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03902: val_loss did not improve from 0.39496\n",
      "Epoch 3903/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2446e-04 - fbeta: 1.0000 - val_loss: 0.7027 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03903: val_loss did not improve from 0.39496\n",
      "Epoch 3904/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2429e-04 - fbeta: 1.0000 - val_loss: 0.7018 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03904: val_loss did not improve from 0.39496\n",
      "Epoch 3905/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2460e-04 - fbeta: 1.0000 - val_loss: 0.7002 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03905: val_loss did not improve from 0.39496\n",
      "Epoch 3906/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2445e-04 - fbeta: 1.0000 - val_loss: 0.7006 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03906: val_loss did not improve from 0.39496\n",
      "Epoch 3907/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2434e-04 - fbeta: 1.0000 - val_loss: 0.7008 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03907: val_loss did not improve from 0.39496\n",
      "Epoch 3908/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2424e-04 - fbeta: 1.0000 - val_loss: 0.7016 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03908: val_loss did not improve from 0.39496\n",
      "Epoch 3909/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2406e-04 - fbeta: 1.0000 - val_loss: 0.7035 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03909: val_loss did not improve from 0.39496\n",
      "Epoch 3910/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2401e-04 - fbeta: 1.0000 - val_loss: 0.7033 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03910: val_loss did not improve from 0.39496\n",
      "Epoch 3911/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2420e-04 - fbeta: 1.0000 - val_loss: 0.7035 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03911: val_loss did not improve from 0.39496\n",
      "Epoch 3912/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2418e-04 - fbeta: 1.0000 - val_loss: 0.7019 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03912: val_loss did not improve from 0.39496\n",
      "Epoch 3913/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2414e-04 - fbeta: 1.0000 - val_loss: 0.7005 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03913: val_loss did not improve from 0.39496\n",
      "Epoch 3914/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2413e-04 - fbeta: 1.0000 - val_loss: 0.7004 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03914: val_loss did not improve from 0.39496\n",
      "Epoch 3915/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2405e-04 - fbeta: 1.0000 - val_loss: 0.7015 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03915: val_loss did not improve from 0.39496\n",
      "Epoch 3916/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2408e-04 - fbeta: 1.0000 - val_loss: 0.7006 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03916: val_loss did not improve from 0.39496\n",
      "Epoch 3917/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2386e-04 - fbeta: 1.0000 - val_loss: 0.7006 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03917: val_loss did not improve from 0.39496\n",
      "Epoch 3918/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2390e-04 - fbeta: 1.0000 - val_loss: 0.7000 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03918: val_loss did not improve from 0.39496\n",
      "Epoch 3919/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2381e-04 - fbeta: 1.0000 - val_loss: 0.7003 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03919: val_loss did not improve from 0.39496\n",
      "Epoch 3920/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2416e-04 - fbeta: 1.0000 - val_loss: 0.6994 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03920: val_loss did not improve from 0.39496\n",
      "Epoch 3921/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2401e-04 - fbeta: 1.0000 - val_loss: 0.7021 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03921: val_loss did not improve from 0.39496\n",
      "Epoch 3922/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2372e-04 - fbeta: 1.0000 - val_loss: 0.7027 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03922: val_loss did not improve from 0.39496\n",
      "Epoch 3923/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2370e-04 - fbeta: 1.0000 - val_loss: 0.7028 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03923: val_loss did not improve from 0.39496\n",
      "Epoch 3924/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2366e-04 - fbeta: 1.0000 - val_loss: 0.7026 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03924: val_loss did not improve from 0.39496\n",
      "Epoch 3925/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2361e-04 - fbeta: 1.0000 - val_loss: 0.7015 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03925: val_loss did not improve from 0.39496\n",
      "Epoch 3926/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2410e-04 - fbeta: 1.0000 - val_loss: 0.6942 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03926: val_loss did not improve from 0.39496\n",
      "Epoch 3927/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2371e-04 - fbeta: 1.0000 - val_loss: 0.6979 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03927: val_loss did not improve from 0.39496\n",
      "Epoch 3928/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2343e-04 - fbeta: 1.0000 - val_loss: 0.7000 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03928: val_loss did not improve from 0.39496\n",
      "Epoch 3929/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2339e-04 - fbeta: 1.0000 - val_loss: 0.7007 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03929: val_loss did not improve from 0.39496\n",
      "Epoch 3930/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2333e-04 - fbeta: 1.0000 - val_loss: 0.7005 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03930: val_loss did not improve from 0.39496\n",
      "Epoch 3931/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2332e-04 - fbeta: 1.0000 - val_loss: 0.7013 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03931: val_loss did not improve from 0.39496\n",
      "Epoch 3932/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2320e-04 - fbeta: 1.0000 - val_loss: 0.7016 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03932: val_loss did not improve from 0.39496\n",
      "Epoch 3933/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2336e-04 - fbeta: 1.0000 - val_loss: 0.7021 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03933: val_loss did not improve from 0.39496\n",
      "Epoch 3934/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2338e-04 - fbeta: 1.0000 - val_loss: 0.7032 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03934: val_loss did not improve from 0.39496\n",
      "Epoch 3935/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2316e-04 - fbeta: 1.0000 - val_loss: 0.7037 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03935: val_loss did not improve from 0.39496\n",
      "Epoch 3936/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2310e-04 - fbeta: 1.0000 - val_loss: 0.7030 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03936: val_loss did not improve from 0.39496\n",
      "Epoch 3937/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2303e-04 - fbeta: 1.0000 - val_loss: 0.7028 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03937: val_loss did not improve from 0.39496\n",
      "Epoch 3938/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2322e-04 - fbeta: 1.0000 - val_loss: 0.7037 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03938: val_loss did not improve from 0.39496\n",
      "Epoch 3939/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2313e-04 - fbeta: 1.0000 - val_loss: 0.7026 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03939: val_loss did not improve from 0.39496\n",
      "Epoch 3940/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2296e-04 - fbeta: 1.0000 - val_loss: 0.7034 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03940: val_loss did not improve from 0.39496\n",
      "Epoch 3941/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2307e-04 - fbeta: 1.0000 - val_loss: 0.7022 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03941: val_loss did not improve from 0.39496\n",
      "Epoch 3942/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2287e-04 - fbeta: 1.0000 - val_loss: 0.7019 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03942: val_loss did not improve from 0.39496\n",
      "Epoch 3943/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2284e-04 - fbeta: 1.0000 - val_loss: 0.7016 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03943: val_loss did not improve from 0.39496\n",
      "Epoch 3944/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2277e-04 - fbeta: 1.0000 - val_loss: 0.7018 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03944: val_loss did not improve from 0.39496\n",
      "Epoch 3945/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2285e-04 - fbeta: 1.0000 - val_loss: 0.7017 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03945: val_loss did not improve from 0.39496\n",
      "Epoch 3946/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2280e-04 - fbeta: 1.0000 - val_loss: 0.7023 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03946: val_loss did not improve from 0.39496\n",
      "Epoch 3947/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2275e-04 - fbeta: 1.0000 - val_loss: 0.7018 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03947: val_loss did not improve from 0.39496\n",
      "Epoch 3948/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2272e-04 - fbeta: 1.0000 - val_loss: 0.7017 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03948: val_loss did not improve from 0.39496\n",
      "Epoch 3949/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2262e-04 - fbeta: 1.0000 - val_loss: 0.7014 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03949: val_loss did not improve from 0.39496\n",
      "Epoch 3950/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2260e-04 - fbeta: 1.0000 - val_loss: 0.7022 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03950: val_loss did not improve from 0.39496\n",
      "Epoch 3951/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2254e-04 - fbeta: 1.0000 - val_loss: 0.7018 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03951: val_loss did not improve from 0.39496\n",
      "Epoch 3952/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2251e-04 - fbeta: 1.0000 - val_loss: 0.7015 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03952: val_loss did not improve from 0.39496\n",
      "Epoch 3953/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2254e-04 - fbeta: 1.0000 - val_loss: 0.7022 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03953: val_loss did not improve from 0.39496\n",
      "Epoch 3954/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2256e-04 - fbeta: 1.0000 - val_loss: 0.7019 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03954: val_loss did not improve from 0.39496\n",
      "Epoch 3955/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2244e-04 - fbeta: 1.0000 - val_loss: 0.7042 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03955: val_loss did not improve from 0.39496\n",
      "Epoch 3956/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2252e-04 - fbeta: 1.0000 - val_loss: 0.7029 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03956: val_loss did not improve from 0.39496\n",
      "Epoch 3957/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2245e-04 - fbeta: 1.0000 - val_loss: 0.7030 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03957: val_loss did not improve from 0.39496\n",
      "Epoch 3958/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2254e-04 - fbeta: 1.0000 - val_loss: 0.7034 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03958: val_loss did not improve from 0.39496\n",
      "Epoch 3959/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2228e-04 - fbeta: 1.0000 - val_loss: 0.7020 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03959: val_loss did not improve from 0.39496\n",
      "Epoch 3960/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2231e-04 - fbeta: 1.0000 - val_loss: 0.7020 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03960: val_loss did not improve from 0.39496\n",
      "Epoch 3961/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2224e-04 - fbeta: 1.0000 - val_loss: 0.7041 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03961: val_loss did not improve from 0.39496\n",
      "Epoch 3962/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2207e-04 - fbeta: 1.0000 - val_loss: 0.7055 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03962: val_loss did not improve from 0.39496\n",
      "Epoch 3963/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2233e-04 - fbeta: 1.0000 - val_loss: 0.7055 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03963: val_loss did not improve from 0.39496\n",
      "Epoch 3964/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2205e-04 - fbeta: 1.0000 - val_loss: 0.7047 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03964: val_loss did not improve from 0.39496\n",
      "Epoch 3965/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2219e-04 - fbeta: 1.0000 - val_loss: 0.7038 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03965: val_loss did not improve from 0.39496\n",
      "Epoch 3966/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2215e-04 - fbeta: 1.0000 - val_loss: 0.7042 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03966: val_loss did not improve from 0.39496\n",
      "Epoch 3967/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2215e-04 - fbeta: 1.0000 - val_loss: 0.7036 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03967: val_loss did not improve from 0.39496\n",
      "Epoch 3968/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2200e-04 - fbeta: 1.0000 - val_loss: 0.7024 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03968: val_loss did not improve from 0.39496\n",
      "Epoch 3969/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2190e-04 - fbeta: 1.0000 - val_loss: 0.7025 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03969: val_loss did not improve from 0.39496\n",
      "Epoch 3970/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2182e-04 - fbeta: 1.0000 - val_loss: 0.7031 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03970: val_loss did not improve from 0.39496\n",
      "Epoch 3971/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2179e-04 - fbeta: 1.0000 - val_loss: 0.7030 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03971: val_loss did not improve from 0.39496\n",
      "Epoch 3972/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2197e-04 - fbeta: 1.0000 - val_loss: 0.7056 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03972: val_loss did not improve from 0.39496\n",
      "Epoch 3973/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2178e-04 - fbeta: 1.0000 - val_loss: 0.7056 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03973: val_loss did not improve from 0.39496\n",
      "Epoch 3974/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2175e-04 - fbeta: 1.0000 - val_loss: 0.7053 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03974: val_loss did not improve from 0.39496\n",
      "Epoch 3975/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2170e-04 - fbeta: 1.0000 - val_loss: 0.7044 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03975: val_loss did not improve from 0.39496\n",
      "Epoch 3976/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2167e-04 - fbeta: 1.0000 - val_loss: 0.7040 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03976: val_loss did not improve from 0.39496\n",
      "Epoch 3977/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2174e-04 - fbeta: 1.0000 - val_loss: 0.7039 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03977: val_loss did not improve from 0.39496\n",
      "Epoch 3978/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2167e-04 - fbeta: 1.0000 - val_loss: 0.7022 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03978: val_loss did not improve from 0.39496\n",
      "Epoch 3979/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2143e-04 - fbeta: 1.0000 - val_loss: 0.7030 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03979: val_loss did not improve from 0.39496\n",
      "Epoch 3980/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2152e-04 - fbeta: 1.0000 - val_loss: 0.7038 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03980: val_loss did not improve from 0.39496\n",
      "Epoch 3981/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2152e-04 - fbeta: 1.0000 - val_loss: 0.7031 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03981: val_loss did not improve from 0.39496\n",
      "Epoch 3982/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2156e-04 - fbeta: 1.0000 - val_loss: 0.7029 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03982: val_loss did not improve from 0.39496\n",
      "Epoch 3983/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2146e-04 - fbeta: 1.0000 - val_loss: 0.7035 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03983: val_loss did not improve from 0.39496\n",
      "Epoch 3984/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2150e-04 - fbeta: 1.0000 - val_loss: 0.7046 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03984: val_loss did not improve from 0.39496\n",
      "Epoch 3985/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2147e-04 - fbeta: 1.0000 - val_loss: 0.7045 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03985: val_loss did not improve from 0.39496\n",
      "Epoch 3986/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2127e-04 - fbeta: 1.0000 - val_loss: 0.7037 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03986: val_loss did not improve from 0.39496\n",
      "Epoch 3987/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2130e-04 - fbeta: 1.0000 - val_loss: 0.7039 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03987: val_loss did not improve from 0.39496\n",
      "Epoch 3988/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2124e-04 - fbeta: 1.0000 - val_loss: 0.7032 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03988: val_loss did not improve from 0.39496\n",
      "Epoch 3989/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2117e-04 - fbeta: 1.0000 - val_loss: 0.7036 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03989: val_loss did not improve from 0.39496\n",
      "Epoch 3990/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2103e-04 - fbeta: 1.0000 - val_loss: 0.7036 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03990: val_loss did not improve from 0.39496\n",
      "Epoch 3991/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2152e-04 - fbeta: 1.0000 - val_loss: 0.7016 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03991: val_loss did not improve from 0.39496\n",
      "Epoch 3992/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2115e-04 - fbeta: 1.0000 - val_loss: 0.7010 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03992: val_loss did not improve from 0.39496\n",
      "Epoch 3993/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2116e-04 - fbeta: 1.0000 - val_loss: 0.7011 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03993: val_loss did not improve from 0.39496\n",
      "Epoch 3994/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2098e-04 - fbeta: 1.0000 - val_loss: 0.7023 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03994: val_loss did not improve from 0.39496\n",
      "Epoch 3995/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2107e-04 - fbeta: 1.0000 - val_loss: 0.7012 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03995: val_loss did not improve from 0.39496\n",
      "Epoch 3996/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2091e-04 - fbeta: 1.0000 - val_loss: 0.7018 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03996: val_loss did not improve from 0.39496\n",
      "Epoch 3997/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2097e-04 - fbeta: 1.0000 - val_loss: 0.7026 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03997: val_loss did not improve from 0.39496\n",
      "Epoch 3998/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2090e-04 - fbeta: 1.0000 - val_loss: 0.7025 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03998: val_loss did not improve from 0.39496\n",
      "Epoch 3999/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2094e-04 - fbeta: 1.0000 - val_loss: 0.7020 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 03999: val_loss did not improve from 0.39496\n",
      "Epoch 4000/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2083e-04 - fbeta: 1.0000 - val_loss: 0.7020 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04000: val_loss did not improve from 0.39496\n",
      "Epoch 4001/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2078e-04 - fbeta: 1.0000 - val_loss: 0.7035 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04001: val_loss did not improve from 0.39496\n",
      "Epoch 4002/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2070e-04 - fbeta: 1.0000 - val_loss: 0.7029 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04002: val_loss did not improve from 0.39496\n",
      "Epoch 4003/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2080e-04 - fbeta: 1.0000 - val_loss: 0.7023 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04003: val_loss did not improve from 0.39496\n",
      "Epoch 4004/5000\n",
      "622/622 [==============================] - 25s 41ms/step - loss: 1.2072e-04 - fbeta: 1.0000 - val_loss: 0.7033 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04004: val_loss did not improve from 0.39496\n",
      "Epoch 4005/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2049e-04 - fbeta: 1.0000 - val_loss: 0.7022 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04005: val_loss did not improve from 0.39496\n",
      "Epoch 4006/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2068e-04 - fbeta: 1.0000 - val_loss: 0.7041 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04006: val_loss did not improve from 0.39496\n",
      "Epoch 4007/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2049e-04 - fbeta: 1.0000 - val_loss: 0.7040 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04007: val_loss did not improve from 0.39496\n",
      "Epoch 4008/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2049e-04 - fbeta: 1.0000 - val_loss: 0.7050 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04008: val_loss did not improve from 0.39496\n",
      "Epoch 4009/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2041e-04 - fbeta: 1.0000 - val_loss: 0.7038 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04009: val_loss did not improve from 0.39496\n",
      "Epoch 4010/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2041e-04 - fbeta: 1.0000 - val_loss: 0.7033 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04010: val_loss did not improve from 0.39496\n",
      "Epoch 4011/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2044e-04 - fbeta: 1.0000 - val_loss: 0.7026 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04011: val_loss did not improve from 0.39496\n",
      "Epoch 4012/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2021e-04 - fbeta: 1.0000 - val_loss: 0.7032 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04012: val_loss did not improve from 0.39496\n",
      "Epoch 4013/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2035e-04 - fbeta: 1.0000 - val_loss: 0.7038 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04013: val_loss did not improve from 0.39496\n",
      "Epoch 4014/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2022e-04 - fbeta: 1.0000 - val_loss: 0.7037 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04014: val_loss did not improve from 0.39496\n",
      "Epoch 4015/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2022e-04 - fbeta: 1.0000 - val_loss: 0.7035 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04015: val_loss did not improve from 0.39496\n",
      "Epoch 4016/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2030e-04 - fbeta: 1.0000 - val_loss: 0.7048 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04016: val_loss did not improve from 0.39496\n",
      "Epoch 4017/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2031e-04 - fbeta: 1.0000 - val_loss: 0.7038 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04017: val_loss did not improve from 0.39496\n",
      "Epoch 4018/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2016e-04 - fbeta: 1.0000 - val_loss: 0.7041 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04018: val_loss did not improve from 0.39496\n",
      "Epoch 4019/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2010e-04 - fbeta: 1.0000 - val_loss: 0.7031 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04019: val_loss did not improve from 0.39496\n",
      "Epoch 4020/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1995e-04 - fbeta: 1.0000 - val_loss: 0.7020 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04020: val_loss did not improve from 0.39496\n",
      "Epoch 4021/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2005e-04 - fbeta: 1.0000 - val_loss: 0.7022 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04021: val_loss did not improve from 0.39496\n",
      "Epoch 4022/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2001e-04 - fbeta: 1.0000 - val_loss: 0.7017 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04022: val_loss did not improve from 0.39496\n",
      "Epoch 4023/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2002e-04 - fbeta: 1.0000 - val_loss: 0.7018 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04023: val_loss did not improve from 0.39496\n",
      "Epoch 4024/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1998e-04 - fbeta: 1.0000 - val_loss: 0.7020 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04024: val_loss did not improve from 0.39496\n",
      "Epoch 4025/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2004e-04 - fbeta: 1.0000 - val_loss: 0.7011 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04025: val_loss did not improve from 0.39496\n",
      "Epoch 4026/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2005e-04 - fbeta: 1.0000 - val_loss: 0.7025 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04026: val_loss did not improve from 0.39496\n",
      "Epoch 4027/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1992e-04 - fbeta: 1.0000 - val_loss: 0.7020 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04027: val_loss did not improve from 0.39496\n",
      "Epoch 4028/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1975e-04 - fbeta: 1.0000 - val_loss: 0.7013 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04028: val_loss did not improve from 0.39496\n",
      "Epoch 4029/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1977e-04 - fbeta: 1.0000 - val_loss: 0.7016 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04029: val_loss did not improve from 0.39496\n",
      "Epoch 4030/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1971e-04 - fbeta: 1.0000 - val_loss: 0.7012 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04030: val_loss did not improve from 0.39496\n",
      "Epoch 4031/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.2007e-04 - fbeta: 1.0000 - val_loss: 0.7013 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04031: val_loss did not improve from 0.39496\n",
      "Epoch 4032/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1968e-04 - fbeta: 1.0000 - val_loss: 0.7027 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04032: val_loss did not improve from 0.39496\n",
      "Epoch 4033/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1976e-04 - fbeta: 1.0000 - val_loss: 0.7035 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04033: val_loss did not improve from 0.39496\n",
      "Epoch 4034/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1965e-04 - fbeta: 1.0000 - val_loss: 0.7032 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04034: val_loss did not improve from 0.39496\n",
      "Epoch 4035/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1958e-04 - fbeta: 1.0000 - val_loss: 0.7031 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04035: val_loss did not improve from 0.39496\n",
      "Epoch 4036/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1955e-04 - fbeta: 1.0000 - val_loss: 0.7032 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04036: val_loss did not improve from 0.39496\n",
      "Epoch 4037/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1955e-04 - fbeta: 1.0000 - val_loss: 0.7027 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04037: val_loss did not improve from 0.39496\n",
      "Epoch 4038/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1945e-04 - fbeta: 1.0000 - val_loss: 0.7031 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04038: val_loss did not improve from 0.39496\n",
      "Epoch 4039/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1933e-04 - fbeta: 1.0000 - val_loss: 0.7038 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04039: val_loss did not improve from 0.39496\n",
      "Epoch 4040/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1944e-04 - fbeta: 1.0000 - val_loss: 0.7055 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04040: val_loss did not improve from 0.39496\n",
      "Epoch 4041/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1943e-04 - fbeta: 1.0000 - val_loss: 0.7045 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04041: val_loss did not improve from 0.39496\n",
      "Epoch 4042/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1929e-04 - fbeta: 1.0000 - val_loss: 0.7042 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04042: val_loss did not improve from 0.39496\n",
      "Epoch 4043/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1930e-04 - fbeta: 1.0000 - val_loss: 0.7042 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04043: val_loss did not improve from 0.39496\n",
      "Epoch 4044/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1943e-04 - fbeta: 1.0000 - val_loss: 0.7037 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04044: val_loss did not improve from 0.39496\n",
      "Epoch 4045/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1934e-04 - fbeta: 1.0000 - val_loss: 0.7007 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04045: val_loss did not improve from 0.39496\n",
      "Epoch 4046/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1931e-04 - fbeta: 1.0000 - val_loss: 0.6984 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04046: val_loss did not improve from 0.39496\n",
      "Epoch 4047/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1918e-04 - fbeta: 1.0000 - val_loss: 0.6991 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04047: val_loss did not improve from 0.39496\n",
      "Epoch 4048/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1913e-04 - fbeta: 1.0000 - val_loss: 0.6982 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04048: val_loss did not improve from 0.39496\n",
      "Epoch 4049/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1917e-04 - fbeta: 1.0000 - val_loss: 0.7002 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04049: val_loss did not improve from 0.39496\n",
      "Epoch 4050/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1913e-04 - fbeta: 1.0000 - val_loss: 0.7015 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04050: val_loss did not improve from 0.39496\n",
      "Epoch 4051/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1904e-04 - fbeta: 1.0000 - val_loss: 0.7024 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04051: val_loss did not improve from 0.39496\n",
      "Epoch 4052/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1901e-04 - fbeta: 1.0000 - val_loss: 0.7010 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04052: val_loss did not improve from 0.39496\n",
      "Epoch 4053/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1903e-04 - fbeta: 1.0000 - val_loss: 0.7033 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04053: val_loss did not improve from 0.39496\n",
      "Epoch 4054/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1883e-04 - fbeta: 1.0000 - val_loss: 0.7040 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04054: val_loss did not improve from 0.39496\n",
      "Epoch 4055/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1885e-04 - fbeta: 1.0000 - val_loss: 0.7033 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04055: val_loss did not improve from 0.39496\n",
      "Epoch 4056/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1895e-04 - fbeta: 1.0000 - val_loss: 0.7031 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04056: val_loss did not improve from 0.39496\n",
      "Epoch 4057/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1880e-04 - fbeta: 1.0000 - val_loss: 0.7035 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04057: val_loss did not improve from 0.39496\n",
      "Epoch 4058/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1919e-04 - fbeta: 1.0000 - val_loss: 0.7071 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04058: val_loss did not improve from 0.39496\n",
      "Epoch 4059/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1882e-04 - fbeta: 1.0000 - val_loss: 0.7050 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04059: val_loss did not improve from 0.39496\n",
      "Epoch 4060/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1879e-04 - fbeta: 1.0000 - val_loss: 0.7006 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04060: val_loss did not improve from 0.39496\n",
      "Epoch 4061/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1877e-04 - fbeta: 1.0000 - val_loss: 0.7019 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04061: val_loss did not improve from 0.39496\n",
      "Epoch 4062/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1845e-04 - fbeta: 1.0000 - val_loss: 0.7024 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04062: val_loss did not improve from 0.39496\n",
      "Epoch 4063/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1873e-04 - fbeta: 1.0000 - val_loss: 0.7040 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04063: val_loss did not improve from 0.39496\n",
      "Epoch 4064/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1852e-04 - fbeta: 1.0000 - val_loss: 0.7026 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04064: val_loss did not improve from 0.39496\n",
      "Epoch 4065/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1845e-04 - fbeta: 1.0000 - val_loss: 0.7034 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04065: val_loss did not improve from 0.39496\n",
      "Epoch 4066/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1836e-04 - fbeta: 1.0000 - val_loss: 0.7036 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04066: val_loss did not improve from 0.39496\n",
      "Epoch 4067/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1842e-04 - fbeta: 1.0000 - val_loss: 0.7026 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04067: val_loss did not improve from 0.39496\n",
      "Epoch 4068/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1840e-04 - fbeta: 1.0000 - val_loss: 0.7030 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04068: val_loss did not improve from 0.39496\n",
      "Epoch 4069/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1834e-04 - fbeta: 1.0000 - val_loss: 0.7029 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04069: val_loss did not improve from 0.39496\n",
      "Epoch 4070/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1823e-04 - fbeta: 1.0000 - val_loss: 0.7040 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04070: val_loss did not improve from 0.39496\n",
      "Epoch 4071/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1832e-04 - fbeta: 1.0000 - val_loss: 0.7029 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04071: val_loss did not improve from 0.39496\n",
      "Epoch 4072/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1821e-04 - fbeta: 1.0000 - val_loss: 0.7042 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04072: val_loss did not improve from 0.39496\n",
      "Epoch 4073/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1830e-04 - fbeta: 1.0000 - val_loss: 0.7044 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04073: val_loss did not improve from 0.39496\n",
      "Epoch 4074/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1808e-04 - fbeta: 1.0000 - val_loss: 0.7037 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04074: val_loss did not improve from 0.39496\n",
      "Epoch 4075/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1818e-04 - fbeta: 1.0000 - val_loss: 0.7046 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04075: val_loss did not improve from 0.39496\n",
      "Epoch 4076/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1804e-04 - fbeta: 1.0000 - val_loss: 0.7056 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04076: val_loss did not improve from 0.39496\n",
      "Epoch 4077/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1804e-04 - fbeta: 1.0000 - val_loss: 0.7041 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04077: val_loss did not improve from 0.39496\n",
      "Epoch 4078/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1806e-04 - fbeta: 1.0000 - val_loss: 0.7041 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04078: val_loss did not improve from 0.39496\n",
      "Epoch 4079/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1804e-04 - fbeta: 1.0000 - val_loss: 0.7039 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04079: val_loss did not improve from 0.39496\n",
      "Epoch 4080/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1796e-04 - fbeta: 1.0000 - val_loss: 0.7047 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04080: val_loss did not improve from 0.39496\n",
      "Epoch 4081/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1787e-04 - fbeta: 1.0000 - val_loss: 0.7024 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04081: val_loss did not improve from 0.39496\n",
      "Epoch 4082/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1788e-04 - fbeta: 1.0000 - val_loss: 0.7029 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04082: val_loss did not improve from 0.39496\n",
      "Epoch 4083/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1772e-04 - fbeta: 1.0000 - val_loss: 0.7018 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04083: val_loss did not improve from 0.39496\n",
      "Epoch 4084/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1784e-04 - fbeta: 1.0000 - val_loss: 0.7015 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04084: val_loss did not improve from 0.39496\n",
      "Epoch 4085/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1762e-04 - fbeta: 1.0000 - val_loss: 0.7015 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04085: val_loss did not improve from 0.39496\n",
      "Epoch 4086/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1778e-04 - fbeta: 1.0000 - val_loss: 0.7019 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04086: val_loss did not improve from 0.39496\n",
      "Epoch 4087/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1772e-04 - fbeta: 1.0000 - val_loss: 0.7029 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04087: val_loss did not improve from 0.39496\n",
      "Epoch 4088/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1770e-04 - fbeta: 1.0000 - val_loss: 0.7017 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04088: val_loss did not improve from 0.39496\n",
      "Epoch 4089/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1763e-04 - fbeta: 1.0000 - val_loss: 0.7024 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04089: val_loss did not improve from 0.39496\n",
      "Epoch 4090/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1754e-04 - fbeta: 1.0000 - val_loss: 0.7031 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04090: val_loss did not improve from 0.39496\n",
      "Epoch 4091/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1776e-04 - fbeta: 1.0000 - val_loss: 0.7018 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04091: val_loss did not improve from 0.39496\n",
      "Epoch 4092/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1777e-04 - fbeta: 1.0000 - val_loss: 0.7026 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04092: val_loss did not improve from 0.39496\n",
      "Epoch 4093/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1763e-04 - fbeta: 1.0000 - val_loss: 0.7024 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04093: val_loss did not improve from 0.39496\n",
      "Epoch 4094/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1749e-04 - fbeta: 1.0000 - val_loss: 0.7039 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04094: val_loss did not improve from 0.39496\n",
      "Epoch 4095/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1779e-04 - fbeta: 1.0000 - val_loss: 0.7053 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04095: val_loss did not improve from 0.39496\n",
      "Epoch 4096/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1747e-04 - fbeta: 1.0000 - val_loss: 0.7040 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04096: val_loss did not improve from 0.39496\n",
      "Epoch 4097/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1788e-04 - fbeta: 1.0000 - val_loss: 0.7002 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04097: val_loss did not improve from 0.39496\n",
      "Epoch 4098/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1761e-04 - fbeta: 1.0000 - val_loss: 0.7030 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04098: val_loss did not improve from 0.39496\n",
      "Epoch 4099/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1738e-04 - fbeta: 1.0000 - val_loss: 0.7026 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04099: val_loss did not improve from 0.39496\n",
      "Epoch 4100/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1741e-04 - fbeta: 1.0000 - val_loss: 0.7034 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04100: val_loss did not improve from 0.39496\n",
      "Epoch 4101/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1726e-04 - fbeta: 1.0000 - val_loss: 0.7043 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04101: val_loss did not improve from 0.39496\n",
      "Epoch 4102/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1709e-04 - fbeta: 1.0000 - val_loss: 0.7020 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04102: val_loss did not improve from 0.39496\n",
      "Epoch 4103/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1723e-04 - fbeta: 1.0000 - val_loss: 0.7031 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04103: val_loss did not improve from 0.39496\n",
      "Epoch 4104/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1729e-04 - fbeta: 1.0000 - val_loss: 0.7042 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04104: val_loss did not improve from 0.39496\n",
      "Epoch 4105/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1708e-04 - fbeta: 1.0000 - val_loss: 0.7043 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04105: val_loss did not improve from 0.39496\n",
      "Epoch 4106/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1711e-04 - fbeta: 1.0000 - val_loss: 0.7031 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04106: val_loss did not improve from 0.39496\n",
      "Epoch 4107/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1700e-04 - fbeta: 1.0000 - val_loss: 0.7056 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04107: val_loss did not improve from 0.39496\n",
      "Epoch 4108/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1710e-04 - fbeta: 1.0000 - val_loss: 0.7047 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04108: val_loss did not improve from 0.39496\n",
      "Epoch 4109/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1698e-04 - fbeta: 1.0000 - val_loss: 0.7048 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04109: val_loss did not improve from 0.39496\n",
      "Epoch 4110/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1708e-04 - fbeta: 1.0000 - val_loss: 0.7023 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04110: val_loss did not improve from 0.39496\n",
      "Epoch 4111/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1694e-04 - fbeta: 1.0000 - val_loss: 0.7027 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04111: val_loss did not improve from 0.39496\n",
      "Epoch 4112/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1687e-04 - fbeta: 1.0000 - val_loss: 0.7032 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04112: val_loss did not improve from 0.39496\n",
      "Epoch 4113/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1697e-04 - fbeta: 1.0000 - val_loss: 0.7055 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04113: val_loss did not improve from 0.39496\n",
      "Epoch 4114/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1693e-04 - fbeta: 1.0000 - val_loss: 0.7062 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04114: val_loss did not improve from 0.39496\n",
      "Epoch 4115/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1677e-04 - fbeta: 1.0000 - val_loss: 0.7054 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04115: val_loss did not improve from 0.39496\n",
      "Epoch 4116/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1676e-04 - fbeta: 1.0000 - val_loss: 0.7061 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04116: val_loss did not improve from 0.39496\n",
      "Epoch 4117/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1677e-04 - fbeta: 1.0000 - val_loss: 0.7065 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04117: val_loss did not improve from 0.39496\n",
      "Epoch 4118/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1680e-04 - fbeta: 1.0000 - val_loss: 0.7065 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04118: val_loss did not improve from 0.39496\n",
      "Epoch 4119/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1684e-04 - fbeta: 1.0000 - val_loss: 0.7058 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04119: val_loss did not improve from 0.39496\n",
      "Epoch 4120/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1678e-04 - fbeta: 1.0000 - val_loss: 0.7073 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04120: val_loss did not improve from 0.39496\n",
      "Epoch 4121/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1684e-04 - fbeta: 1.0000 - val_loss: 0.7062 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04121: val_loss did not improve from 0.39496\n",
      "Epoch 4122/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1658e-04 - fbeta: 1.0000 - val_loss: 0.7062 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04122: val_loss did not improve from 0.39496\n",
      "Epoch 4123/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1660e-04 - fbeta: 1.0000 - val_loss: 0.7084 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04123: val_loss did not improve from 0.39496\n",
      "Epoch 4124/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1636e-04 - fbeta: 1.0000 - val_loss: 0.7065 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04124: val_loss did not improve from 0.39496\n",
      "Epoch 4125/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1629e-04 - fbeta: 1.0000 - val_loss: 0.7061 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04125: val_loss did not improve from 0.39496\n",
      "Epoch 4126/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1635e-04 - fbeta: 1.0000 - val_loss: 0.7054 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04126: val_loss did not improve from 0.39496\n",
      "Epoch 4127/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1627e-04 - fbeta: 1.0000 - val_loss: 0.7060 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04127: val_loss did not improve from 0.39496\n",
      "Epoch 4128/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1622e-04 - fbeta: 1.0000 - val_loss: 0.7060 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04128: val_loss did not improve from 0.39496\n",
      "Epoch 4129/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1644e-04 - fbeta: 1.0000 - val_loss: 0.7040 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04129: val_loss did not improve from 0.39496\n",
      "Epoch 4130/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1636e-04 - fbeta: 1.0000 - val_loss: 0.7063 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04130: val_loss did not improve from 0.39496\n",
      "Epoch 4131/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1632e-04 - fbeta: 1.0000 - val_loss: 0.7054 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04131: val_loss did not improve from 0.39496\n",
      "Epoch 4132/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1622e-04 - fbeta: 1.0000 - val_loss: 0.7068 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04132: val_loss did not improve from 0.39496\n",
      "Epoch 4133/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1605e-04 - fbeta: 1.0000 - val_loss: 0.7054 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04133: val_loss did not improve from 0.39496\n",
      "Epoch 4134/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1621e-04 - fbeta: 1.0000 - val_loss: 0.7034 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04134: val_loss did not improve from 0.39496\n",
      "Epoch 4135/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1615e-04 - fbeta: 1.0000 - val_loss: 0.7018 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04135: val_loss did not improve from 0.39496\n",
      "Epoch 4136/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1606e-04 - fbeta: 1.0000 - val_loss: 0.7032 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04136: val_loss did not improve from 0.39496\n",
      "Epoch 4137/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1595e-04 - fbeta: 1.0000 - val_loss: 0.7047 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04137: val_loss did not improve from 0.39496\n",
      "Epoch 4138/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1599e-04 - fbeta: 1.0000 - val_loss: 0.7041 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04138: val_loss did not improve from 0.39496\n",
      "Epoch 4139/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1598e-04 - fbeta: 1.0000 - val_loss: 0.7048 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04139: val_loss did not improve from 0.39496\n",
      "Epoch 4140/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1589e-04 - fbeta: 1.0000 - val_loss: 0.7046 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04140: val_loss did not improve from 0.39496\n",
      "Epoch 4141/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1578e-04 - fbeta: 1.0000 - val_loss: 0.7049 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04141: val_loss did not improve from 0.39496\n",
      "Epoch 4142/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1583e-04 - fbeta: 1.0000 - val_loss: 0.7046 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04142: val_loss did not improve from 0.39496\n",
      "Epoch 4143/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1584e-04 - fbeta: 1.0000 - val_loss: 0.7044 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04143: val_loss did not improve from 0.39496\n",
      "Epoch 4144/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1604e-04 - fbeta: 1.0000 - val_loss: 0.7022 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04144: val_loss did not improve from 0.39496\n",
      "Epoch 4145/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1607e-04 - fbeta: 1.0000 - val_loss: 0.7019 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04145: val_loss did not improve from 0.39496\n",
      "Epoch 4146/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1604e-04 - fbeta: 1.0000 - val_loss: 0.7029 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04146: val_loss did not improve from 0.39496\n",
      "Epoch 4147/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1614e-04 - fbeta: 1.0000 - val_loss: 0.7031 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04147: val_loss did not improve from 0.39496\n",
      "Epoch 4148/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1583e-04 - fbeta: 1.0000 - val_loss: 0.7043 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04148: val_loss did not improve from 0.39496\n",
      "Epoch 4149/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1569e-04 - fbeta: 1.0000 - val_loss: 0.7064 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04149: val_loss did not improve from 0.39496\n",
      "Epoch 4150/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1558e-04 - fbeta: 1.0000 - val_loss: 0.7061 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04150: val_loss did not improve from 0.39496\n",
      "Epoch 4151/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1553e-04 - fbeta: 1.0000 - val_loss: 0.7050 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04151: val_loss did not improve from 0.39496\n",
      "Epoch 4152/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1557e-04 - fbeta: 1.0000 - val_loss: 0.7046 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04152: val_loss did not improve from 0.39496\n",
      "Epoch 4153/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1571e-04 - fbeta: 1.0000 - val_loss: 0.7044 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04153: val_loss did not improve from 0.39496\n",
      "Epoch 4154/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1564e-04 - fbeta: 1.0000 - val_loss: 0.7043 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04154: val_loss did not improve from 0.39496\n",
      "Epoch 4155/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1554e-04 - fbeta: 1.0000 - val_loss: 0.7027 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04155: val_loss did not improve from 0.39496\n",
      "Epoch 4156/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1553e-04 - fbeta: 1.0000 - val_loss: 0.7050 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04156: val_loss did not improve from 0.39496\n",
      "Epoch 4157/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1532e-04 - fbeta: 1.0000 - val_loss: 0.7049 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04157: val_loss did not improve from 0.39496\n",
      "Epoch 4158/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1525e-04 - fbeta: 1.0000 - val_loss: 0.7052 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04158: val_loss did not improve from 0.39496\n",
      "Epoch 4159/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1531e-04 - fbeta: 1.0000 - val_loss: 0.7040 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04159: val_loss did not improve from 0.39496\n",
      "Epoch 4160/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1516e-04 - fbeta: 1.0000 - val_loss: 0.7049 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04160: val_loss did not improve from 0.39496\n",
      "Epoch 4161/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1525e-04 - fbeta: 1.0000 - val_loss: 0.7049 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04161: val_loss did not improve from 0.39496\n",
      "Epoch 4162/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1527e-04 - fbeta: 1.0000 - val_loss: 0.7048 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04162: val_loss did not improve from 0.39496\n",
      "Epoch 4163/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1513e-04 - fbeta: 1.0000 - val_loss: 0.7041 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04163: val_loss did not improve from 0.39496\n",
      "Epoch 4164/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1518e-04 - fbeta: 1.0000 - val_loss: 0.7052 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04164: val_loss did not improve from 0.39496\n",
      "Epoch 4165/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1498e-04 - fbeta: 1.0000 - val_loss: 0.7067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04165: val_loss did not improve from 0.39496\n",
      "Epoch 4166/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1513e-04 - fbeta: 1.0000 - val_loss: 0.7064 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04166: val_loss did not improve from 0.39496\n",
      "Epoch 4167/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1500e-04 - fbeta: 1.0000 - val_loss: 0.7064 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04167: val_loss did not improve from 0.39496\n",
      "Epoch 4168/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1498e-04 - fbeta: 1.0000 - val_loss: 0.7071 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04168: val_loss did not improve from 0.39496\n",
      "Epoch 4169/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1496e-04 - fbeta: 1.0000 - val_loss: 0.7066 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04169: val_loss did not improve from 0.39496\n",
      "Epoch 4170/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1500e-04 - fbeta: 1.0000 - val_loss: 0.7062 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04170: val_loss did not improve from 0.39496\n",
      "Epoch 4171/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1485e-04 - fbeta: 1.0000 - val_loss: 0.7065 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04171: val_loss did not improve from 0.39496\n",
      "Epoch 4172/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1483e-04 - fbeta: 1.0000 - val_loss: 0.7070 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04172: val_loss did not improve from 0.39496\n",
      "Epoch 4173/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1498e-04 - fbeta: 1.0000 - val_loss: 0.7063 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04173: val_loss did not improve from 0.39496\n",
      "Epoch 4174/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1480e-04 - fbeta: 1.0000 - val_loss: 0.7064 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04174: val_loss did not improve from 0.39496\n",
      "Epoch 4175/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1480e-04 - fbeta: 1.0000 - val_loss: 0.7062 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04175: val_loss did not improve from 0.39496\n",
      "Epoch 4176/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1463e-04 - fbeta: 1.0000 - val_loss: 0.7045 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04176: val_loss did not improve from 0.39496\n",
      "Epoch 4177/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1491e-04 - fbeta: 1.0000 - val_loss: 0.6997 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04177: val_loss did not improve from 0.39496\n",
      "Epoch 4178/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1482e-04 - fbeta: 1.0000 - val_loss: 0.7016 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04178: val_loss did not improve from 0.39496\n",
      "Epoch 4179/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1463e-04 - fbeta: 1.0000 - val_loss: 0.7032 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04179: val_loss did not improve from 0.39496\n",
      "Epoch 4180/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1459e-04 - fbeta: 1.0000 - val_loss: 0.7046 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04180: val_loss did not improve from 0.39496\n",
      "Epoch 4181/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1451e-04 - fbeta: 1.0000 - val_loss: 0.7047 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04181: val_loss did not improve from 0.39496\n",
      "Epoch 4182/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1450e-04 - fbeta: 1.0000 - val_loss: 0.7044 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04182: val_loss did not improve from 0.39496\n",
      "Epoch 4183/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1439e-04 - fbeta: 1.0000 - val_loss: 0.7059 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04183: val_loss did not improve from 0.39496\n",
      "Epoch 4184/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1446e-04 - fbeta: 1.0000 - val_loss: 0.7078 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04184: val_loss did not improve from 0.39496\n",
      "Epoch 4185/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1447e-04 - fbeta: 1.0000 - val_loss: 0.7073 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04185: val_loss did not improve from 0.39496\n",
      "Epoch 4186/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1426e-04 - fbeta: 1.0000 - val_loss: 0.7063 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04186: val_loss did not improve from 0.39496\n",
      "Epoch 4187/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1436e-04 - fbeta: 1.0000 - val_loss: 0.7008 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04187: val_loss did not improve from 0.39496\n",
      "Epoch 4188/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1443e-04 - fbeta: 1.0000 - val_loss: 0.7032 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04188: val_loss did not improve from 0.39496\n",
      "Epoch 4189/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1435e-04 - fbeta: 1.0000 - val_loss: 0.7059 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04189: val_loss did not improve from 0.39496\n",
      "Epoch 4190/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1424e-04 - fbeta: 1.0000 - val_loss: 0.7052 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04190: val_loss did not improve from 0.39496\n",
      "Epoch 4191/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1420e-04 - fbeta: 1.0000 - val_loss: 0.7043 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04191: val_loss did not improve from 0.39496\n",
      "Epoch 4192/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1405e-04 - fbeta: 1.0000 - val_loss: 0.7044 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04192: val_loss did not improve from 0.39496\n",
      "Epoch 4193/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1423e-04 - fbeta: 1.0000 - val_loss: 0.7048 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04193: val_loss did not improve from 0.39496\n",
      "Epoch 4194/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1417e-04 - fbeta: 1.0000 - val_loss: 0.7039 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04194: val_loss did not improve from 0.39496\n",
      "Epoch 4195/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1421e-04 - fbeta: 1.0000 - val_loss: 0.7040 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04195: val_loss did not improve from 0.39496\n",
      "Epoch 4196/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1414e-04 - fbeta: 1.0000 - val_loss: 0.7037 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04196: val_loss did not improve from 0.39496\n",
      "Epoch 4197/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1402e-04 - fbeta: 1.0000 - val_loss: 0.7045 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04197: val_loss did not improve from 0.39496\n",
      "Epoch 4198/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1391e-04 - fbeta: 1.0000 - val_loss: 0.7055 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04198: val_loss did not improve from 0.39496\n",
      "Epoch 4199/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1394e-04 - fbeta: 1.0000 - val_loss: 0.7057 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04199: val_loss did not improve from 0.39496\n",
      "Epoch 4200/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1392e-04 - fbeta: 1.0000 - val_loss: 0.7101 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04200: val_loss did not improve from 0.39496\n",
      "Epoch 4201/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1405e-04 - fbeta: 1.0000 - val_loss: 0.7090 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04201: val_loss did not improve from 0.39496\n",
      "Epoch 4202/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1394e-04 - fbeta: 1.0000 - val_loss: 0.7084 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04202: val_loss did not improve from 0.39496\n",
      "Epoch 4203/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1404e-04 - fbeta: 1.0000 - val_loss: 0.7074 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04203: val_loss did not improve from 0.39496\n",
      "Epoch 4204/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1379e-04 - fbeta: 1.0000 - val_loss: 0.7057 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04204: val_loss did not improve from 0.39496\n",
      "Epoch 4205/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1379e-04 - fbeta: 1.0000 - val_loss: 0.7068 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04205: val_loss did not improve from 0.39496\n",
      "Epoch 4206/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1369e-04 - fbeta: 1.0000 - val_loss: 0.7064 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04206: val_loss did not improve from 0.39496\n",
      "Epoch 4207/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1372e-04 - fbeta: 1.0000 - val_loss: 0.7054 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04207: val_loss did not improve from 0.39496\n",
      "Epoch 4208/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1353e-04 - fbeta: 1.0000 - val_loss: 0.7041 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04208: val_loss did not improve from 0.39496\n",
      "Epoch 4209/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1366e-04 - fbeta: 1.0000 - val_loss: 0.7048 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04209: val_loss did not improve from 0.39496\n",
      "Epoch 4210/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1368e-04 - fbeta: 1.0000 - val_loss: 0.7074 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04210: val_loss did not improve from 0.39496\n",
      "Epoch 4211/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1352e-04 - fbeta: 1.0000 - val_loss: 0.7073 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04211: val_loss did not improve from 0.39496\n",
      "Epoch 4212/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1372e-04 - fbeta: 1.0000 - val_loss: 0.7084 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04212: val_loss did not improve from 0.39496\n",
      "Epoch 4213/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1355e-04 - fbeta: 1.0000 - val_loss: 0.7069 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04213: val_loss did not improve from 0.39496\n",
      "Epoch 4214/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1352e-04 - fbeta: 1.0000 - val_loss: 0.7070 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04214: val_loss did not improve from 0.39496\n",
      "Epoch 4215/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1335e-04 - fbeta: 1.0000 - val_loss: 0.7065 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04215: val_loss did not improve from 0.39496\n",
      "Epoch 4216/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1345e-04 - fbeta: 1.0000 - val_loss: 0.7074 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04216: val_loss did not improve from 0.39496\n",
      "Epoch 4217/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1335e-04 - fbeta: 1.0000 - val_loss: 0.7065 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04217: val_loss did not improve from 0.39496\n",
      "Epoch 4218/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1337e-04 - fbeta: 1.0000 - val_loss: 0.7054 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04218: val_loss did not improve from 0.39496\n",
      "Epoch 4219/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1332e-04 - fbeta: 1.0000 - val_loss: 0.7062 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04219: val_loss did not improve from 0.39496\n",
      "Epoch 4220/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1358e-04 - fbeta: 1.0000 - val_loss: 0.7057 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04220: val_loss did not improve from 0.39496\n",
      "Epoch 4221/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1342e-04 - fbeta: 1.0000 - val_loss: 0.7058 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04221: val_loss did not improve from 0.39496\n",
      "Epoch 4222/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1327e-04 - fbeta: 1.0000 - val_loss: 0.7042 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04222: val_loss did not improve from 0.39496\n",
      "Epoch 4223/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1338e-04 - fbeta: 1.0000 - val_loss: 0.7058 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04223: val_loss did not improve from 0.39496\n",
      "Epoch 4224/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1324e-04 - fbeta: 1.0000 - val_loss: 0.7054 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04224: val_loss did not improve from 0.39496\n",
      "Epoch 4225/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1316e-04 - fbeta: 1.0000 - val_loss: 0.7059 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04225: val_loss did not improve from 0.39496\n",
      "Epoch 4226/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1314e-04 - fbeta: 1.0000 - val_loss: 0.7061 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04226: val_loss did not improve from 0.39496\n",
      "Epoch 4227/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1309e-04 - fbeta: 1.0000 - val_loss: 0.7057 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04227: val_loss did not improve from 0.39496\n",
      "Epoch 4228/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1322e-04 - fbeta: 1.0000 - val_loss: 0.7095 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04228: val_loss did not improve from 0.39496\n",
      "Epoch 4229/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1331e-04 - fbeta: 1.0000 - val_loss: 0.7082 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04229: val_loss did not improve from 0.39496\n",
      "Epoch 4230/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1308e-04 - fbeta: 1.0000 - val_loss: 0.7078 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04230: val_loss did not improve from 0.39496\n",
      "Epoch 4231/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1294e-04 - fbeta: 1.0000 - val_loss: 0.7069 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04231: val_loss did not improve from 0.39496\n",
      "Epoch 4232/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1295e-04 - fbeta: 1.0000 - val_loss: 0.7064 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04232: val_loss did not improve from 0.39496\n",
      "Epoch 4233/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1286e-04 - fbeta: 1.0000 - val_loss: 0.7066 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04233: val_loss did not improve from 0.39496\n",
      "Epoch 4234/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1330e-04 - fbeta: 1.0000 - val_loss: 0.7059 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04234: val_loss did not improve from 0.39496\n",
      "Epoch 4235/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1295e-04 - fbeta: 1.0000 - val_loss: 0.7068 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04235: val_loss did not improve from 0.39496\n",
      "Epoch 4236/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1287e-04 - fbeta: 1.0000 - val_loss: 0.7062 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04236: val_loss did not improve from 0.39496\n",
      "Epoch 4237/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1287e-04 - fbeta: 1.0000 - val_loss: 0.7054 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04237: val_loss did not improve from 0.39496\n",
      "Epoch 4238/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1273e-04 - fbeta: 1.0000 - val_loss: 0.7061 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04238: val_loss did not improve from 0.39496\n",
      "Epoch 4239/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1270e-04 - fbeta: 1.0000 - val_loss: 0.7046 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04239: val_loss did not improve from 0.39496\n",
      "Epoch 4240/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1281e-04 - fbeta: 1.0000 - val_loss: 0.7000 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04240: val_loss did not improve from 0.39496\n",
      "Epoch 4241/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1278e-04 - fbeta: 1.0000 - val_loss: 0.7018 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04241: val_loss did not improve from 0.39496\n",
      "Epoch 4242/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1269e-04 - fbeta: 1.0000 - val_loss: 0.7025 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04242: val_loss did not improve from 0.39496\n",
      "Epoch 4243/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1253e-04 - fbeta: 1.0000 - val_loss: 0.7007 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04243: val_loss did not improve from 0.39496\n",
      "Epoch 4244/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1255e-04 - fbeta: 1.0000 - val_loss: 0.7020 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04244: val_loss did not improve from 0.39496\n",
      "Epoch 4245/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1244e-04 - fbeta: 1.0000 - val_loss: 0.7045 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04245: val_loss did not improve from 0.39496\n",
      "Epoch 4246/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1240e-04 - fbeta: 1.0000 - val_loss: 0.7049 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04246: val_loss did not improve from 0.39496\n",
      "Epoch 4247/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1280e-04 - fbeta: 1.0000 - val_loss: 0.7059 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04247: val_loss did not improve from 0.39496\n",
      "Epoch 4248/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1258e-04 - fbeta: 1.0000 - val_loss: 0.7043 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04248: val_loss did not improve from 0.39496\n",
      "Epoch 4249/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1251e-04 - fbeta: 1.0000 - val_loss: 0.7043 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04249: val_loss did not improve from 0.39496\n",
      "Epoch 4250/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1240e-04 - fbeta: 1.0000 - val_loss: 0.7036 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04250: val_loss did not improve from 0.39496\n",
      "Epoch 4251/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1217e-04 - fbeta: 1.0000 - val_loss: 0.7052 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04251: val_loss did not improve from 0.39496\n",
      "Epoch 4252/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1213e-04 - fbeta: 1.0000 - val_loss: 0.7054 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04252: val_loss did not improve from 0.39496\n",
      "Epoch 4253/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1218e-04 - fbeta: 1.0000 - val_loss: 0.7050 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04253: val_loss did not improve from 0.39496\n",
      "Epoch 4254/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1216e-04 - fbeta: 1.0000 - val_loss: 0.7057 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04254: val_loss did not improve from 0.39496\n",
      "Epoch 4255/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1200e-04 - fbeta: 1.0000 - val_loss: 0.7061 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04255: val_loss did not improve from 0.39496\n",
      "Epoch 4256/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1221e-04 - fbeta: 1.0000 - val_loss: 0.7067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04256: val_loss did not improve from 0.39496\n",
      "Epoch 4257/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1201e-04 - fbeta: 1.0000 - val_loss: 0.7073 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04257: val_loss did not improve from 0.39496\n",
      "Epoch 4258/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1214e-04 - fbeta: 1.0000 - val_loss: 0.7047 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04258: val_loss did not improve from 0.39496\n",
      "Epoch 4259/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1198e-04 - fbeta: 1.0000 - val_loss: 0.7046 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04259: val_loss did not improve from 0.39496\n",
      "Epoch 4260/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1204e-04 - fbeta: 1.0000 - val_loss: 0.7058 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04260: val_loss did not improve from 0.39496\n",
      "Epoch 4261/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1186e-04 - fbeta: 1.0000 - val_loss: 0.7047 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04261: val_loss did not improve from 0.39496\n",
      "Epoch 4262/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1194e-04 - fbeta: 1.0000 - val_loss: 0.7037 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04262: val_loss did not improve from 0.39496\n",
      "Epoch 4263/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1192e-04 - fbeta: 1.0000 - val_loss: 0.7056 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04263: val_loss did not improve from 0.39496\n",
      "Epoch 4264/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1191e-04 - fbeta: 1.0000 - val_loss: 0.7070 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04264: val_loss did not improve from 0.39496\n",
      "Epoch 4265/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1186e-04 - fbeta: 1.0000 - val_loss: 0.7059 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04265: val_loss did not improve from 0.39496\n",
      "Epoch 4266/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1196e-04 - fbeta: 1.0000 - val_loss: 0.7080 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04266: val_loss did not improve from 0.39496\n",
      "Epoch 4267/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1172e-04 - fbeta: 1.0000 - val_loss: 0.7071 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04267: val_loss did not improve from 0.39496\n",
      "Epoch 4268/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1182e-04 - fbeta: 1.0000 - val_loss: 0.7072 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04268: val_loss did not improve from 0.39496\n",
      "Epoch 4269/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1185e-04 - fbeta: 1.0000 - val_loss: 0.7079 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04269: val_loss did not improve from 0.39496\n",
      "Epoch 4270/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1166e-04 - fbeta: 1.0000 - val_loss: 0.7062 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04270: val_loss did not improve from 0.39496\n",
      "Epoch 4271/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1160e-04 - fbeta: 1.0000 - val_loss: 0.7066 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04271: val_loss did not improve from 0.39496\n",
      "Epoch 4272/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1161e-04 - fbeta: 1.0000 - val_loss: 0.7067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04272: val_loss did not improve from 0.39496\n",
      "Epoch 4273/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1156e-04 - fbeta: 1.0000 - val_loss: 0.7069 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04273: val_loss did not improve from 0.39496\n",
      "Epoch 4274/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1178e-04 - fbeta: 1.0000 - val_loss: 0.7014 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04274: val_loss did not improve from 0.39496\n",
      "Epoch 4275/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1169e-04 - fbeta: 1.0000 - val_loss: 0.7037 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04275: val_loss did not improve from 0.39496\n",
      "Epoch 4276/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1152e-04 - fbeta: 1.0000 - val_loss: 0.7055 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04276: val_loss did not improve from 0.39496\n",
      "Epoch 4277/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1160e-04 - fbeta: 1.0000 - val_loss: 0.7066 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04277: val_loss did not improve from 0.39496\n",
      "Epoch 4278/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1141e-04 - fbeta: 1.0000 - val_loss: 0.7067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04278: val_loss did not improve from 0.39496\n",
      "Epoch 4279/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1135e-04 - fbeta: 1.0000 - val_loss: 0.7076 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04279: val_loss did not improve from 0.39496\n",
      "Epoch 4280/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1136e-04 - fbeta: 1.0000 - val_loss: 0.7081 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04280: val_loss did not improve from 0.39496\n",
      "Epoch 4281/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1141e-04 - fbeta: 1.0000 - val_loss: 0.7080 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04281: val_loss did not improve from 0.39496\n",
      "Epoch 4282/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1131e-04 - fbeta: 1.0000 - val_loss: 0.7076 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04282: val_loss did not improve from 0.39496\n",
      "Epoch 4283/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1129e-04 - fbeta: 1.0000 - val_loss: 0.7074 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04283: val_loss did not improve from 0.39496\n",
      "Epoch 4284/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1126e-04 - fbeta: 1.0000 - val_loss: 0.7074 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04284: val_loss did not improve from 0.39496\n",
      "Epoch 4285/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1118e-04 - fbeta: 1.0000 - val_loss: 0.7074 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04285: val_loss did not improve from 0.39496\n",
      "Epoch 4286/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1121e-04 - fbeta: 1.0000 - val_loss: 0.7060 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04286: val_loss did not improve from 0.39496\n",
      "Epoch 4287/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1130e-04 - fbeta: 1.0000 - val_loss: 0.7077 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04287: val_loss did not improve from 0.39496\n",
      "Epoch 4288/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1125e-04 - fbeta: 1.0000 - val_loss: 0.7073 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04288: val_loss did not improve from 0.39496\n",
      "Epoch 4289/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1113e-04 - fbeta: 1.0000 - val_loss: 0.7080 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04289: val_loss did not improve from 0.39496\n",
      "Epoch 4290/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1109e-04 - fbeta: 1.0000 - val_loss: 0.7087 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04290: val_loss did not improve from 0.39496\n",
      "Epoch 4291/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1110e-04 - fbeta: 1.0000 - val_loss: 0.7080 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04291: val_loss did not improve from 0.39496\n",
      "Epoch 4292/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1105e-04 - fbeta: 1.0000 - val_loss: 0.7076 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04292: val_loss did not improve from 0.39496\n",
      "Epoch 4293/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1103e-04 - fbeta: 1.0000 - val_loss: 0.7077 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04293: val_loss did not improve from 0.39496\n",
      "Epoch 4294/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1095e-04 - fbeta: 1.0000 - val_loss: 0.7069 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04294: val_loss did not improve from 0.39496\n",
      "Epoch 4295/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1085e-04 - fbeta: 1.0000 - val_loss: 0.7070 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04295: val_loss did not improve from 0.39496\n",
      "Epoch 4296/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1097e-04 - fbeta: 1.0000 - val_loss: 0.7075 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04296: val_loss did not improve from 0.39496\n",
      "Epoch 4297/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1085e-04 - fbeta: 1.0000 - val_loss: 0.7082 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04297: val_loss did not improve from 0.39496\n",
      "Epoch 4298/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1083e-04 - fbeta: 1.0000 - val_loss: 0.7099 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04298: val_loss did not improve from 0.39496\n",
      "Epoch 4299/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1080e-04 - fbeta: 1.0000 - val_loss: 0.7081 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04299: val_loss did not improve from 0.39496\n",
      "Epoch 4300/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1089e-04 - fbeta: 1.0000 - val_loss: 0.7076 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04300: val_loss did not improve from 0.39496\n",
      "Epoch 4301/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1063e-04 - fbeta: 1.0000 - val_loss: 0.7058 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04301: val_loss did not improve from 0.39496\n",
      "Epoch 4302/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1068e-04 - fbeta: 1.0000 - val_loss: 0.7064 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04302: val_loss did not improve from 0.39496\n",
      "Epoch 4303/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1059e-04 - fbeta: 1.0000 - val_loss: 0.7057 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04303: val_loss did not improve from 0.39496\n",
      "Epoch 4304/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1069e-04 - fbeta: 1.0000 - val_loss: 0.7068 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04304: val_loss did not improve from 0.39496\n",
      "Epoch 4305/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1058e-04 - fbeta: 1.0000 - val_loss: 0.7063 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04305: val_loss did not improve from 0.39496\n",
      "Epoch 4306/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1049e-04 - fbeta: 1.0000 - val_loss: 0.7073 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04306: val_loss did not improve from 0.39496\n",
      "Epoch 4307/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1047e-04 - fbeta: 1.0000 - val_loss: 0.7090 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04307: val_loss did not improve from 0.39496\n",
      "Epoch 4308/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1054e-04 - fbeta: 1.0000 - val_loss: 0.7085 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04308: val_loss did not improve from 0.39496\n",
      "Epoch 4309/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1074e-04 - fbeta: 1.0000 - val_loss: 0.7066 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04309: val_loss did not improve from 0.39496\n",
      "Epoch 4310/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1064e-04 - fbeta: 1.0000 - val_loss: 0.7071 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04310: val_loss did not improve from 0.39496\n",
      "Epoch 4311/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1045e-04 - fbeta: 1.0000 - val_loss: 0.7054 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04311: val_loss did not improve from 0.39496\n",
      "Epoch 4312/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1036e-04 - fbeta: 1.0000 - val_loss: 0.7060 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04312: val_loss did not improve from 0.39496\n",
      "Epoch 4313/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1042e-04 - fbeta: 1.0000 - val_loss: 0.7058 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04313: val_loss did not improve from 0.39496\n",
      "Epoch 4314/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1036e-04 - fbeta: 1.0000 - val_loss: 0.7068 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04314: val_loss did not improve from 0.39496\n",
      "Epoch 4315/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1022e-04 - fbeta: 1.0000 - val_loss: 0.7072 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04315: val_loss did not improve from 0.39496\n",
      "Epoch 4316/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1025e-04 - fbeta: 1.0000 - val_loss: 0.7063 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04316: val_loss did not improve from 0.39496\n",
      "Epoch 4317/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1013e-04 - fbeta: 1.0000 - val_loss: 0.7066 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04317: val_loss did not improve from 0.39496\n",
      "Epoch 4318/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1014e-04 - fbeta: 1.0000 - val_loss: 0.7064 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04318: val_loss did not improve from 0.39496\n",
      "Epoch 4319/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1020e-04 - fbeta: 1.0000 - val_loss: 0.7069 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04319: val_loss did not improve from 0.39496\n",
      "Epoch 4320/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1001e-04 - fbeta: 1.0000 - val_loss: 0.7073 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04320: val_loss did not improve from 0.39496\n",
      "Epoch 4321/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1008e-04 - fbeta: 1.0000 - val_loss: 0.7076 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04321: val_loss did not improve from 0.39496\n",
      "Epoch 4322/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1000e-04 - fbeta: 1.0000 - val_loss: 0.7065 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04322: val_loss did not improve from 0.39496\n",
      "Epoch 4323/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1000e-04 - fbeta: 1.0000 - val_loss: 0.7070 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04323: val_loss did not improve from 0.39496\n",
      "Epoch 4324/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0999e-04 - fbeta: 1.0000 - val_loss: 0.7061 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04324: val_loss did not improve from 0.39496\n",
      "Epoch 4325/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0996e-04 - fbeta: 1.0000 - val_loss: 0.7064 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04325: val_loss did not improve from 0.39496\n",
      "Epoch 4326/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0993e-04 - fbeta: 1.0000 - val_loss: 0.7081 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04326: val_loss did not improve from 0.39496\n",
      "Epoch 4327/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1005e-04 - fbeta: 1.0000 - val_loss: 0.7079 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04327: val_loss did not improve from 0.39496\n",
      "Epoch 4328/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0984e-04 - fbeta: 1.0000 - val_loss: 0.7082 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04328: val_loss did not improve from 0.39496\n",
      "Epoch 4329/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.1010e-04 - fbeta: 1.0000 - val_loss: 0.7100 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04329: val_loss did not improve from 0.39496\n",
      "Epoch 4330/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0997e-04 - fbeta: 1.0000 - val_loss: 0.7103 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04330: val_loss did not improve from 0.39496\n",
      "Epoch 4331/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0987e-04 - fbeta: 1.0000 - val_loss: 0.7098 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04331: val_loss did not improve from 0.39496\n",
      "Epoch 4332/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0987e-04 - fbeta: 1.0000 - val_loss: 0.7095 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04332: val_loss did not improve from 0.39496\n",
      "Epoch 4333/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0977e-04 - fbeta: 1.0000 - val_loss: 0.7077 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04333: val_loss did not improve from 0.39496\n",
      "Epoch 4334/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0973e-04 - fbeta: 1.0000 - val_loss: 0.7074 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04334: val_loss did not improve from 0.39496\n",
      "Epoch 4335/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0966e-04 - fbeta: 1.0000 - val_loss: 0.7076 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04335: val_loss did not improve from 0.39496\n",
      "Epoch 4336/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0952e-04 - fbeta: 1.0000 - val_loss: 0.7069 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04336: val_loss did not improve from 0.39496\n",
      "Epoch 4337/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0951e-04 - fbeta: 1.0000 - val_loss: 0.7078 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04337: val_loss did not improve from 0.39496\n",
      "Epoch 4338/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0947e-04 - fbeta: 1.0000 - val_loss: 0.7073 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04338: val_loss did not improve from 0.39496\n",
      "Epoch 4339/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0955e-04 - fbeta: 1.0000 - val_loss: 0.7072 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04339: val_loss did not improve from 0.39496\n",
      "Epoch 4340/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0951e-04 - fbeta: 1.0000 - val_loss: 0.7059 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04340: val_loss did not improve from 0.39496\n",
      "Epoch 4341/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0952e-04 - fbeta: 1.0000 - val_loss: 0.7071 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04341: val_loss did not improve from 0.39496\n",
      "Epoch 4342/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0945e-04 - fbeta: 1.0000 - val_loss: 0.7067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04342: val_loss did not improve from 0.39496\n",
      "Epoch 4343/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0947e-04 - fbeta: 1.0000 - val_loss: 0.7069 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04343: val_loss did not improve from 0.39496\n",
      "Epoch 4344/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0945e-04 - fbeta: 1.0000 - val_loss: 0.7072 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04344: val_loss did not improve from 0.39496\n",
      "Epoch 4345/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0934e-04 - fbeta: 1.0000 - val_loss: 0.7069 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04345: val_loss did not improve from 0.39496\n",
      "Epoch 4346/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0940e-04 - fbeta: 1.0000 - val_loss: 0.7067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04346: val_loss did not improve from 0.39496\n",
      "Epoch 4347/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0939e-04 - fbeta: 1.0000 - val_loss: 0.7073 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04347: val_loss did not improve from 0.39496\n",
      "Epoch 4348/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0921e-04 - fbeta: 1.0000 - val_loss: 0.7079 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04348: val_loss did not improve from 0.39496\n",
      "Epoch 4349/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0942e-04 - fbeta: 1.0000 - val_loss: 0.7106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04349: val_loss did not improve from 0.39496\n",
      "Epoch 4350/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0941e-04 - fbeta: 1.0000 - val_loss: 0.7103 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04350: val_loss did not improve from 0.39496\n",
      "Epoch 4351/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0932e-04 - fbeta: 1.0000 - val_loss: 0.7093 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04351: val_loss did not improve from 0.39496\n",
      "Epoch 4352/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0911e-04 - fbeta: 1.0000 - val_loss: 0.7089 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04352: val_loss did not improve from 0.39496\n",
      "Epoch 4353/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0917e-04 - fbeta: 1.0000 - val_loss: 0.7095 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04353: val_loss did not improve from 0.39496\n",
      "Epoch 4354/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0907e-04 - fbeta: 1.0000 - val_loss: 0.7093 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04354: val_loss did not improve from 0.39496\n",
      "Epoch 4355/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0909e-04 - fbeta: 1.0000 - val_loss: 0.7088 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04355: val_loss did not improve from 0.39496\n",
      "Epoch 4356/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0898e-04 - fbeta: 1.0000 - val_loss: 0.7090 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04356: val_loss did not improve from 0.39496\n",
      "Epoch 4357/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0907e-04 - fbeta: 1.0000 - val_loss: 0.7092 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04357: val_loss did not improve from 0.39496\n",
      "Epoch 4358/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0901e-04 - fbeta: 1.0000 - val_loss: 0.7097 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04358: val_loss did not improve from 0.39496\n",
      "Epoch 4359/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0900e-04 - fbeta: 1.0000 - val_loss: 0.7094 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04359: val_loss did not improve from 0.39496\n",
      "Epoch 4360/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0913e-04 - fbeta: 1.0000 - val_loss: 0.7103 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04360: val_loss did not improve from 0.39496\n",
      "Epoch 4361/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0892e-04 - fbeta: 1.0000 - val_loss: 0.7107 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04361: val_loss did not improve from 0.39496\n",
      "Epoch 4362/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0903e-04 - fbeta: 1.0000 - val_loss: 0.7111 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04362: val_loss did not improve from 0.39496\n",
      "Epoch 4363/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0900e-04 - fbeta: 1.0000 - val_loss: 0.7106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04363: val_loss did not improve from 0.39496\n",
      "Epoch 4364/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0889e-04 - fbeta: 1.0000 - val_loss: 0.7098 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04364: val_loss did not improve from 0.39496\n",
      "Epoch 4365/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0888e-04 - fbeta: 1.0000 - val_loss: 0.7098 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04365: val_loss did not improve from 0.39496\n",
      "Epoch 4366/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0874e-04 - fbeta: 1.0000 - val_loss: 0.7092 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04366: val_loss did not improve from 0.39496\n",
      "Epoch 4367/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0874e-04 - fbeta: 1.0000 - val_loss: 0.7102 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04367: val_loss did not improve from 0.39496\n",
      "Epoch 4368/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0870e-04 - fbeta: 1.0000 - val_loss: 0.7091 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04368: val_loss did not improve from 0.39496\n",
      "Epoch 4369/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0867e-04 - fbeta: 1.0000 - val_loss: 0.7094 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04369: val_loss did not improve from 0.39496\n",
      "Epoch 4370/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0868e-04 - fbeta: 1.0000 - val_loss: 0.7091 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04370: val_loss did not improve from 0.39496\n",
      "Epoch 4371/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0870e-04 - fbeta: 1.0000 - val_loss: 0.7100 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04371: val_loss did not improve from 0.39496\n",
      "Epoch 4372/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0874e-04 - fbeta: 1.0000 - val_loss: 0.7096 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04372: val_loss did not improve from 0.39496\n",
      "Epoch 4373/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0869e-04 - fbeta: 1.0000 - val_loss: 0.7100 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04373: val_loss did not improve from 0.39496\n",
      "Epoch 4374/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0876e-04 - fbeta: 1.0000 - val_loss: 0.7106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04374: val_loss did not improve from 0.39496\n",
      "Epoch 4375/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0871e-04 - fbeta: 1.0000 - val_loss: 0.7089 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04375: val_loss did not improve from 0.39496\n",
      "Epoch 4376/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0857e-04 - fbeta: 1.0000 - val_loss: 0.7094 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04376: val_loss did not improve from 0.39496\n",
      "Epoch 4377/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0852e-04 - fbeta: 1.0000 - val_loss: 0.7099 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04377: val_loss did not improve from 0.39496\n",
      "Epoch 4378/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0838e-04 - fbeta: 1.0000 - val_loss: 0.7088 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04378: val_loss did not improve from 0.39496\n",
      "Epoch 4379/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0866e-04 - fbeta: 1.0000 - val_loss: 0.7082 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04379: val_loss did not improve from 0.39496\n",
      "Epoch 4380/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0837e-04 - fbeta: 1.0000 - val_loss: 0.7083 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04380: val_loss did not improve from 0.39496\n",
      "Epoch 4381/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0831e-04 - fbeta: 1.0000 - val_loss: 0.7085 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04381: val_loss did not improve from 0.39496\n",
      "Epoch 4382/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0823e-04 - fbeta: 1.0000 - val_loss: 0.7077 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04382: val_loss did not improve from 0.39496\n",
      "Epoch 4383/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0839e-04 - fbeta: 1.0000 - val_loss: 0.7075 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04383: val_loss did not improve from 0.39496\n",
      "Epoch 4384/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0816e-04 - fbeta: 1.0000 - val_loss: 0.7067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04384: val_loss did not improve from 0.39496\n",
      "Epoch 4385/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0815e-04 - fbeta: 1.0000 - val_loss: 0.7071 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04385: val_loss did not improve from 0.39496\n",
      "Epoch 4386/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0809e-04 - fbeta: 1.0000 - val_loss: 0.7071 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04386: val_loss did not improve from 0.39496\n",
      "Epoch 4387/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0835e-04 - fbeta: 1.0000 - val_loss: 0.7058 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04387: val_loss did not improve from 0.39496\n",
      "Epoch 4388/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0809e-04 - fbeta: 1.0000 - val_loss: 0.7064 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04388: val_loss did not improve from 0.39496\n",
      "Epoch 4389/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0828e-04 - fbeta: 1.0000 - val_loss: 0.7050 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04389: val_loss did not improve from 0.39496\n",
      "Epoch 4390/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0808e-04 - fbeta: 1.0000 - val_loss: 0.7058 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04390: val_loss did not improve from 0.39496\n",
      "Epoch 4391/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0803e-04 - fbeta: 1.0000 - val_loss: 0.7071 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04391: val_loss did not improve from 0.39496\n",
      "Epoch 4392/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0797e-04 - fbeta: 1.0000 - val_loss: 0.7071 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04392: val_loss did not improve from 0.39496\n",
      "Epoch 4393/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0795e-04 - fbeta: 1.0000 - val_loss: 0.7080 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04393: val_loss did not improve from 0.39496\n",
      "Epoch 4394/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0802e-04 - fbeta: 1.0000 - val_loss: 0.7086 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04394: val_loss did not improve from 0.39496\n",
      "Epoch 4395/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0795e-04 - fbeta: 1.0000 - val_loss: 0.7075 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04395: val_loss did not improve from 0.39496\n",
      "Epoch 4396/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0797e-04 - fbeta: 1.0000 - val_loss: 0.7078 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04396: val_loss did not improve from 0.39496\n",
      "Epoch 4397/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0790e-04 - fbeta: 1.0000 - val_loss: 0.7080 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04397: val_loss did not improve from 0.39496\n",
      "Epoch 4398/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0773e-04 - fbeta: 1.0000 - val_loss: 0.7098 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04398: val_loss did not improve from 0.39496\n",
      "Epoch 4399/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0788e-04 - fbeta: 1.0000 - val_loss: 0.7091 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04399: val_loss did not improve from 0.39496\n",
      "Epoch 4400/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0788e-04 - fbeta: 1.0000 - val_loss: 0.7098 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04400: val_loss did not improve from 0.39496\n",
      "Epoch 4401/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0782e-04 - fbeta: 1.0000 - val_loss: 0.7100 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04401: val_loss did not improve from 0.39496\n",
      "Epoch 4402/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0766e-04 - fbeta: 1.0000 - val_loss: 0.7098 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04402: val_loss did not improve from 0.39496\n",
      "Epoch 4403/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0772e-04 - fbeta: 1.0000 - val_loss: 0.7097 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04403: val_loss did not improve from 0.39496\n",
      "Epoch 4404/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0762e-04 - fbeta: 1.0000 - val_loss: 0.7108 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04404: val_loss did not improve from 0.39496\n",
      "Epoch 4405/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0767e-04 - fbeta: 1.0000 - val_loss: 0.7085 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04405: val_loss did not improve from 0.39496\n",
      "Epoch 4406/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0761e-04 - fbeta: 1.0000 - val_loss: 0.7089 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04406: val_loss did not improve from 0.39496\n",
      "Epoch 4407/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0749e-04 - fbeta: 1.0000 - val_loss: 0.7067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04407: val_loss did not improve from 0.39496\n",
      "Epoch 4408/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0758e-04 - fbeta: 1.0000 - val_loss: 0.7086 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04408: val_loss did not improve from 0.39496\n",
      "Epoch 4409/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0751e-04 - fbeta: 1.0000 - val_loss: 0.7074 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04409: val_loss did not improve from 0.39496\n",
      "Epoch 4410/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0751e-04 - fbeta: 1.0000 - val_loss: 0.7053 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04410: val_loss did not improve from 0.39496\n",
      "Epoch 4411/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0733e-04 - fbeta: 1.0000 - val_loss: 0.7067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04411: val_loss did not improve from 0.39496\n",
      "Epoch 4412/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0741e-04 - fbeta: 1.0000 - val_loss: 0.7067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04412: val_loss did not improve from 0.39496\n",
      "Epoch 4413/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0731e-04 - fbeta: 1.0000 - val_loss: 0.7058 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04413: val_loss did not improve from 0.39496\n",
      "Epoch 4414/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0727e-04 - fbeta: 1.0000 - val_loss: 0.7066 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04414: val_loss did not improve from 0.39496\n",
      "Epoch 4415/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0723e-04 - fbeta: 1.0000 - val_loss: 0.7073 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04415: val_loss did not improve from 0.39496\n",
      "Epoch 4416/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0731e-04 - fbeta: 1.0000 - val_loss: 0.7078 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04416: val_loss did not improve from 0.39496\n",
      "Epoch 4417/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0746e-04 - fbeta: 1.0000 - val_loss: 0.7073 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04417: val_loss did not improve from 0.39496\n",
      "Epoch 4418/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0727e-04 - fbeta: 1.0000 - val_loss: 0.7075 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04418: val_loss did not improve from 0.39496\n",
      "Epoch 4419/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0722e-04 - fbeta: 1.0000 - val_loss: 0.7094 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04419: val_loss did not improve from 0.39496\n",
      "Epoch 4420/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0719e-04 - fbeta: 1.0000 - val_loss: 0.7087 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04420: val_loss did not improve from 0.39496\n",
      "Epoch 4421/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0709e-04 - fbeta: 1.0000 - val_loss: 0.7075 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04421: val_loss did not improve from 0.39496\n",
      "Epoch 4422/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0708e-04 - fbeta: 1.0000 - val_loss: 0.7077 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04422: val_loss did not improve from 0.39496\n",
      "Epoch 4423/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0700e-04 - fbeta: 1.0000 - val_loss: 0.7075 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04423: val_loss did not improve from 0.39496\n",
      "Epoch 4424/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0712e-04 - fbeta: 1.0000 - val_loss: 0.7086 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04424: val_loss did not improve from 0.39496\n",
      "Epoch 4425/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0701e-04 - fbeta: 1.0000 - val_loss: 0.7112 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04425: val_loss did not improve from 0.39496\n",
      "Epoch 4426/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0712e-04 - fbeta: 1.0000 - val_loss: 0.7112 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04426: val_loss did not improve from 0.39496\n",
      "Epoch 4427/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0727e-04 - fbeta: 1.0000 - val_loss: 0.7063 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04427: val_loss did not improve from 0.39496\n",
      "Epoch 4428/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0709e-04 - fbeta: 1.0000 - val_loss: 0.7067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04428: val_loss did not improve from 0.39496\n",
      "Epoch 4429/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0703e-04 - fbeta: 1.0000 - val_loss: 0.7074 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04429: val_loss did not improve from 0.39496\n",
      "Epoch 4430/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0689e-04 - fbeta: 1.0000 - val_loss: 0.7082 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04430: val_loss did not improve from 0.39496\n",
      "Epoch 4431/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0683e-04 - fbeta: 1.0000 - val_loss: 0.7086 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04431: val_loss did not improve from 0.39496\n",
      "Epoch 4432/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0680e-04 - fbeta: 1.0000 - val_loss: 0.7082 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04432: val_loss did not improve from 0.39496\n",
      "Epoch 4433/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0684e-04 - fbeta: 1.0000 - val_loss: 0.7087 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04433: val_loss did not improve from 0.39496\n",
      "Epoch 4434/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0692e-04 - fbeta: 1.0000 - val_loss: 0.7111 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04434: val_loss did not improve from 0.39496\n",
      "Epoch 4435/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0704e-04 - fbeta: 1.0000 - val_loss: 0.7086 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04435: val_loss did not improve from 0.39496\n",
      "Epoch 4436/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0685e-04 - fbeta: 1.0000 - val_loss: 0.7067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04436: val_loss did not improve from 0.39496\n",
      "Epoch 4437/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0683e-04 - fbeta: 1.0000 - val_loss: 0.7070 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04437: val_loss did not improve from 0.39496\n",
      "Epoch 4438/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0666e-04 - fbeta: 1.0000 - val_loss: 0.7085 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04438: val_loss did not improve from 0.39496\n",
      "Epoch 4439/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0663e-04 - fbeta: 1.0000 - val_loss: 0.7055 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04439: val_loss did not improve from 0.39496\n",
      "Epoch 4440/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0671e-04 - fbeta: 1.0000 - val_loss: 0.7059 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04440: val_loss did not improve from 0.39496\n",
      "Epoch 4441/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0692e-04 - fbeta: 1.0000 - val_loss: 0.7036 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04441: val_loss did not improve from 0.39496\n",
      "Epoch 4442/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0668e-04 - fbeta: 1.0000 - val_loss: 0.7039 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04442: val_loss did not improve from 0.39496\n",
      "Epoch 4443/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0657e-04 - fbeta: 1.0000 - val_loss: 0.7044 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04443: val_loss did not improve from 0.39496\n",
      "Epoch 4444/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0668e-04 - fbeta: 1.0000 - val_loss: 0.7032 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04444: val_loss did not improve from 0.39496\n",
      "Epoch 4445/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0666e-04 - fbeta: 1.0000 - val_loss: 0.7039 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04445: val_loss did not improve from 0.39496\n",
      "Epoch 4446/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0663e-04 - fbeta: 1.0000 - val_loss: 0.7047 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04446: val_loss did not improve from 0.39496\n",
      "Epoch 4447/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0654e-04 - fbeta: 1.0000 - val_loss: 0.7064 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04447: val_loss did not improve from 0.39496\n",
      "Epoch 4448/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0631e-04 - fbeta: 1.0000 - val_loss: 0.7063 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04448: val_loss did not improve from 0.39496\n",
      "Epoch 4449/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0636e-04 - fbeta: 1.0000 - val_loss: 0.7073 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04449: val_loss did not improve from 0.39496\n",
      "Epoch 4450/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0632e-04 - fbeta: 1.0000 - val_loss: 0.7072 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04450: val_loss did not improve from 0.39496\n",
      "Epoch 4451/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0629e-04 - fbeta: 1.0000 - val_loss: 0.7080 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04451: val_loss did not improve from 0.39496\n",
      "Epoch 4452/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0640e-04 - fbeta: 1.0000 - val_loss: 0.7082 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04452: val_loss did not improve from 0.39496\n",
      "Epoch 4453/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0621e-04 - fbeta: 1.0000 - val_loss: 0.7095 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04453: val_loss did not improve from 0.39496\n",
      "Epoch 4454/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0623e-04 - fbeta: 1.0000 - val_loss: 0.7091 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04454: val_loss did not improve from 0.39496\n",
      "Epoch 4455/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0622e-04 - fbeta: 1.0000 - val_loss: 0.7083 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04455: val_loss did not improve from 0.39496\n",
      "Epoch 4456/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0618e-04 - fbeta: 1.0000 - val_loss: 0.7086 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04456: val_loss did not improve from 0.39496\n",
      "Epoch 4457/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0614e-04 - fbeta: 1.0000 - val_loss: 0.7087 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04457: val_loss did not improve from 0.39496\n",
      "Epoch 4458/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0608e-04 - fbeta: 1.0000 - val_loss: 0.7104 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04458: val_loss did not improve from 0.39496\n",
      "Epoch 4459/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0616e-04 - fbeta: 1.0000 - val_loss: 0.7101 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04459: val_loss did not improve from 0.39496\n",
      "Epoch 4460/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0601e-04 - fbeta: 1.0000 - val_loss: 0.7100 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04460: val_loss did not improve from 0.39496\n",
      "Epoch 4461/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0600e-04 - fbeta: 1.0000 - val_loss: 0.7093 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04461: val_loss did not improve from 0.39496\n",
      "Epoch 4462/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0592e-04 - fbeta: 1.0000 - val_loss: 0.7093 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04462: val_loss did not improve from 0.39496\n",
      "Epoch 4463/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0607e-04 - fbeta: 1.0000 - val_loss: 0.7095 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04463: val_loss did not improve from 0.39496\n",
      "Epoch 4464/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0583e-04 - fbeta: 1.0000 - val_loss: 0.7097 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04464: val_loss did not improve from 0.39496\n",
      "Epoch 4465/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0587e-04 - fbeta: 1.0000 - val_loss: 0.7103 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04465: val_loss did not improve from 0.39496\n",
      "Epoch 4466/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0577e-04 - fbeta: 1.0000 - val_loss: 0.7094 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04466: val_loss did not improve from 0.39496\n",
      "Epoch 4467/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0594e-04 - fbeta: 1.0000 - val_loss: 0.7089 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04467: val_loss did not improve from 0.39496\n",
      "Epoch 4468/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0587e-04 - fbeta: 1.0000 - val_loss: 0.7090 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04468: val_loss did not improve from 0.39496\n",
      "Epoch 4469/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0579e-04 - fbeta: 1.0000 - val_loss: 0.7090 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04469: val_loss did not improve from 0.39496\n",
      "Epoch 4470/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0583e-04 - fbeta: 1.0000 - val_loss: 0.7098 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04470: val_loss did not improve from 0.39496\n",
      "Epoch 4471/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0584e-04 - fbeta: 1.0000 - val_loss: 0.7104 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04471: val_loss did not improve from 0.39496\n",
      "Epoch 4472/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0565e-04 - fbeta: 1.0000 - val_loss: 0.7097 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04472: val_loss did not improve from 0.39496\n",
      "Epoch 4473/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0565e-04 - fbeta: 1.0000 - val_loss: 0.7106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04473: val_loss did not improve from 0.39496\n",
      "Epoch 4474/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0561e-04 - fbeta: 1.0000 - val_loss: 0.7106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04474: val_loss did not improve from 0.39496\n",
      "Epoch 4475/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0554e-04 - fbeta: 1.0000 - val_loss: 0.7108 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04475: val_loss did not improve from 0.39496\n",
      "Epoch 4476/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0560e-04 - fbeta: 1.0000 - val_loss: 0.7105 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04476: val_loss did not improve from 0.39496\n",
      "Epoch 4477/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0547e-04 - fbeta: 1.0000 - val_loss: 0.7091 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04477: val_loss did not improve from 0.39496\n",
      "Epoch 4478/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0553e-04 - fbeta: 1.0000 - val_loss: 0.7078 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04478: val_loss did not improve from 0.39496\n",
      "Epoch 4479/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0542e-04 - fbeta: 1.0000 - val_loss: 0.7072 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04479: val_loss did not improve from 0.39496\n",
      "Epoch 4480/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0541e-04 - fbeta: 1.0000 - val_loss: 0.7076 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04480: val_loss did not improve from 0.39496\n",
      "Epoch 4481/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0552e-04 - fbeta: 1.0000 - val_loss: 0.7085 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04481: val_loss did not improve from 0.39496\n",
      "Epoch 4482/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0539e-04 - fbeta: 1.0000 - val_loss: 0.7085 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04482: val_loss did not improve from 0.39496\n",
      "Epoch 4483/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0537e-04 - fbeta: 1.0000 - val_loss: 0.7086 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04483: val_loss did not improve from 0.39496\n",
      "Epoch 4484/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0542e-04 - fbeta: 1.0000 - val_loss: 0.7102 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04484: val_loss did not improve from 0.39496\n",
      "Epoch 4485/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0527e-04 - fbeta: 1.0000 - val_loss: 0.7106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04485: val_loss did not improve from 0.39496\n",
      "Epoch 4486/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0535e-04 - fbeta: 1.0000 - val_loss: 0.7068 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04486: val_loss did not improve from 0.39496\n",
      "Epoch 4487/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0530e-04 - fbeta: 1.0000 - val_loss: 0.7080 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04487: val_loss did not improve from 0.39496\n",
      "Epoch 4488/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0530e-04 - fbeta: 1.0000 - val_loss: 0.7079 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04488: val_loss did not improve from 0.39496\n",
      "Epoch 4489/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0533e-04 - fbeta: 1.0000 - val_loss: 0.7095 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04489: val_loss did not improve from 0.39496\n",
      "Epoch 4490/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0535e-04 - fbeta: 1.0000 - val_loss: 0.7093 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04490: val_loss did not improve from 0.39496\n",
      "Epoch 4491/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0533e-04 - fbeta: 1.0000 - val_loss: 0.7101 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04491: val_loss did not improve from 0.39496\n",
      "Epoch 4492/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0512e-04 - fbeta: 1.0000 - val_loss: 0.7105 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04492: val_loss did not improve from 0.39496\n",
      "Epoch 4493/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0530e-04 - fbeta: 1.0000 - val_loss: 0.7091 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04493: val_loss did not improve from 0.39496\n",
      "Epoch 4494/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0500e-04 - fbeta: 1.0000 - val_loss: 0.7097 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04494: val_loss did not improve from 0.39496\n",
      "Epoch 4495/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0500e-04 - fbeta: 1.0000 - val_loss: 0.7107 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04495: val_loss did not improve from 0.39496\n",
      "Epoch 4496/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0504e-04 - fbeta: 1.0000 - val_loss: 0.7115 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04496: val_loss did not improve from 0.39496\n",
      "Epoch 4497/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0503e-04 - fbeta: 1.0000 - val_loss: 0.7117 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04497: val_loss did not improve from 0.39496\n",
      "Epoch 4498/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0505e-04 - fbeta: 1.0000 - val_loss: 0.7114 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04498: val_loss did not improve from 0.39496\n",
      "Epoch 4499/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0501e-04 - fbeta: 1.0000 - val_loss: 0.7103 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04499: val_loss did not improve from 0.39496\n",
      "Epoch 4500/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0486e-04 - fbeta: 1.0000 - val_loss: 0.7095 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04500: val_loss did not improve from 0.39496\n",
      "Epoch 4501/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0503e-04 - fbeta: 1.0000 - val_loss: 0.7107 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04501: val_loss did not improve from 0.39496\n",
      "Epoch 4502/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0485e-04 - fbeta: 1.0000 - val_loss: 0.7092 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04502: val_loss did not improve from 0.39496\n",
      "Epoch 4503/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0514e-04 - fbeta: 1.0000 - val_loss: 0.7041 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04503: val_loss did not improve from 0.39496\n",
      "Epoch 4504/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0491e-04 - fbeta: 1.0000 - val_loss: 0.7063 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04504: val_loss did not improve from 0.39496\n",
      "Epoch 4505/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0485e-04 - fbeta: 1.0000 - val_loss: 0.7067 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04505: val_loss did not improve from 0.39496\n",
      "Epoch 4506/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0473e-04 - fbeta: 1.0000 - val_loss: 0.7080 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04506: val_loss did not improve from 0.39496\n",
      "Epoch 4507/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0469e-04 - fbeta: 1.0000 - val_loss: 0.7081 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04507: val_loss did not improve from 0.39496\n",
      "Epoch 4508/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0476e-04 - fbeta: 1.0000 - val_loss: 0.7103 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04508: val_loss did not improve from 0.39496\n",
      "Epoch 4509/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0469e-04 - fbeta: 1.0000 - val_loss: 0.7109 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04509: val_loss did not improve from 0.39496\n",
      "Epoch 4510/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0473e-04 - fbeta: 1.0000 - val_loss: 0.7116 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04510: val_loss did not improve from 0.39496\n",
      "Epoch 4511/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0453e-04 - fbeta: 1.0000 - val_loss: 0.7120 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04511: val_loss did not improve from 0.39496\n",
      "Epoch 4512/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0464e-04 - fbeta: 1.0000 - val_loss: 0.7110 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04512: val_loss did not improve from 0.39496\n",
      "Epoch 4513/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0457e-04 - fbeta: 1.0000 - val_loss: 0.7112 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04513: val_loss did not improve from 0.39496\n",
      "Epoch 4514/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0454e-04 - fbeta: 1.0000 - val_loss: 0.7113 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04514: val_loss did not improve from 0.39496\n",
      "Epoch 4515/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0438e-04 - fbeta: 1.0000 - val_loss: 0.7111 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04515: val_loss did not improve from 0.39496\n",
      "Epoch 4516/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0446e-04 - fbeta: 1.0000 - val_loss: 0.7110 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04516: val_loss did not improve from 0.39496\n",
      "Epoch 4517/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0443e-04 - fbeta: 1.0000 - val_loss: 0.7114 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04517: val_loss did not improve from 0.39496\n",
      "Epoch 4518/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0441e-04 - fbeta: 1.0000 - val_loss: 0.7109 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04518: val_loss did not improve from 0.39496\n",
      "Epoch 4519/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0455e-04 - fbeta: 1.0000 - val_loss: 0.7101 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04519: val_loss did not improve from 0.39496\n",
      "Epoch 4520/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0435e-04 - fbeta: 1.0000 - val_loss: 0.7100 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04520: val_loss did not improve from 0.39496\n",
      "Epoch 4521/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0435e-04 - fbeta: 1.0000 - val_loss: 0.7106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04521: val_loss did not improve from 0.39496\n",
      "Epoch 4522/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0425e-04 - fbeta: 1.0000 - val_loss: 0.7109 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04522: val_loss did not improve from 0.39496\n",
      "Epoch 4523/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0427e-04 - fbeta: 1.0000 - val_loss: 0.7106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04523: val_loss did not improve from 0.39496\n",
      "Epoch 4524/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0418e-04 - fbeta: 1.0000 - val_loss: 0.7108 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04524: val_loss did not improve from 0.39496\n",
      "Epoch 4525/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0428e-04 - fbeta: 1.0000 - val_loss: 0.7101 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04525: val_loss did not improve from 0.39496\n",
      "Epoch 4526/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0427e-04 - fbeta: 1.0000 - val_loss: 0.7068 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04526: val_loss did not improve from 0.39496\n",
      "Epoch 4527/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0424e-04 - fbeta: 1.0000 - val_loss: 0.7084 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04527: val_loss did not improve from 0.39496\n",
      "Epoch 4528/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0426e-04 - fbeta: 1.0000 - val_loss: 0.7099 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04528: val_loss did not improve from 0.39496\n",
      "Epoch 4529/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0417e-04 - fbeta: 1.0000 - val_loss: 0.7111 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04529: val_loss did not improve from 0.39496\n",
      "Epoch 4530/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0417e-04 - fbeta: 1.0000 - val_loss: 0.7126 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04530: val_loss did not improve from 0.39496\n",
      "Epoch 4531/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0415e-04 - fbeta: 1.0000 - val_loss: 0.7139 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04531: val_loss did not improve from 0.39496\n",
      "Epoch 4532/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0399e-04 - fbeta: 1.0000 - val_loss: 0.7125 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04532: val_loss did not improve from 0.39496\n",
      "Epoch 4533/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0413e-04 - fbeta: 1.0000 - val_loss: 0.7119 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04533: val_loss did not improve from 0.39496\n",
      "Epoch 4534/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0403e-04 - fbeta: 1.0000 - val_loss: 0.7106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04534: val_loss did not improve from 0.39496\n",
      "Epoch 4535/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0398e-04 - fbeta: 1.0000 - val_loss: 0.7079 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04535: val_loss did not improve from 0.39496\n",
      "Epoch 4536/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0390e-04 - fbeta: 1.0000 - val_loss: 0.7087 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04536: val_loss did not improve from 0.39496\n",
      "Epoch 4537/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0383e-04 - fbeta: 1.0000 - val_loss: 0.7106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04537: val_loss did not improve from 0.39496\n",
      "Epoch 4538/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0386e-04 - fbeta: 1.0000 - val_loss: 0.7104 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04538: val_loss did not improve from 0.39496\n",
      "Epoch 4539/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0376e-04 - fbeta: 1.0000 - val_loss: 0.7094 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04539: val_loss did not improve from 0.39496\n",
      "Epoch 4540/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0378e-04 - fbeta: 1.0000 - val_loss: 0.7089 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04540: val_loss did not improve from 0.39496\n",
      "Epoch 4541/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0385e-04 - fbeta: 1.0000 - val_loss: 0.7080 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04541: val_loss did not improve from 0.39496\n",
      "Epoch 4542/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0377e-04 - fbeta: 1.0000 - val_loss: 0.7093 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04542: val_loss did not improve from 0.39496\n",
      "Epoch 4543/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0372e-04 - fbeta: 1.0000 - val_loss: 0.7092 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04543: val_loss did not improve from 0.39496\n",
      "Epoch 4544/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0361e-04 - fbeta: 1.0000 - val_loss: 0.7094 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04544: val_loss did not improve from 0.39496\n",
      "Epoch 4545/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0363e-04 - fbeta: 1.0000 - val_loss: 0.7089 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04545: val_loss did not improve from 0.39496\n",
      "Epoch 4546/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0367e-04 - fbeta: 1.0000 - val_loss: 0.7086 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04546: val_loss did not improve from 0.39496\n",
      "Epoch 4547/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0367e-04 - fbeta: 1.0000 - val_loss: 0.7077 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04547: val_loss did not improve from 0.39496\n",
      "Epoch 4548/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0381e-04 - fbeta: 1.0000 - val_loss: 0.7095 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04548: val_loss did not improve from 0.39496\n",
      "Epoch 4549/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0362e-04 - fbeta: 1.0000 - val_loss: 0.7104 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04549: val_loss did not improve from 0.39496\n",
      "Epoch 4550/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0350e-04 - fbeta: 1.0000 - val_loss: 0.7096 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04550: val_loss did not improve from 0.39496\n",
      "Epoch 4551/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0347e-04 - fbeta: 1.0000 - val_loss: 0.7102 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04551: val_loss did not improve from 0.39496\n",
      "Epoch 4552/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0350e-04 - fbeta: 1.0000 - val_loss: 0.7105 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04552: val_loss did not improve from 0.39496\n",
      "Epoch 4553/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0365e-04 - fbeta: 1.0000 - val_loss: 0.7137 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04553: val_loss did not improve from 0.39496\n",
      "Epoch 4554/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0352e-04 - fbeta: 1.0000 - val_loss: 0.7136 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04554: val_loss did not improve from 0.39496\n",
      "Epoch 4555/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0344e-04 - fbeta: 1.0000 - val_loss: 0.7137 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04555: val_loss did not improve from 0.39496\n",
      "Epoch 4556/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0343e-04 - fbeta: 1.0000 - val_loss: 0.7130 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04556: val_loss did not improve from 0.39496\n",
      "Epoch 4557/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0335e-04 - fbeta: 1.0000 - val_loss: 0.7125 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04557: val_loss did not improve from 0.39496\n",
      "Epoch 4558/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0338e-04 - fbeta: 1.0000 - val_loss: 0.7112 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04558: val_loss did not improve from 0.39496\n",
      "Epoch 4559/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0319e-04 - fbeta: 1.0000 - val_loss: 0.7108 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04559: val_loss did not improve from 0.39496\n",
      "Epoch 4560/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0329e-04 - fbeta: 1.0000 - val_loss: 0.7118 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04560: val_loss did not improve from 0.39496\n",
      "Epoch 4561/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0326e-04 - fbeta: 1.0000 - val_loss: 0.7103 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04561: val_loss did not improve from 0.39496\n",
      "Epoch 4562/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0318e-04 - fbeta: 1.0000 - val_loss: 0.7099 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04562: val_loss did not improve from 0.39496\n",
      "Epoch 4563/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0327e-04 - fbeta: 1.0000 - val_loss: 0.7121 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04563: val_loss did not improve from 0.39496\n",
      "Epoch 4564/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0337e-04 - fbeta: 1.0000 - val_loss: 0.7123 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04564: val_loss did not improve from 0.39496\n",
      "Epoch 4565/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0330e-04 - fbeta: 1.0000 - val_loss: 0.7120 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04565: val_loss did not improve from 0.39496\n",
      "Epoch 4566/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0318e-04 - fbeta: 1.0000 - val_loss: 0.7105 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04566: val_loss did not improve from 0.39496\n",
      "Epoch 4567/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0307e-04 - fbeta: 1.0000 - val_loss: 0.7104 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04567: val_loss did not improve from 0.39496\n",
      "Epoch 4568/5000\n",
      "622/622 [==============================] - 25s 41ms/step - loss: 1.0305e-04 - fbeta: 1.0000 - val_loss: 0.7106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04568: val_loss did not improve from 0.39496\n",
      "Epoch 4569/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0301e-04 - fbeta: 1.0000 - val_loss: 0.7107 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04569: val_loss did not improve from 0.39496\n",
      "Epoch 4570/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0295e-04 - fbeta: 1.0000 - val_loss: 0.7112 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04570: val_loss did not improve from 0.39496\n",
      "Epoch 4571/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0299e-04 - fbeta: 1.0000 - val_loss: 0.7114 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04571: val_loss did not improve from 0.39496\n",
      "Epoch 4572/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0285e-04 - fbeta: 1.0000 - val_loss: 0.7108 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04572: val_loss did not improve from 0.39496\n",
      "Epoch 4573/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0290e-04 - fbeta: 1.0000 - val_loss: 0.7120 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04573: val_loss did not improve from 0.39496\n",
      "Epoch 4574/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0284e-04 - fbeta: 1.0000 - val_loss: 0.7114 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04574: val_loss did not improve from 0.39496\n",
      "Epoch 4575/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0284e-04 - fbeta: 1.0000 - val_loss: 0.7111 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04575: val_loss did not improve from 0.39496\n",
      "Epoch 4576/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0274e-04 - fbeta: 1.0000 - val_loss: 0.7117 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04576: val_loss did not improve from 0.39496\n",
      "Epoch 4577/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0278e-04 - fbeta: 1.0000 - val_loss: 0.7106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04577: val_loss did not improve from 0.39496\n",
      "Epoch 4578/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0310e-04 - fbeta: 1.0000 - val_loss: 0.7064 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04578: val_loss did not improve from 0.39496\n",
      "Epoch 4579/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0299e-04 - fbeta: 1.0000 - val_loss: 0.7072 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04579: val_loss did not improve from 0.39496\n",
      "Epoch 4580/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0328e-04 - fbeta: 1.0000 - val_loss: 0.7052 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04580: val_loss did not improve from 0.39496\n",
      "Epoch 4581/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0295e-04 - fbeta: 1.0000 - val_loss: 0.7094 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04581: val_loss did not improve from 0.39496\n",
      "Epoch 4582/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0270e-04 - fbeta: 1.0000 - val_loss: 0.7109 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04582: val_loss did not improve from 0.39496\n",
      "Epoch 4583/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0261e-04 - fbeta: 1.0000 - val_loss: 0.7102 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04583: val_loss did not improve from 0.39496\n",
      "Epoch 4584/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0253e-04 - fbeta: 1.0000 - val_loss: 0.7105 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04584: val_loss did not improve from 0.39496\n",
      "Epoch 4585/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0255e-04 - fbeta: 1.0000 - val_loss: 0.7112 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04585: val_loss did not improve from 0.39496\n",
      "Epoch 4586/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0263e-04 - fbeta: 1.0000 - val_loss: 0.7148 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04586: val_loss did not improve from 0.39496\n",
      "Epoch 4587/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0267e-04 - fbeta: 1.0000 - val_loss: 0.7159 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04587: val_loss did not improve from 0.39496\n",
      "Epoch 4588/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0245e-04 - fbeta: 1.0000 - val_loss: 0.7142 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04588: val_loss did not improve from 0.39496\n",
      "Epoch 4589/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0247e-04 - fbeta: 1.0000 - val_loss: 0.7141 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04589: val_loss did not improve from 0.39496\n",
      "Epoch 4590/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0253e-04 - fbeta: 1.0000 - val_loss: 0.7149 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04590: val_loss did not improve from 0.39496\n",
      "Epoch 4591/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0241e-04 - fbeta: 1.0000 - val_loss: 0.7141 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04591: val_loss did not improve from 0.39496\n",
      "Epoch 4592/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0244e-04 - fbeta: 1.0000 - val_loss: 0.7118 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04592: val_loss did not improve from 0.39496\n",
      "Epoch 4593/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0255e-04 - fbeta: 1.0000 - val_loss: 0.7064 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04593: val_loss did not improve from 0.39496\n",
      "Epoch 4594/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0238e-04 - fbeta: 1.0000 - val_loss: 0.7080 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04594: val_loss did not improve from 0.39496\n",
      "Epoch 4595/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0235e-04 - fbeta: 1.0000 - val_loss: 0.7098 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04595: val_loss did not improve from 0.39496\n",
      "Epoch 4596/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0232e-04 - fbeta: 1.0000 - val_loss: 0.7106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04596: val_loss did not improve from 0.39496\n",
      "Epoch 4597/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0225e-04 - fbeta: 1.0000 - val_loss: 0.7106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04597: val_loss did not improve from 0.39496\n",
      "Epoch 4598/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0227e-04 - fbeta: 1.0000 - val_loss: 0.7104 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04598: val_loss did not improve from 0.39496\n",
      "Epoch 4599/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0219e-04 - fbeta: 1.0000 - val_loss: 0.7102 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04599: val_loss did not improve from 0.39496\n",
      "Epoch 4600/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0224e-04 - fbeta: 1.0000 - val_loss: 0.7101 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04600: val_loss did not improve from 0.39496\n",
      "Epoch 4601/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0220e-04 - fbeta: 1.0000 - val_loss: 0.7109 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04601: val_loss did not improve from 0.39496\n",
      "Epoch 4602/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0216e-04 - fbeta: 1.0000 - val_loss: 0.7112 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04602: val_loss did not improve from 0.39496\n",
      "Epoch 4603/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0202e-04 - fbeta: 1.0000 - val_loss: 0.7120 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04603: val_loss did not improve from 0.39496\n",
      "Epoch 4604/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0212e-04 - fbeta: 1.0000 - val_loss: 0.7102 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04604: val_loss did not improve from 0.39496\n",
      "Epoch 4605/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0207e-04 - fbeta: 1.0000 - val_loss: 0.7111 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04605: val_loss did not improve from 0.39496\n",
      "Epoch 4606/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0210e-04 - fbeta: 1.0000 - val_loss: 0.7117 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04606: val_loss did not improve from 0.39496\n",
      "Epoch 4607/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0199e-04 - fbeta: 1.0000 - val_loss: 0.7116 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04607: val_loss did not improve from 0.39496\n",
      "Epoch 4608/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0194e-04 - fbeta: 1.0000 - val_loss: 0.7110 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04608: val_loss did not improve from 0.39496\n",
      "Epoch 4609/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0191e-04 - fbeta: 1.0000 - val_loss: 0.7116 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04609: val_loss did not improve from 0.39496\n",
      "Epoch 4610/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0192e-04 - fbeta: 1.0000 - val_loss: 0.7115 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04610: val_loss did not improve from 0.39496\n",
      "Epoch 4611/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0187e-04 - fbeta: 1.0000 - val_loss: 0.7125 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04611: val_loss did not improve from 0.39496\n",
      "Epoch 4612/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0189e-04 - fbeta: 1.0000 - val_loss: 0.7127 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04612: val_loss did not improve from 0.39496\n",
      "Epoch 4613/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0183e-04 - fbeta: 1.0000 - val_loss: 0.7141 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04613: val_loss did not improve from 0.39496\n",
      "Epoch 4614/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0195e-04 - fbeta: 1.0000 - val_loss: 0.7137 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04614: val_loss did not improve from 0.39496\n",
      "Epoch 4615/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0177e-04 - fbeta: 1.0000 - val_loss: 0.7115 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04615: val_loss did not improve from 0.39496\n",
      "Epoch 4616/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0183e-04 - fbeta: 1.0000 - val_loss: 0.7114 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04616: val_loss did not improve from 0.39496\n",
      "Epoch 4617/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0172e-04 - fbeta: 1.0000 - val_loss: 0.7125 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04617: val_loss did not improve from 0.39496\n",
      "Epoch 4618/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0182e-04 - fbeta: 1.0000 - val_loss: 0.7135 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04618: val_loss did not improve from 0.39496\n",
      "Epoch 4619/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0183e-04 - fbeta: 1.0000 - val_loss: 0.7141 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04619: val_loss did not improve from 0.39496\n",
      "Epoch 4620/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0197e-04 - fbeta: 1.0000 - val_loss: 0.7146 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04620: val_loss did not improve from 0.39496\n",
      "Epoch 4621/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0173e-04 - fbeta: 1.0000 - val_loss: 0.7151 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04621: val_loss did not improve from 0.39496\n",
      "Epoch 4622/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0164e-04 - fbeta: 1.0000 - val_loss: 0.7152 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04622: val_loss did not improve from 0.39496\n",
      "Epoch 4623/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0160e-04 - fbeta: 1.0000 - val_loss: 0.7152 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04623: val_loss did not improve from 0.39496\n",
      "Epoch 4624/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0149e-04 - fbeta: 1.0000 - val_loss: 0.7143 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04624: val_loss did not improve from 0.39496\n",
      "Epoch 4625/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0153e-04 - fbeta: 1.0000 - val_loss: 0.7134 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04625: val_loss did not improve from 0.39496\n",
      "Epoch 4626/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0141e-04 - fbeta: 1.0000 - val_loss: 0.7136 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04626: val_loss did not improve from 0.39496\n",
      "Epoch 4627/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0145e-04 - fbeta: 1.0000 - val_loss: 0.7141 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04627: val_loss did not improve from 0.39496\n",
      "Epoch 4628/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0149e-04 - fbeta: 1.0000 - val_loss: 0.7126 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04628: val_loss did not improve from 0.39496\n",
      "Epoch 4629/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0141e-04 - fbeta: 1.0000 - val_loss: 0.7114 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04629: val_loss did not improve from 0.39496\n",
      "Epoch 4630/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0135e-04 - fbeta: 1.0000 - val_loss: 0.7111 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04630: val_loss did not improve from 0.39496\n",
      "Epoch 4631/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0135e-04 - fbeta: 1.0000 - val_loss: 0.7117 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04631: val_loss did not improve from 0.39496\n",
      "Epoch 4632/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0134e-04 - fbeta: 1.0000 - val_loss: 0.7128 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04632: val_loss did not improve from 0.39496\n",
      "Epoch 4633/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0130e-04 - fbeta: 1.0000 - val_loss: 0.7126 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04633: val_loss did not improve from 0.39496\n",
      "Epoch 4634/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0122e-04 - fbeta: 1.0000 - val_loss: 0.7118 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04634: val_loss did not improve from 0.39496\n",
      "Epoch 4635/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0118e-04 - fbeta: 1.0000 - val_loss: 0.7114 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04635: val_loss did not improve from 0.39496\n",
      "Epoch 4636/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0125e-04 - fbeta: 1.0000 - val_loss: 0.7094 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04636: val_loss did not improve from 0.39496\n",
      "Epoch 4637/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0121e-04 - fbeta: 1.0000 - val_loss: 0.7103 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04637: val_loss did not improve from 0.39496\n",
      "Epoch 4638/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0117e-04 - fbeta: 1.0000 - val_loss: 0.7109 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04638: val_loss did not improve from 0.39496\n",
      "Epoch 4639/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0115e-04 - fbeta: 1.0000 - val_loss: 0.7109 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04639: val_loss did not improve from 0.39496\n",
      "Epoch 4640/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0111e-04 - fbeta: 1.0000 - val_loss: 0.7112 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04640: val_loss did not improve from 0.39496\n",
      "Epoch 4641/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0106e-04 - fbeta: 1.0000 - val_loss: 0.7129 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04641: val_loss did not improve from 0.39496\n",
      "Epoch 4642/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0114e-04 - fbeta: 1.0000 - val_loss: 0.7113 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04642: val_loss did not improve from 0.39496\n",
      "Epoch 4643/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0111e-04 - fbeta: 1.0000 - val_loss: 0.7098 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04643: val_loss did not improve from 0.39496\n",
      "Epoch 4644/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0104e-04 - fbeta: 1.0000 - val_loss: 0.7111 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04644: val_loss did not improve from 0.39496\n",
      "Epoch 4645/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0108e-04 - fbeta: 1.0000 - val_loss: 0.7126 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04645: val_loss did not improve from 0.39496\n",
      "Epoch 4646/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0093e-04 - fbeta: 1.0000 - val_loss: 0.7140 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04646: val_loss did not improve from 0.39496\n",
      "Epoch 4647/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0109e-04 - fbeta: 1.0000 - val_loss: 0.7142 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04647: val_loss did not improve from 0.39496\n",
      "Epoch 4648/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0105e-04 - fbeta: 1.0000 - val_loss: 0.7155 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04648: val_loss did not improve from 0.39496\n",
      "Epoch 4649/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0098e-04 - fbeta: 1.0000 - val_loss: 0.7131 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04649: val_loss did not improve from 0.39496\n",
      "Epoch 4650/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0092e-04 - fbeta: 1.0000 - val_loss: 0.7121 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04650: val_loss did not improve from 0.39496\n",
      "Epoch 4651/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0097e-04 - fbeta: 1.0000 - val_loss: 0.7107 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04651: val_loss did not improve from 0.39496\n",
      "Epoch 4652/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0084e-04 - fbeta: 1.0000 - val_loss: 0.7122 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04652: val_loss did not improve from 0.39496\n",
      "Epoch 4653/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0070e-04 - fbeta: 1.0000 - val_loss: 0.7128 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04653: val_loss did not improve from 0.39496\n",
      "Epoch 4654/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0069e-04 - fbeta: 1.0000 - val_loss: 0.7124 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04654: val_loss did not improve from 0.39496\n",
      "Epoch 4655/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0088e-04 - fbeta: 1.0000 - val_loss: 0.7101 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04655: val_loss did not improve from 0.39496\n",
      "Epoch 4656/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0073e-04 - fbeta: 1.0000 - val_loss: 0.7106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04656: val_loss did not improve from 0.39496\n",
      "Epoch 4657/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0064e-04 - fbeta: 1.0000 - val_loss: 0.7121 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04657: val_loss did not improve from 0.39496\n",
      "Epoch 4658/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0070e-04 - fbeta: 1.0000 - val_loss: 0.7121 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04658: val_loss did not improve from 0.39496\n",
      "Epoch 4659/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0062e-04 - fbeta: 1.0000 - val_loss: 0.7124 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04659: val_loss did not improve from 0.39496\n",
      "Epoch 4660/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0054e-04 - fbeta: 1.0000 - val_loss: 0.7118 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04660: val_loss did not improve from 0.39496\n",
      "Epoch 4661/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0051e-04 - fbeta: 1.0000 - val_loss: 0.7098 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04661: val_loss did not improve from 0.39496\n",
      "Epoch 4662/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0061e-04 - fbeta: 1.0000 - val_loss: 0.7081 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04662: val_loss did not improve from 0.39496\n",
      "Epoch 4663/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0068e-04 - fbeta: 1.0000 - val_loss: 0.7088 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04663: val_loss did not improve from 0.39496\n",
      "Epoch 4664/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0054e-04 - fbeta: 1.0000 - val_loss: 0.7101 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04664: val_loss did not improve from 0.39496\n",
      "Epoch 4665/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0044e-04 - fbeta: 1.0000 - val_loss: 0.7099 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04665: val_loss did not improve from 0.39496\n",
      "Epoch 4666/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0041e-04 - fbeta: 1.0000 - val_loss: 0.7100 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04666: val_loss did not improve from 0.39496\n",
      "Epoch 4667/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0040e-04 - fbeta: 1.0000 - val_loss: 0.7113 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04667: val_loss did not improve from 0.39496\n",
      "Epoch 4668/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0039e-04 - fbeta: 1.0000 - val_loss: 0.7126 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04668: val_loss did not improve from 0.39496\n",
      "Epoch 4669/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0029e-04 - fbeta: 1.0000 - val_loss: 0.7131 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04669: val_loss did not improve from 0.39496\n",
      "Epoch 4670/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0036e-04 - fbeta: 1.0000 - val_loss: 0.7141 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04670: val_loss did not improve from 0.39496\n",
      "Epoch 4671/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0031e-04 - fbeta: 1.0000 - val_loss: 0.7133 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04671: val_loss did not improve from 0.39496\n",
      "Epoch 4672/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0023e-04 - fbeta: 1.0000 - val_loss: 0.7120 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04672: val_loss did not improve from 0.39496\n",
      "Epoch 4673/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0044e-04 - fbeta: 1.0000 - val_loss: 0.7057 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04673: val_loss did not improve from 0.39496\n",
      "Epoch 4674/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0039e-04 - fbeta: 1.0000 - val_loss: 0.7062 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04674: val_loss did not improve from 0.39496\n",
      "Epoch 4675/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0029e-04 - fbeta: 1.0000 - val_loss: 0.7082 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04675: val_loss did not improve from 0.39496\n",
      "Epoch 4676/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0010e-04 - fbeta: 1.0000 - val_loss: 0.7102 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04676: val_loss did not improve from 0.39496\n",
      "Epoch 4677/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0027e-04 - fbeta: 1.0000 - val_loss: 0.7109 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04677: val_loss did not improve from 0.39496\n",
      "Epoch 4678/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0018e-04 - fbeta: 1.0000 - val_loss: 0.7112 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04678: val_loss did not improve from 0.39496\n",
      "Epoch 4679/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0011e-04 - fbeta: 1.0000 - val_loss: 0.7109 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04679: val_loss did not improve from 0.39496\n",
      "Epoch 4680/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0019e-04 - fbeta: 1.0000 - val_loss: 0.7122 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04680: val_loss did not improve from 0.39496\n",
      "Epoch 4681/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0019e-04 - fbeta: 1.0000 - val_loss: 0.7124 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04681: val_loss did not improve from 0.39496\n",
      "Epoch 4682/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0012e-04 - fbeta: 1.0000 - val_loss: 0.7123 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04682: val_loss did not improve from 0.39496\n",
      "Epoch 4683/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0001e-04 - fbeta: 1.0000 - val_loss: 0.7121 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04683: val_loss did not improve from 0.39496\n",
      "Epoch 4684/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0006e-04 - fbeta: 1.0000 - val_loss: 0.7113 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04684: val_loss did not improve from 0.39496\n",
      "Epoch 4685/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9918e-05 - fbeta: 1.0000 - val_loss: 0.7112 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04685: val_loss did not improve from 0.39496\n",
      "Epoch 4686/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9991e-05 - fbeta: 1.0000 - val_loss: 0.7125 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04686: val_loss did not improve from 0.39496\n",
      "Epoch 4687/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9915e-05 - fbeta: 1.0000 - val_loss: 0.7124 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04687: val_loss did not improve from 0.39496\n",
      "Epoch 4688/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 1.0013e-04 - fbeta: 1.0000 - val_loss: 0.7128 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04688: val_loss did not improve from 0.39496\n",
      "Epoch 4689/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9926e-05 - fbeta: 1.0000 - val_loss: 0.7130 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04689: val_loss did not improve from 0.39496\n",
      "Epoch 4690/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9941e-05 - fbeta: 1.0000 - val_loss: 0.7124 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04690: val_loss did not improve from 0.39496\n",
      "Epoch 4691/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9785e-05 - fbeta: 1.0000 - val_loss: 0.7126 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04691: val_loss did not improve from 0.39496\n",
      "Epoch 4692/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9744e-05 - fbeta: 1.0000 - val_loss: 0.7121 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04692: val_loss did not improve from 0.39496\n",
      "Epoch 4693/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9802e-05 - fbeta: 1.0000 - val_loss: 0.7134 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04693: val_loss did not improve from 0.39496\n",
      "Epoch 4694/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9742e-05 - fbeta: 1.0000 - val_loss: 0.7129 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04694: val_loss did not improve from 0.39496\n",
      "Epoch 4695/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9609e-05 - fbeta: 1.0000 - val_loss: 0.7140 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04695: val_loss did not improve from 0.39496\n",
      "Epoch 4696/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9726e-05 - fbeta: 1.0000 - val_loss: 0.7145 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04696: val_loss did not improve from 0.39496\n",
      "Epoch 4697/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9709e-05 - fbeta: 1.0000 - val_loss: 0.7139 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04697: val_loss did not improve from 0.39496\n",
      "Epoch 4698/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9539e-05 - fbeta: 1.0000 - val_loss: 0.7116 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04698: val_loss did not improve from 0.39496\n",
      "Epoch 4699/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9582e-05 - fbeta: 1.0000 - val_loss: 0.7117 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04699: val_loss did not improve from 0.39496\n",
      "Epoch 4700/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9630e-05 - fbeta: 1.0000 - val_loss: 0.7110 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04700: val_loss did not improve from 0.39496\n",
      "Epoch 4701/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9525e-05 - fbeta: 1.0000 - val_loss: 0.7115 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04701: val_loss did not improve from 0.39496\n",
      "Epoch 4702/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9469e-05 - fbeta: 1.0000 - val_loss: 0.7119 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04702: val_loss did not improve from 0.39496\n",
      "Epoch 4703/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9546e-05 - fbeta: 1.0000 - val_loss: 0.7134 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04703: val_loss did not improve from 0.39496\n",
      "Epoch 4704/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9459e-05 - fbeta: 1.0000 - val_loss: 0.7134 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04704: val_loss did not improve from 0.39496\n",
      "Epoch 4705/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9459e-05 - fbeta: 1.0000 - val_loss: 0.7133 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04705: val_loss did not improve from 0.39496\n",
      "Epoch 4706/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9418e-05 - fbeta: 1.0000 - val_loss: 0.7129 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04706: val_loss did not improve from 0.39496\n",
      "Epoch 4707/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9388e-05 - fbeta: 1.0000 - val_loss: 0.7137 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04707: val_loss did not improve from 0.39496\n",
      "Epoch 4708/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9464e-05 - fbeta: 1.0000 - val_loss: 0.7137 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04708: val_loss did not improve from 0.39496\n",
      "Epoch 4709/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9317e-05 - fbeta: 1.0000 - val_loss: 0.7134 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04709: val_loss did not improve from 0.39496\n",
      "Epoch 4710/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9353e-05 - fbeta: 1.0000 - val_loss: 0.7130 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04710: val_loss did not improve from 0.39496\n",
      "Epoch 4711/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9311e-05 - fbeta: 1.0000 - val_loss: 0.7114 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04711: val_loss did not improve from 0.39496\n",
      "Epoch 4712/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9318e-05 - fbeta: 1.0000 - val_loss: 0.7111 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04712: val_loss did not improve from 0.39496\n",
      "Epoch 4713/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9236e-05 - fbeta: 1.0000 - val_loss: 0.7121 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04713: val_loss did not improve from 0.39496\n",
      "Epoch 4714/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9182e-05 - fbeta: 1.0000 - val_loss: 0.7133 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04714: val_loss did not improve from 0.39496\n",
      "Epoch 4715/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9164e-05 - fbeta: 1.0000 - val_loss: 0.7137 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04715: val_loss did not improve from 0.39496\n",
      "Epoch 4716/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9155e-05 - fbeta: 1.0000 - val_loss: 0.7137 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04716: val_loss did not improve from 0.39496\n",
      "Epoch 4717/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9097e-05 - fbeta: 1.0000 - val_loss: 0.7140 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04717: val_loss did not improve from 0.39496\n",
      "Epoch 4718/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9177e-05 - fbeta: 1.0000 - val_loss: 0.7136 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04718: val_loss did not improve from 0.39496\n",
      "Epoch 4719/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9136e-05 - fbeta: 1.0000 - val_loss: 0.7141 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04719: val_loss did not improve from 0.39496\n",
      "Epoch 4720/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9082e-05 - fbeta: 1.0000 - val_loss: 0.7136 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04720: val_loss did not improve from 0.39496\n",
      "Epoch 4721/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9031e-05 - fbeta: 1.0000 - val_loss: 0.7135 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04721: val_loss did not improve from 0.39496\n",
      "Epoch 4722/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9051e-05 - fbeta: 1.0000 - val_loss: 0.7130 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04722: val_loss did not improve from 0.39496\n",
      "Epoch 4723/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8998e-05 - fbeta: 1.0000 - val_loss: 0.7133 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04723: val_loss did not improve from 0.39496\n",
      "Epoch 4724/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8964e-05 - fbeta: 1.0000 - val_loss: 0.7132 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04724: val_loss did not improve from 0.39496\n",
      "Epoch 4725/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8985e-05 - fbeta: 1.0000 - val_loss: 0.7135 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04725: val_loss did not improve from 0.39496\n",
      "Epoch 4726/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8927e-05 - fbeta: 1.0000 - val_loss: 0.7162 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04726: val_loss did not improve from 0.39496\n",
      "Epoch 4727/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8953e-05 - fbeta: 1.0000 - val_loss: 0.7156 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04727: val_loss did not improve from 0.39496\n",
      "Epoch 4728/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8968e-05 - fbeta: 1.0000 - val_loss: 0.7142 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04728: val_loss did not improve from 0.39496\n",
      "Epoch 4729/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8831e-05 - fbeta: 1.0000 - val_loss: 0.7138 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04729: val_loss did not improve from 0.39496\n",
      "Epoch 4730/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8869e-05 - fbeta: 1.0000 - val_loss: 0.7132 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04730: val_loss did not improve from 0.39496\n",
      "Epoch 4731/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8924e-05 - fbeta: 1.0000 - val_loss: 0.7104 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04731: val_loss did not improve from 0.39496\n",
      "Epoch 4732/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8902e-05 - fbeta: 1.0000 - val_loss: 0.7114 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04732: val_loss did not improve from 0.39496\n",
      "Epoch 4733/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.9088e-05 - fbeta: 1.0000 - val_loss: 0.7121 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04733: val_loss did not improve from 0.39496\n",
      "Epoch 4734/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8810e-05 - fbeta: 1.0000 - val_loss: 0.7137 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04734: val_loss did not improve from 0.39496\n",
      "Epoch 4735/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8708e-05 - fbeta: 1.0000 - val_loss: 0.7128 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04735: val_loss did not improve from 0.39496\n",
      "Epoch 4736/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8622e-05 - fbeta: 1.0000 - val_loss: 0.7136 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04736: val_loss did not improve from 0.39496\n",
      "Epoch 4737/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8663e-05 - fbeta: 1.0000 - val_loss: 0.7138 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04737: val_loss did not improve from 0.39496\n",
      "Epoch 4738/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8660e-05 - fbeta: 1.0000 - val_loss: 0.7134 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04738: val_loss did not improve from 0.39496\n",
      "Epoch 4739/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8568e-05 - fbeta: 1.0000 - val_loss: 0.7135 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04739: val_loss did not improve from 0.39496\n",
      "Epoch 4740/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8653e-05 - fbeta: 1.0000 - val_loss: 0.7112 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04740: val_loss did not improve from 0.39496\n",
      "Epoch 4741/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8625e-05 - fbeta: 1.0000 - val_loss: 0.7112 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04741: val_loss did not improve from 0.39496\n",
      "Epoch 4742/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8657e-05 - fbeta: 1.0000 - val_loss: 0.7123 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04742: val_loss did not improve from 0.39496\n",
      "Epoch 4743/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8808e-05 - fbeta: 1.0000 - val_loss: 0.7132 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04743: val_loss did not improve from 0.39496\n",
      "Epoch 4744/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8542e-05 - fbeta: 1.0000 - val_loss: 0.7133 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04744: val_loss did not improve from 0.39496\n",
      "Epoch 4745/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8581e-05 - fbeta: 1.0000 - val_loss: 0.7106 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04745: val_loss did not improve from 0.39496\n",
      "Epoch 4746/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8654e-05 - fbeta: 1.0000 - val_loss: 0.7113 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04746: val_loss did not improve from 0.39496\n",
      "Epoch 4747/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8563e-05 - fbeta: 1.0000 - val_loss: 0.7123 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04747: val_loss did not improve from 0.39496\n",
      "Epoch 4748/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8426e-05 - fbeta: 1.0000 - val_loss: 0.7129 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04748: val_loss did not improve from 0.39496\n",
      "Epoch 4749/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8378e-05 - fbeta: 1.0000 - val_loss: 0.7130 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04749: val_loss did not improve from 0.39496\n",
      "Epoch 4750/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8359e-05 - fbeta: 1.0000 - val_loss: 0.7136 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04750: val_loss did not improve from 0.39496\n",
      "Epoch 4751/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8597e-05 - fbeta: 1.0000 - val_loss: 0.7131 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04751: val_loss did not improve from 0.39496\n",
      "Epoch 4752/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8363e-05 - fbeta: 1.0000 - val_loss: 0.7120 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04752: val_loss did not improve from 0.39496\n",
      "Epoch 4753/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8556e-05 - fbeta: 1.0000 - val_loss: 0.7117 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04753: val_loss did not improve from 0.39496\n",
      "Epoch 4754/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8354e-05 - fbeta: 1.0000 - val_loss: 0.7131 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04754: val_loss did not improve from 0.39496\n",
      "Epoch 4755/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8208e-05 - fbeta: 1.0000 - val_loss: 0.7137 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04755: val_loss did not improve from 0.39496\n",
      "Epoch 4756/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8383e-05 - fbeta: 1.0000 - val_loss: 0.7146 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04756: val_loss did not improve from 0.39496\n",
      "Epoch 4757/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8193e-05 - fbeta: 1.0000 - val_loss: 0.7145 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04757: val_loss did not improve from 0.39496\n",
      "Epoch 4758/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8144e-05 - fbeta: 1.0000 - val_loss: 0.7141 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04758: val_loss did not improve from 0.39496\n",
      "Epoch 4759/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8101e-05 - fbeta: 1.0000 - val_loss: 0.7144 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04759: val_loss did not improve from 0.39496\n",
      "Epoch 4760/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8208e-05 - fbeta: 1.0000 - val_loss: 0.7150 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04760: val_loss did not improve from 0.39496\n",
      "Epoch 4761/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8076e-05 - fbeta: 1.0000 - val_loss: 0.7142 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04761: val_loss did not improve from 0.39496\n",
      "Epoch 4762/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7958e-05 - fbeta: 1.0000 - val_loss: 0.7134 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04762: val_loss did not improve from 0.39496\n",
      "Epoch 4763/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8031e-05 - fbeta: 1.0000 - val_loss: 0.7130 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04763: val_loss did not improve from 0.39496\n",
      "Epoch 4764/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8027e-05 - fbeta: 1.0000 - val_loss: 0.7127 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04764: val_loss did not improve from 0.39496\n",
      "Epoch 4765/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8103e-05 - fbeta: 1.0000 - val_loss: 0.7141 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04765: val_loss did not improve from 0.39496\n",
      "Epoch 4766/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7974e-05 - fbeta: 1.0000 - val_loss: 0.7156 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04766: val_loss did not improve from 0.39496\n",
      "Epoch 4767/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8078e-05 - fbeta: 1.0000 - val_loss: 0.7140 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04767: val_loss did not improve from 0.39496\n",
      "Epoch 4768/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7917e-05 - fbeta: 1.0000 - val_loss: 0.7151 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04768: val_loss did not improve from 0.39496\n",
      "Epoch 4769/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.8077e-05 - fbeta: 1.0000 - val_loss: 0.7159 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04769: val_loss did not improve from 0.39496\n",
      "Epoch 4770/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7954e-05 - fbeta: 1.0000 - val_loss: 0.7150 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04770: val_loss did not improve from 0.39496\n",
      "Epoch 4771/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7849e-05 - fbeta: 1.0000 - val_loss: 0.7143 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04771: val_loss did not improve from 0.39496\n",
      "Epoch 4772/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7803e-05 - fbeta: 1.0000 - val_loss: 0.7145 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04772: val_loss did not improve from 0.39496\n",
      "Epoch 4773/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7713e-05 - fbeta: 1.0000 - val_loss: 0.7149 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04773: val_loss did not improve from 0.39496\n",
      "Epoch 4774/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7807e-05 - fbeta: 1.0000 - val_loss: 0.7168 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04774: val_loss did not improve from 0.39496\n",
      "Epoch 4775/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7769e-05 - fbeta: 1.0000 - val_loss: 0.7167 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04775: val_loss did not improve from 0.39496\n",
      "Epoch 4776/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7756e-05 - fbeta: 1.0000 - val_loss: 0.7151 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04776: val_loss did not improve from 0.39496\n",
      "Epoch 4777/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7663e-05 - fbeta: 1.0000 - val_loss: 0.7148 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04777: val_loss did not improve from 0.39496\n",
      "Epoch 4778/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7664e-05 - fbeta: 1.0000 - val_loss: 0.7149 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04778: val_loss did not improve from 0.39496\n",
      "Epoch 4779/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7612e-05 - fbeta: 1.0000 - val_loss: 0.7148 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04779: val_loss did not improve from 0.39496\n",
      "Epoch 4780/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7724e-05 - fbeta: 1.0000 - val_loss: 0.7135 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04780: val_loss did not improve from 0.39496\n",
      "Epoch 4781/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7884e-05 - fbeta: 1.0000 - val_loss: 0.7089 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04781: val_loss did not improve from 0.39496\n",
      "Epoch 4782/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7693e-05 - fbeta: 1.0000 - val_loss: 0.7100 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04782: val_loss did not improve from 0.39496\n",
      "Epoch 4783/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7584e-05 - fbeta: 1.0000 - val_loss: 0.7111 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04783: val_loss did not improve from 0.39496\n",
      "Epoch 4784/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7610e-05 - fbeta: 1.0000 - val_loss: 0.7117 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04784: val_loss did not improve from 0.39496\n",
      "Epoch 4785/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7494e-05 - fbeta: 1.0000 - val_loss: 0.7130 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04785: val_loss did not improve from 0.39496\n",
      "Epoch 4786/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7429e-05 - fbeta: 1.0000 - val_loss: 0.7136 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04786: val_loss did not improve from 0.39496\n",
      "Epoch 4787/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7382e-05 - fbeta: 1.0000 - val_loss: 0.7146 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04787: val_loss did not improve from 0.39496\n",
      "Epoch 4788/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7471e-05 - fbeta: 1.0000 - val_loss: 0.7151 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04788: val_loss did not improve from 0.39496\n",
      "Epoch 4789/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7399e-05 - fbeta: 1.0000 - val_loss: 0.7154 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04789: val_loss did not improve from 0.39496\n",
      "Epoch 4790/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7339e-05 - fbeta: 1.0000 - val_loss: 0.7145 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04790: val_loss did not improve from 0.39496\n",
      "Epoch 4791/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7329e-05 - fbeta: 1.0000 - val_loss: 0.7130 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04791: val_loss did not improve from 0.39496\n",
      "Epoch 4792/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7324e-05 - fbeta: 1.0000 - val_loss: 0.7131 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04792: val_loss did not improve from 0.39496\n",
      "Epoch 4793/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7325e-05 - fbeta: 1.0000 - val_loss: 0.7135 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04793: val_loss did not improve from 0.39496\n",
      "Epoch 4794/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7191e-05 - fbeta: 1.0000 - val_loss: 0.7137 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04794: val_loss did not improve from 0.39496\n",
      "Epoch 4795/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7161e-05 - fbeta: 1.0000 - val_loss: 0.7134 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04795: val_loss did not improve from 0.39496\n",
      "Epoch 4796/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7141e-05 - fbeta: 1.0000 - val_loss: 0.7139 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04796: val_loss did not improve from 0.39496\n",
      "Epoch 4797/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7185e-05 - fbeta: 1.0000 - val_loss: 0.7142 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04797: val_loss did not improve from 0.39496\n",
      "Epoch 4798/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7158e-05 - fbeta: 1.0000 - val_loss: 0.7138 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04798: val_loss did not improve from 0.39496\n",
      "Epoch 4799/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7061e-05 - fbeta: 1.0000 - val_loss: 0.7150 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04799: val_loss did not improve from 0.39496\n",
      "Epoch 4800/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7069e-05 - fbeta: 1.0000 - val_loss: 0.7146 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04800: val_loss did not improve from 0.39496\n",
      "Epoch 4801/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7028e-05 - fbeta: 1.0000 - val_loss: 0.7163 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04801: val_loss did not improve from 0.39496\n",
      "Epoch 4802/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7113e-05 - fbeta: 1.0000 - val_loss: 0.7163 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04802: val_loss did not improve from 0.39496\n",
      "Epoch 4803/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7014e-05 - fbeta: 1.0000 - val_loss: 0.7155 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04803: val_loss did not improve from 0.39496\n",
      "Epoch 4804/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7084e-05 - fbeta: 1.0000 - val_loss: 0.7154 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04804: val_loss did not improve from 0.39496\n",
      "Epoch 4805/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7039e-05 - fbeta: 1.0000 - val_loss: 0.7138 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04805: val_loss did not improve from 0.39496\n",
      "Epoch 4806/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7124e-05 - fbeta: 1.0000 - val_loss: 0.7144 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04806: val_loss did not improve from 0.39496\n",
      "Epoch 4807/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.7086e-05 - fbeta: 1.0000 - val_loss: 0.7145 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04807: val_loss did not improve from 0.39496\n",
      "Epoch 4808/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6958e-05 - fbeta: 1.0000 - val_loss: 0.7153 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04808: val_loss did not improve from 0.39496\n",
      "Epoch 4809/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6919e-05 - fbeta: 1.0000 - val_loss: 0.7164 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04809: val_loss did not improve from 0.39496\n",
      "Epoch 4810/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6849e-05 - fbeta: 1.0000 - val_loss: 0.7171 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04810: val_loss did not improve from 0.39496\n",
      "Epoch 4811/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6880e-05 - fbeta: 1.0000 - val_loss: 0.7180 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04811: val_loss did not improve from 0.39496\n",
      "Epoch 4812/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6896e-05 - fbeta: 1.0000 - val_loss: 0.7162 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04812: val_loss did not improve from 0.39496\n",
      "Epoch 4813/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6850e-05 - fbeta: 1.0000 - val_loss: 0.7159 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04813: val_loss did not improve from 0.39496\n",
      "Epoch 4814/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6756e-05 - fbeta: 1.0000 - val_loss: 0.7159 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04814: val_loss did not improve from 0.39496\n",
      "Epoch 4815/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6690e-05 - fbeta: 1.0000 - val_loss: 0.7155 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04815: val_loss did not improve from 0.39496\n",
      "Epoch 4816/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6789e-05 - fbeta: 1.0000 - val_loss: 0.7159 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04816: val_loss did not improve from 0.39496\n",
      "Epoch 4817/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6760e-05 - fbeta: 1.0000 - val_loss: 0.7157 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04817: val_loss did not improve from 0.39496\n",
      "Epoch 4818/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6786e-05 - fbeta: 1.0000 - val_loss: 0.7157 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04818: val_loss did not improve from 0.39496\n",
      "Epoch 4819/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6767e-05 - fbeta: 1.0000 - val_loss: 0.7156 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04819: val_loss did not improve from 0.39496\n",
      "Epoch 4820/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6625e-05 - fbeta: 1.0000 - val_loss: 0.7169 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04820: val_loss did not improve from 0.39496\n",
      "Epoch 4821/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6717e-05 - fbeta: 1.0000 - val_loss: 0.7182 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04821: val_loss did not improve from 0.39496\n",
      "Epoch 4822/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6621e-05 - fbeta: 1.0000 - val_loss: 0.7181 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04822: val_loss did not improve from 0.39496\n",
      "Epoch 4823/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6607e-05 - fbeta: 1.0000 - val_loss: 0.7174 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04823: val_loss did not improve from 0.39496\n",
      "Epoch 4824/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6863e-05 - fbeta: 1.0000 - val_loss: 0.7183 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04824: val_loss did not improve from 0.39496\n",
      "Epoch 4825/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6553e-05 - fbeta: 1.0000 - val_loss: 0.7170 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04825: val_loss did not improve from 0.39496\n",
      "Epoch 4826/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6593e-05 - fbeta: 1.0000 - val_loss: 0.7162 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04826: val_loss did not improve from 0.39496\n",
      "Epoch 4827/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6554e-05 - fbeta: 1.0000 - val_loss: 0.7160 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04827: val_loss did not improve from 0.39496\n",
      "Epoch 4828/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6622e-05 - fbeta: 1.0000 - val_loss: 0.7161 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04828: val_loss did not improve from 0.39496\n",
      "Epoch 4829/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6373e-05 - fbeta: 1.0000 - val_loss: 0.7156 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04829: val_loss did not improve from 0.39496\n",
      "Epoch 4830/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6451e-05 - fbeta: 1.0000 - val_loss: 0.7155 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04830: val_loss did not improve from 0.39496\n",
      "Epoch 4831/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6427e-05 - fbeta: 1.0000 - val_loss: 0.7149 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04831: val_loss did not improve from 0.39496\n",
      "Epoch 4832/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6362e-05 - fbeta: 1.0000 - val_loss: 0.7153 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04832: val_loss did not improve from 0.39496\n",
      "Epoch 4833/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6489e-05 - fbeta: 1.0000 - val_loss: 0.7151 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04833: val_loss did not improve from 0.39496\n",
      "Epoch 4834/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6383e-05 - fbeta: 1.0000 - val_loss: 0.7156 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04834: val_loss did not improve from 0.39496\n",
      "Epoch 4835/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6392e-05 - fbeta: 1.0000 - val_loss: 0.7161 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04835: val_loss did not improve from 0.39496\n",
      "Epoch 4836/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6269e-05 - fbeta: 1.0000 - val_loss: 0.7153 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04836: val_loss did not improve from 0.39496\n",
      "Epoch 4837/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6278e-05 - fbeta: 1.0000 - val_loss: 0.7153 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04837: val_loss did not improve from 0.39496\n",
      "Epoch 4838/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6159e-05 - fbeta: 1.0000 - val_loss: 0.7145 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04838: val_loss did not improve from 0.39496\n",
      "Epoch 4839/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6133e-05 - fbeta: 1.0000 - val_loss: 0.7146 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04839: val_loss did not improve from 0.39496\n",
      "Epoch 4840/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6113e-05 - fbeta: 1.0000 - val_loss: 0.7137 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04840: val_loss did not improve from 0.39496\n",
      "Epoch 4841/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6072e-05 - fbeta: 1.0000 - val_loss: 0.7140 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04841: val_loss did not improve from 0.39496\n",
      "Epoch 4842/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6036e-05 - fbeta: 1.0000 - val_loss: 0.7149 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04842: val_loss did not improve from 0.39496\n",
      "Epoch 4843/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6059e-05 - fbeta: 1.0000 - val_loss: 0.7139 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04843: val_loss did not improve from 0.39496\n",
      "Epoch 4844/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6021e-05 - fbeta: 1.0000 - val_loss: 0.7141 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04844: val_loss did not improve from 0.39496\n",
      "Epoch 4845/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6089e-05 - fbeta: 1.0000 - val_loss: 0.7152 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04845: val_loss did not improve from 0.39496\n",
      "Epoch 4846/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6008e-05 - fbeta: 1.0000 - val_loss: 0.7140 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04846: val_loss did not improve from 0.39496\n",
      "Epoch 4847/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5917e-05 - fbeta: 1.0000 - val_loss: 0.7136 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04847: val_loss did not improve from 0.39496\n",
      "Epoch 4848/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6014e-05 - fbeta: 1.0000 - val_loss: 0.7140 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04848: val_loss did not improve from 0.39496\n",
      "Epoch 4849/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6022e-05 - fbeta: 1.0000 - val_loss: 0.7140 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04849: val_loss did not improve from 0.39496\n",
      "Epoch 4850/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5979e-05 - fbeta: 1.0000 - val_loss: 0.7141 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04850: val_loss did not improve from 0.39496\n",
      "Epoch 4851/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.6058e-05 - fbeta: 1.0000 - val_loss: 0.7135 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04851: val_loss did not improve from 0.39496\n",
      "Epoch 4852/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5826e-05 - fbeta: 1.0000 - val_loss: 0.7179 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04852: val_loss did not improve from 0.39496\n",
      "Epoch 4853/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5893e-05 - fbeta: 1.0000 - val_loss: 0.7166 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04853: val_loss did not improve from 0.39496\n",
      "Epoch 4854/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5887e-05 - fbeta: 1.0000 - val_loss: 0.7157 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04854: val_loss did not improve from 0.39496\n",
      "Epoch 4855/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5803e-05 - fbeta: 1.0000 - val_loss: 0.7157 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04855: val_loss did not improve from 0.39496\n",
      "Epoch 4856/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5716e-05 - fbeta: 1.0000 - val_loss: 0.7158 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04856: val_loss did not improve from 0.39496\n",
      "Epoch 4857/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5725e-05 - fbeta: 1.0000 - val_loss: 0.7154 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04857: val_loss did not improve from 0.39496\n",
      "Epoch 4858/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5791e-05 - fbeta: 1.0000 - val_loss: 0.7151 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04858: val_loss did not improve from 0.39496\n",
      "Epoch 4859/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5731e-05 - fbeta: 1.0000 - val_loss: 0.7140 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04859: val_loss did not improve from 0.39496\n",
      "Epoch 4860/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5707e-05 - fbeta: 1.0000 - val_loss: 0.7154 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04860: val_loss did not improve from 0.39496\n",
      "Epoch 4861/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5696e-05 - fbeta: 1.0000 - val_loss: 0.7153 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04861: val_loss did not improve from 0.39496\n",
      "Epoch 4862/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5709e-05 - fbeta: 1.0000 - val_loss: 0.7149 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04862: val_loss did not improve from 0.39496\n",
      "Epoch 4863/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5610e-05 - fbeta: 1.0000 - val_loss: 0.7144 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04863: val_loss did not improve from 0.39496\n",
      "Epoch 4864/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5536e-05 - fbeta: 1.0000 - val_loss: 0.7149 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04864: val_loss did not improve from 0.39496\n",
      "Epoch 4865/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5644e-05 - fbeta: 1.0000 - val_loss: 0.7152 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04865: val_loss did not improve from 0.39496\n",
      "Epoch 4866/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5507e-05 - fbeta: 1.0000 - val_loss: 0.7146 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04866: val_loss did not improve from 0.39496\n",
      "Epoch 4867/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5516e-05 - fbeta: 1.0000 - val_loss: 0.7147 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04867: val_loss did not improve from 0.39496\n",
      "Epoch 4868/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5635e-05 - fbeta: 1.0000 - val_loss: 0.7129 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04868: val_loss did not improve from 0.39496\n",
      "Epoch 4869/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5495e-05 - fbeta: 1.0000 - val_loss: 0.7136 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04869: val_loss did not improve from 0.39496\n",
      "Epoch 4870/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5500e-05 - fbeta: 1.0000 - val_loss: 0.7125 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04870: val_loss did not improve from 0.39496\n",
      "Epoch 4871/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5447e-05 - fbeta: 1.0000 - val_loss: 0.7136 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04871: val_loss did not improve from 0.39496\n",
      "Epoch 4872/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5441e-05 - fbeta: 1.0000 - val_loss: 0.7139 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04872: val_loss did not improve from 0.39496\n",
      "Epoch 4873/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5482e-05 - fbeta: 1.0000 - val_loss: 0.7145 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04873: val_loss did not improve from 0.39496\n",
      "Epoch 4874/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5387e-05 - fbeta: 1.0000 - val_loss: 0.7136 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04874: val_loss did not improve from 0.39496\n",
      "Epoch 4875/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5495e-05 - fbeta: 1.0000 - val_loss: 0.7132 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04875: val_loss did not improve from 0.39496\n",
      "Epoch 4876/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5403e-05 - fbeta: 1.0000 - val_loss: 0.7140 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04876: val_loss did not improve from 0.39496\n",
      "Epoch 4877/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5472e-05 - fbeta: 1.0000 - val_loss: 0.7137 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04877: val_loss did not improve from 0.39496\n",
      "Epoch 4878/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5470e-05 - fbeta: 1.0000 - val_loss: 0.7085 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04878: val_loss did not improve from 0.39496\n",
      "Epoch 4879/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5365e-05 - fbeta: 1.0000 - val_loss: 0.7101 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04879: val_loss did not improve from 0.39496\n",
      "Epoch 4880/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5209e-05 - fbeta: 1.0000 - val_loss: 0.7104 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04880: val_loss did not improve from 0.39496\n",
      "Epoch 4881/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5222e-05 - fbeta: 1.0000 - val_loss: 0.7096 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04881: val_loss did not improve from 0.39496\n",
      "Epoch 4882/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5295e-05 - fbeta: 1.0000 - val_loss: 0.7108 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04882: val_loss did not improve from 0.39496\n",
      "Epoch 4883/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5230e-05 - fbeta: 1.0000 - val_loss: 0.7126 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04883: val_loss did not improve from 0.39496\n",
      "Epoch 4884/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5197e-05 - fbeta: 1.0000 - val_loss: 0.7121 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04884: val_loss did not improve from 0.39496\n",
      "Epoch 4885/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5151e-05 - fbeta: 1.0000 - val_loss: 0.7147 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04885: val_loss did not improve from 0.39496\n",
      "Epoch 4886/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5181e-05 - fbeta: 1.0000 - val_loss: 0.7155 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04886: val_loss did not improve from 0.39496\n",
      "Epoch 4887/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5146e-05 - fbeta: 1.0000 - val_loss: 0.7153 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04887: val_loss did not improve from 0.39496\n",
      "Epoch 4888/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5113e-05 - fbeta: 1.0000 - val_loss: 0.7163 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04888: val_loss did not improve from 0.39496\n",
      "Epoch 4889/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5007e-05 - fbeta: 1.0000 - val_loss: 0.7160 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04889: val_loss did not improve from 0.39496\n",
      "Epoch 4890/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 9.5063e-05 - fbeta: 1.0000 - val_loss: 0.7168 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04890: val_loss did not improve from 0.39496\n",
      "Epoch 4891/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4894e-05 - fbeta: 1.0000 - val_loss: 0.7166 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04891: val_loss did not improve from 0.39496\n",
      "Epoch 4892/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4996e-05 - fbeta: 1.0000 - val_loss: 0.7154 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04892: val_loss did not improve from 0.39496\n",
      "Epoch 4893/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4962e-05 - fbeta: 1.0000 - val_loss: 0.7159 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04893: val_loss did not improve from 0.39496\n",
      "Epoch 4894/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4979e-05 - fbeta: 1.0000 - val_loss: 0.7142 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04894: val_loss did not improve from 0.39496\n",
      "Epoch 4895/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4904e-05 - fbeta: 1.0000 - val_loss: 0.7152 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04895: val_loss did not improve from 0.39496\n",
      "Epoch 4896/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4933e-05 - fbeta: 1.0000 - val_loss: 0.7156 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04896: val_loss did not improve from 0.39496\n",
      "Epoch 4897/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4819e-05 - fbeta: 1.0000 - val_loss: 0.7154 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04897: val_loss did not improve from 0.39496\n",
      "Epoch 4898/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4809e-05 - fbeta: 1.0000 - val_loss: 0.7146 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04898: val_loss did not improve from 0.39496\n",
      "Epoch 4899/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4839e-05 - fbeta: 1.0000 - val_loss: 0.7148 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04899: val_loss did not improve from 0.39496\n",
      "Epoch 4900/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4728e-05 - fbeta: 1.0000 - val_loss: 0.7159 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04900: val_loss did not improve from 0.39496\n",
      "Epoch 4901/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4717e-05 - fbeta: 1.0000 - val_loss: 0.7159 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04901: val_loss did not improve from 0.39496\n",
      "Epoch 4902/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4684e-05 - fbeta: 1.0000 - val_loss: 0.7163 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04902: val_loss did not improve from 0.39496\n",
      "Epoch 4903/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4655e-05 - fbeta: 1.0000 - val_loss: 0.7166 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04903: val_loss did not improve from 0.39496\n",
      "Epoch 4904/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4710e-05 - fbeta: 1.0000 - val_loss: 0.7162 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04904: val_loss did not improve from 0.39496\n",
      "Epoch 4905/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4625e-05 - fbeta: 1.0000 - val_loss: 0.7162 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04905: val_loss did not improve from 0.39496\n",
      "Epoch 4906/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4704e-05 - fbeta: 1.0000 - val_loss: 0.7159 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04906: val_loss did not improve from 0.39496\n",
      "Epoch 4907/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4547e-05 - fbeta: 1.0000 - val_loss: 0.7165 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04907: val_loss did not improve from 0.39496\n",
      "Epoch 4908/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4606e-05 - fbeta: 1.0000 - val_loss: 0.7167 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04908: val_loss did not improve from 0.39496\n",
      "Epoch 4909/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4545e-05 - fbeta: 1.0000 - val_loss: 0.7173 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04909: val_loss did not improve from 0.39496\n",
      "Epoch 4910/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4650e-05 - fbeta: 1.0000 - val_loss: 0.7171 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04910: val_loss did not improve from 0.39496\n",
      "Epoch 4911/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4540e-05 - fbeta: 1.0000 - val_loss: 0.7180 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04911: val_loss did not improve from 0.39496\n",
      "Epoch 4912/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4455e-05 - fbeta: 1.0000 - val_loss: 0.7169 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04912: val_loss did not improve from 0.39496\n",
      "Epoch 4913/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4440e-05 - fbeta: 1.0000 - val_loss: 0.7169 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04913: val_loss did not improve from 0.39496\n",
      "Epoch 4914/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4437e-05 - fbeta: 1.0000 - val_loss: 0.7173 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04914: val_loss did not improve from 0.39496\n",
      "Epoch 4915/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4466e-05 - fbeta: 1.0000 - val_loss: 0.7178 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04915: val_loss did not improve from 0.39496\n",
      "Epoch 4916/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4433e-05 - fbeta: 1.0000 - val_loss: 0.7177 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04916: val_loss did not improve from 0.39496\n",
      "Epoch 4917/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4422e-05 - fbeta: 1.0000 - val_loss: 0.7139 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04917: val_loss did not improve from 0.39496\n",
      "Epoch 4918/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4379e-05 - fbeta: 1.0000 - val_loss: 0.7151 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04918: val_loss did not improve from 0.39496\n",
      "Epoch 4919/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4328e-05 - fbeta: 1.0000 - val_loss: 0.7169 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04919: val_loss did not improve from 0.39496\n",
      "Epoch 4920/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4382e-05 - fbeta: 1.0000 - val_loss: 0.7171 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04920: val_loss did not improve from 0.39496\n",
      "Epoch 4921/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4246e-05 - fbeta: 1.0000 - val_loss: 0.7161 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04921: val_loss did not improve from 0.39496\n",
      "Epoch 4922/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4311e-05 - fbeta: 1.0000 - val_loss: 0.7171 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04922: val_loss did not improve from 0.39496\n",
      "Epoch 4923/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4269e-05 - fbeta: 1.0000 - val_loss: 0.7172 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04923: val_loss did not improve from 0.39496\n",
      "Epoch 4924/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4211e-05 - fbeta: 1.0000 - val_loss: 0.7171 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04924: val_loss did not improve from 0.39496\n",
      "Epoch 4925/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4249e-05 - fbeta: 1.0000 - val_loss: 0.7177 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04925: val_loss did not improve from 0.39496\n",
      "Epoch 4926/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4189e-05 - fbeta: 1.0000 - val_loss: 0.7175 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04926: val_loss did not improve from 0.39496\n",
      "Epoch 4927/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4172e-05 - fbeta: 1.0000 - val_loss: 0.7177 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04927: val_loss did not improve from 0.39496\n",
      "Epoch 4928/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4130e-05 - fbeta: 1.0000 - val_loss: 0.7185 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04928: val_loss did not improve from 0.39496\n",
      "Epoch 4929/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4133e-05 - fbeta: 1.0000 - val_loss: 0.7201 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04929: val_loss did not improve from 0.39496\n",
      "Epoch 4930/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4092e-05 - fbeta: 1.0000 - val_loss: 0.7187 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04930: val_loss did not improve from 0.39496\n",
      "Epoch 4931/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4031e-05 - fbeta: 1.0000 - val_loss: 0.7185 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04931: val_loss did not improve from 0.39496\n",
      "Epoch 4932/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4048e-05 - fbeta: 1.0000 - val_loss: 0.7182 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04932: val_loss did not improve from 0.39496\n",
      "Epoch 4933/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4028e-05 - fbeta: 1.0000 - val_loss: 0.7183 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04933: val_loss did not improve from 0.39496\n",
      "Epoch 4934/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4011e-05 - fbeta: 1.0000 - val_loss: 0.7177 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04934: val_loss did not improve from 0.39496\n",
      "Epoch 4935/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3888e-05 - fbeta: 1.0000 - val_loss: 0.7167 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04935: val_loss did not improve from 0.39496\n",
      "Epoch 4936/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3922e-05 - fbeta: 1.0000 - val_loss: 0.7167 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04936: val_loss did not improve from 0.39496\n",
      "Epoch 4937/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.4062e-05 - fbeta: 1.0000 - val_loss: 0.7179 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04937: val_loss did not improve from 0.39496\n",
      "Epoch 4938/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3987e-05 - fbeta: 1.0000 - val_loss: 0.7172 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04938: val_loss did not improve from 0.39496\n",
      "Epoch 4939/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3844e-05 - fbeta: 1.0000 - val_loss: 0.7153 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04939: val_loss did not improve from 0.39496\n",
      "Epoch 4940/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3924e-05 - fbeta: 1.0000 - val_loss: 0.7146 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04940: val_loss did not improve from 0.39496\n",
      "Epoch 4941/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3871e-05 - fbeta: 1.0000 - val_loss: 0.7139 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04941: val_loss did not improve from 0.39496\n",
      "Epoch 4942/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3872e-05 - fbeta: 1.0000 - val_loss: 0.7145 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04942: val_loss did not improve from 0.39496\n",
      "Epoch 4943/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3789e-05 - fbeta: 1.0000 - val_loss: 0.7146 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04943: val_loss did not improve from 0.39496\n",
      "Epoch 4944/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3918e-05 - fbeta: 1.0000 - val_loss: 0.7140 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04944: val_loss did not improve from 0.39496\n",
      "Epoch 4945/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3702e-05 - fbeta: 1.0000 - val_loss: 0.7154 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04945: val_loss did not improve from 0.39496\n",
      "Epoch 4946/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3722e-05 - fbeta: 1.0000 - val_loss: 0.7135 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04946: val_loss did not improve from 0.39496\n",
      "Epoch 4947/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3649e-05 - fbeta: 1.0000 - val_loss: 0.7145 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04947: val_loss did not improve from 0.39496\n",
      "Epoch 4948/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3671e-05 - fbeta: 1.0000 - val_loss: 0.7157 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04948: val_loss did not improve from 0.39496\n",
      "Epoch 4949/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3613e-05 - fbeta: 1.0000 - val_loss: 0.7158 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04949: val_loss did not improve from 0.39496\n",
      "Epoch 4950/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3599e-05 - fbeta: 1.0000 - val_loss: 0.7163 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04950: val_loss did not improve from 0.39496\n",
      "Epoch 4951/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3562e-05 - fbeta: 1.0000 - val_loss: 0.7162 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04951: val_loss did not improve from 0.39496\n",
      "Epoch 4952/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3628e-05 - fbeta: 1.0000 - val_loss: 0.7161 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04952: val_loss did not improve from 0.39496\n",
      "Epoch 4953/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3599e-05 - fbeta: 1.0000 - val_loss: 0.7147 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04953: val_loss did not improve from 0.39496\n",
      "Epoch 4954/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3563e-05 - fbeta: 1.0000 - val_loss: 0.7144 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04954: val_loss did not improve from 0.39496\n",
      "Epoch 4955/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3442e-05 - fbeta: 1.0000 - val_loss: 0.7157 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04955: val_loss did not improve from 0.39496\n",
      "Epoch 4956/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3461e-05 - fbeta: 1.0000 - val_loss: 0.7180 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04956: val_loss did not improve from 0.39496\n",
      "Epoch 4957/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3484e-05 - fbeta: 1.0000 - val_loss: 0.7176 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04957: val_loss did not improve from 0.39496\n",
      "Epoch 4958/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3427e-05 - fbeta: 1.0000 - val_loss: 0.7174 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04958: val_loss did not improve from 0.39496\n",
      "Epoch 4959/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3397e-05 - fbeta: 1.0000 - val_loss: 0.7171 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04959: val_loss did not improve from 0.39496\n",
      "Epoch 4960/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3399e-05 - fbeta: 1.0000 - val_loss: 0.7167 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04960: val_loss did not improve from 0.39496\n",
      "Epoch 4961/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3418e-05 - fbeta: 1.0000 - val_loss: 0.7172 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04961: val_loss did not improve from 0.39496\n",
      "Epoch 4962/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3335e-05 - fbeta: 1.0000 - val_loss: 0.7172 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04962: val_loss did not improve from 0.39496\n",
      "Epoch 4963/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3318e-05 - fbeta: 1.0000 - val_loss: 0.7176 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04963: val_loss did not improve from 0.39496\n",
      "Epoch 4964/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3350e-05 - fbeta: 1.0000 - val_loss: 0.7181 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04964: val_loss did not improve from 0.39496\n",
      "Epoch 4965/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3308e-05 - fbeta: 1.0000 - val_loss: 0.7190 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04965: val_loss did not improve from 0.39496\n",
      "Epoch 4966/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3283e-05 - fbeta: 1.0000 - val_loss: 0.7181 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04966: val_loss did not improve from 0.39496\n",
      "Epoch 4967/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3283e-05 - fbeta: 1.0000 - val_loss: 0.7171 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04967: val_loss did not improve from 0.39496\n",
      "Epoch 4968/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3312e-05 - fbeta: 1.0000 - val_loss: 0.7175 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04968: val_loss did not improve from 0.39496\n",
      "Epoch 4969/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3299e-05 - fbeta: 1.0000 - val_loss: 0.7172 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04969: val_loss did not improve from 0.39496\n",
      "Epoch 4970/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3240e-05 - fbeta: 1.0000 - val_loss: 0.7180 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04970: val_loss did not improve from 0.39496\n",
      "Epoch 4971/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3203e-05 - fbeta: 1.0000 - val_loss: 0.7173 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04971: val_loss did not improve from 0.39496\n",
      "Epoch 4972/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3148e-05 - fbeta: 1.0000 - val_loss: 0.7175 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04972: val_loss did not improve from 0.39496\n",
      "Epoch 4973/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3122e-05 - fbeta: 1.0000 - val_loss: 0.7161 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04973: val_loss did not improve from 0.39496\n",
      "Epoch 4974/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3063e-05 - fbeta: 1.0000 - val_loss: 0.7168 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04974: val_loss did not improve from 0.39496\n",
      "Epoch 4975/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3130e-05 - fbeta: 1.0000 - val_loss: 0.7160 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04975: val_loss did not improve from 0.39496\n",
      "Epoch 4976/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3088e-05 - fbeta: 1.0000 - val_loss: 0.7164 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04976: val_loss did not improve from 0.39496\n",
      "Epoch 4977/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3043e-05 - fbeta: 1.0000 - val_loss: 0.7164 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04977: val_loss did not improve from 0.39496\n",
      "Epoch 4978/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2979e-05 - fbeta: 1.0000 - val_loss: 0.7174 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04978: val_loss did not improve from 0.39496\n",
      "Epoch 4979/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2965e-05 - fbeta: 1.0000 - val_loss: 0.7159 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04979: val_loss did not improve from 0.39496\n",
      "Epoch 4980/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2932e-05 - fbeta: 1.0000 - val_loss: 0.7157 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04980: val_loss did not improve from 0.39496\n",
      "Epoch 4981/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.3040e-05 - fbeta: 1.0000 - val_loss: 0.7158 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04981: val_loss did not improve from 0.39496\n",
      "Epoch 4982/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2972e-05 - fbeta: 1.0000 - val_loss: 0.7161 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04982: val_loss did not improve from 0.39496\n",
      "Epoch 4983/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2942e-05 - fbeta: 1.0000 - val_loss: 0.7160 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04983: val_loss did not improve from 0.39496\n",
      "Epoch 4984/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2852e-05 - fbeta: 1.0000 - val_loss: 0.7176 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04984: val_loss did not improve from 0.39496\n",
      "Epoch 4985/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2879e-05 - fbeta: 1.0000 - val_loss: 0.7173 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04985: val_loss did not improve from 0.39496\n",
      "Epoch 4986/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2843e-05 - fbeta: 1.0000 - val_loss: 0.7179 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04986: val_loss did not improve from 0.39496\n",
      "Epoch 4987/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2734e-05 - fbeta: 1.0000 - val_loss: 0.7180 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04987: val_loss did not improve from 0.39496\n",
      "Epoch 4988/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2765e-05 - fbeta: 1.0000 - val_loss: 0.7181 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04988: val_loss did not improve from 0.39496\n",
      "Epoch 4989/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2787e-05 - fbeta: 1.0000 - val_loss: 0.7170 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04989: val_loss did not improve from 0.39496\n",
      "Epoch 4990/5000\n",
      "622/622 [==============================] - 25s 41ms/step - loss: 9.2693e-05 - fbeta: 1.0000 - val_loss: 0.7167 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04990: val_loss did not improve from 0.39496\n",
      "Epoch 4991/5000\n",
      "622/622 [==============================] - 25s 41ms/step - loss: 9.2680e-05 - fbeta: 1.0000 - val_loss: 0.7168 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04991: val_loss did not improve from 0.39496\n",
      "Epoch 4992/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2659e-05 - fbeta: 1.0000 - val_loss: 0.7173 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04992: val_loss did not improve from 0.39496\n",
      "Epoch 4993/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2668e-05 - fbeta: 1.0000 - val_loss: 0.7177 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04993: val_loss did not improve from 0.39496\n",
      "Epoch 4994/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2589e-05 - fbeta: 1.0000 - val_loss: 0.7165 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04994: val_loss did not improve from 0.39496\n",
      "Epoch 4995/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2674e-05 - fbeta: 1.0000 - val_loss: 0.7165 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04995: val_loss did not improve from 0.39496\n",
      "Epoch 4996/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2630e-05 - fbeta: 1.0000 - val_loss: 0.7167 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04996: val_loss did not improve from 0.39496\n",
      "Epoch 4997/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2566e-05 - fbeta: 1.0000 - val_loss: 0.7169 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04997: val_loss did not improve from 0.39496\n",
      "Epoch 4998/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2571e-05 - fbeta: 1.0000 - val_loss: 0.7173 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04998: val_loss did not improve from 0.39496\n",
      "Epoch 4999/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2582e-05 - fbeta: 1.0000 - val_loss: 0.7180 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 04999: val_loss did not improve from 0.39496\n",
      "Epoch 5000/5000\n",
      "622/622 [==============================] - 25s 40ms/step - loss: 9.2458e-05 - fbeta: 1.0000 - val_loss: 0.7181 - val_fbeta: 0.9205\n",
      "\n",
      "Epoch 05000: val_loss did not improve from 0.39496\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras import callbacks\n",
    "\n",
    "PARAM_MAX_EPOCHS = 5000 # PARAM: number of model-fit runs\n",
    "PARAM_N_BATCH = 20 # PARAM: number of input samples for one feedfwd-backprop step\n",
    "\n",
    "checkpointer = callbacks.ModelCheckpoint (\n",
    "    filepath=os.path.join ('model','model.w.best.h5'),\n",
    "    verbose=1,\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model.fit (X_train, y_train,\n",
    "                     epochs=PARAM_MAX_EPOCHS, batch_size=PARAM_N_BATCH, validation_split=0.1, shuffle=True,\n",
    "                     callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_fbeta', 'val_loss', 'fbeta', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "print (history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, axs = plt.subplots (1, 2)\n",
    "\n",
    "# summarize history for accuracy\n",
    "axs[0].plot (history.history['fbeta'][:400])\n",
    "if 'val_fbeta' in history.history:\n",
    "    axs[0].plot (history.history['val_fbeta'][:400])\n",
    "axs[0].set (xlabel='epoch', ylabel='score (higher better)', title='F-{} score'.format (PARAM_BETA))\n",
    "axs[0].legend (['train', 'validation'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "axs[1].plot (history.history['loss'][:400])\n",
    "if 'val_loss' in history.history:\n",
    "    axs[1].plot (history.history['val_loss'][:400])\n",
    "axs[1].set (xlabel='epoch', ylabel='loss (lower better)', title='loss (cat x-entropy)')\n",
    "axs[1].legend (['train', 'validation'], loc='upper left')\n",
    "\n",
    "fig.set_size_inches ((15., 6.), forward=True)\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**discussion**\n",
    "\n",
    "[2018-09-02]\n",
    "\n",
    "epoch 205:\n",
    "- loss: 0.0280\n",
    "- val_loss: 0.4546\n",
    "- fbeta: 1.0000\n",
    "- val_fbeta: 0.9412\n",
    "\n",
    "_\n",
    "\n",
    "Above graphs show the F-beta score per epoch with beta = 1 on the left and the *loss per epoch*, calulated by the mean squared error (mse) on the right.\n",
    "\n",
    "*loss per epoch*:\n",
    "- gradient steps start with a loss of 0.052, end by 0.042 and show a smooth concave curve. The curve couldn't be better except a faster drop in the first 10 epochs.\n",
    "- the worse: mse after 1st epoch = 0.052 - the CNN learns very slow and in tiny steps (1st/2nd epoch: 0.052-0.049 = 0.003)\n",
    "\n",
    "*F-beta score per epoch*\n",
    "- evaluation metric immediately drops to zero after some epochs - the CNN doesn't learn anything yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reasons / todo\n",
    "\n",
    "*input data*\n",
    "\n",
    "(1) The used dataset only has 240 samples for training, validation and test. This is by far nothing for the CNN.\n",
    "\n",
    "Todo: retrieve more samples for the dataset\n",
    "\n",
    "(2) A quick look at random spectrograms show kind of chaotic information - as a human being it is hard to tell if there's any structure behind each key-mode pair. This may apply to the CNN too.\n",
    "\n",
    "Todo: find additional filter techniques / methods to clearly bring out structures for the CNN\n",
    "\n",
    "(3) Songs can change in key over their whole length.\n",
    "\n",
    "Todo: take appropriate sample of a song - ommit bridges, refrains, silent passages, noisy songs\n",
    "\n",
    "_\n",
    "\n",
    "*model training*\n",
    "\n",
    "The model was trained for 100 epochs, each in batches of 10 samples per feedfwd-backprop step. To make sure that the architecture is well suited, more epochs shall be run.\n",
    "\n",
    "Todo: increase epochs, change batch size\n",
    "\n",
    "_\n",
    "\n",
    "*model architecture*\n",
    "\n",
    "Todo: To better understand the insight of the CNN, visualize the filter of the convolutions. May there be enlightenment what kind of architecture works best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compare learning algorithm to benchmarks\n",
    "\n",
    "[i] below statements can be run without executing the whole notebook\n",
    "\n",
    "Therefor, go to and execute <a href='#load-learning-algorithm'>load learning algorithm</a>\n",
    "\n",
    "**TODO** **TODO** **TODO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 3s 17ms/step\n",
      "[('loss', 0.005754849627271466), ('fbeta', 0.935651016646418)]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate (X_test, y_test, verbose=1)\n",
    "print ([(model.metrics_names[i], score[i]) for i in range (len (model.metrics_names))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8309754 21\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict (X_test[np.newaxis, 0])\n",
    "print (prediction.max (), prediction.argmax ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> saving model... done\n"
     ]
    }
   ],
   "source": [
    "# serialization of model architecture\n",
    "import os\n",
    "\n",
    "save_name = os.path.join ('model', 'model.arch.yaml')\n",
    "\n",
    "print ('>>> saving model...', end=' ', flush=True)\n",
    "yaml_string = model.to_yaml ()\n",
    "with open (save_name, 'w') as yaml_file:\n",
    "    yaml_file.write (yaml_string)\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> saving history... done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print ('>>> saving history...', end=' ', flush=True)\n",
    "hist_df = pd.DataFrame.from_dict (history.history)\n",
    "hist_df.to_csv (os.path.join ('model', 'model.hist_180902.csv'))\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> loading and compiling model... done\n",
      ">>> loading best weights into model... done\n"
     ]
    }
   ],
   "source": [
    "# load model architecture\n",
    "from keras import models\n",
    "\n",
    "load_name = os.path.join ('model', 'model.arch_180902.yaml')\n",
    "print ('>>> loading and compiling model...', end=' ', flush=True)\n",
    "with open (load_name, 'r') as yaml_file:\n",
    "    yaml_string = yaml_file.read ()\n",
    "model = models.model_from_yaml (yaml_string)\n",
    "model.compile (optimizer=opt_sgd, loss=losses.mean_squared_error, metrics=[fbeta])\n",
    "print ('done')\n",
    "\n",
    "# load best weights\n",
    "print ('>>> loading best weights into model...', end=' ', flush=True)\n",
    "model.load_weights (os.path.join ('model','model.w.best_180902.h5'))\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_spectro/8-0/TRHQWMN128F426AB93.png\n",
      "y_true 8-0\n",
      "y_pred 8-0\n"
     ]
    }
   ],
   "source": [
    "idx = 278\n",
    "test_file = src_spectro_data['filenames'][idx]\n",
    "\n",
    "test_spectro = path_to_tensor (test_file)\n",
    "test_pred = model.predict (test_spectro)\n",
    "\n",
    "print (test_file)\n",
    "print ('y_true', src_spectro_data['target_names'][src_spectro_data['target'][idx]])\n",
    "print ('y_pred', src_spectro_data['target_names'][test_pred.argmax ()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obsolete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**drawbacks** (known, unresolvable issues)\n",
    "\n",
    "(WRONG) *music keys vs CNN key classes*\n",
    "\n",
    "See <a href='https://www.researchgate.net/publication/228963946_Audio_onset_detection_using_machine_learning_techniques_the_effect_and_applicability_of_key_and_tempo_information'>Chuan, Ching-Hua & Chew, Elaine. (2018). Audio onset detection using machine learning techniques: the effect and applicability of key and tempo information.</a>, p. 18\n",
    "\n",
    "The spectrograms show a pitch range given by the <a href='https://en.wikipedia.org/wiki/Scientific_pitch_notation#Table_of_note_frequencies'>Scientific Pitch Notation</a>. By that the range of notes goes from $C_{-1}$ = $0_{MIDI}$ up to $G_9$ = $127_{MIDI}$.\n",
    "\n",
    "Each note can be the tonic of a music key - for example the key 'C major' exists 11 times (ocatve -1 to 9). Thus the information of 128 keys is now squeezed into 24 key classes.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
