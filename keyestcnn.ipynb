{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio key estimation of digital music with CNNs\n",
    "Udacity Machine Learning Nanodegree - Capstone project\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "The project is structured as stated in section 'Project Design' of the Capstone project proposal.\n",
    "\n",
    "_\n",
    "<pre>\n",
    "<a href='#Data-Preprocessing'>Data Preprocessing</a>\n",
    "  <a href='#Million-Song-Dataset'>Million Song Dataset</a> - selection of appropriate songs, separate jupyter notebook\n",
    "  <a href='#Signal-Processing-and-Feature-Extraction'>Signal Processing and Feature Extraction</a> - separate jupyter notebook\n",
    "\n",
    "<a href='#Model-Preparation'>Model Preparation</a>\n",
    "  <a href='#Load-and-prepare-data'>Load and prepare data</a> - read spectrogram images, conversion to tensors\n",
    "  <a href='#Split-data-into-train-and-test-set'>Splitting data into training/testing sets</a>\n",
    "  <a href='#Model-architecture'>CNN model architecture</a>\n",
    "  <a href='#Model-parameter'>CNN model parameter</a>\n",
    "\n",
    "<a href='#Model-Training-and-Evaluation'>Model Training and Evaluation</a>\n",
    "  <a href='#Model-training'>Model training</a>\n",
    "  <a href='#Model-evaluation-and-comparison'>Model evaluation and comparison</a>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current version of the project is working, but\n",
    "\n",
    "the project is still ongoing...\n",
    "\n",
    "discussion and remarks of what to do can be found in section\n",
    "\n",
    "<a href='#reasons-/-todo'>reasons / todo</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Million Song Dataset\n",
    "- utilized to select appropriate song samples\n",
    "- holds information about key and mode per song (targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juypter Notebook <a href='./00.hlp/msd/msd.ipynb'>msd</a>\n",
    "\n",
    "outputs: csv file *songs_conf=75_tracks_filt.csv*, which holds all songs with key confidence and mode confidence > 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>key_confidence</th>\n",
       "      <th>mode</th>\n",
       "      <th>mode_confidence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>track_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852</td>\n",
       "      <td>114.493</td>\n",
       "      <td>TRMMMGL128F92FD6AB</td>\n",
       "      <td>SOHSSPG12A8C144BE0</td>\n",
       "      <td>Clifford T. Ward</td>\n",
       "      <td>Mad About You</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  key_confidence  mode  mode_confidence    tempo            track_id  \\\n",
       "0    7           0.896     1            0.852  114.493  TRMMMGL128F92FD6AB   \n",
       "\n",
       "              song_id       artist_name     song_title  \n",
       "0  SOHSSPG12A8C144BE0  Clifford T. Ward  Mad About You  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] number of records: 47913\n"
     ]
    }
   ],
   "source": [
    "# LIST SELECTED SONGS\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "selsongsfile = os.path.join ('00.hlp', 'msd', 'songs_conf=75_tracks_filt.csv')\n",
    "selsongs = pd.read_csv (selsongsfile, header=0, index_col=0)\n",
    "display (selsongs.head (1))\n",
    "print ('[i] number of records:', len (selsongs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD AUDIO DATASET\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "PARAM_RND_STATE = 42\n",
    "\n",
    "container_path = os.path.join ('src_audio')\n",
    "load_content = False\n",
    "description = ['key C, mode minor', 'key C, mode major',\n",
    "               'key C#, mode minor', 'key C#, mode major',\n",
    "               'key D, mode minor', 'key D, mode major',\n",
    "               'key D#, mode minor', 'key D#, mode major',\n",
    "               'key E, mode minor', 'key E, mode major',\n",
    "               'key F, mode minor', 'key F, mode major',\n",
    "               'key F#, mode minor', 'key F#, mode major',\n",
    "               'key G, mode minor', 'key G, mode major',\n",
    "               'key G#, mode minor', 'key G#, mode major',\n",
    "               'key A, mode minor', 'key A, mode major',\n",
    "               'key A#, mode minor', 'key A#, mode major',\n",
    "               'key B, mode minor', 'key B, mode major']\n",
    "\n",
    "src_audio_data = datasets.load_files (container_path=container_path,\n",
    "                                      description=description,\n",
    "                                      load_content=load_content,\n",
    "                                      random_state=PARAM_RND_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>key_confidence</th>\n",
       "      <th>mode</th>\n",
       "      <th>mode_confidence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>track_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8519</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>120.637</td>\n",
       "      <td>TRCJFML128F425F625</td>\n",
       "      <td>SOMDRWH12A8C1351D0</td>\n",
       "      <td>Joe Christmas</td>\n",
       "      <td>Sonnet 61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33783</th>\n",
       "      <td>2</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0</td>\n",
       "      <td>0.937</td>\n",
       "      <td>89.469</td>\n",
       "      <td>TRJQUAR128F9336E73</td>\n",
       "      <td>SOIQHFF12AB018745F</td>\n",
       "      <td>Mariee Sioux</td>\n",
       "      <td>Love Song</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31721</th>\n",
       "      <td>9</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>143.093</td>\n",
       "      <td>TRERTES128F426EA61</td>\n",
       "      <td>SOKGLAB12A8C132D24</td>\n",
       "      <td>Mad Season</td>\n",
       "      <td>Artifical Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24744</th>\n",
       "      <td>4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988</td>\n",
       "      <td>130.772</td>\n",
       "      <td>TRPNLNH12903CC90CD</td>\n",
       "      <td>SOSZNNV12AB0186A54</td>\n",
       "      <td>OHM</td>\n",
       "      <td>Common Sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31147</th>\n",
       "      <td>4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960</td>\n",
       "      <td>94.544</td>\n",
       "      <td>TRLOXSL128F1484144</td>\n",
       "      <td>SOGYLOK12A6D4F9435</td>\n",
       "      <td>Orson</td>\n",
       "      <td>Happiness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       key  key_confidence  mode  mode_confidence    tempo  \\\n",
       "8519    11           1.000     1            1.000  120.637   \n",
       "33783    2           0.959     0            0.937   89.469   \n",
       "31721    9           1.000     1            1.000  143.093   \n",
       "24744    4           1.000     1            0.988  130.772   \n",
       "31147    4           1.000     1            0.960   94.544   \n",
       "\n",
       "                 track_id             song_id    artist_name     song_title  \n",
       "8519   TRCJFML128F425F625  SOMDRWH12A8C1351D0  Joe Christmas      Sonnet 61  \n",
       "33783  TRJQUAR128F9336E73  SOIQHFF12AB018745F   Mariee Sioux      Love Song  \n",
       "31721  TRERTES128F426EA61  SOKGLAB12A8C132D24     Mad Season  Artifical Red  \n",
       "24744  TRPNLNH12903CC90CD  SOSZNNV12AB0186A54            OHM   Common Sense  \n",
       "31147  TRLOXSL128F1484144  SOGYLOK12A6D4F9435          Orson      Happiness  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] number of records: 240\n",
      "[i] min of: key_confidence = 0.809 , mode_confidence = 0.777\n",
      "[i] tempo: min = 0.0 , max = 248.32299999999998\n"
     ]
    }
   ],
   "source": [
    "# FYI: LIST SOME OF THE USED SONGS\n",
    "filenames = list (os.path.basename (filepath) for filepath in src_audio_data['filenames'])\n",
    "usedsongs_track_id = list (os.path.splitext (fn)[0] for fn in filenames)\n",
    "usedsongs = selsongs.query ('track_id in @usedsongs_track_id')\n",
    "\n",
    "display (usedsongs.sample(5))\n",
    "print ('[i] number of records:', len (usedsongs))\n",
    "print ('[i] min of: key_confidence =', usedsongs['key_confidence'].min (), ',', \\\n",
    "       'mode_confidence =', usedsongs['mode_confidence'].min ())\n",
    "print ('[i] tempo: min =', usedsongs['tempo'].min (), ',', \\\n",
    "       'max =', usedsongs['tempo'].max ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Processing and Feature Extraction\n",
    "- create spectrograms of audio files with discrete Fourier transform (DFT)\n",
    "- save spectrograms as images for further use in CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juypter Notebook <a href='./00.hlp/fft/fft.ipynb'>fft</a>\n",
    "\n",
    "ouptuts: spectrograms (png images) of audio files with same folder structure as *src_audio* in new container path named *src_spectro*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of a spectrogram image**\n",
    "\n",
    "<img src ='./src_spectro/7-0/TREDRTV12903D03829.png' align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['target', 'DESCR', 'filenames', 'target_names'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD SPECTROGRAM FILENAMES\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "PARAM_RND_STATE = 42\n",
    "\n",
    "container_path = os.path.join ('src_spectro')\n",
    "load_content = False\n",
    "description = ['key C, mode minor', 'key C, mode major',\n",
    "               'key C#, mode minor', 'key C#, mode major',\n",
    "               'key D, mode minor', 'key D, mode major',\n",
    "               'key D#, mode minor', 'key D#, mode major',\n",
    "               'key E, mode minor', 'key E, mode major',\n",
    "               'key F, mode minor', 'key F, mode major',\n",
    "               'key F#, mode minor', 'key F#, mode major',\n",
    "               'key G, mode minor', 'key G, mode major',\n",
    "               'key G#, mode minor', 'key G#, mode major',\n",
    "               'key A, mode minor', 'key A, mode major',\n",
    "               'key A#, mode minor', 'key A#, mode major',\n",
    "               'key B, mode minor', 'key B, mode major']\n",
    "\n",
    "src_spectro_data = datasets.load_files (container_path=container_path,\n",
    "                                        description=description,\n",
    "                                        load_content=load_content,\n",
    "                                        random_state=PARAM_RND_STATE)\n",
    "src_spectro_data.keys ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] example of loaded spectrogram file data:\n",
      "    spectrogram image name: src_spectro/1-0/TRLZZOJ128F1494C12.png\n",
      "    spectrogram image key-mode pair: 1-0 = key C#, mode minor = target class 2\n"
     ]
    }
   ],
   "source": [
    "print ('[i] example of loaded spectrogram file data:')\n",
    "print ('    spectrogram image name:', src_spectro_data['filenames'][0])\n",
    "print ('    spectrogram image key-mode pair:',\\\n",
    "       src_spectro_data['target_names'][src_spectro_data['target'][0]],\\\n",
    "       '=', src_spectro_data['DESCR'][src_spectro_data['target'][0]],\\\n",
    "       '= target class', src_spectro_data['target'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in images, convert to tensors**\n",
    "\n",
    "Keras Conv2D layers expect a **4D tensor with shape (batch, rows, cols, channels)** (if param data_format='channels_last') (src: <a href='https://keras.io/layers/convolutional/#conv2d'>Keras Conv2D</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] image size: (150, 128)\n",
      "[i] pixel format: RGB\n"
     ]
    }
   ],
   "source": [
    "# open a random image and take a look at the attributes\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open (src_spectro_data['filenames'][0])\n",
    "print ('[i] image size:', im.size)\n",
    "print ('[i] pixel format:', im.mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images are of size (150, 128) and have 3 channels\n",
    "\n",
    "for CNN: no need to change target size\n",
    "\n",
    "below functions read images and convert those to tensors - code taken from Udacity MLND dog-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor (img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img (img_path, color_mode='grayscale')#, target_size=(88, 88))\n",
    "    # convert PIL.Image.Image type to 3D tensor\n",
    "    x = image.img_to_array (img)\n",
    "    # convert 3D tensor to 4D tensor\n",
    "    return np.expand_dims (x, axis=0)\n",
    "\n",
    "def paths_to_tensor (img_paths):\n",
    "    list_of_tensors = [path_to_tensor (img_path) for img_path in tqdm (img_paths)]\n",
    "    return np.vstack (list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 1167.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "spectro_tensors = paths_to_tensor (src_spectro_data['filenames'])#.astype ('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] shape of spectrogram tensors: (240, 128, 150, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('[i] shape of spectrogram tensors:', spectro_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] number of output classes: 24\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "targets = np_utils.to_categorical (np.array (src_spectro_data['target']), 24)\n",
    "print ('[i] number of output classes:', targets.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Training dataset consists of 216 samples\n",
      "[i] Testing dataset consists of 24 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split (spectro_tensors, targets, test_size=0.10, shuffle=True, random_state=PARAM_RND_STATE)\n",
    "\n",
    "print ('[i] Training dataset consists of {} samples'.format (X_train.shape[0]))\n",
    "print ('[i] Testing dataset consists of {} samples'.format (X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 128, 150, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 150, 16)      32        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 150, 32)      2080      \n",
      "_________________________________________________________________\n",
      "maxp_2 (MaxPooling2D)        (None, 64, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 75, 64)        8256      \n",
      "_________________________________________________________________\n",
      "maxp_3 (MaxPooling2D)        (None, 32, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "avg_flatten (GlobalAveragePo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 24)                1560      \n",
      "=================================================================\n",
      "Total params: 11,928\n",
      "Trainable params: 11,928\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "from keras import backend as K\n",
    "\n",
    "# clear everything known of past instances (\"useful to avoid clutter from old models / layers\")\n",
    "K.clear_session ()\n",
    "\n",
    "# input layer\n",
    "inputs = layers.Input (shape=spectro_tensors.shape[1:], name='input')\n",
    "\n",
    "# hidden layers\n",
    "net = layers.Conv2D (filters=16, kernel_size=(1,1), strides=(1,1),\n",
    "                     padding='same', # don't lose information due to conv window runs out of image / strides = 1 = OK\n",
    "                     activation='relu',\n",
    "                     name='conv2d_1') (inputs)\n",
    "#net = layers.MaxPooling2D (pool_size=(2,2), strides=None, name='maxp_1') (net)\n",
    "\n",
    "net = layers.Conv2D (filters=32, kernel_size=(2,2), strides=(1,1),\n",
    "              padding='same',\n",
    "              activation='relu',\n",
    "              name='conv2d_2') (net)\n",
    "net = layers.MaxPooling2D (pool_size=(2,2), strides=None, name='maxp_2') (net)\n",
    "\n",
    "net = layers.Conv2D (filters=64, kernel_size=(2,2), strides=(1,1),\n",
    "              padding='same',\n",
    "              activation='relu',\n",
    "              name='conv2d_3') (net)\n",
    "net = layers.MaxPooling2D (pool_size=(2,2), strides=None, name='maxp_3') (net)\n",
    "\n",
    "#net = layers.Conv2D (filters=64, kernel_size=(2,2), strides=(1,1),\n",
    "#              padding='same',\n",
    "#              activation='relu',\n",
    "#              name='conv2d_4') (net)\n",
    "#net = layers.MaxPooling2D (pool_size=(2,2), strides=None, name='maxp_4') (net)\n",
    "\n",
    "# 'flatten layer'\n",
    "net = layers.GlobalAveragePooling2D (name='avg_flatten') (net)\n",
    "\n",
    "# output layer\n",
    "outputs = layers.Dense (units=targets.shape[1], activation='softmax', name='output') (net)\n",
    "\n",
    "\n",
    "model = models.Model (inputs=inputs, outputs=outputs)\n",
    "model.summary ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameter\n",
    "(metric, loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: Arseny Kravchenko http://arseny.info/2017/f-beta-score-for-keras.html\n",
    "from keras import backend as K\n",
    "\n",
    "PARAM_BETA = 1\n",
    "def fbeta (y_true, y_pred):\n",
    "\n",
    "    # just in case of hipster activation at the final layer\n",
    "    y_pred = K.clip (y_pred, 0, 1)\n",
    "\n",
    "    tp = K.sum (K.round (y_true * y_pred)) + K.epsilon ()\n",
    "    fp = K.sum (K.round (K.clip (y_pred - y_true, 0, 1)))\n",
    "    fn = K.sum (K.round (K.clip (y_true - y_pred, 0, 1)))\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    beta_squared = PARAM_BETA ** 2\n",
    "    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers, losses\n",
    "\n",
    "PARAM_LR = 0.0001\n",
    "opt_sgd = optimizers.SGD (lr=PARAM_LR, momentum=0.8)\n",
    "opt_adamax = optimizers.Adamax (lr=PARAM_LR, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "\n",
    "\n",
    "model.compile (optimizer=opt_sgd, loss=losses.mean_squared_error, metrics=[fbeta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 194 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "194/194 [==============================] - 11s 55ms/step - loss: 0.0477 - fbeta: 0.0086 - val_loss: 0.0444 - val_fbeta: 0.0826\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04445, saving model to model/model.w.best.h5\n",
      "Epoch 2/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0473 - fbeta: 0.0094 - val_loss: 0.0443 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04445 to 0.04426, saving model to model/model.w.best.h5\n",
      "Epoch 3/100\n",
      "194/194 [==============================] - 10s 51ms/step - loss: 0.0470 - fbeta: 1.9963e-08 - val_loss: 0.0441 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04426 to 0.04408, saving model to model/model.w.best.h5\n",
      "Epoch 4/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0467 - fbeta: 2.0166e-08 - val_loss: 0.0439 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04408 to 0.04394, saving model to model/model.w.best.h5\n",
      "Epoch 5/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0465 - fbeta: 2.0337e-08 - val_loss: 0.0438 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04394 to 0.04382, saving model to model/model.w.best.h5\n",
      "Epoch 6/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0463 - fbeta: 2.0337e-08 - val_loss: 0.0437 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04382 to 0.04371, saving model to model/model.w.best.h5\n",
      "Epoch 7/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0461 - fbeta: 2.0619e-08 - val_loss: 0.0436 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.04371 to 0.04361, saving model to model/model.w.best.h5\n",
      "Epoch 8/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0459 - fbeta: 2.0619e-08 - val_loss: 0.0435 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04361 to 0.04353, saving model to model/model.w.best.h5\n",
      "Epoch 9/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0457 - fbeta: 2.0619e-08 - val_loss: 0.0434 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04353 to 0.04345, saving model to model/model.w.best.h5\n",
      "Epoch 10/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0456 - fbeta: 2.0619e-08 - val_loss: 0.0434 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.04345 to 0.04338, saving model to model/model.w.best.h5\n",
      "Epoch 11/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0454 - fbeta: 2.0619e-08 - val_loss: 0.0433 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.04338 to 0.04332, saving model to model/model.w.best.h5\n",
      "Epoch 12/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0453 - fbeta: 2.0619e-08 - val_loss: 0.0433 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.04332 to 0.04326, saving model to model/model.w.best.h5\n",
      "Epoch 13/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0452 - fbeta: 2.0619e-08 - val_loss: 0.0432 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.04326 to 0.04321, saving model to model/model.w.best.h5\n",
      "Epoch 14/100\n",
      "194/194 [==============================] - 10s 51ms/step - loss: 0.0451 - fbeta: 2.0619e-08 - val_loss: 0.0432 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.04321 to 0.04316, saving model to model/model.w.best.h5\n",
      "Epoch 15/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0450 - fbeta: 2.0619e-08 - val_loss: 0.0431 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.04316 to 0.04311, saving model to model/model.w.best.h5\n",
      "Epoch 16/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0449 - fbeta: 2.0619e-08 - val_loss: 0.0431 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.04311 to 0.04307, saving model to model/model.w.best.h5\n",
      "Epoch 17/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0448 - fbeta: 2.0619e-08 - val_loss: 0.0430 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.04307 to 0.04302, saving model to model/model.w.best.h5\n",
      "Epoch 18/100\n",
      "194/194 [==============================] - 10s 51ms/step - loss: 0.0447 - fbeta: 2.0619e-08 - val_loss: 0.0430 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.04302 to 0.04298, saving model to model/model.w.best.h5\n",
      "Epoch 19/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0446 - fbeta: 2.0619e-08 - val_loss: 0.0429 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.04298 to 0.04294, saving model to model/model.w.best.h5\n",
      "Epoch 20/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0446 - fbeta: 2.0619e-08 - val_loss: 0.0429 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.04294 to 0.04290, saving model to model/model.w.best.h5\n",
      "Epoch 21/100\n",
      "194/194 [==============================] - 11s 58ms/step - loss: 0.0445 - fbeta: 2.0619e-08 - val_loss: 0.0429 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.04290 to 0.04287, saving model to model/model.w.best.h5\n",
      "Epoch 22/100\n",
      "194/194 [==============================] - 11s 55ms/step - loss: 0.0444 - fbeta: 2.0619e-08 - val_loss: 0.0428 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.04287 to 0.04283, saving model to model/model.w.best.h5\n",
      "Epoch 23/100\n",
      "194/194 [==============================] - 10s 54ms/step - loss: 0.0443 - fbeta: 2.0619e-08 - val_loss: 0.0428 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.04283 to 0.04280, saving model to model/model.w.best.h5\n",
      "Epoch 24/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0443 - fbeta: 2.0619e-08 - val_loss: 0.0428 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.04280 to 0.04277, saving model to model/model.w.best.h5\n",
      "Epoch 25/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0442 - fbeta: 2.0619e-08 - val_loss: 0.0427 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.04277 to 0.04274, saving model to model/model.w.best.h5\n",
      "Epoch 26/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0442 - fbeta: 2.0619e-08 - val_loss: 0.0427 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.04274 to 0.04271, saving model to model/model.w.best.h5\n",
      "Epoch 27/100\n",
      "194/194 [==============================] - 11s 54ms/step - loss: 0.0441 - fbeta: 2.0619e-08 - val_loss: 0.0427 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.04271 to 0.04268, saving model to model/model.w.best.h5\n",
      "Epoch 28/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0441 - fbeta: 2.0619e-08 - val_loss: 0.0427 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.04268 to 0.04265, saving model to model/model.w.best.h5\n",
      "Epoch 29/100\n",
      "194/194 [==============================] - 11s 55ms/step - loss: 0.0440 - fbeta: 2.0619e-08 - val_loss: 0.0426 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.04265 to 0.04262, saving model to model/model.w.best.h5\n",
      "Epoch 30/100\n",
      "194/194 [==============================] - 11s 54ms/step - loss: 0.0440 - fbeta: 2.0619e-08 - val_loss: 0.0426 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.04262 to 0.04260, saving model to model/model.w.best.h5\n",
      "Epoch 31/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0439 - fbeta: 2.0619e-08 - val_loss: 0.0426 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.04260 to 0.04258, saving model to model/model.w.best.h5\n",
      "Epoch 32/100\n",
      "194/194 [==============================] - 10s 54ms/step - loss: 0.0439 - fbeta: 2.0619e-08 - val_loss: 0.0426 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.04258 to 0.04255, saving model to model/model.w.best.h5\n",
      "Epoch 33/100\n",
      "194/194 [==============================] - 11s 56ms/step - loss: 0.0438 - fbeta: 2.0619e-08 - val_loss: 0.0425 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.04255 to 0.04252, saving model to model/model.w.best.h5\n",
      "Epoch 34/100\n",
      "194/194 [==============================] - 10s 54ms/step - loss: 0.0438 - fbeta: 2.0619e-08 - val_loss: 0.0425 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.04252 to 0.04250, saving model to model/model.w.best.h5\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0437 - fbeta: 2.0619e-08 - val_loss: 0.0425 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.04250 to 0.04248, saving model to model/model.w.best.h5\n",
      "Epoch 36/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0437 - fbeta: 2.0619e-08 - val_loss: 0.0425 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.04248 to 0.04246, saving model to model/model.w.best.h5\n",
      "Epoch 37/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0436 - fbeta: 2.0619e-08 - val_loss: 0.0424 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.04246 to 0.04244, saving model to model/model.w.best.h5\n",
      "Epoch 38/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0436 - fbeta: 2.0619e-08 - val_loss: 0.0424 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.04244 to 0.04242, saving model to model/model.w.best.h5\n",
      "Epoch 39/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0436 - fbeta: 2.0619e-08 - val_loss: 0.0424 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.04242 to 0.04240, saving model to model/model.w.best.h5\n",
      "Epoch 40/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0435 - fbeta: 2.0619e-08 - val_loss: 0.0424 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.04240 to 0.04238, saving model to model/model.w.best.h5\n",
      "Epoch 41/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0435 - fbeta: 2.0619e-08 - val_loss: 0.0424 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.04238 to 0.04237, saving model to model/model.w.best.h5\n",
      "Epoch 42/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0435 - fbeta: 2.0619e-08 - val_loss: 0.0423 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.04237 to 0.04235, saving model to model/model.w.best.h5\n",
      "Epoch 43/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0434 - fbeta: 2.0619e-08 - val_loss: 0.0423 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.04235 to 0.04233, saving model to model/model.w.best.h5\n",
      "Epoch 44/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0434 - fbeta: 2.0619e-08 - val_loss: 0.0423 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.04233 to 0.04232, saving model to model/model.w.best.h5\n",
      "Epoch 45/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0434 - fbeta: 2.0619e-08 - val_loss: 0.0423 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.04232 to 0.04230, saving model to model/model.w.best.h5\n",
      "Epoch 46/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0433 - fbeta: 2.0619e-08 - val_loss: 0.0423 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.04230 to 0.04229, saving model to model/model.w.best.h5\n",
      "Epoch 47/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0433 - fbeta: 2.0619e-08 - val_loss: 0.0423 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.04229 to 0.04227, saving model to model/model.w.best.h5\n",
      "Epoch 48/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0433 - fbeta: 2.0619e-08 - val_loss: 0.0423 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.04227 to 0.04226, saving model to model/model.w.best.h5\n",
      "Epoch 49/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0432 - fbeta: 2.0619e-08 - val_loss: 0.0422 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.04226 to 0.04224, saving model to model/model.w.best.h5\n",
      "Epoch 50/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0432 - fbeta: 2.0619e-08 - val_loss: 0.0422 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.04224 to 0.04223, saving model to model/model.w.best.h5\n",
      "Epoch 51/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0432 - fbeta: 2.0619e-08 - val_loss: 0.0422 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.04223 to 0.04222, saving model to model/model.w.best.h5\n",
      "Epoch 52/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0432 - fbeta: 2.0619e-08 - val_loss: 0.0422 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.04222 to 0.04220, saving model to model/model.w.best.h5\n",
      "Epoch 53/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0431 - fbeta: 2.0619e-08 - val_loss: 0.0422 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.04220 to 0.04219, saving model to model/model.w.best.h5\n",
      "Epoch 54/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0431 - fbeta: 2.0619e-08 - val_loss: 0.0422 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.04219 to 0.04218, saving model to model/model.w.best.h5\n",
      "Epoch 55/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0431 - fbeta: 2.0619e-08 - val_loss: 0.0422 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.04218 to 0.04217, saving model to model/model.w.best.h5\n",
      "Epoch 56/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0431 - fbeta: 2.0619e-08 - val_loss: 0.0422 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.04217 to 0.04216, saving model to model/model.w.best.h5\n",
      "Epoch 57/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0430 - fbeta: 2.0619e-08 - val_loss: 0.0422 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.04216 to 0.04215, saving model to model/model.w.best.h5\n",
      "Epoch 58/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0430 - fbeta: 2.0619e-08 - val_loss: 0.0421 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.04215 to 0.04214, saving model to model/model.w.best.h5\n",
      "Epoch 59/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0430 - fbeta: 2.0619e-08 - val_loss: 0.0421 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.04214 to 0.04213, saving model to model/model.w.best.h5\n",
      "Epoch 60/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0430 - fbeta: 2.0619e-08 - val_loss: 0.0421 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.04213 to 0.04212, saving model to model/model.w.best.h5\n",
      "Epoch 61/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0430 - fbeta: 2.0619e-08 - val_loss: 0.0421 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.04212 to 0.04211, saving model to model/model.w.best.h5\n",
      "Epoch 62/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0429 - fbeta: 2.0619e-08 - val_loss: 0.0421 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.04211 to 0.04210, saving model to model/model.w.best.h5\n",
      "Epoch 63/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0429 - fbeta: 2.0619e-08 - val_loss: 0.0421 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.04210 to 0.04209, saving model to model/model.w.best.h5\n",
      "Epoch 64/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0429 - fbeta: 2.0619e-08 - val_loss: 0.0421 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.04209 to 0.04208, saving model to model/model.w.best.h5\n",
      "Epoch 65/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0429 - fbeta: 2.0619e-08 - val_loss: 0.0421 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.04208 to 0.04207, saving model to model/model.w.best.h5\n",
      "Epoch 66/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0429 - fbeta: 2.0619e-08 - val_loss: 0.0421 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.04207 to 0.04207, saving model to model/model.w.best.h5\n",
      "Epoch 67/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0428 - fbeta: 2.0619e-08 - val_loss: 0.0421 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.04207 to 0.04206, saving model to model/model.w.best.h5\n",
      "Epoch 68/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0428 - fbeta: 2.0619e-08 - val_loss: 0.0421 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.04206 to 0.04205, saving model to model/model.w.best.h5\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0428 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.04205 to 0.04204, saving model to model/model.w.best.h5\n",
      "Epoch 70/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0428 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.04204 to 0.04204, saving model to model/model.w.best.h5\n",
      "Epoch 71/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0428 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.04204 to 0.04203, saving model to model/model.w.best.h5\n",
      "Epoch 72/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0428 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.04203 to 0.04202, saving model to model/model.w.best.h5\n",
      "Epoch 73/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0427 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.04202 to 0.04202, saving model to model/model.w.best.h5\n",
      "Epoch 74/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0427 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.04202 to 0.04201, saving model to model/model.w.best.h5\n",
      "Epoch 75/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0427 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.04201 to 0.04200, saving model to model/model.w.best.h5\n",
      "Epoch 76/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0427 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.04200 to 0.04200, saving model to model/model.w.best.h5\n",
      "Epoch 77/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0427 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.04200 to 0.04199, saving model to model/model.w.best.h5\n",
      "Epoch 78/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0427 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.04199 to 0.04199, saving model to model/model.w.best.h5\n",
      "Epoch 79/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0427 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.04199 to 0.04198, saving model to model/model.w.best.h5\n",
      "Epoch 80/100\n",
      "194/194 [==============================] - 10s 52ms/step - loss: 0.0426 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.04198 to 0.04197, saving model to model/model.w.best.h5\n",
      "Epoch 81/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0426 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.04197 to 0.04197, saving model to model/model.w.best.h5\n",
      "Epoch 82/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0426 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.04197 to 0.04196, saving model to model/model.w.best.h5\n",
      "Epoch 83/100\n",
      "194/194 [==============================] - 11s 54ms/step - loss: 0.0426 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.04196 to 0.04196, saving model to model/model.w.best.h5\n",
      "Epoch 84/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0426 - fbeta: 2.0619e-08 - val_loss: 0.0420 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.04196 to 0.04195, saving model to model/model.w.best.h5\n",
      "Epoch 85/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0426 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.04195 to 0.04195, saving model to model/model.w.best.h5\n",
      "Epoch 86/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0426 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.04195 to 0.04194, saving model to model/model.w.best.h5\n",
      "Epoch 87/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0426 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.04194 to 0.04194, saving model to model/model.w.best.h5\n",
      "Epoch 88/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0425 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.04194 to 0.04193, saving model to model/model.w.best.h5\n",
      "Epoch 89/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0425 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.04193 to 0.04193, saving model to model/model.w.best.h5\n",
      "Epoch 90/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0425 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.04193 to 0.04192, saving model to model/model.w.best.h5\n",
      "Epoch 91/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0425 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.04192 to 0.04192, saving model to model/model.w.best.h5\n",
      "Epoch 92/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0425 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.04192 to 0.04191, saving model to model/model.w.best.h5\n",
      "Epoch 93/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0425 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.04191 to 0.04191, saving model to model/model.w.best.h5\n",
      "Epoch 94/100\n",
      "194/194 [==============================] - 10s 54ms/step - loss: 0.0425 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.04191 to 0.04191, saving model to model/model.w.best.h5\n",
      "Epoch 95/100\n",
      "194/194 [==============================] - 11s 56ms/step - loss: 0.0425 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.04191 to 0.04190, saving model to model/model.w.best.h5\n",
      "Epoch 96/100\n",
      "194/194 [==============================] - 11s 54ms/step - loss: 0.0425 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.04190 to 0.04190, saving model to model/model.w.best.h5\n",
      "Epoch 97/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0425 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.04190 to 0.04189, saving model to model/model.w.best.h5\n",
      "Epoch 98/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0424 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.04189 to 0.04189, saving model to model/model.w.best.h5\n",
      "Epoch 99/100\n",
      "194/194 [==============================] - 10s 53ms/step - loss: 0.0424 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.04189 to 0.04189, saving model to model/model.w.best.h5\n",
      "Epoch 100/100\n",
      "194/194 [==============================] - 11s 55ms/step - loss: 0.0424 - fbeta: 2.0619e-08 - val_loss: 0.0419 - val_fbeta: 2.7273e-08\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.04189 to 0.04188, saving model to model/model.w.best.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras import callbacks\n",
    "\n",
    "PARAM_MAX_EPOCHS = 100 # PARAM: number of model-fit runs\n",
    "PARAM_N_BATCH = 10 # PARAM: number of input samples for one feedfwd-backprop step\n",
    "\n",
    "checkpointer = callbacks.ModelCheckpoint (\n",
    "    filepath=os.path.join ('model','model.w.best.h5'),\n",
    "    verbose=1,\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model.fit (X_train, y_train,\n",
    "                     epochs=PARAM_MAX_EPOCHS, batch_size=PARAM_N_BATCH, validation_split=0.1, shuffle=True,\n",
    "                     callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_fbeta', 'fbeta', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "print (history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, axs = plt.subplots (1, 2)\n",
    "\n",
    "# summarize history for accuracy\n",
    "axs[0].plot (history.history['fbeta'])\n",
    "if 'val_fbeta' in history.history:\n",
    "    axs[0].plot (history.history['val_fbeta'])\n",
    "axs[0].set (xlabel='epoch', ylabel='score (higher better)', title='F-{} score'.format (PARAM_BETA))\n",
    "axs[0].legend (['train', 'validation'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "axs[1].plot (history.history['loss'])\n",
    "if 'val_loss' in history.history:\n",
    "    axs[1].plot (history.history['val_loss'])\n",
    "axs[1].set (xlabel='epoch', ylabel='loss (lower better)', title='loss (mse)')\n",
    "axs[1].legend (['train', 'validation'], loc='upper left')\n",
    "\n",
    "fig.set_size_inches ((15., 6.), forward=True)\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**discussion**\n",
    "\n",
    "Above graphs show the F-beta score per epoch with beta = 1 on the left and the *loss per epoch*, calulated by the mean squared error (mse) on the right.\n",
    "\n",
    "*loss per epoch*:\n",
    "- gradient steps start with a loss of 0.052, end by 0.042 and show a smooth concave curve. The curve couldn't be better except a faster drop in the first 10 epochs.\n",
    "- the worse: mse after 1st epoch = 0.052 - the CNN learns very slow and in tiny steps (1st/2nd epoch: 0.052-0.049 = 0.003)\n",
    "\n",
    "*F-beta score per epoch*\n",
    "- evaluation metric immediately drops to zero after some epochs - the CNN doesn't learn anything yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reasons / todo\n",
    "\n",
    "*input data*\n",
    "\n",
    "(1) The used dataset only has 240 samples for training, validation and test. This is by far nothing for the CNN.\n",
    "\n",
    "Todo: retrieve more samples for the dataset\n",
    "\n",
    "(2) A quick look at random spectrograms show kind of chaotic information - as a human being it is hard to tell if there's any structure behind each key-mode pair. This may apply to the CNN too.\n",
    "\n",
    "Todo: find additional filter techniques / methods to clearly bring out structures for the CNN\n",
    "\n",
    "(3) Songs can change in key over their whole length.\n",
    "\n",
    "Todo: take appropriate sample of a song - ommit bridges, refrains, silent passages, noisy songs\n",
    "\n",
    "_\n",
    "\n",
    "*model training*\n",
    "\n",
    "The model was trained for 100 epochs, each in batches of 10 samples per feedfwd-backprop step. To make sure that the architecture is well suited, more epochs shall be run.\n",
    "\n",
    "Todo: increase epochs, change batch size\n",
    "\n",
    "_\n",
    "\n",
    "*model architecture*\n",
    "\n",
    "Todo: To better understand the insight of the CNN, visualize the filter of the convolutions. May there be enlightenment what kind of architecture works best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compare learning algorithm to benchmarks\n",
    "\n",
    "[i] below statements can be run without executing the whole notebook\n",
    "\n",
    "Therefor, go to and execute <a href='#load-learning-algorithm'>load learning algorithm</a>\n",
    "\n",
    "**TODO** **TODO** **TODO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 16ms/step\n",
      "[0.042050689458847046, 8.333333134658005e-09]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate (X_test, y_test, verbose=1)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> saving model... done\n"
     ]
    }
   ],
   "source": [
    "# serialization of model architecture\n",
    "import os\n",
    "\n",
    "save_name = os.path.join ('model', 'model.arch.yaml')\n",
    "\n",
    "print ('>>> saving model...', end=' ', flush=True)\n",
    "yaml_string = model.to_yaml ()\n",
    "with open (save_name, 'w') as yaml_file:\n",
    "    yaml_file.write (yaml_string)\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> loading and compiling model... done\n",
      ">>> loading best weights into model... done\n"
     ]
    }
   ],
   "source": [
    "# load model architecture\n",
    "from keras import models\n",
    "\n",
    "print ('>>> loading and compiling model...', end=' ', flush=True)\n",
    "with open (save_name, 'r') as yaml_file:\n",
    "    yaml_string = yaml_file.read ()\n",
    "model = models.model_from_yaml (yaml_string)\n",
    "model.compile (optimizer=opt_sgd, loss=losses.mean_squared_error, metrics=[fbeta])\n",
    "print ('done')\n",
    "\n",
    "# load best weights\n",
    "print ('>>> loading best weights into model...', end=' ', flush=True)\n",
    "model.load_weights (os.path.join ('model','model.w.best.h5'))\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_spectro/4-0/TROEPPK128F92F33EC.png\n",
      "y_true 4-0\n",
      "y_pred 6-1\n"
     ]
    }
   ],
   "source": [
    "idx = 20\n",
    "test_file = src_spectro_data['filenames'][idx]\n",
    "\n",
    "test_spectro = path_to_tensor (test_file)\n",
    "test_pred = model.predict (test_spectro)\n",
    "\n",
    "print (test_file)\n",
    "print ('y_true', src_spectro_data['target_names'][src_spectro_data['target'][idx]])\n",
    "print ('y_pred', src_spectro_data['target_names'][test_pred.argmax ()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obsolete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**drawbacks** (known, unresolvable issues)\n",
    "\n",
    "(WRONG) *music keys vs CNN key classes*\n",
    "\n",
    "See <a href='https://www.researchgate.net/publication/228963946_Audio_onset_detection_using_machine_learning_techniques_the_effect_and_applicability_of_key_and_tempo_information'>Chuan, Ching-Hua & Chew, Elaine. (2018). Audio onset detection using machine learning techniques: the effect and applicability of key and tempo information.</a>, p. 18\n",
    "\n",
    "The spectrograms show a pitch range given by the <a href='https://en.wikipedia.org/wiki/Scientific_pitch_notation#Table_of_note_frequencies'>Scientific Pitch Notation</a>. By that the range of notes goes from $C_{-1}$ = $0_{MIDI}$ up to $G_9$ = $127_{MIDI}$.\n",
    "\n",
    "Each note can be the tonic of a music key - for example the key 'C major' exists 11 times (ocatve -1 to 9). Thus the information of 128 keys is now squeezed into 24 key classes.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
